Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 12:11:23 PM
==== episode 1/10000 ====
action = 0
probs = 0.2608 0.2110 0.2333 0.2949

action = 0
probs = 0.1765 0.2475 0.2610 0.3150

action = 2
probs = 0.1776 0.2167 0.3037 0.3020

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0007116030901670456 0.08070650696754456
encoder.encoder.weight_hh_l0: -0.00023087624867912382 0.08180419355630875
encoder.encoder.bias_ih_l0: -0.005141052883118391 0.08287999778985977
encoder.encoder.bias_hh_l0: 0.004856020212173462 0.08238153159618378
encoder.encoder.weight_ih_l0_reverse: 0.00015422112483065575 0.08261323720216751
encoder.encoder.weight_hh_l0_reverse: 0.0005968182813376188 0.08145575225353241
encoder.encoder.bias_ih_l0_reverse: 0.01223052479326725 0.08220864087343216
encoder.encoder.bias_hh_l0_reverse: 0.004096076823771 0.08128350228071213
decider.lstm.weight_ih_l0: -0.0013416457222774625 0.14476174116134644
decider.lstm.weight_hh_l0: 0.00039524585008621216 0.14444048702716827
decider.lstm.bias_ih_l0: 0.004634251818060875 0.153535857796669
decider.lstm.bias_hh_l0: -0.014353209175169468 0.13703615963459015
decider.linear1.weight: 0.003160386811941862 0.11768044531345367
decider.linear1.bias: 0.0038485736586153507 0.11530635505914688
decider.linear2.weight: 0.0003479563747532666 0.0511520579457283
decider.linear2.bias: 0.0005383333191275597 0.05427265912294388
decider.linear3.weight: -0.001615753397345543 0.0508420504629612
decider.linear3.bias: 0.022421564906835556 0.07315105199813843

Rewards:
166.4543
166.4543
166.4543
objective = 236.922119140625
==== episode 100/10000 ====
action = 0
probs = 0.2964 0.1620 0.2084 0.3332

action = 3
probs = 0.1981 0.1813 0.3024 0.3182

action = 3
probs = 0.1767 0.1710 0.3618 0.2905

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000664045219309628 0.0807211697101593
encoder.encoder.weight_hh_l0: -0.0002347127447137609 0.08181300759315491
encoder.encoder.bias_ih_l0: -0.004827101249247789 0.08303044736385345
encoder.encoder.bias_hh_l0: 0.005169968586415052 0.08247543126344681
encoder.encoder.weight_ih_l0_reverse: 0.0001359644520562142 0.08264391869306564
encoder.encoder.weight_hh_l0_reverse: 0.0006132618291303515 0.08147840201854706
encoder.encoder.bias_ih_l0_reverse: 0.01227384340018034 0.0822640210390091
encoder.encoder.bias_hh_l0_reverse: 0.004139391705393791 0.08127487450838089
decider.lstm.weight_ih_l0: -0.0013487169053405523 0.14477920532226562
decider.lstm.weight_hh_l0: 0.00036679161712527275 0.1444600224494934
decider.lstm.bias_ih_l0: 0.005118591710925102 0.15309999883174896
decider.lstm.bias_hh_l0: -0.013868862763047218 0.13718576729297638
decider.linear1.weight: 0.0031623318791389465 0.11772859841585159
decider.linear1.bias: 0.003953846171498299 0.11516392230987549
decider.linear2.weight: 0.00042826635763049126 0.051162198185920715
decider.linear2.bias: 0.0006570534314960241 0.05421449989080429
decider.linear3.weight: -0.0018303531687706709 0.05091498792171478
decider.linear3.bias: 0.022267933934926987 0.07272905111312866

Rewards:
154.9260
154.9260
154.9260
objective = 185.787841796875
==== episode 200/10000 ====
action = 3
probs = 0.3084 0.1743 0.1813 0.3359

action = 3
probs = 0.2387 0.1698 0.2580 0.3335

action = 0
probs = 0.1863 0.1448 0.3819 0.2870

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0006331948097795248 0.08072878420352936
encoder.encoder.weight_hh_l0: -0.00024014177324716002 0.08183179795742035
encoder.encoder.bias_ih_l0: -0.004713142290711403 0.08304861932992935
encoder.encoder.bias_hh_l0: 0.005283930338919163 0.08243326842784882
encoder.encoder.weight_ih_l0_reverse: 0.00014567241305485368 0.08266372978687286
encoder.encoder.weight_hh_l0_reverse: 0.0006238824571482837 0.08148399740457535
encoder.encoder.bias_ih_l0_reverse: 0.012349420227110386 0.0822124183177948
encoder.encoder.bias_hh_l0_reverse: 0.004214968532323837 0.08133285492658615
decider.lstm.weight_ih_l0: -0.0013611754402518272 0.1447816640138626
decider.lstm.weight_hh_l0: 0.0003886534832417965 0.1444624960422516
decider.lstm.bias_ih_l0: 0.005425725132226944 0.15313269197940826
decider.lstm.bias_hh_l0: -0.013561734929680824 0.1373562514781952
decider.linear1.weight: 0.0031725801527500153 0.11775633692741394
decider.linear1.bias: 0.003951015882194042 0.11515560746192932
decider.linear2.weight: 0.0004514063766691834 0.051166582852602005
decider.linear2.bias: 0.000701388344168663 0.054180290549993515
decider.linear3.weight: -0.0018720536027103662 0.050940096378326416
decider.linear3.bias: 0.02223542332649231 0.07238245755434036

Rewards:
132.4494
132.4494
132.4494
objective = 170.8287353515625
==== episode 300/10000 ====
action = 3
probs = 0.3215 0.2066 0.1780 0.2939

action = 0
probs = 0.2930 0.1986 0.2387 0.2697

action = 2
probs = 0.2503 0.1790 0.3295 0.2412

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0006144284852780402 0.08075091242790222
encoder.encoder.weight_hh_l0: -0.00024400472466368228 0.08185146749019623
encoder.encoder.bias_ih_l0: -0.004634995479136705 0.08309069275856018
encoder.encoder.bias_hh_l0: 0.0053620776161551476 0.08233688026666641
encoder.encoder.weight_ih_l0_reverse: 0.00013655409566126764 0.08267077058553696
encoder.encoder.weight_hh_l0_reverse: 0.0006139384349808097 0.0814775824546814
encoder.encoder.bias_ih_l0_reverse: 0.01225086860358715 0.08215555548667908
encoder.encoder.bias_hh_l0_reverse: 0.0041164192371070385 0.081358902156353
decider.lstm.weight_ih_l0: -0.0013652039924636483 0.1447875052690506
decider.lstm.weight_hh_l0: 0.00039109145291149616 0.14444024860858917
decider.lstm.bias_ih_l0: 0.005209476687014103 0.15306545794010162
decider.lstm.bias_hh_l0: -0.013777977786958218 0.1373158097267151
decider.linear1.weight: 0.0031679028179496527 0.1177220568060875
decider.linear1.bias: 0.003758437931537628 0.11503170430660248
decider.linear2.weight: 0.00034241436515003443 0.051159217953681946
decider.linear2.bias: 0.0005034806672483683 0.054278623312711716
decider.linear3.weight: -0.0018311783205717802 0.050807442516088486
decider.linear3.bias: 0.022307446226477623 0.071445994079113

Rewards:
147.2450
147.2450
147.2450
objective = 174.8388671875
==== episode 400/10000 ====
action = 0
probs = 0.3445 0.2157 0.1928 0.2470

action = 0
probs = 0.3096 0.2124 0.2536 0.2244

action = 3
probs = 0.3311 0.1864 0.2734 0.2092

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0006163378129713237 0.08075053244829178
encoder.encoder.weight_hh_l0: -0.0002402673417236656 0.0818493440747261
encoder.encoder.bias_ih_l0: -0.004587517119944096 0.08311440795660019
encoder.encoder.bias_hh_l0: 0.005409556906670332 0.0823560506105423
encoder.encoder.weight_ih_l0_reverse: 0.00012778736709151417 0.08268750458955765
encoder.encoder.weight_hh_l0_reverse: 0.0006092059193179011 0.08147840946912766
encoder.encoder.bias_ih_l0_reverse: 0.01215710025280714 0.08214661478996277
encoder.encoder.bias_hh_l0_reverse: 0.00402265228331089 0.08129855245351791
decider.lstm.weight_ih_l0: -0.0013596501667052507 0.14478574693202972
decider.lstm.weight_hh_l0: 0.00039954460225999355 0.1444440335035324
decider.lstm.bias_ih_l0: 0.00506331492215395 0.15319734811782837
decider.lstm.bias_hh_l0: -0.013924142345786095 0.13719502091407776
decider.linear1.weight: 0.0031656164210289717 0.11770541965961456
decider.linear1.bias: 0.0036705713719129562 0.11499560624361038
decider.linear2.weight: 0.0002840591478161514 0.05116104334592819
decider.linear2.bias: 0.0003883864264935255 0.05439619719982147
decider.linear3.weight: -0.0018181916093453765 0.05076079070568085
decider.linear3.bias: 0.02231357991695404 0.07051578909158707

Rewards:
155.3006
155.3006
155.3006
objective = 196.8467254638672
==== episode 500/10000 ====
action = 3
probs = 0.3717 0.2037 0.2000 0.2246

action = 2
probs = 0.3585 0.2045 0.2360 0.2010

action = 0
probs = 0.3597 0.1980 0.2393 0.2031

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000622775696683675 0.08074413985013962
encoder.encoder.weight_hh_l0: -0.00023949834576342255 0.08185981214046478
encoder.encoder.bias_ih_l0: -0.004553013015538454 0.08315931260585785
encoder.encoder.bias_hh_l0: 0.005444059614092112 0.08240332454442978
encoder.encoder.weight_ih_l0_reverse: 0.0001246319734491408 0.08269418030977249
encoder.encoder.weight_hh_l0_reverse: 0.0006022698944434524 0.08148933947086334
encoder.encoder.bias_ih_l0_reverse: 0.012102286331355572 0.08218517899513245
encoder.encoder.bias_hh_l0_reverse: 0.003967838827520609 0.08127846568822861
decider.lstm.weight_ih_l0: -0.0013603450497612357 0.14478950202465057
decider.lstm.weight_hh_l0: 0.0003941457252949476 0.14442402124404907
decider.lstm.bias_ih_l0: 0.004984274506568909 0.1530977040529251
decider.lstm.bias_hh_l0: -0.014003176242113113 0.13721774518489838
decider.linear1.weight: 0.0031586294062435627 0.11769889295101166
decider.linear1.bias: 0.003697680775076151 0.11498311161994934
decider.linear2.weight: 0.0002639248559717089 0.051167212426662445
decider.linear2.bias: 0.0003633967135101557 0.054481085389852524
decider.linear3.weight: -0.0018238372867926955 0.050758615136146545
decider.linear3.bias: 0.022295065224170685 0.07000663876533508

Rewards:
125.9517
125.9517
125.9517
objective = 166.24896240234375
==== episode 600/10000 ====
action = 3
probs = 0.3427 0.2241 0.2280 0.2052

action = 0
probs = 0.3509 0.2273 0.2416 0.1802

action = 1
probs = 0.3799 0.2257 0.2246 0.1699

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0006223558448255062 0.08076140284538269
encoder.encoder.weight_hh_l0: -0.00024151276738848537 0.08186887949705124
encoder.encoder.bias_ih_l0: -0.004485470708459616 0.08319338411092758
encoder.encoder.bias_hh_l0: 0.005511600058525801 0.08240410685539246
encoder.encoder.weight_ih_l0_reverse: 0.00013977430353406817 0.08269387483596802
encoder.encoder.weight_hh_l0_reverse: 0.0005860871751792729 0.08149610459804535
encoder.encoder.bias_ih_l0_reverse: 0.012019357644021511 0.0821852833032608
encoder.encoder.bias_hh_l0_reverse: 0.0038849085103720427 0.08126112073659897
decider.lstm.weight_ih_l0: -0.0013664521975442767 0.14479811489582062
decider.lstm.weight_hh_l0: 0.00042660138569772243 0.14442545175552368
decider.lstm.bias_ih_l0: 0.004841204732656479 0.15323933959007263
decider.lstm.bias_hh_l0: -0.014146246016025543 0.1370912790298462
decider.linear1.weight: 0.003150785341858864 0.11769317090511322
decider.linear1.bias: 0.003713885322213173 0.114942267537117
decider.linear2.weight: 0.00022344139870256186 0.051174625754356384
decider.linear2.bias: 0.0002789737191051245 0.054495297372341156
decider.linear3.weight: -0.0018122777109965682 0.0507381446659565
decider.linear3.bias: 0.022325757890939713 0.07001177966594696

Rewards:
160.4008
160.4008
160.4008
objective = 220.2585906982422
==== episode 700/10000 ====
action = 1
probs = 0.4284 0.2084 0.1884 0.1748

action = 0
probs = 0.4141 0.2231 0.1955 0.1673

action = 1
probs = 0.3871 0.2182 0.2057 0.1890

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000600483501330018 0.08078745752573013
encoder.encoder.weight_hh_l0: -0.000231256359256804 0.08189988136291504
encoder.encoder.bias_ih_l0: -0.004372279625386 0.08318594098091125
encoder.encoder.bias_hh_l0: 0.005624786484986544 0.08231929689645767
encoder.encoder.weight_ih_l0_reverse: 0.00014535232912749052 0.08270768076181412
encoder.encoder.weight_hh_l0_reverse: 0.0005955621600151062 0.08150814473628998
encoder.encoder.bias_ih_l0_reverse: 0.012144481763243675 0.08209744840860367
encoder.encoder.bias_hh_l0_reverse: 0.004010036587715149 0.0813031941652298
decider.lstm.weight_ih_l0: -0.0013780072331428528 0.14481082558631897
decider.lstm.weight_hh_l0: 0.00034720078110694885 0.1443547159433365
decider.lstm.bias_ih_l0: 0.00510693434625864 0.15320006012916565
decider.lstm.bias_hh_l0: -0.013880513608455658 0.13735702633857727
decider.linear1.weight: 0.00315344100818038 0.11771558225154877
decider.linear1.bias: 0.00379945058375597 0.11496996879577637
decider.linear2.weight: 0.0002607977658044547 0.051180414855480194
decider.linear2.bias: 0.00035877572372555733 0.05455676466226578
decider.linear3.weight: -0.0018268495332449675 0.05076558142900467
decider.linear3.bias: 0.02228742465376854 0.06914529204368591

Rewards:
151.0950
151.0950
151.0950
objective = 200.06240844726562
==== episode 800/10000 ====
action = 0
probs = 0.4141 0.2513 0.1730 0.1616

action = 0
probs = 0.3627 0.2569 0.2134 0.1670

action = 1
probs = 0.3175 0.2296 0.2440 0.2088

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0005860671517439187 0.080812968313694
encoder.encoder.weight_hh_l0: -0.00023535570653621107 0.08192108571529388
encoder.encoder.bias_ih_l0: -0.004336673766374588 0.0832112655043602
encoder.encoder.bias_hh_l0: 0.005660390947014093 0.08213502913713455
encoder.encoder.weight_ih_l0_reverse: 0.00015067285858094692 0.08272263407707214
encoder.encoder.weight_hh_l0_reverse: 0.000603349064476788 0.0815129429101944
encoder.encoder.bias_ih_l0_reverse: 0.012167004868388176 0.08203954249620438
encoder.encoder.bias_hh_l0_reverse: 0.004032561555504799 0.08133336156606674
decider.lstm.weight_ih_l0: -0.0013868543319404125 0.14482156932353973
decider.lstm.weight_hh_l0: 0.0003542373888194561 0.14435318112373352
decider.lstm.bias_ih_l0: 0.005095791071653366 0.15323324501514435
decider.lstm.bias_hh_l0: -0.013891654089093208 0.13728894293308258
decider.linear1.weight: 0.003166183829307556 0.11771772056818008
decider.linear1.bias: 0.0037385234609246254 0.11495298892259598
decider.linear2.weight: 0.0002577155246399343 0.051178932189941406
decider.linear2.bias: 0.0003743593115359545 0.05448126047849655
decider.linear3.weight: -0.0018182507483288646 0.050744496285915375
decider.linear3.bias: 0.02232196182012558 0.06956104189157486

Rewards:
153.4407
153.4407
153.4407
objective = 172.21356201171875
==== episode 900/10000 ====
action = 2
probs = 0.3343 0.2872 0.2013 0.1772

action = 3
probs = 0.3086 0.2988 0.2153 0.1773

action = 0
probs = 0.2945 0.2599 0.2355 0.2101

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0006202571094036102 0.08080791682004929
encoder.encoder.weight_hh_l0: -0.00022995185281615704 0.08189026266336441
encoder.encoder.bias_ih_l0: -0.00470818392932415 0.0831148773431778
encoder.encoder.bias_hh_l0: 0.005288880784064531 0.0820607841014862
encoder.encoder.weight_ih_l0_reverse: 0.0001378892338834703 0.0827077329158783
encoder.encoder.weight_hh_l0_reverse: 0.000564660644158721 0.08150072395801544
encoder.encoder.bias_ih_l0_reverse: 0.011910932138562202 0.08212338387966156
encoder.encoder.bias_hh_l0_reverse: 0.0037764888256788254 0.08128367364406586
decider.lstm.weight_ih_l0: -0.0014021744718775153 0.1448018103837967
decider.lstm.weight_hh_l0: 0.00040771905332803726 0.14436979591846466
decider.lstm.bias_ih_l0: 0.004323484376072884 0.15331266820430756
decider.lstm.bias_hh_l0: -0.01466396078467369 0.13711170852184296
decider.linear1.weight: 0.003172622062265873 0.11765635758638382
decider.linear1.bias: 0.0034457696601748466 0.11498334258794785
decider.linear2.weight: 0.00017646100604906678 0.051166798919439316
decider.linear2.bias: 0.00020213518291711807 0.05450627952814102
decider.linear3.weight: -0.0017863661050796509 0.050648756325244904
decider.linear3.bias: 0.022400833666324615 0.07080941647291183

Rewards:
144.2031
144.2031
144.2031
objective = 218.97088623046875
==== episode 1000/10000 ====
action = 0
probs = 0.3260 0.3178 0.2034 0.1528

action = 2
probs = 0.2882 0.3272 0.2258 0.1588

action = 1
probs = 0.2943 0.2742 0.2503 0.1812

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0006080036982893944 0.08083680272102356
encoder.encoder.weight_hh_l0: -0.00023043861438054591 0.08190938085317612
encoder.encoder.bias_ih_l0: -0.004555650055408478 0.08314330875873566
encoder.encoder.bias_hh_l0: 0.005441414657980204 0.08204908668994904
encoder.encoder.weight_ih_l0_reverse: 0.0001561100798426196 0.08272980153560638
encoder.encoder.weight_hh_l0_reverse: 0.0005723978974856436 0.08150888234376907
encoder.encoder.bias_ih_l0_reverse: 0.011991332285106182 0.08210208266973495
encoder.encoder.bias_hh_l0_reverse: 0.0038568894378840923 0.08130466192960739
decider.lstm.weight_ih_l0: -0.0014004415133967996 0.14481386542320251
decider.lstm.weight_hh_l0: 0.0004144323756918311 0.14439034461975098
decider.lstm.bias_ih_l0: 0.004384879022836685 0.15337823331356049
decider.lstm.bias_hh_l0: -0.014602568000555038 0.13701088726520538
decider.linear1.weight: 0.003166650189086795 0.11767353117465973
decider.linear1.bias: 0.0035633821971714497 0.11499276757240295
decider.linear2.weight: 0.00019777983834501356 0.05117766559123993
decider.linear2.bias: 0.00024552689865231514 0.05448649451136589
decider.linear3.weight: -0.0018030612263828516 0.050662703812122345
decider.linear3.bias: 0.022390224039554596 0.07070676237344742

Rewards:
132.4061
132.4061
132.4061
objective = 172.2635955810547
==== episode 1100/10000 ====
action = 0
probs = 0.2750 0.4149 0.1788 0.1313

action = 1
probs = 0.2273 0.4515 0.1754 0.1458

action = 1
probs = 0.2481 0.3584 0.2075 0.1859

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0006018904969096184 0.0808812603354454
encoder.encoder.weight_hh_l0: -0.00022816176351625472 0.08193716406822205
encoder.encoder.bias_ih_l0: -0.004485473036766052 0.08306806534528732
encoder.encoder.bias_hh_l0: 0.005511592607945204 0.08189234137535095
encoder.encoder.weight_ih_l0_reverse: 0.0001793714618543163 0.0827733501791954
encoder.encoder.weight_hh_l0_reverse: 0.0006006625480949879 0.08152732253074646
encoder.encoder.bias_ih_l0_reverse: 0.012310842052102089 0.08217804878950119
encoder.encoder.bias_hh_l0_reverse: 0.0041763996705412865 0.08131888508796692
decider.lstm.weight_ih_l0: -0.0013921911595389247 0.14484678208827972
decider.lstm.weight_hh_l0: 0.00041256321128457785 0.1443992406129837
decider.lstm.bias_ih_l0: 0.004339973442256451 0.1537969559431076
decider.lstm.bias_hh_l0: -0.014647466130554676 0.1369490772485733
decider.linear1.weight: 0.0031575546599924564 0.11771459132432938
decider.linear1.bias: 0.0036946963518857956 0.11502189934253693
decider.linear2.weight: 0.00022703580907545984 0.05119450390338898
decider.linear2.bias: 0.00030247075483202934 0.054556239396333694
decider.linear3.weight: -0.0018119465094059706 0.05076119676232338
decider.linear3.bias: 0.022430896759033203 0.07145141810178757

Rewards:
183.7409
183.7409
183.7409
objective = 190.6024627685547
==== episode 1200/10000 ====
action = 2
probs = 0.2579 0.4825 0.1472 0.1123

action = 1
probs = 0.2038 0.5420 0.1410 0.1132

action = 1
probs = 0.1844 0.4684 0.1967 0.1505

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0005956852110102773 0.08094247430562973
encoder.encoder.weight_hh_l0: -0.00023335932928603142 0.08199141919612885
encoder.encoder.bias_ih_l0: -0.004161451477557421 0.08314519375562668
encoder.encoder.bias_hh_l0: 0.005835609510540962 0.08185896277427673
encoder.encoder.weight_ih_l0_reverse: 0.00024779632803983986 0.08281797170639038
encoder.encoder.weight_hh_l0_reverse: 0.000660796882584691 0.08157150447368622
encoder.encoder.bias_ih_l0_reverse: 0.012726311571896076 0.082248255610466
encoder.encoder.bias_hh_l0_reverse: 0.004591869655996561 0.08138685673475266
decider.lstm.weight_ih_l0: -0.0013716442044824362 0.14489798247814178
decider.lstm.weight_hh_l0: 0.00038881879299879074 0.14444684982299805
decider.lstm.bias_ih_l0: 0.004580918699502945 0.15395225584506989
decider.lstm.bias_hh_l0: -0.01440652646124363 0.13688328862190247
decider.linear1.weight: 0.0031322375871241093 0.11777309328317642
decider.linear1.bias: 0.004030147567391396 0.11500447243452072
decider.linear2.weight: 0.000315838900860399 0.05121859163045883
decider.linear2.bias: 0.0004783256445080042 0.05456804856657982
decider.linear3.weight: -0.0018277991330251098 0.05090614780783653
decider.linear3.bias: 0.022424867376685143 0.07187125831842422

Rewards:
140.2155
140.2155
140.2155
objective = 153.611083984375
==== episode 1300/10000 ====
action = 1
probs = 0.2694 0.4715 0.1359 0.1232

action = 1
probs = 0.2072 0.5355 0.1357 0.1215

action = 1
probs = 0.1717 0.4655 0.2049 0.1578

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0005934939254075289 0.08093486726284027
encoder.encoder.weight_hh_l0: -0.00023410285939462483 0.08197187632322311
encoder.encoder.bias_ih_l0: -0.004322485066950321 0.08311944454908371
encoder.encoder.bias_hh_l0: 0.00567457964643836 0.0818263590335846
encoder.encoder.weight_ih_l0_reverse: 0.0002628140791784972 0.08281072229146957
encoder.encoder.weight_hh_l0_reverse: 0.0006432302761822939 0.08155982196331024
encoder.encoder.bias_ih_l0_reverse: 0.012639682739973068 0.08222883939743042
encoder.encoder.bias_hh_l0_reverse: 0.004505243618041277 0.08136323094367981
decider.lstm.weight_ih_l0: -0.0013844323111698031 0.1448821872472763
decider.lstm.weight_hh_l0: 0.0004186027217656374 0.1444753259420395
decider.lstm.bias_ih_l0: 0.004442521370947361 0.15388619899749756
decider.lstm.bias_hh_l0: -0.014544916339218616 0.136882945895195
decider.linear1.weight: 0.003142006229609251 0.117752805352211
decider.linear1.bias: 0.00393142644315958 0.1149362176656723
decider.linear2.weight: 0.0003140578919555992 0.05121416226029396
decider.linear2.bias: 0.0004660410340875387 0.05458897724747658
decider.linear3.weight: -0.0018270977307111025 0.05088616535067558
decider.linear3.bias: 0.022426806390285492 0.07180988788604736

Rewards:
166.6321
166.6321
166.6321
objective = 118.9157943725586
==== episode 1400/10000 ====
action = 0
probs = 0.3111 0.4750 0.1134 0.1005

action = 1
probs = 0.2577 0.5260 0.1140 0.1023

action = 1
probs = 0.2390 0.4772 0.1604 0.1233

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000579863612074405 0.08096776157617569
encoder.encoder.weight_hh_l0: -0.00023676060664001852 0.08200547099113464
encoder.encoder.bias_ih_l0: -0.004172316752374172 0.08306624740362167
encoder.encoder.bias_hh_l0: 0.005824745632708073 0.08180118352174759
encoder.encoder.weight_ih_l0_reverse: 0.00030710772261954844 0.08286236226558685
encoder.encoder.weight_hh_l0_reverse: 0.0007375755812972784 0.08160452544689178
encoder.encoder.bias_ih_l0_reverse: 0.013034623116254807 0.08227043598890305
encoder.encoder.bias_hh_l0_reverse: 0.00490018492564559 0.08134825527667999
decider.lstm.weight_ih_l0: -0.00132317328825593 0.14491115510463715
decider.lstm.weight_hh_l0: 0.00041287357453256845 0.14453649520874023
decider.lstm.bias_ih_l0: 0.005171440541744232 0.1541546732187271
decider.lstm.bias_hh_l0: -0.013815995305776596 0.1370922029018402
decider.linear1.weight: 0.0031404956243932247 0.1178044006228447
decider.linear1.bias: 0.004140153527259827 0.1149202287197113
decider.linear2.weight: 0.0003471478121355176 0.05123377591371536
decider.linear2.bias: 0.0005300161428749561 0.05465313419699669
decider.linear3.weight: -0.0018813596107065678 0.05093114823102951
decider.linear3.bias: 0.022311311215162277 0.07014652341604233

Rewards:
183.7409
183.7409
183.7409
objective = 156.17576599121094
==== episode 1500/10000 ====
action = 1
probs = 0.3272 0.4838 0.1029 0.0862

action = 1
probs = 0.3098 0.4987 0.1075 0.0840

action = 1
probs = 0.2704 0.4509 0.1562 0.1226

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0005311593413352966 0.0809917002916336
encoder.encoder.weight_hh_l0: -0.00024273840244859457 0.08203115314245224
encoder.encoder.bias_ih_l0: -0.004045573528856039 0.08304759114980698
encoder.encoder.bias_hh_l0: 0.005951488856226206 0.08180364221334457
encoder.encoder.weight_ih_l0_reverse: 0.00035907229175791144 0.08289556205272675
encoder.encoder.weight_hh_l0_reverse: 0.0007590058376081288 0.08162528276443481
encoder.encoder.bias_ih_l0_reverse: 0.013162634335458279 0.08222281187772751
encoder.encoder.bias_hh_l0_reverse: 0.005028197541832924 0.08133039623498917
decider.lstm.weight_ih_l0: -0.0013227289309725165 0.14491817355155945
decider.lstm.weight_hh_l0: 0.0004280806751921773 0.144513800740242
decider.lstm.bias_ih_l0: 0.00541211012750864 0.15417951345443726
decider.lstm.bias_hh_l0: -0.013575315475463867 0.13720348477363586
decider.linear1.weight: 0.003158676205202937 0.11783602833747864
decider.linear1.bias: 0.004248162731528282 0.11498545110225677
decider.linear2.weight: 0.00037177029298618436 0.05124371498823166
decider.linear2.bias: 0.0005881490651518106 0.054634902626276016
decider.linear3.weight: -0.0019169283332303166 0.05096961930394173
decider.linear3.bias: 0.022274117916822433 0.069607213139534

Rewards:
166.6321
166.6321
166.6321
objective = 123.22704315185547
==== episode 1600/10000 ====
action = 1
probs = 0.3123 0.5311 0.0895 0.0672

action = 1
probs = 0.3229 0.5229 0.0909 0.0633

action = 1
probs = 0.2814 0.4693 0.1440 0.1054

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0004469942068681121 0.08110570162534714
encoder.encoder.weight_hh_l0: -0.00026061738026328385 0.082117460668087
encoder.encoder.bias_ih_l0: -0.0035798719618469477 0.0830596536397934
encoder.encoder.bias_hh_l0: 0.006417193450033665 0.08189737051725388
encoder.encoder.weight_ih_l0_reverse: 0.0004746524791698903 0.08300948143005371
encoder.encoder.weight_hh_l0_reverse: 0.0008656075224280357 0.08172059059143066
encoder.encoder.bias_ih_l0_reverse: 0.013784936629235744 0.08221489936113358
encoder.encoder.bias_hh_l0_reverse: 0.005650501232594252 0.08131305873394012
decider.lstm.weight_ih_l0: -0.0012855801032856107 0.14496929943561554
decider.lstm.weight_hh_l0: 0.0004801906179636717 0.1445816308259964
decider.lstm.bias_ih_l0: 0.006054434925317764 0.15441910922527313
decider.lstm.bias_hh_l0: -0.012932984158396721 0.13734778761863708
decider.linear1.weight: 0.0031904501374810934 0.11791842430830002
decider.linear1.bias: 0.004543474409729242 0.11501696705818176
decider.linear2.weight: 0.00043288880260661244 0.051267653703689575
decider.linear2.bias: 0.000715779373422265 0.054633501917123795
decider.linear3.weight: -0.0019611744210124016 0.05107101798057556
decider.linear3.bias: 0.02218375913798809 0.069282665848732

Rewards:
166.6321
166.6321
166.6321
objective = 113.18229675292969
==== episode 1700/10000 ====
action = 0
probs = 0.2805 0.5674 0.0872 0.0649

action = 1
probs = 0.2605 0.5834 0.0923 0.0638

action = 1
probs = 0.1990 0.5724 0.1398 0.0888

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0004059086786583066 0.08120106160640717
encoder.encoder.weight_hh_l0: -0.00027692175353877246 0.08216915279626846
encoder.encoder.bias_ih_l0: -0.003144806018099189 0.08320501446723938
encoder.encoder.bias_hh_l0: 0.006852257531136274 0.08197150379419327
encoder.encoder.weight_ih_l0_reverse: 0.0005336116882972419 0.08309851586818695
encoder.encoder.weight_hh_l0_reverse: 0.0009305162238888443 0.08178406953811646
encoder.encoder.bias_ih_l0_reverse: 0.014123929664492607 0.08220478892326355
encoder.encoder.bias_hh_l0_reverse: 0.005989492870867252 0.08135794848203659
decider.lstm.weight_ih_l0: -0.0012554946588352323 0.14499688148498535
decider.lstm.weight_hh_l0: 0.0005109335761517286 0.14467789232730865
decider.lstm.bias_ih_l0: 0.0062554627656936646 0.15446767210960388
decider.lstm.bias_hh_l0: -0.012731955386698246 0.13716357946395874
decider.linear1.weight: 0.0032034958712756634 0.11795331537723541
decider.linear1.bias: 0.00478699617087841 0.11488115787506104
decider.linear2.weight: 0.0004674604570027441 0.051288265734910965
decider.linear2.bias: 0.0008075176738202572 0.054667841643095016
decider.linear3.weight: -0.0019836262799799442 0.051154330372810364
decider.linear3.bias: 0.022150738164782524 0.07009891420602798

Rewards:
183.7409
183.7409
183.7409
objective = 145.03627014160156
==== episode 1800/10000 ====
action = 1
probs = 0.2680 0.5737 0.0930 0.0653

action = 2
probs = 0.2854 0.5581 0.0959 0.0606

action = 0
probs = 0.2196 0.5464 0.1465 0.0875

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0004414032446220517 0.08116308599710464
encoder.encoder.weight_hh_l0: -0.0002621764724608511 0.08214608579874039
encoder.encoder.bias_ih_l0: -0.0034379546996206045 0.08317693322896957
encoder.encoder.bias_hh_l0: 0.006559106986969709 0.08192060142755508
encoder.encoder.weight_ih_l0_reverse: 0.0005079770926386118 0.08307982981204987
encoder.encoder.weight_hh_l0_reverse: 0.0008809170685708523 0.08174151182174683
encoder.encoder.bias_ih_l0_reverse: 0.013880019076168537 0.08225097507238388
encoder.encoder.bias_hh_l0_reverse: 0.0057455855421721935 0.08125907927751541
decider.lstm.weight_ih_l0: -0.0012644842499867082 0.14497041702270508
decider.lstm.weight_hh_l0: 0.00044772960245609283 0.14463217556476593
decider.lstm.bias_ih_l0: 0.006093645468354225 0.1543426662683487
decider.lstm.bias_hh_l0: -0.012893772684037685 0.1371433585882187
decider.linear1.weight: 0.003188695525750518 0.11793775111436844
decider.linear1.bias: 0.004631947726011276 0.11494509130716324
decider.linear2.weight: 0.00043478317093104124 0.051284320652484894
decider.linear2.bias: 0.0007157847285270691 0.054660119116306305
decider.linear3.weight: -0.001978263258934021 0.0511048249900341
decider.linear3.bias: 0.022158579900860786 0.07013965398073196

Rewards:
159.0619
159.0619
159.0619
objective = 234.1290283203125
==== episode 1900/10000 ====
action = 1
probs = 0.2858 0.5752 0.0864 0.0526

action = 0
probs = 0.3167 0.5479 0.0877 0.0477

action = 1
probs = 0.2386 0.5659 0.1268 0.0687

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00040815683314576745 0.08121965825557709
encoder.encoder.weight_hh_l0: -0.0002700001059565693 0.08221589028835297
encoder.encoder.bias_ih_l0: -0.0029660214204341173 0.0832693800330162
encoder.encoder.bias_hh_l0: 0.007031040266156197 0.08201095461845398
encoder.encoder.weight_ih_l0_reverse: 0.000550287077203393 0.08315920829772949
encoder.encoder.weight_hh_l0_reverse: 0.000979784526862204 0.08181091398000717
encoder.encoder.bias_ih_l0_reverse: 0.014365212991833687 0.08229774981737137
encoder.encoder.bias_hh_l0_reverse: 0.006230778992176056 0.08131259679794312
decider.lstm.weight_ih_l0: -0.0011889694724231958 0.14502766728401184
decider.lstm.weight_hh_l0: 0.0005158083513379097 0.1447076052427292
decider.lstm.bias_ih_l0: 0.006787458434700966 0.154561385512352
decider.lstm.bias_hh_l0: -0.01219996064901352 0.1371908038854599
decider.linear1.weight: 0.003201065119355917 0.1180126890540123
decider.linear1.bias: 0.004907445516437292 0.11492501199245453
decider.linear2.weight: 0.0004893833538517356 0.05130825936794281
decider.linear2.bias: 0.00081985117867589 0.0546993613243103
decider.linear3.weight: -0.0020329649560153484 0.05119658261537552
decider.linear3.bias: 0.022047216072678566 0.0694529116153717

Rewards:
151.0950
151.0950
151.0950
objective = 114.43515014648438
==== episode 2000/10000 ====
action = 0
probs = 0.2783 0.6055 0.0738 0.0425

action = 0
probs = 0.2977 0.5792 0.0796 0.0435

action = 1
probs = 0.2051 0.5976 0.1302 0.0671

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00036719560739584267 0.08131439238786697
encoder.encoder.weight_hh_l0: -0.00027654957375489175 0.08231890201568604
encoder.encoder.bias_ih_l0: -0.0023222118616104126 0.08341057598590851
encoder.encoder.bias_hh_l0: 0.0076748463325202465 0.08212621510028839
encoder.encoder.weight_ih_l0_reverse: 0.0006176152965053916 0.08326270431280136
encoder.encoder.weight_hh_l0_reverse: 0.0011281735496595502 0.08191264420747757
encoder.encoder.bias_ih_l0_reverse: 0.015069094486534595 0.08237612992525101
encoder.encoder.bias_hh_l0_reverse: 0.006934656761586666 0.08132018148899078
decider.lstm.weight_ih_l0: -0.0010889358818531036 0.14510668814182281
decider.lstm.weight_hh_l0: 0.0005716782761737704 0.14481085538864136
decider.lstm.bias_ih_l0: 0.007547022774815559 0.15480785071849823
decider.lstm.bias_hh_l0: -0.011440401896834373 0.1372263878583908
decider.linear1.weight: 0.003209590446203947 0.11810155212879181
decider.linear1.bias: 0.005229078233242035 0.11491940170526505
decider.linear2.weight: 0.0005674528074450791 0.051334843039512634
decider.linear2.bias: 0.0009539434686303139 0.05476289242506027
decider.linear3.weight: -0.0020897481590509415 0.051306866109371185
decider.linear3.bias: 0.02193557843565941 0.0692974254488945

Rewards:
153.4407
153.4407
153.4407
objective = 153.71852111816406
==== episode 2100/10000 ====
action = 2
probs = 0.2847 0.6015 0.0698 0.0439

action = 1
probs = 0.3206 0.5691 0.0708 0.0395

action = 1
probs = 0.2416 0.5777 0.1171 0.0636

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0004178346716798842 0.08126799017190933
encoder.encoder.weight_hh_l0: -0.00025836756685748696 0.08228833228349686
encoder.encoder.bias_ih_l0: -0.0026264055632054806 0.0833534225821495
encoder.encoder.bias_hh_l0: 0.0073706540279090405 0.08211862295866013
encoder.encoder.weight_ih_l0_reverse: 0.0005546467727981508 0.08320334553718567
encoder.encoder.weight_hh_l0_reverse: 0.0010544669348746538 0.08187591284513474
encoder.encoder.bias_ih_l0_reverse: 0.014758119359612465 0.0824134349822998
encoder.encoder.bias_hh_l0_reverse: 0.006623679772019386 0.0813230350613594
decider.lstm.weight_ih_l0: -0.0011354900198057294 0.14507773518562317
decider.lstm.weight_hh_l0: 0.0004873998695984483 0.14475272595882416
decider.lstm.bias_ih_l0: 0.007118469104170799 0.15467676520347595
decider.lstm.bias_hh_l0: -0.011868959292769432 0.1373150795698166
decider.linear1.weight: 0.0031972634606063366 0.11805590242147446
decider.linear1.bias: 0.005092255305498838 0.11497218906879425
decider.linear2.weight: 0.0005372948944568634 0.05132650211453438
decider.linear2.bias: 0.0009154942817986012 0.054736487567424774
decider.linear3.weight: -0.0020743017084896564 0.05127129331231117
decider.linear3.bias: 0.021959640085697174 0.06917988508939743

Rewards:
140.2155
140.2155
140.2155
objective = 176.39268493652344
==== episode 2200/10000 ====
action = 0
probs = 0.3496 0.5159 0.0890 0.0455

action = 1
probs = 0.3165 0.5413 0.0965 0.0458

action = 1
probs = 0.2125 0.5613 0.1587 0.0675

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00043644756078720093 0.08121401816606522
encoder.encoder.weight_hh_l0: -0.0002711398992687464 0.08224141597747803
encoder.encoder.bias_ih_l0: -0.0029337373562157154 0.08334382623434067
encoder.encoder.bias_hh_l0: 0.00706332316622138 0.08218217641115189
encoder.encoder.weight_ih_l0_reverse: 0.0005283312639221549 0.08313889801502228
encoder.encoder.weight_hh_l0_reverse: 0.0009496491984464228 0.08183490484952927
encoder.encoder.bias_ih_l0_reverse: 0.01429969072341919 0.08229189366102219
encoder.encoder.bias_hh_l0_reverse: 0.006165251135826111 0.0813419446349144
decider.lstm.weight_ih_l0: -0.0011924676364287734 0.14503686130046844
decider.lstm.weight_hh_l0: 0.00048116431571543217 0.14470189809799194
decider.lstm.bias_ih_l0: 0.00675487145781517 0.15446025133132935
decider.lstm.bias_hh_l0: -0.012232556939125061 0.13722778856754303
decider.linear1.weight: 0.003188930219039321 0.11800384521484375
decider.linear1.bias: 0.004964207299053669 0.11491663753986359
decider.linear2.weight: 0.000529220444150269 0.051319584250450134
decider.linear2.bias: 0.0009109582751989365 0.054662153124809265
decider.linear3.weight: -0.0020607365295290947 0.05125610902905464
decider.linear3.bias: 0.022026989609003067 0.06902135163545609

Rewards:
183.7409
183.7409
183.7409
objective = 137.34353637695312
==== episode 2300/10000 ====
action = 1
probs = 0.4101 0.4877 0.0684 0.0338

action = 1
probs = 0.3774 0.5270 0.0659 0.0297

action = 1
probs = 0.2095 0.6032 0.1294 0.0579

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003852895461022854 0.08130885660648346
encoder.encoder.weight_hh_l0: -0.0002808287099469453 0.08233334869146347
encoder.encoder.bias_ih_l0: -0.0023841403890401125 0.08341346681118011
encoder.encoder.bias_hh_l0: 0.007612923625856638 0.08233443647623062
encoder.encoder.weight_ih_l0_reverse: 0.0006068269140087068 0.0832223892211914
encoder.encoder.weight_hh_l0_reverse: 0.0010738748824223876 0.0819358304142952
encoder.encoder.bias_ih_l0_reverse: 0.014955963008105755 0.08229463547468185
encoder.encoder.bias_hh_l0_reverse: 0.006821525748819113 0.08141593635082245
decider.lstm.weight_ih_l0: -0.0011413788888603449 0.14509963989257812
decider.lstm.weight_hh_l0: 0.0006076795980334282 0.14480657875537872
decider.lstm.bias_ih_l0: 0.007418034598231316 0.15474532544612885
decider.lstm.bias_hh_l0: -0.011569391936063766 0.1374029815196991
decider.linear1.weight: 0.0032401825301349163 0.11808274686336517
decider.linear1.bias: 0.005423182621598244 0.1148894727230072
decider.linear2.weight: 0.0006354001816362143 0.051353730261325836
decider.linear2.bias: 0.001105212839320302 0.05477781221270561
decider.linear3.weight: -0.0021434398368000984 0.05141323804855347
decider.linear3.bias: 0.021862927824258804 0.06811106204986572

Rewards:
166.6321
166.6321
166.6321
objective = 103.53926849365234
==== episode 2400/10000 ====
action = 1
probs = 0.4161 0.5046 0.0510 0.0283

action = 1
probs = 0.4213 0.5092 0.0456 0.0240

action = 1
probs = 0.2159 0.6398 0.0910 0.0533

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003329376922920346 0.08143783360719681
encoder.encoder.weight_hh_l0: -0.0002873072517104447 0.08246925473213196
encoder.encoder.bias_ih_l0: -0.0015758303925395012 0.08351152390241623
encoder.encoder.bias_hh_l0: 0.008421234786510468 0.08235485851764679
encoder.encoder.weight_ih_l0_reverse: 0.0006649959832429886 0.08335544914007187
encoder.encoder.weight_hh_l0_reverse: 0.0013080203207209706 0.08207095414400101
encoder.encoder.bias_ih_l0_reverse: 0.015911340713500977 0.08238513767719269
encoder.encoder.bias_hh_l0_reverse: 0.007776905316859484 0.08155719935894012
decider.lstm.weight_ih_l0: -0.001045995275489986 0.14519557356834412
decider.lstm.weight_hh_l0: 0.000698992982506752 0.14493167400360107
decider.lstm.bias_ih_l0: 0.008231055922806263 0.1550164818763733
decider.lstm.bias_hh_l0: -0.01075636874884367 0.13766925036907196
decider.linear1.weight: 0.0032539889216423035 0.11817117780447006
decider.linear1.bias: 0.005797318182885647 0.11481916904449463
decider.linear2.weight: 0.0006879335851408541 0.05138320103287697
decider.linear2.bias: 0.0011922037228941917 0.05487476661801338
decider.linear3.weight: -0.0022060489282011986 0.051518842577934265
decider.linear3.bias: 0.021740764379501343 0.06761933118104935

Rewards:
166.6321
166.6321
166.6321
objective = 100.29045104980469
==== episode 2500/10000 ====
action = 1
probs = 0.3793 0.5586 0.0361 0.0260

action = 0
probs = 0.3577 0.5824 0.0379 0.0220

action = 1
probs = 0.1942 0.6771 0.0812 0.0475

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003012434463016689 0.08150511234998703
encoder.encoder.weight_hh_l0: -0.0002910741313826293 0.08252481371164322
encoder.encoder.bias_ih_l0: -0.0013612271286547184 0.08353111892938614
encoder.encoder.bias_hh_l0: 0.008635837584733963 0.08243997395038605
encoder.encoder.weight_ih_l0_reverse: 0.0007030125707387924 0.0833931416273117
encoder.encoder.weight_hh_l0_reverse: 0.0013812490506097674 0.08212651312351227
encoder.encoder.bias_ih_l0_reverse: 0.01620037667453289 0.08242867887020111
encoder.encoder.bias_hh_l0_reverse: 0.008065944537520409 0.08159568160772324
decider.lstm.weight_ih_l0: -0.0010417759185656905 0.1452249139547348
decider.lstm.weight_hh_l0: 0.000699963653460145 0.1449841409921646
decider.lstm.bias_ih_l0: 0.00827147625386715 0.15511706471443176
decider.lstm.bias_hh_l0: -0.010715948417782784 0.1377192586660385
decider.linear1.weight: 0.00327701005153358 0.11819706112146378
decider.linear1.bias: 0.0059916554018855095 0.11491157859563828
decider.linear2.weight: 0.0008169843349605799 0.051406633108854294
decider.linear2.bias: 0.0013474083971232176 0.054846588522195816
decider.linear3.weight: -0.0023404210805892944 0.051705438643693924
decider.linear3.bias: 0.021671976894140244 0.06788472086191177

Rewards:
151.0950
151.0950
151.0950
objective = 100.74791717529297
==== episode 2600/10000 ====
action = 1
probs = 0.3308 0.6130 0.0327 0.0236

action = 1
probs = 0.3067 0.6335 0.0374 0.0224

action = 0
probs = 0.1677 0.6584 0.1074 0.0664

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003167418180964887 0.08153194189071655
encoder.encoder.weight_hh_l0: -0.00025894559803418815 0.08255507797002792
encoder.encoder.bias_ih_l0: -0.0013918415643274784 0.08354009687900543
encoder.encoder.bias_hh_l0: 0.008605224080383778 0.08240244537591934
encoder.encoder.weight_ih_l0_reverse: 0.0006607448449358344 0.08337519317865372
encoder.encoder.weight_hh_l0_reverse: 0.0013196651125326753 0.08212462067604065
encoder.encoder.bias_ih_l0_reverse: 0.01605340465903282 0.08249025046825409
encoder.encoder.bias_hh_l0_reverse: 0.00791897438466549 0.08160964399576187
decider.lstm.weight_ih_l0: -0.0010839705355465412 0.14520889520645142
decider.lstm.weight_hh_l0: 0.0006554513238370419 0.14487715065479279
decider.lstm.bias_ih_l0: 0.007933109067380428 0.1549566090106964
decider.lstm.bias_hh_l0: -0.01105431653559208 0.13781964778900146
decider.linear1.weight: 0.0032940669916570187 0.11819677799940109
decider.linear1.bias: 0.005993322003632784 0.11499350517988205
decider.linear2.weight: 0.0008212992688640952 0.0514121949672699
decider.linear2.bias: 0.001331976382061839 0.05476885661482811
decider.linear3.weight: -0.002321160864084959 0.05172036215662956
decider.linear3.bias: 0.021739628165960312 0.06845862418413162

Rewards:
129.0447
129.0447
129.0447
objective = 117.4891357421875
==== episode 2700/10000 ====
action = 1
probs = 0.3177 0.6327 0.0272 0.0224

action = 1
probs = 0.2402 0.7130 0.0272 0.0196

action = 2
probs = 0.1351 0.7228 0.0804 0.0616

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003050399827770889 0.08161667734384537
encoder.encoder.weight_hh_l0: -0.0002815991756506264 0.08264248073101044
encoder.encoder.bias_ih_l0: -0.0009282607934437692 0.08360981196165085
encoder.encoder.bias_hh_l0: 0.009068803861737251 0.0825309008359909
encoder.encoder.weight_ih_l0_reverse: 0.0006688303546980023 0.08344197273254395
encoder.encoder.weight_hh_l0_reverse: 0.001469093724153936 0.08221250027418137
encoder.encoder.bias_ih_l0_reverse: 0.016610965132713318 0.08262625336647034
encoder.encoder.bias_hh_l0_reverse: 0.008476532064378262 0.08174265921115875
decider.lstm.weight_ih_l0: -0.0010454237926751375 0.14527057111263275
decider.lstm.weight_hh_l0: 0.0006742570549249649 0.14496135711669922
decider.lstm.bias_ih_l0: 0.008203224278986454 0.15517501533031464
decider.lstm.bias_hh_l0: -0.010784201323986053 0.1379488855600357
decider.linear1.weight: 0.003284782636910677 0.1182325929403305
decider.linear1.bias: 0.006235295441001654 0.1150168851017952
decider.linear2.weight: 0.0008932239725254476 0.05142894387245178
decider.linear2.bias: 0.0014684363268315792 0.05488135293126106
decider.linear3.weight: -0.0023578288964927197 0.051795657724142075
decider.linear3.bias: 0.021675387397408485 0.06876246631145477

Rewards:
148.3957
148.3957
148.3957
objective = 164.06277465820312
==== episode 2800/10000 ====
action = 1
probs = 0.4182 0.5144 0.0377 0.0298

action = 2
probs = 0.2845 0.6417 0.0424 0.0313

action = 1
probs = 0.1333 0.6579 0.1178 0.0910

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003969524404965341 0.08144963532686234
encoder.encoder.weight_hh_l0: -0.00022129523858893663 0.0824979692697525
encoder.encoder.bias_ih_l0: -0.0019603583496063948 0.08341953158378601
encoder.encoder.bias_hh_l0: 0.00803670659661293 0.08246312290430069
encoder.encoder.weight_ih_l0_reverse: 0.0005404754774644971 0.0832417905330658
encoder.encoder.weight_hh_l0_reverse: 0.0011234796838834882 0.08207125216722488
encoder.encoder.bias_ih_l0_reverse: 0.015453548170626163 0.08257018774747849
encoder.encoder.bias_hh_l0_reverse: 0.007319115102291107 0.0815761610865593
decider.lstm.weight_ih_l0: -0.0011652472894638777 0.14516647160053253
decider.lstm.weight_hh_l0: 0.0004520972725003958 0.14478519558906555
decider.lstm.bias_ih_l0: 0.007124027237296104 0.1548995077610016
decider.lstm.bias_hh_l0: -0.01186339184641838 0.1377512812614441
decider.linear1.weight: 0.003242053557187319 0.11809659004211426
decider.linear1.bias: 0.005816765129566193 0.1149759292602539
decider.linear2.weight: 0.0007977223722264171 0.05140432342886925
decider.linear2.bias: 0.0013191844336688519 0.05478658527135849
decider.linear3.weight: -0.002255320316180587 0.05173799395561218
decider.linear3.bias: 0.02191399782896042 0.0686500295996666

Rewards:
150.8889
150.8889
150.8889
objective = 213.43035888671875
==== episode 2900/10000 ====
action = 1
probs = 0.3383 0.6021 0.0325 0.0271

action = 1
probs = 0.1904 0.7511 0.0320 0.0265

action = 1
probs = 0.0924 0.7420 0.0850 0.0807

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000352899864083156 0.08158347010612488
encoder.encoder.weight_hh_l0: -0.0002642465115059167 0.08263004571199417
encoder.encoder.bias_ih_l0: -0.001178193953819573 0.08362890779972076
encoder.encoder.bias_hh_l0: 0.008818873204290867 0.08266184478998184
encoder.encoder.weight_ih_l0_reverse: 0.0005737465689890087 0.08336689323186874
encoder.encoder.weight_hh_l0_reverse: 0.0013071864377707243 0.08216793090105057
encoder.encoder.bias_ih_l0_reverse: 0.01615968346595764 0.08269421011209488
encoder.encoder.bias_hh_l0_reverse: 0.008025250397622585 0.08173143118619919
decider.lstm.weight_ih_l0: -0.0011084078578278422 0.145247220993042
decider.lstm.weight_hh_l0: 0.0005405504489317536 0.14487354457378387
decider.lstm.bias_ih_l0: 0.007719641551375389 0.1550762802362442
decider.lstm.bias_hh_l0: -0.01126778032630682 0.1378750056028366
decider.linear1.weight: 0.003273400943726301 0.1181788444519043
decider.linear1.bias: 0.006164575926959515 0.11500878632068634
decider.linear2.weight: 0.0008915601065382361 0.0514267161488533
decider.linear2.bias: 0.001473869662731886 0.05490054562687874
decider.linear3.weight: -0.0023114285431802273 0.05183209478855133
decider.linear3.bias: 0.021820463240146637 0.06939886510372162

Rewards:
166.6321
166.6321
166.6321
objective = 60.6584587097168
==== episode 3000/10000 ====
action = 1
probs = 0.2689 0.6787 0.0284 0.0241

action = 0
probs = 0.1931 0.7547 0.0282 0.0240

action = 1
probs = 0.1049 0.7654 0.0638 0.0659

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00037201883969828486 0.08160474896430969
encoder.encoder.weight_hh_l0: -0.00025206644204445183 0.08266203850507736
encoder.encoder.bias_ih_l0: -0.0010772139066830277 0.08368256688117981
encoder.encoder.bias_hh_l0: 0.0089198537170887 0.0826331377029419
encoder.encoder.weight_ih_l0_reverse: 0.0005897505325265229 0.08341129869222641
encoder.encoder.weight_hh_l0_reverse: 0.001388970180414617 0.08219237625598907
encoder.encoder.bias_ih_l0_reverse: 0.01640579290688038 0.08277173340320587
encoder.encoder.bias_hh_l0_reverse: 0.008271361701190472 0.08175621926784515
decider.lstm.weight_ih_l0: -0.0010699613485485315 0.14527760446071625
decider.lstm.weight_hh_l0: 0.0005525513552129269 0.1449413150548935
decider.lstm.bias_ih_l0: 0.007964025251567364 0.15508493781089783
decider.lstm.bias_hh_l0: -0.011023388244211674 0.13794440031051636
decider.linear1.weight: 0.003272636327892542 0.1182193011045456
decider.linear1.bias: 0.006215003319084644 0.11495237052440643
decider.linear2.weight: 0.0009151654085144401 0.05143069848418236
decider.linear2.bias: 0.0014806459657847881 0.054934751242399216
decider.linear3.weight: -0.0023510525934398174 0.05178041756153107
decider.linear3.bias: 0.021719425916671753 0.06941137462854385

Rewards:
151.0950
151.0950
151.0950
objective = 115.80616760253906
==== episode 3100/10000 ====
action = 1
probs = 0.2022 0.7580 0.0215 0.0183

action = 1
probs = 0.1400 0.8233 0.0197 0.0170

action = 1
probs = 0.0789 0.8152 0.0515 0.0545

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003170707786921412 0.08176330476999283
encoder.encoder.weight_hh_l0: -0.0002909769827965647 0.08282190561294556
encoder.encoder.bias_ih_l0: -0.00018725544214248657 0.08388206362724304
encoder.encoder.bias_hh_l0: 0.00980981346219778 0.0827937051653862
encoder.encoder.weight_ih_l0_reverse: 0.0006567756645381451 0.08355725556612015
encoder.encoder.weight_hh_l0_reverse: 0.0016753566451370716 0.08232101052999496
encoder.encoder.bias_ih_l0_reverse: 0.017348000779747963 0.08288182318210602
encoder.encoder.bias_hh_l0_reverse: 0.009213566780090332 0.0819200649857521
decider.lstm.weight_ih_l0: -0.0009714174084365368 0.14537528157234192
decider.lstm.weight_hh_l0: 0.000626487541012466 0.14504851400852203
decider.lstm.bias_ih_l0: 0.008808831684291363 0.15518516302108765
decider.lstm.bias_hh_l0: -0.01017857901751995 0.1381668597459793
decider.linear1.weight: 0.003291633678600192 0.11833696812391281
decider.linear1.bias: 0.006681513506919146 0.11500938981771469
decider.linear2.weight: 0.0010078728664666414 0.05146293342113495
decider.linear2.bias: 0.001641962444409728 0.05500053986907005
decider.linear3.weight: -0.002411241177469492 0.05189676210284233
decider.linear3.bias: 0.021607067435979843 0.06987033784389496

Rewards:
166.6321
166.6321
166.6321
objective = 37.5312614440918
==== episode 3200/10000 ====
action = 1
probs = 0.2456 0.7122 0.0202 0.0221

action = 1
probs = 0.1837 0.7755 0.0193 0.0215

action = 1
probs = 0.1005 0.7764 0.0525 0.0706

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003849133790936321 0.08168888092041016
encoder.encoder.weight_hh_l0: -0.0002460557734593749 0.08274514973163605
encoder.encoder.bias_ih_l0: -0.0007985674892552197 0.08373259007930756
encoder.encoder.bias_hh_l0: 0.009198499843478203 0.08266156166791916
encoder.encoder.weight_ih_l0_reverse: 0.0005977648543193936 0.08347643911838531
encoder.encoder.weight_hh_l0_reverse: 0.0015286036068573594 0.08227550983428955
encoder.encoder.bias_ih_l0_reverse: 0.016888903453946114 0.08290395885705948
encoder.encoder.bias_hh_l0_reverse: 0.008754472248256207 0.08181878924369812
decider.lstm.weight_ih_l0: -0.0010457790922373533 0.1453312486410141
decider.lstm.weight_hh_l0: 0.0005470358300954103 0.14501500129699707
decider.lstm.bias_ih_l0: 0.008161811158061028 0.15511393547058105
decider.lstm.bias_hh_l0: -0.010825606063008308 0.13815027475357056
decider.linear1.weight: 0.0032855174504220486 0.11827141046524048
decider.linear1.bias: 0.006429839413613081 0.11492472141981125
decider.linear2.weight: 0.0009501438471488655 0.051453929394483566
decider.linear2.bias: 0.0015364056453108788 0.05499495938420296
decider.linear3.weight: -0.0024011400528252125 0.05184696242213249
decider.linear3.bias: 0.02162722311913967 0.06935717910528183

Rewards:
166.6321
166.6321
166.6321
objective = 47.03194808959961
==== episode 3300/10000 ====
action = 1
probs = 0.1775 0.7923 0.0146 0.0156

action = 1
probs = 0.1224 0.8505 0.0128 0.0143

action = 1
probs = 0.0704 0.8440 0.0357 0.0498

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030283076921477914 0.08186054974794388
encoder.encoder.weight_hh_l0: -0.00030611312831752 0.08291971683502197
encoder.encoder.bias_ih_l0: 0.00021088897483423352 0.08397851139307022
encoder.encoder.bias_hh_l0: 0.010207954794168472 0.08288286626338959
encoder.encoder.weight_ih_l0_reverse: 0.0006943896296434104 0.0836491659283638
encoder.encoder.weight_hh_l0_reverse: 0.0018916880944743752 0.08241840451955795
encoder.encoder.bias_ih_l0_reverse: 0.018000781536102295 0.08299882709980011
encoder.encoder.bias_hh_l0_reverse: 0.009866347536444664 0.08201167732477188
decider.lstm.weight_ih_l0: -0.0009120182367041707 0.14544789493083954
decider.lstm.weight_hh_l0: 0.0006393077783286572 0.14515459537506104
decider.lstm.bias_ih_l0: 0.009246785193681717 0.15529237687587738
decider.lstm.bias_hh_l0: -0.00974063016474247 0.13833825290203094
decider.linear1.weight: 0.003305931342765689 0.11841897666454315
decider.linear1.bias: 0.0070227161049842834 0.1150028184056282
decider.linear2.weight: 0.0010896895546466112 0.05149518698453903
decider.linear2.bias: 0.0017651747912168503 0.055099815130233765
decider.linear3.weight: -0.002485270146280527 0.05199672654271126
decider.linear3.bias: 0.021473828703165054 0.06989387422800064

Rewards:
166.6321
166.6321
166.6321
objective = 31.349040985107422
==== episode 3400/10000 ====
action = 1
probs = 0.1123 0.8602 0.0138 0.0138

action = 1
probs = 0.0821 0.8925 0.0123 0.0132

action = 1
probs = 0.0464 0.8686 0.0349 0.0501

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00020451965974643826 0.08196913450956345
encoder.encoder.weight_hh_l0: -0.00034411318483762443 0.08303152769804001
encoder.encoder.bias_ih_l0: 0.0007219765684567392 0.08412826806306839
encoder.encoder.bias_hh_l0: 0.010719044134020805 0.08305269479751587
encoder.encoder.weight_ih_l0_reverse: 0.0007897017640061677 0.0837210863828659
encoder.encoder.weight_hh_l0_reverse: 0.002048659836873412 0.08249513059854507
encoder.encoder.bias_ih_l0_reverse: 0.018507303670048714 0.08301282674074173
encoder.encoder.bias_hh_l0_reverse: 0.010372868739068508 0.08210336416959763
decider.lstm.weight_ih_l0: -0.0008448894950561225 0.14551140367984772
decider.lstm.weight_hh_l0: 0.0007306284969672561 0.1451873481273651
decider.lstm.bias_ih_l0: 0.009958109818398952 0.15535233914852142
decider.lstm.bias_hh_l0: -0.009029312059283257 0.1383545994758606
decider.linear1.weight: 0.0033326009288430214 0.118504598736763
decider.linear1.bias: 0.007335844449698925 0.11506443470716476
decider.linear2.weight: 0.0011436546919867396 0.051516808569431305
decider.linear2.bias: 0.0018467563204467297 0.055086325854063034
decider.linear3.weight: -0.0024556168355047703 0.05207837000489235
decider.linear3.bias: 0.02155202440917492 0.07100468873977661

Rewards:
166.6321
166.6321
166.6321
objective = 22.508283615112305
==== episode 3500/10000 ====
action = 1
probs = 0.1384 0.8287 0.0168 0.0161

action = 1
probs = 0.0992 0.8705 0.0147 0.0156

action = 1
probs = 0.0580 0.8348 0.0441 0.0631

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00024863079306669533 0.08188694715499878
encoder.encoder.weight_hh_l0: -0.0003083384071942419 0.08293686807155609
encoder.encoder.bias_ih_l0: 0.00012496412091422826 0.08400718867778778
encoder.encoder.bias_hh_l0: 0.010122032836079597 0.08295539021492004
encoder.encoder.weight_ih_l0_reverse: 0.0007275848183780909 0.08363854885101318
encoder.encoder.weight_hh_l0_reverse: 0.001830743975006044 0.0824294462800026
encoder.encoder.bias_ih_l0_reverse: 0.017920007929205894 0.08300230652093887
encoder.encoder.bias_hh_l0_reverse: 0.00978556927293539 0.08202129602432251
decider.lstm.weight_ih_l0: -0.000955817406065762 0.14544568955898285
decider.lstm.weight_hh_l0: 0.0006497463909909129 0.14512485265731812
decider.lstm.bias_ih_l0: 0.009182950481772423 0.15527230501174927
decider.lstm.bias_hh_l0: -0.009804470464587212 0.1383039653301239
decider.linear1.weight: 0.0032929647713899612 0.11841458082199097
decider.linear1.bias: 0.006943979766219854 0.11502481997013092
decider.linear2.weight: 0.0010527628473937511 0.05149589478969574
decider.linear2.bias: 0.001706079114228487 0.055034663528203964
decider.linear3.weight: -0.002417805604636669 0.051993515342473984
decider.linear3.bias: 0.021616950631141663 0.0707244947552681

Rewards:
166.6321
166.6321
166.6321
objective = 28.176496505737305
==== episode 3600/10000 ====
action = 0
probs = 0.1757 0.7879 0.0176 0.0189

action = 1
probs = 0.1079 0.8526 0.0167 0.0228

action = 1
probs = 0.0667 0.8237 0.0413 0.0683

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002720538468565792 0.08182638138532639
encoder.encoder.weight_hh_l0: -0.00030498337582685053 0.08286872506141663
encoder.encoder.bias_ih_l0: -0.00025244263815693557 0.08390544354915619
encoder.encoder.bias_hh_l0: 0.00974462740123272 0.08287572860717773
encoder.encoder.weight_ih_l0_reverse: 0.0006929907249286771 0.08358785510063171
encoder.encoder.weight_hh_l0_reverse: 0.0017214774852618575 0.08238550275564194
encoder.encoder.bias_ih_l0_reverse: 0.017585990950465202 0.08298135548830032
encoder.encoder.bias_hh_l0_reverse: 0.009451555088162422 0.08199237287044525
decider.lstm.weight_ih_l0: -0.0010056670289486647 0.14541226625442505
decider.lstm.weight_hh_l0: 0.0006049091462045908 0.14511238038539886
decider.lstm.bias_ih_l0: 0.008806757628917694 0.1552485078573227
decider.lstm.bias_hh_l0: -0.01018066331744194 0.1382828950881958
decider.linear1.weight: 0.00326726445928216 0.11837232112884521
decider.linear1.bias: 0.006785677280277014 0.11493251472711563
decider.linear2.weight: 0.0010133973555639386 0.051487997174263
decider.linear2.bias: 0.001653102459385991 0.05504565313458443
decider.linear3.weight: -0.002428005915135145 0.05197370797395706
decider.linear3.bias: 0.021609175950288773 0.07025547325611115

Rewards:
183.7409
183.7409
183.7409
objective = 128.16653442382812
==== episode 3700/10000 ====
action = 0
probs = 0.1833 0.7869 0.0143 0.0156

action = 1
probs = 0.1004 0.8695 0.0127 0.0175

action = 1
probs = 0.0530 0.8689 0.0281 0.0500

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002449335006531328 0.0819016844034195
encoder.encoder.weight_hh_l0: -0.00033213887945748866 0.08294612169265747
encoder.encoder.bias_ih_l0: 0.00021870702039450407 0.08401281386613846
encoder.encoder.bias_hh_l0: 0.010215774178504944 0.08297358453273773
encoder.encoder.weight_ih_l0_reverse: 0.0007258264813572168 0.08368904143571854
encoder.encoder.weight_hh_l0_reverse: 0.0019011489348486066 0.08245674520730972
encoder.encoder.bias_ih_l0_reverse: 0.0181573536247015 0.08301011472940445
encoder.encoder.bias_hh_l0_reverse: 0.010022916831076145 0.08211816847324371
decider.lstm.weight_ih_l0: -0.0009229008574038744 0.1454770565032959
decider.lstm.weight_hh_l0: 0.0006889288779348135 0.1452033519744873
decider.lstm.bias_ih_l0: 0.009419592097401619 0.1554340124130249
decider.lstm.bias_hh_l0: -0.009567825123667717 0.13837018609046936
decider.linear1.weight: 0.0032954178750514984 0.1184678003191948
decider.linear1.bias: 0.007250810973346233 0.11490334570407867
decider.linear2.weight: 0.001122680027037859 0.0515245757997036
decider.linear2.bias: 0.0018428214825689793 0.05514202266931534
decider.linear3.weight: -0.0025322316214442253 0.05211659148335457
decider.linear3.bias: 0.021430078893899918 0.07001323997974396

Rewards:
183.7409
183.7409
183.7409
objective = 121.10700988769531
==== episode 3800/10000 ====
action = 1
probs = 0.2399 0.7263 0.0168 0.0170

action = 1
probs = 0.1378 0.8340 0.0134 0.0148

action = 1
probs = 0.0540 0.8608 0.0317 0.0535

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00026886380510404706 0.0818556547164917
encoder.encoder.weight_hh_l0: -0.00033955194521695375 0.08290265500545502
encoder.encoder.bias_ih_l0: 3.0393004635698162e-05 0.0839753970503807
encoder.encoder.bias_hh_l0: 0.010027460753917694 0.08295959234237671
encoder.encoder.weight_ih_l0_reverse: 0.0006672097370028496 0.08364713191986084
encoder.encoder.weight_hh_l0_reverse: 0.0018024565652012825 0.08241011947393417
encoder.encoder.bias_ih_l0_reverse: 0.01782115548849106 0.08294552564620972
encoder.encoder.bias_hh_l0_reverse: 0.009686718694865704 0.08211936801671982
decider.lstm.weight_ih_l0: -0.0009574175928719342 0.1454465687274933
decider.lstm.weight_hh_l0: 0.0006261187372729182 0.14516885578632355
decider.lstm.bias_ih_l0: 0.009150948375463486 0.1553957462310791
decider.lstm.bias_hh_l0: -0.009836464188992977 0.13830305635929108
decider.linear1.weight: 0.003263697028160095 0.1184324324131012
decider.linear1.bias: 0.007101041730493307 0.11486975103616714
decider.linear2.weight: 0.001097243744879961 0.05151951313018799
decider.linear2.bias: 0.0018098605796694756 0.055116187781095505
decider.linear3.weight: -0.0025226501747965813 0.05211395025253296
decider.linear3.bias: 0.021465834230184555 0.06967110931873322

Rewards:
166.6321
166.6321
166.6321
objective = 36.17292785644531
==== episode 3900/10000 ====
action = 1
probs = 0.2561 0.7113 0.0167 0.0159

action = 1
probs = 0.1327 0.8407 0.0133 0.0132

action = 1
probs = 0.0508 0.8671 0.0331 0.0490

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002723447105381638 0.08187270164489746
encoder.encoder.weight_hh_l0: -0.00034694417263381183 0.08291709423065186
encoder.encoder.bias_ih_l0: 0.00013524263340514153 0.08399920910596848
encoder.encoder.bias_hh_l0: 0.010132310912013054 0.08299145847558975
encoder.encoder.weight_ih_l0_reverse: 0.0006565203657373786 0.08366954326629639
encoder.encoder.weight_hh_l0_reverse: 0.0018238723278045654 0.08242331445217133
encoder.encoder.bias_ih_l0_reverse: 0.017903633415699005 0.08294035494327545
encoder.encoder.bias_hh_l0_reverse: 0.009769195690751076 0.08215366303920746
decider.lstm.weight_ih_l0: -0.0009454021928831935 0.1454555243253708
decider.lstm.weight_hh_l0: 0.0006434922106564045 0.14517413079738617
decider.lstm.bias_ih_l0: 0.009229052811861038 0.15544845163822174
decider.lstm.bias_hh_l0: -0.009758362546563148 0.13831481337547302
decider.linear1.weight: 0.0032722146715968847 0.11844240128993988
decider.linear1.bias: 0.0071709430776536465 0.11489397287368774
decider.linear2.weight: 0.0011156402761116624 0.051528312265872955
decider.linear2.bias: 0.0018504937179386616 0.05511491745710373
decider.linear3.weight: -0.002538206521421671 0.05215106159448624
decider.linear3.bias: 0.021436402574181557 0.06951439380645752

Rewards:
166.6321
166.6321
166.6321
objective = 36.486183166503906
==== episode 4000/10000 ====
action = 1
probs = 0.4278 0.5359 0.0175 0.0188

action = 3
probs = 0.2163 0.7542 0.0139 0.0155

action = 1
probs = 0.0660 0.8627 0.0282 0.0431

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031754712108522654 0.08177416771650314
encoder.encoder.weight_hh_l0: -0.0003563689242582768 0.08282554894685745
encoder.encoder.bias_ih_l0: -0.0002563664165791124 0.08387021720409393
encoder.encoder.bias_hh_l0: 0.009740701876580715 0.08292299509048462
encoder.encoder.weight_ih_l0_reverse: 0.0005949317710474133 0.08360254019498825
encoder.encoder.weight_hh_l0_reverse: 0.0017374198650941253 0.08236820995807648
encoder.encoder.bias_ih_l0_reverse: 0.017569757997989655 0.08287361264228821
encoder.encoder.bias_hh_l0_reverse: 0.0094353212043643 0.08209307491779327
decider.lstm.weight_ih_l0: -0.0009719133377075195 0.1454160064458847
decider.lstm.weight_hh_l0: 0.0005899730604141951 0.1451723277568817
decider.lstm.bias_ih_l0: 0.008912879973649979 0.15546482801437378
decider.lstm.bias_hh_l0: -0.010074542835354805 0.13827171921730042
decider.linear1.weight: 0.0032484817784279585 0.11841295659542084
decider.linear1.bias: 0.007119744084775448 0.11477316915988922
decider.linear2.weight: 0.0010939751518890262 0.05153463035821915
decider.linear2.bias: 0.0018118165899068117 0.055164966732263565
decider.linear3.weight: -0.0025724018923938274 0.052213188260793686
decider.linear3.bias: 0.021384937688708305 0.06814391911029816

Rewards:
167.2865
167.2865
167.2865
objective = 275.25616455078125
==== episode 4100/10000 ====
action = 0
probs = 0.4835 0.4730 0.0220 0.0215

action = 0
probs = 0.1887 0.7706 0.0190 0.0217

action = 1
probs = 0.0575 0.8470 0.0385 0.0571

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003459923027548939 0.08170445263385773
encoder.encoder.weight_hh_l0: -0.00036086433101445436 0.08276277780532837
encoder.encoder.bias_ih_l0: -0.0005325719830580056 0.08380479365587234
encoder.encoder.bias_hh_l0: 0.009464493952691555 0.08289429545402527
encoder.encoder.weight_ih_l0_reverse: 0.0005461025284603238 0.08353914320468903
encoder.encoder.weight_hh_l0_reverse: 0.0016507520340383053 0.08232122659683228
encoder.encoder.bias_ih_l0_reverse: 0.017223207280039787 0.08283217996358871
encoder.encoder.bias_hh_l0_reverse: 0.00908876396715641 0.08203122764825821
decider.lstm.weight_ih_l0: -0.0010068259434774518 0.1453811228275299
decider.lstm.weight_hh_l0: 0.0005166491027921438 0.1451522707939148
decider.lstm.bias_ih_l0: 0.008615067228674889 0.15539123117923737
decider.lstm.bias_hh_l0: -0.010372350923717022 0.13819651305675507
decider.linear1.weight: 0.0032062544487416744 0.11836857348680496
decider.linear1.bias: 0.006937243975698948 0.11473912745714188
decider.linear2.weight: 0.0010534287430346012 0.051519446074962616
decider.linear2.bias: 0.001737404614686966 0.055138275027275085
decider.linear3.weight: -0.0025325347669422626 0.05217992141842842
decider.linear3.bias: 0.02147192507982254 0.06784887611865997

Rewards:
153.4407
153.4407
153.4407
objective = 130.94717407226562
==== episode 4200/10000 ====
action = 0
probs = 0.5070 0.4435 0.0250 0.0245

action = 1
probs = 0.1780 0.7804 0.0184 0.0232

action = 1
probs = 0.0598 0.8700 0.0260 0.0442

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003768735332414508 0.08168742060661316
encoder.encoder.weight_hh_l0: -0.0003703123948071152 0.08275629580020905
encoder.encoder.bias_ih_l0: -0.000577774306293577 0.0838085189461708
encoder.encoder.bias_hh_l0: 0.009419293142855167 0.08294537663459778
encoder.encoder.weight_ih_l0_reverse: 0.0005188433569855988 0.08351573348045349
encoder.encoder.weight_hh_l0_reverse: 0.0016473111463710666 0.08231645822525024
encoder.encoder.bias_ih_l0_reverse: 0.01719615049660206 0.08285146206617355
encoder.encoder.bias_hh_l0_reverse: 0.009061711840331554 0.08203907310962677
decider.lstm.weight_ih_l0: -0.0010023718932643533 0.14538076519966125
decider.lstm.weight_hh_l0: 0.0005204050103202462 0.14516250789165497
decider.lstm.bias_ih_l0: 0.008618920110166073 0.1554890125989914
decider.lstm.bias_hh_l0: -0.010368496179580688 0.13814866542816162
decider.linear1.weight: 0.0031928985845297575 0.11836694180965424
decider.linear1.bias: 0.0069509875029325485 0.11472650617361069
decider.linear2.weight: 0.0010370155796408653 0.05152500793337822
decider.linear2.bias: 0.0017163422890007496 0.055194854736328125
decider.linear3.weight: -0.0025283326394855976 0.05220741033554077
decider.linear3.bias: 0.021503273397684097 0.06786397099494934

Rewards:
183.7409
183.7409
183.7409
objective = 65.32230377197266
==== episode 4300/10000 ====
action = 0
probs = 0.4574 0.4853 0.0294 0.0279

action = 1
probs = 0.1516 0.8023 0.0216 0.0245

action = 3
probs = 0.0493 0.8800 0.0283 0.0424

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00038824943476356566 0.08166999369859695
encoder.encoder.weight_hh_l0: -0.00036048953188583255 0.08273547142744064
encoder.encoder.bias_ih_l0: -0.0007528847199864686 0.0837816521525383
encoder.encoder.bias_hh_l0: 0.009244179353117943 0.0829303115606308
encoder.encoder.weight_ih_l0_reverse: 0.0005063951830379665 0.08349939435720444
encoder.encoder.weight_hh_l0_reverse: 0.0015605652006343007 0.08229544013738632
encoder.encoder.bias_ih_l0_reverse: 0.016970891505479813 0.08282456547021866
encoder.encoder.bias_hh_l0_reverse: 0.008836451917886734 0.08205249160528183
decider.lstm.weight_ih_l0: -0.0010114854667335749 0.14536410570144653
decider.lstm.weight_hh_l0: 0.0004889460979029536 0.14515142142772675
decider.lstm.bias_ih_l0: 0.00856168195605278 0.155496746301651
decider.lstm.bias_hh_l0: -0.010425731539726257 0.13804498314857483
decider.linear1.weight: 0.003157417755573988 0.11834199726581573
decider.linear1.bias: 0.006824873853474855 0.11471526324748993
decider.linear2.weight: 0.0010043337242677808 0.05151309072971344
decider.linear2.bias: 0.0016544642858207226 0.05515482276678085
decider.linear3.weight: -0.0024831988848745823 0.0521521270275116
decider.linear3.bias: 0.021596301347017288 0.06854317337274551

Rewards:
167.3462
167.3462
167.3462
objective = 232.28170776367188
==== episode 4400/10000 ====
action = 0
probs = 0.5351 0.4136 0.0251 0.0262

action = 1
probs = 0.2063 0.7450 0.0218 0.0269

action = 1
probs = 0.0595 0.8690 0.0278 0.0437

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003926772915292531 0.0816512405872345
encoder.encoder.weight_hh_l0: -0.0003485359193291515 0.08270946145057678
encoder.encoder.bias_ih_l0: -0.0009720304515212774 0.08370555937290192
encoder.encoder.bias_hh_l0: 0.009025032632052898 0.08283014595508575
encoder.encoder.weight_ih_l0_reverse: 0.0005195377743802965 0.08348308503627777
encoder.encoder.weight_hh_l0_reverse: 0.001545419218018651 0.0822887197136879
encoder.encoder.bias_ih_l0_reverse: 0.016949597746133804 0.08282577246427536
encoder.encoder.bias_hh_l0_reverse: 0.008815155364573002 0.08195891976356506
decider.lstm.weight_ih_l0: -0.0010231599444523454 0.1453508734703064
decider.lstm.weight_hh_l0: 0.000446231453679502 0.14516034722328186
decider.lstm.bias_ih_l0: 0.008422110229730606 0.15538674592971802
decider.lstm.bias_hh_l0: -0.010565297678112984 0.13816046714782715
decider.linear1.weight: 0.003184997010976076 0.11835498362779617
decider.linear1.bias: 0.006947315763682127 0.11464105546474457
decider.linear2.weight: 0.0010352014796808362 0.05152393877506256
decider.linear2.bias: 0.001694107661023736 0.05518278852105141
decider.linear3.weight: -0.00252223527058959 0.052196405827999115
decider.linear3.bias: 0.02151888608932495 0.06767531484365463

Rewards:
183.7409
183.7409
183.7409
objective = 64.9293212890625
==== episode 4500/10000 ====
action = 0
probs = 0.5624 0.3837 0.0252 0.0288

action = 1
probs = 0.2078 0.7420 0.0219 0.0284

action = 1
probs = 0.0553 0.8773 0.0256 0.0418

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0004014010773971677 0.08165371417999268
encoder.encoder.weight_hh_l0: -0.0003532827249728143 0.08271276205778122
encoder.encoder.bias_ih_l0: -0.0009454798419028521 0.083708755671978
encoder.encoder.bias_hh_l0: 0.009051586501300335 0.0828813910484314
encoder.encoder.weight_ih_l0_reverse: 0.0005070825573056936 0.08348183333873749
encoder.encoder.weight_hh_l0_reverse: 0.0015307754511013627 0.08229018747806549
encoder.encoder.bias_ih_l0_reverse: 0.016943540424108505 0.08280869573354721
encoder.encoder.bias_hh_l0_reverse: 0.008809097111225128 0.08196950703859329
decider.lstm.weight_ih_l0: -0.0010226179147139192 0.1453513652086258
decider.lstm.weight_hh_l0: 0.00043968181125819683 0.14516659080982208
decider.lstm.bias_ih_l0: 0.008455697447061539 0.155375137925148
decider.lstm.bias_hh_l0: -0.010531706735491753 0.1381591111421585
decider.linear1.weight: 0.003179375547915697 0.11835892498493195
decider.linear1.bias: 0.006986483000218868 0.11460670083761215
decider.linear2.weight: 0.001018789131194353 0.0515315905213356
decider.linear2.bias: 0.0016643155831843615 0.05516701564192772
decider.linear3.weight: -0.00252993730828166 0.05220825597643852
decider.linear3.bias: 0.021533727645874023 0.06752243638038635

Rewards:
183.7409
183.7409
183.7409
objective = 61.55256271362305
==== episode 4600/10000 ====
action = 0
probs = 0.5246 0.4313 0.0204 0.0236

action = 1
probs = 0.1890 0.7767 0.0151 0.0191

action = 1
probs = 0.0522 0.9038 0.0172 0.0268

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00036999263102188706 0.08174009621143341
encoder.encoder.weight_hh_l0: -0.00036604946944862604 0.08278882503509521
encoder.encoder.bias_ih_l0: -0.0005591455264948308 0.08381504565477371
encoder.encoder.bias_hh_l0: 0.0094379223883152 0.0829741433262825
encoder.encoder.weight_ih_l0_reverse: 0.0005639014998450875 0.08359795063734055
encoder.encoder.weight_hh_l0_reverse: 0.0016837653238326311 0.08235964924097061
encoder.encoder.bias_ih_l0_reverse: 0.017488114535808563 0.08283596485853195
encoder.encoder.bias_hh_l0_reverse: 0.009353669360280037 0.0820603221654892
decider.lstm.weight_ih_l0: -0.0009588640532456338 0.14541441202163696
decider.lstm.weight_hh_l0: 0.0005665109492838383 0.1452610343694687
decider.lstm.bias_ih_l0: 0.008927159011363983 0.15562626719474792
decider.lstm.bias_hh_l0: -0.010060245171189308 0.13823319971561432
decider.linear1.weight: 0.0032350015826523304 0.11842857301235199
decider.linear1.bias: 0.0073057860136032104 0.11463850736618042
decider.linear2.weight: 0.0011003161780536175 0.05156010016798973
decider.linear2.bias: 0.0017964655999094248 0.055277179926633835
decider.linear3.weight: -0.0026514821220189333 0.052269481122493744
decider.linear3.bias: 0.02124154195189476 0.06742426753044128

Rewards:
183.7409
183.7409
183.7409
objective = 61.17672348022461
==== episode 4700/10000 ====
action = 1
probs = 0.4811 0.4837 0.0164 0.0187

action = 1
probs = 0.2221 0.7526 0.0120 0.0134

action = 1
probs = 0.0502 0.9124 0.0151 0.0222

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033982834429480135 0.08181460946798325
encoder.encoder.weight_hh_l0: -0.0003617751644924283 0.08285605907440186
encoder.encoder.bias_ih_l0: -0.00022787749185226858 0.08391016721725464
encoder.encoder.bias_hh_l0: 0.009769191965460777 0.08302389830350876
encoder.encoder.weight_ih_l0_reverse: 0.0005898486124351621 0.08368764817714691
encoder.encoder.weight_hh_l0_reverse: 0.0017918185330927372 0.0824168473482132
encoder.encoder.bias_ih_l0_reverse: 0.017870983108878136 0.08287491649389267
encoder.encoder.bias_hh_l0_reverse: 0.009736539795994759 0.08214838802814484
decider.lstm.weight_ih_l0: -0.0009205248788930476 0.14546112716197968
decider.lstm.weight_hh_l0: 0.0006198752671480179 0.1453114002943039
decider.lstm.bias_ih_l0: 0.00918523594737053 0.1557898074388504
decider.lstm.bias_hh_l0: -0.009802175685763359 0.13828447461128235
decider.linear1.weight: 0.003281058743596077 0.11847484111785889
decider.linear1.bias: 0.007516202982515097 0.11469138413667679
decider.linear2.weight: 0.0011606509797275066 0.05157778039574623
decider.linear2.bias: 0.00190534139983356 0.055344145745038986
decider.linear3.weight: -0.00272937398403883 0.0523085854947567
decider.linear3.bias: 0.021042894572019577 0.06748689711093903

Rewards:
166.6321
166.6321
166.6321
objective = 61.220603942871094
==== episode 4800/10000 ====
action = 1
probs = 0.4729 0.4997 0.0125 0.0149

action = 0
probs = 0.1891 0.7919 0.0086 0.0104

action = 1
probs = 0.0438 0.9246 0.0119 0.0197

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031199894146993756 0.08189701288938522
encoder.encoder.weight_hh_l0: -0.0003609397972468287 0.08293790370225906
encoder.encoder.bias_ih_l0: 0.00021064520115032792 0.0840136855840683
encoder.encoder.bias_hh_l0: 0.010207719169557095 0.08311361819505692
encoder.encoder.weight_ih_l0_reverse: 0.0006069998489692807 0.08378219604492188
encoder.encoder.weight_hh_l0_reverse: 0.0019481574418023229 0.08249825984239578
encoder.encoder.bias_ih_l0_reverse: 0.018418993800878525 0.08294785767793655
encoder.encoder.bias_hh_l0_reverse: 0.010284548625349998 0.08223826438188553
decider.lstm.weight_ih_l0: -0.0008708969107829034 0.14552178978919983
decider.lstm.weight_hh_l0: 0.0006954222917556763 0.1453748345375061
decider.lstm.bias_ih_l0: 0.009521528147161007 0.1559741199016571
decider.lstm.bias_hh_l0: -0.009465896524488926 0.13838452100753784
decider.linear1.weight: 0.003349446691572666 0.11854683607816696
decider.linear1.bias: 0.007873841561377048 0.11474204808473587
decider.linear2.weight: 0.0012524626217782497 0.05161157622933388
decider.linear2.bias: 0.002080217469483614 0.05538859963417053
decider.linear3.weight: -0.0028059689793735743 0.052437879145145416
decider.linear3.bias: 0.020891709253191948 0.06741295009851456

Rewards:
151.0950
151.0950
151.0950
objective = 122.77687072753906
==== episode 4900/10000 ====
action = 0
probs = 0.5635 0.4171 0.0089 0.0105

action = 1
probs = 0.1485 0.8373 0.0060 0.0082

action = 1
probs = 0.0463 0.9298 0.0089 0.0151

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002745385281741619 0.08197738975286484
encoder.encoder.weight_hh_l0: -0.0003625715326052159 0.08303351700305939
encoder.encoder.bias_ih_l0: 0.0008360326173715293 0.08412598073482513
encoder.encoder.bias_hh_l0: 0.010833105072379112 0.0832095593214035
encoder.encoder.weight_ih_l0_reverse: 0.000644606479909271 0.08390183001756668
encoder.encoder.weight_hh_l0_reverse: 0.0022141234949231148 0.0826033428311348
encoder.encoder.bias_ih_l0_reverse: 0.019202258437871933 0.08301259577274323
encoder.encoder.bias_hh_l0_reverse: 0.011067814193665981 0.08227802813053131
decider.lstm.weight_ih_l0: -0.0007800101884640753 0.14560867846012115
decider.lstm.weight_hh_l0: 0.0008204325567930937 0.14548781514167786
decider.lstm.bias_ih_l0: 0.010023660026490688 0.15619243681430817
decider.lstm.bias_hh_l0: -0.008963759988546371 0.13856624066829681
decider.linear1.weight: 0.003427284536883235 0.11864885687828064
decider.linear1.bias: 0.008375737816095352 0.11479707807302475
decider.linear2.weight: 0.0014063341077417135 0.05165603756904602
decider.linear2.bias: 0.0023570149205625057 0.05543846637010574
decider.linear3.weight: -0.002944174688309431 0.05262082815170288
decider.linear3.bias: 0.02061157114803791 0.06628239899873734

Rewards:
183.7409
183.7409
183.7409
objective = 50.468055725097656
==== episode 5000/10000 ====
action = 0
probs = 0.6821 0.3019 0.0068 0.0092

action = 1
probs = 0.2673 0.7169 0.0061 0.0097

action = 1
probs = 0.0918 0.8779 0.0101 0.0201

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002891524927690625 0.08193546533584595
encoder.encoder.weight_hh_l0: -0.0003595106245484203 0.0829729288816452
encoder.encoder.bias_ih_l0: 0.0005181720480322838 0.08400140702724457
encoder.encoder.bias_hh_l0: 0.010515247471630573 0.08305956423282623
encoder.encoder.weight_ih_l0_reverse: 0.0006411554059013724 0.08387596905231476
encoder.encoder.weight_hh_l0_reverse: 0.0021817083470523357 0.08259426057338715
encoder.encoder.bias_ih_l0_reverse: 0.01911347173154354 0.08308184146881104
encoder.encoder.bias_hh_l0_reverse: 0.010979026556015015 0.08211104571819305
decider.lstm.weight_ih_l0: -0.0008369373972527683 0.14559456706047058
decider.lstm.weight_hh_l0: 0.0007074275054037571 0.14553917944431305
decider.lstm.bias_ih_l0: 0.009567906148731709 0.1560242921113968
decider.lstm.bias_hh_l0: -0.009419526904821396 0.13874228298664093
decider.linear1.weight: 0.0034291651099920273 0.11862844973802567
decider.linear1.bias: 0.008211269043385983 0.11481715738773346
decider.linear2.weight: 0.0014104880392551422 0.05165485665202141
decider.linear2.bias: 0.002357225865125656 0.05541656166315079
decider.linear3.weight: -0.0029881312511861324 0.052632056176662445
decider.linear3.bias: 0.02053564414381981 0.06506047397851944

Rewards:
183.7409
183.7409
183.7409
objective = 51.79063415527344
==== episode 5100/10000 ====
action = 0
probs = 0.7347 0.2513 0.0056 0.0084

action = 0
probs = 0.3546 0.6307 0.0054 0.0092

action = 1
probs = 0.0855 0.8814 0.0111 0.0220

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000281555054243654 0.08194226026535034
encoder.encoder.weight_hh_l0: -0.00036367448046803474 0.08298421651124954
encoder.encoder.bias_ih_l0: 0.0005738493637181818 0.0840219035744667
encoder.encoder.bias_hh_l0: 0.010570923797786236 0.08305219560861588
encoder.encoder.weight_ih_l0_reverse: 0.000682707701344043 0.08391497284173965
encoder.encoder.weight_hh_l0_reverse: 0.0022689243778586388 0.08263329416513443
encoder.encoder.bias_ih_l0_reverse: 0.01938680186867714 0.08309800177812576
encoder.encoder.bias_hh_l0_reverse: 0.011252353899180889 0.08204840123653412
decider.lstm.weight_ih_l0: -0.000793128740042448 0.1456213891506195
decider.lstm.weight_hh_l0: 0.0007517673075199127 0.14559783041477203
decider.lstm.bias_ih_l0: 0.00980023480951786 0.15599733591079712
decider.lstm.bias_hh_l0: -0.009187191724777222 0.1388537585735321
decider.linear1.weight: 0.0034395873080939054 0.1186641976237297
decider.linear1.bias: 0.008401596918702126 0.1147533729672432
decider.linear2.weight: 0.001451703254133463 0.05167422071099281
decider.linear2.bias: 0.0024284995160996914 0.05543772876262665
decider.linear3.weight: -0.0030506178736686707 0.05268698185682297
decider.linear3.bias: 0.02042429894208908 0.06441743671894073

Rewards:
153.4407
153.4407
153.4407
objective = 75.25045776367188
==== episode 5200/10000 ====
action = 1
probs = 0.7739 0.2148 0.0042 0.0071

action = 1
probs = 0.5158 0.4731 0.0039 0.0072

action = 1
probs = 0.1148 0.8566 0.0084 0.0202

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002642587060108781 0.08197814226150513
encoder.encoder.weight_hh_l0: -0.0003544109349604696 0.0830211490392685
encoder.encoder.bias_ih_l0: 0.0007578026852570474 0.08403333276510239
encoder.encoder.bias_hh_l0: 0.010754875838756561 0.083060123026371
encoder.encoder.weight_ih_l0_reverse: 0.0007000697078183293 0.08396150171756744
encoder.encoder.weight_hh_l0_reverse: 0.002375122159719467 0.08268790692090988
encoder.encoder.bias_ih_l0_reverse: 0.01970617286860943 0.08314907550811768
encoder.encoder.bias_hh_l0_reverse: 0.0115717314183712 0.08203884959220886
decider.lstm.weight_ih_l0: -0.0007725856848992407 0.1456558257341385
decider.lstm.weight_hh_l0: 0.000766450073570013 0.14564138650894165
decider.lstm.bias_ih_l0: 0.009911691769957542 0.15599371492862701
decider.lstm.bias_hh_l0: -0.00907573290169239 0.138951376080513
decider.linear1.weight: 0.0034681628458201885 0.1187080517411232
decider.linear1.bias: 0.008579328656196594 0.11475648730993271
decider.linear2.weight: 0.0014972840435802937 0.05169529840350151
decider.linear2.bias: 0.002511166036128998 0.05545827001333237
decider.linear3.weight: -0.003102257614955306 0.05276047810912132
decider.linear3.bias: 0.020368125289678574 0.06408315151929855

Rewards:
166.6321
166.6321
166.6321
objective = 135.59735107421875
==== episode 5300/10000 ====
action = 0
probs = 0.7285 0.2575 0.0052 0.0087

action = 1
probs = 0.2990 0.6856 0.0051 0.0103

action = 1
probs = 0.0872 0.8831 0.0086 0.0212

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029010159778408706 0.08196098357439041
encoder.encoder.weight_hh_l0: -0.00035676665720529854 0.08299577236175537
encoder.encoder.bias_ih_l0: 0.0005013504414819181 0.08401293307542801
encoder.encoder.bias_hh_l0: 0.010498425923287868 0.08307776600122452
encoder.encoder.weight_ih_l0_reverse: 0.0006557186716236174 0.08390869200229645
encoder.encoder.weight_hh_l0_reverse: 0.0022450301330536604 0.08263873308897018
encoder.encoder.bias_ih_l0_reverse: 0.019337285310029984 0.08314642310142517
encoder.encoder.bias_hh_l0_reverse: 0.011202841997146606 0.08210156857967377
decider.lstm.weight_ih_l0: -0.0008244552300311625 0.1456177979707718
decider.lstm.weight_hh_l0: 0.0007112607127055526 0.14558111131191254
decider.lstm.bias_ih_l0: 0.00964248925447464 0.15599949657917023
decider.lstm.bias_hh_l0: -0.009344941936433315 0.1388552337884903
decider.linear1.weight: 0.0034487552475184202 0.11866674572229385
decider.linear1.bias: 0.008457494899630547 0.11475233733654022
decider.linear2.weight: 0.0014650560915470123 0.05168401449918747
decider.linear2.bias: 0.0024655091110616922 0.055435776710510254
decider.linear3.weight: -0.0030579562298953533 0.05272343382239342
decider.linear3.bias: 0.02045605331659317 0.06473108381032944

Rewards:
183.7409
183.7409
183.7409
objective = 50.13125228881836
==== episode 5400/10000 ====
action = 0
probs = 0.7669 0.2229 0.0041 0.0061

action = 1
probs = 0.3252 0.6632 0.0043 0.0073

action = 1
probs = 0.0759 0.9031 0.0067 0.0143

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00025529309641569853 0.08205799013376236
encoder.encoder.weight_hh_l0: -0.00035416355240158737 0.08310491591691971
encoder.encoder.bias_ih_l0: 0.0011059887474402785 0.08414608985185623
encoder.encoder.bias_hh_l0: 0.011103067547082901 0.08320117741823196
encoder.encoder.weight_ih_l0_reverse: 0.0007328299107030034 0.08404689282178879
encoder.encoder.weight_hh_l0_reverse: 0.0025250499602407217 0.08277169615030289
encoder.encoder.bias_ih_l0_reverse: 0.020162787288427353 0.0831521674990654
encoder.encoder.bias_hh_l0_reverse: 0.012028341181576252 0.08214277774095535
decider.lstm.weight_ih_l0: -0.0006877087871544063 0.14570894837379456
decider.lstm.weight_hh_l0: 0.000882541760802269 0.14569619297981262
decider.lstm.bias_ih_l0: 0.01039176993072033 0.15615850687026978
decider.lstm.bias_hh_l0: -0.008595661260187626 0.1389523148536682
decider.linear1.weight: 0.00351441977545619 0.11878308653831482
decider.linear1.bias: 0.009019941091537476 0.11475394666194916
decider.linear2.weight: 0.0015878049889579415 0.05173654854297638
decider.linear2.bias: 0.0026767123490571976 0.05547254532575607
decider.linear3.weight: -0.003166300244629383 0.05288658291101456
decider.linear3.bias: 0.020252611488103867 0.06425853073596954

Rewards:
183.7409
183.7409
183.7409
objective = 47.64982223510742
==== episode 5500/10000 ====
action = 2
probs = 0.7137 0.2757 0.0045 0.0061

action = 1
probs = 0.3979 0.5924 0.0041 0.0056

action = 1
probs = 0.0677 0.9125 0.0072 0.0126

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00026542722480371594 0.0820668414235115
encoder.encoder.weight_hh_l0: -0.00034928074455820024 0.0831037238240242
encoder.encoder.bias_ih_l0: 0.0009807466994971037 0.08419189602136612
encoder.encoder.bias_hh_l0: 0.010977823287248611 0.08321992307901382
encoder.encoder.weight_ih_l0_reverse: 0.000719478412065655 0.08403679728507996
encoder.encoder.weight_hh_l0_reverse: 0.002444843528792262 0.08275754749774933
encoder.encoder.bias_ih_l0_reverse: 0.019978655502200127 0.08312637358903885
encoder.encoder.bias_hh_l0_reverse: 0.011844214983284473 0.08219729363918304
decider.lstm.weight_ih_l0: -0.0006919512525200844 0.14568717777729034
decider.lstm.weight_hh_l0: 0.0008686243090778589 0.14565838873386383
decider.lstm.bias_ih_l0: 0.010378492064774036 0.15611766278743744
decider.lstm.bias_hh_l0: -0.008608946576714516 0.13888323307037354
decider.linear1.weight: 0.003502014558762312 0.11876551061868668
decider.linear1.bias: 0.008965791203081608 0.11474234610795975
decider.linear2.weight: 0.0015925830230116844 0.051737766712903976
decider.linear2.bias: 0.002673211507499218 0.05543796718120575
decider.linear3.weight: -0.0031572403386235237 0.05287598818540573
decider.linear3.bias: 0.02028251811861992 0.06481418013572693

Rewards:
140.2155
140.2155
140.2155
objective = 281.2095947265625
==== episode 5600/10000 ====
action = 1
probs = 0.7595 0.2317 0.0038 0.0049

action = 0
probs = 0.3624 0.6289 0.0037 0.0050

action = 1
probs = 0.0525 0.9299 0.0065 0.0111

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00024783998378552496 0.0821416899561882
encoder.encoder.weight_hh_l0: -0.0003448963398113847 0.0831933468580246
encoder.encoder.bias_ih_l0: 0.001487997709773481 0.08426017314195633
encoder.encoder.bias_hh_l0: 0.011485070921480656 0.08332788199186325
encoder.encoder.weight_ih_l0_reverse: 0.0007369770901277661 0.08412028104066849
encoder.encoder.weight_hh_l0_reverse: 0.0026344312354922295 0.08284363150596619
encoder.encoder.bias_ih_l0_reverse: 0.020532898604869843 0.08315468579530716
encoder.encoder.bias_hh_l0_reverse: 0.01239845808595419 0.08224359154701233
decider.lstm.weight_ih_l0: -0.0006186313112266362 0.14575354754924774
decider.lstm.weight_hh_l0: 0.000973588670603931 0.14572779834270477
decider.lstm.bias_ih_l0: 0.01076122559607029 0.1563050001859665
decider.lstm.bias_hh_l0: -0.00822620838880539 0.138935387134552
decider.linear1.weight: 0.00358973303809762 0.11884592473506927
decider.linear1.bias: 0.009363550692796707 0.1148090809583664
decider.linear2.weight: 0.0016676277155056596 0.05177150294184685
decider.linear2.bias: 0.002817115979269147 0.05544271320104599
decider.linear3.weight: -0.003199116326868534 0.05299666151404381
decider.linear3.bias: 0.020215101540088654 0.06448212265968323

Rewards:
151.0950
151.0950
151.0950
objective = 128.41590881347656
==== episode 5700/10000 ====
action = 0
probs = 0.7599 0.2315 0.0034 0.0052

action = 1
probs = 0.1796 0.8103 0.0035 0.0066

action = 0
probs = 0.0323 0.9493 0.0057 0.0127

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002454851637594402 0.0821906253695488
encoder.encoder.weight_hh_l0: -0.00033507298212498426 0.08324987441301346
encoder.encoder.bias_ih_l0: 0.001702993642538786 0.08432302623987198
encoder.encoder.bias_hh_l0: 0.011700063943862915 0.08340975642204285
encoder.encoder.weight_ih_l0_reverse: 0.0007293311064131558 0.08415810018777847
encoder.encoder.weight_hh_l0_reverse: 0.00270408159121871 0.08288637548685074
encoder.encoder.bias_ih_l0_reverse: 0.02079157717525959 0.08319893479347229
encoder.encoder.bias_hh_l0_reverse: 0.012657136656343937 0.0822831392288208
decider.lstm.weight_ih_l0: -0.0005822916282340884 0.14578582346439362
decider.lstm.weight_hh_l0: 0.0010244589066132903 0.14572390913963318
decider.lstm.bias_ih_l0: 0.01097693108022213 0.15643639862537384
decider.lstm.bias_hh_l0: -0.008010516874492168 0.13895921409130096
decider.linear1.weight: 0.003648629877716303 0.11890871822834015
decider.linear1.bias: 0.009634945541620255 0.11485297232866287
decider.linear2.weight: 0.001686082687228918 0.051802393049001694
decider.linear2.bias: 0.0028768163174390793 0.055451322346925735
decider.linear3.weight: -0.0031966667156666517 0.05311603471636772
decider.linear3.bias: 0.020267276093363762 0.06480826437473297

Rewards:
159.7293
159.7293
159.7293
objective = 208.6459197998047
==== episode 5800/10000 ====
action = 0
probs = 0.6959 0.2949 0.0036 0.0056

action = 1
probs = 0.1077 0.8849 0.0025 0.0049

action = 1
probs = 0.0178 0.9704 0.0036 0.0082

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00022045988589525223 0.08229202032089233
encoder.encoder.weight_hh_l0: -0.00034817386767826974 0.08340159058570862
encoder.encoder.bias_ih_l0: 0.002469269558787346 0.08448158204555511
encoder.encoder.bias_hh_l0: 0.012466337531805038 0.08361607789993286
encoder.encoder.weight_ih_l0_reverse: 0.0007879073964431882 0.08426057547330856
encoder.encoder.weight_hh_l0_reverse: 0.0029335860162973404 0.0829911157488823
encoder.encoder.bias_ih_l0_reverse: 0.0214455034583807 0.08314435929059982
encoder.encoder.bias_hh_l0_reverse: 0.013311064802110195 0.08242467790842056
decider.lstm.weight_ih_l0: -0.00042318113264627755 0.14588263630867004
decider.lstm.weight_hh_l0: 0.0013832233380526304 0.1457676738500595
decider.lstm.bias_ih_l0: 0.01189702469855547 0.1567942053079605
decider.lstm.bias_hh_l0: -0.007090431638062 0.13885805010795593
decider.linear1.weight: 0.0037307129241526127 0.11901672184467316
decider.linear1.bias: 0.010039027780294418 0.11488346010446548
decider.linear2.weight: 0.0017652763053774834 0.05183570459485054
decider.linear2.bias: 0.0030164322815835476 0.05550501495599747
decider.linear3.weight: -0.0032422086223959923 0.05323885753750801
decider.linear3.bias: 0.020183853805065155 0.06527525186538696

Rewards:
183.7409
183.7409
183.7409
objective = 31.534561157226562
==== episode 5900/10000 ====
action = 0
probs = 0.6755 0.3173 0.0028 0.0044

action = 3
probs = 0.0917 0.9031 0.0018 0.0034

action = 1
probs = 0.0166 0.9754 0.0025 0.0056

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00019066809909418225 0.08236067742109299
encoder.encoder.weight_hh_l0: -0.0003470156225375831 0.08350686728954315
encoder.encoder.bias_ih_l0: 0.0030084208119660616 0.08457385003566742
encoder.encoder.bias_hh_l0: 0.013005486689507961 0.08369646966457367
encoder.encoder.weight_ih_l0_reverse: 0.0008292834972962737 0.08434783667325974
encoder.encoder.weight_hh_l0_reverse: 0.0031103286892175674 0.08307692408561707
encoder.encoder.bias_ih_l0_reverse: 0.02188931405544281 0.08314361423254013
encoder.encoder.bias_hh_l0_reverse: 0.01375488005578518 0.08247480541467667
decider.lstm.weight_ih_l0: -0.0003338093520142138 0.14594978094100952
decider.lstm.weight_hh_l0: 0.0015682507073506713 0.1458389312028885
decider.lstm.bias_ih_l0: 0.012335743755102158 0.1569414585828781
decider.lstm.bias_hh_l0: -0.006651701871305704 0.13888370990753174
decider.linear1.weight: 0.0038060019724071026 0.1190924122929573
decider.linear1.bias: 0.010337059386074543 0.1149192675948143
decider.linear2.weight: 0.001846791012212634 0.05186730995774269
decider.linear2.bias: 0.0031375824473798275 0.055563148111104965
decider.linear3.weight: -0.003351157531142235 0.05333173647522926
decider.linear3.bias: 0.019980650395154953 0.06512357294559479

Rewards:
167.1077
167.1077
167.1077
objective = 339.74755859375
==== episode 6000/10000 ====
action = 0
probs = 0.8586 0.1353 0.0024 0.0036

action = 1
probs = 0.2383 0.7526 0.0030 0.0060

action = 1
probs = 0.0339 0.9532 0.0039 0.0090

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002205643686465919 0.08221007138490677
encoder.encoder.weight_hh_l0: -0.00037411146331578493 0.0832996666431427
encoder.encoder.bias_ih_l0: 0.00199908041395247 0.08438090980052948
encoder.encoder.bias_hh_l0: 0.011996142566204071 0.08341913670301437
encoder.encoder.weight_ih_l0_reverse: 0.0007605933933518827 0.08424003422260284
encoder.encoder.weight_hh_l0_reverse: 0.002868585055693984 0.08294691145420074
encoder.encoder.bias_ih_l0_reverse: 0.02109627239406109 0.08324373513460159
encoder.encoder.bias_hh_l0_reverse: 0.012961835600435734 0.08219701051712036
decider.lstm.weight_ih_l0: -0.0005101576680317521 0.1458432376384735
decider.lstm.weight_hh_l0: 0.001230951282195747 0.1458113044500351
decider.lstm.bias_ih_l0: 0.01131262257695198 0.15660351514816284
decider.lstm.bias_hh_l0: -0.007674822583794594 0.13906686007976532
decider.linear1.weight: 0.003781395498663187 0.11904935538768768
decider.linear1.bias: 0.010166998952627182 0.11492149531841278
decider.linear2.weight: 0.001793893170543015 0.05187046155333519
decider.linear2.bias: 0.0030732247978448868 0.055515218526124954
decider.linear3.weight: -0.003376121399924159 0.05333627015352249
decider.linear3.bias: 0.020070135593414307 0.06380557268857956

Rewards:
183.7409
183.7409
183.7409
objective = 29.678997039794922
==== episode 6100/10000 ====
action = 0
probs = 0.8574 0.1379 0.0019 0.0028

action = 1
probs = 0.1777 0.8160 0.0021 0.0042

action = 1
probs = 0.0262 0.9652 0.0026 0.0060

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002007350994972512 0.08230291306972504
encoder.encoder.weight_hh_l0: -0.00036568878567777574 0.08342953771352768
encoder.encoder.bias_ih_l0: 0.002628420013934374 0.08449734002351761
encoder.encoder.bias_hh_l0: 0.01262548565864563 0.08355459570884705
encoder.encoder.weight_ih_l0_reverse: 0.0007978642825037241 0.0843331590294838
encoder.encoder.weight_hh_l0_reverse: 0.003031698055565357 0.0830414816737175
encoder.encoder.bias_ih_l0_reverse: 0.02161906659603119 0.08322688192129135
encoder.encoder.bias_hh_l0_reverse: 0.013484635390341282 0.08227450400590897
decider.lstm.weight_ih_l0: -0.0004057698242831975 0.1459217518568039
decider.lstm.weight_hh_l0: 0.0014085256261751056 0.14588285982608795
decider.lstm.bias_ih_l0: 0.011883758008480072 0.15681646764278412
decider.lstm.bias_hh_l0: -0.007103688083589077 0.1390363872051239
decider.linear1.weight: 0.0038429219275712967 0.11914118379354477
decider.linear1.bias: 0.010495711117982864 0.1149723008275032
decider.linear2.weight: 0.0018932167440652847 0.0519096665084362
decider.linear2.bias: 0.00322949537076056 0.055578265339136124
decider.linear3.weight: -0.0036265216767787933 0.053590986877679825
decider.linear3.bias: 0.019855646416544914 0.06374652683734894

Rewards:
183.7409
183.7409
183.7409
objective = 24.04461669921875
==== episode 6200/10000 ====
action = 0
probs = 0.8182 0.1758 0.0021 0.0039

action = 1
probs = 0.1102 0.8829 0.0019 0.0049

action = 1
probs = 0.0169 0.9736 0.0024 0.0071

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00021369545720517635 0.08232038468122482
encoder.encoder.weight_hh_l0: -0.0003595563757698983 0.08344892412424088
encoder.encoder.bias_ih_l0: 0.0026663760654628277 0.08450618386268616
encoder.encoder.bias_hh_l0: 0.012663442641496658 0.08359944820404053
encoder.encoder.weight_ih_l0_reverse: 0.000782980234362185 0.08432058990001678
encoder.encoder.weight_hh_l0_reverse: 0.0029811414424329996 0.08303074538707733
encoder.encoder.bias_ih_l0_reverse: 0.021583737805485725 0.08321066200733185
encoder.encoder.bias_hh_l0_reverse: 0.01344930287450552 0.08233719319105148
decider.lstm.weight_ih_l0: -0.00041253495146520436 0.1459200233221054
decider.lstm.weight_hh_l0: 0.0014022842515259981 0.14583678543567657
decider.lstm.bias_ih_l0: 0.011927093379199505 0.15688011050224304
decider.lstm.bias_hh_l0: -0.00706034991890192 0.1389630138874054
decider.linear1.weight: 0.0038267408963292837 0.1191381961107254
decider.linear1.bias: 0.010448534041643143 0.11496409773826599
decider.linear2.weight: 0.0018632294377312064 0.051905687898397446
decider.linear2.bias: 0.003196415025740862 0.055565230548381805
decider.linear3.weight: -0.0036290392745286226 0.053683310747146606
decider.linear3.bias: 0.02000335231423378 0.0644989013671875

Rewards:
183.7409
183.7409
183.7409
objective = 21.555770874023438
==== episode 6300/10000 ====
action = 0
probs = 0.8305 0.1646 0.0017 0.0032

action = 1
probs = 0.0983 0.8962 0.0015 0.0040

action = 1
probs = 0.0148 0.9775 0.0019 0.0058

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00020520109683275223 0.08236001431941986
encoder.encoder.weight_hh_l0: -0.00036691801506094635 0.08351616561412811
encoder.encoder.bias_ih_l0: 0.003034734632819891 0.084572933614254
encoder.encoder.bias_hh_l0: 0.013031800277531147 0.08365099877119064
encoder.encoder.weight_ih_l0_reverse: 0.0008036325452849269 0.08437910676002502
encoder.encoder.weight_hh_l0_reverse: 0.003080445108935237 0.08308219164609909
encoder.encoder.bias_ih_l0_reverse: 0.021854618564248085 0.08323955535888672
encoder.encoder.bias_hh_l0_reverse: 0.013720190152525902 0.08235248923301697
decider.lstm.weight_ih_l0: -0.0003707615833263844 0.1459653377532959
decider.lstm.weight_hh_l0: 0.0014923671260476112 0.1458815485239029
decider.lstm.bias_ih_l0: 0.012160157784819603 0.1569887399673462
decider.lstm.bias_hh_l0: -0.00682728411629796 0.1390172839164734
decider.linear1.weight: 0.003864120692014694 0.11920877546072006
decider.linear1.bias: 0.010689305141568184 0.11501161754131317
decider.linear2.weight: 0.001897358102723956 0.05194269120693207
decider.linear2.bias: 0.003277809824794531 0.05559135973453522
decider.linear3.weight: -0.0037456287536770105 0.053821861743927
decider.linear3.bias: 0.019854724407196045 0.06433126330375671

Rewards:
183.7409
183.7409
183.7409
objective = 19.47744369506836
==== episode 6400/10000 ====
action = 0
probs = 0.8288 0.1673 0.0014 0.0026

action = 1
probs = 0.0834 0.9125 0.0011 0.0030

action = 1
probs = 0.0128 0.9815 0.0014 0.0042

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000186637815204449 0.08243205398321152
encoder.encoder.weight_hh_l0: -0.0003601430216804147 0.08362574875354767
encoder.encoder.bias_ih_l0: 0.0035636548418551683 0.08467324823141098
encoder.encoder.bias_hh_l0: 0.013560723513364792 0.0837455615401268
encoder.encoder.weight_ih_l0_reverse: 0.0008363354136236012 0.0844544917345047
encoder.encoder.weight_hh_l0_reverse: 0.0032240424770861864 0.08316396921873093
encoder.encoder.bias_ih_l0_reverse: 0.02227637730538845 0.08323603868484497
encoder.encoder.bias_hh_l0_reverse: 0.014141950756311417 0.08239594101905823
decider.lstm.weight_ih_l0: -0.0002903070126194507 0.14602872729301453
decider.lstm.weight_hh_l0: 0.0016299065900966525 0.14593428373336792
decider.lstm.bias_ih_l0: 0.012588712386786938 0.15712659060955048
decider.lstm.bias_hh_l0: -0.006398737896233797 0.13903018832206726
decider.linear1.weight: 0.003913134336471558 0.11929002404212952
decider.linear1.bias: 0.010995667427778244 0.11509102582931519
decider.linear2.weight: 0.001966770738363266 0.051976412534713745
decider.linear2.bias: 0.003388607408851385 0.05563187599182129
decider.linear3.weight: -0.0038657505065202713 0.053955670446157455
decider.linear3.bias: 0.019684594124555588 0.06421034038066864

Rewards:
183.7409
183.7409
183.7409
objective = 18.252609252929688
==== episode 6500/10000 ====
action = 0
probs = 0.8570 0.1399 0.0011 0.0020

action = 1
probs = 0.1009 0.8953 0.0011 0.0027

action = 1
probs = 0.0164 0.9783 0.0014 0.0040

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00018172078125644475 0.082439124584198
encoder.encoder.weight_hh_l0: -0.00036074037780053914 0.08363695442676544
encoder.encoder.bias_ih_l0: 0.003640482435002923 0.08468975871801376
encoder.encoder.bias_hh_l0: 0.013637552037835121 0.08372687548398972
encoder.encoder.weight_ih_l0_reverse: 0.0008237543515861034 0.08446357399225235
encoder.encoder.weight_hh_l0_reverse: 0.003219037549570203 0.08316025882959366
encoder.encoder.bias_ih_l0_reverse: 0.022234797477722168 0.08324985206127167
encoder.encoder.bias_hh_l0_reverse: 0.014100365340709686 0.08238402754068375
decider.lstm.weight_ih_l0: -0.0003016315749846399 0.1460302621126175
decider.lstm.weight_hh_l0: 0.0015998516464605927 0.14596407115459442
decider.lstm.bias_ih_l0: 0.012469342909753323 0.15712374448776245
decider.lstm.bias_hh_l0: -0.006518103182315826 0.13907088339328766
decider.linear1.weight: 0.003930667880922556 0.1193179339170456
decider.linear1.bias: 0.01104141678661108 0.11514080315828323
decider.linear2.weight: 0.001979969907552004 0.05199996381998062
decider.linear2.bias: 0.0034122741781175137 0.05566548556089401
decider.linear3.weight: -0.003963243216276169 0.05402927100658417
decider.linear3.bias: 0.01954791322350502 0.06375328451395035

Rewards:
183.7409
183.7409
183.7409
objective = 17.568889617919922
==== episode 6600/10000 ====
action = 1
probs = 0.9036 0.0943 0.0007 0.0014

action = 0
probs = 0.2891 0.7075 0.0010 0.0024

action = 1
probs = 0.0241 0.9708 0.0013 0.0038

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001598889648448676 0.0824614092707634
encoder.encoder.weight_hh_l0: -0.00035849070991389453 0.08366851508617401
encoder.encoder.bias_ih_l0: 0.003761416533961892 0.0847076028585434
encoder.encoder.bias_hh_l0: 0.013758489862084389 0.0837123915553093
encoder.encoder.weight_ih_l0_reverse: 0.00083702034316957 0.08449859172105789
encoder.encoder.weight_hh_l0_reverse: 0.0033012458588927984 0.08320079743862152
encoder.encoder.bias_ih_l0_reverse: 0.022392887622117996 0.08330371230840683
encoder.encoder.bias_hh_l0_reverse: 0.014258462935686111 0.08230689913034439
decider.lstm.weight_ih_l0: -0.0002838236396200955 0.14605605602264404
decider.lstm.weight_hh_l0: 0.001620978000573814 0.14602206647396088
decider.lstm.bias_ih_l0: 0.012523192912340164 0.15712736546993256
decider.lstm.bias_hh_l0: -0.0064642480574548244 0.1391439437866211
decider.linear1.weight: 0.0039610546082258224 0.11938086152076721
decider.linear1.bias: 0.011273887008428574 0.115206778049469
decider.linear2.weight: 0.002053764881566167 0.05203178524971008
decider.linear2.bias: 0.0035155368968844414 0.05568880960345268
decider.linear3.weight: -0.004054605029523373 0.05412690341472626
decider.linear3.bias: 0.019419044256210327 0.06295648217201233

Rewards:
151.0950
151.0950
151.0950
objective = 182.88888549804688
==== episode 6700/10000 ====
action = 0
probs = 0.9176 0.0808 0.0005 0.0010

action = 1
probs = 0.1310 0.8662 0.0008 0.0020

action = 1
probs = 0.0161 0.9802 0.0010 0.0027

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00013576082710642368 0.08254856616258621
encoder.encoder.weight_hh_l0: -0.0003377370594535023 0.08381149172782898
encoder.encoder.bias_ih_l0: 0.0043124048970639706 0.08478916436433792
encoder.encoder.bias_hh_l0: 0.0143094751983881 0.08379917591810226
encoder.encoder.weight_ih_l0_reverse: 0.0008916289079934359 0.08459777384996414
encoder.encoder.weight_hh_l0_reverse: 0.003508790396153927 0.08332422375679016
encoder.encoder.bias_ih_l0_reverse: 0.02297205477952957 0.08333965390920639
encoder.encoder.bias_hh_l0_reverse: 0.014837624505162239 0.08229045569896698
decider.lstm.weight_ih_l0: -0.0001847040985012427 0.14613835513591766
decider.lstm.weight_hh_l0: 0.001771862036548555 0.14608894288539886
decider.lstm.bias_ih_l0: 0.013059364631772041 0.15722687542438507
decider.lstm.bias_hh_l0: -0.0059280782006680965 0.13918781280517578
decider.linear1.weight: 0.004002667963504791 0.11950430274009705
decider.linear1.bias: 0.011788741685450077 0.11527584493160248
decider.linear2.weight: 0.0021449835039675236 0.05208520591259003
decider.linear2.bias: 0.0036611855030059814 0.055738165974617004
decider.linear3.weight: -0.0041548036970198154 0.05431145429611206
decider.linear3.bias: 0.01930125802755356 0.06284918636083603

Rewards:
183.7409
183.7409
183.7409
objective = 15.289026260375977
==== episode 6800/10000 ====
action = 0
probs = 0.9082 0.0897 0.0008 0.0013

action = 0
probs = 0.1134 0.8829 0.0012 0.0025

action = 1
probs = 0.0112 0.9830 0.0017 0.0041

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001593321212567389 0.08249685168266296
encoder.encoder.weight_hh_l0: -0.00034542835783213377 0.08371778577566147
encoder.encoder.bias_ih_l0: 0.003871314460411668 0.08473941683769226
encoder.encoder.bias_hh_l0: 0.01386838685721159 0.08376498520374298
encoder.encoder.weight_ih_l0_reverse: 0.0008427551947534084 0.08452808856964111
encoder.encoder.weight_hh_l0_reverse: 0.0033400491811335087 0.08324067294597626
encoder.encoder.bias_ih_l0_reverse: 0.02256379835307598 0.08329983055591583
encoder.encoder.bias_hh_l0_reverse: 0.014429370872676373 0.08231338858604431
decider.lstm.weight_ih_l0: -0.00024632122949697077 0.1460808515548706
decider.lstm.weight_hh_l0: 0.0016770779620856047 0.14601515233516693
decider.lstm.bias_ih_l0: 0.012755382806062698 0.15717816352844238
decider.lstm.bias_hh_l0: -0.006232057698071003 0.13912515342235565
decider.linear1.weight: 0.003975981846451759 0.11944197118282318
decider.linear1.bias: 0.011554554104804993 0.11525963991880417
decider.linear2.weight: 0.002077259588986635 0.052060872316360474
decider.linear2.bias: 0.0035441159270703793 0.05567050352692604
decider.linear3.weight: -0.004018689505755901 0.05423053354024887
decider.linear3.bias: 0.01953858509659767 0.06320058554410934

Rewards:
153.4407
153.4407
153.4407
objective = 117.12559509277344
==== episode 6900/10000 ====
action = 0
probs = 0.9312 0.0673 0.0006 0.0009

action = 1
probs = 0.1370 0.8598 0.0011 0.0021

action = 1
probs = 0.0148 0.9812 0.0012 0.0028

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00013477742322720587 0.08255670964717865
encoder.encoder.weight_hh_l0: -0.000337058212608099 0.083803690969944
encoder.encoder.bias_ih_l0: 0.004230620339512825 0.08480915427207947
encoder.encoder.bias_hh_l0: 0.014227690175175667 0.08380550146102905
encoder.encoder.weight_ih_l0_reverse: 0.0008749610278755426 0.08459880203008652
encoder.encoder.weight_hh_l0_reverse: 0.0034818670246750116 0.08331958204507828
encoder.encoder.bias_ih_l0_reverse: 0.022922653704881668 0.0833471268415451
encoder.encoder.bias_hh_l0_reverse: 0.01478822436183691 0.08228795230388641
decider.lstm.weight_ih_l0: -0.0001872345746960491 0.14613619446754456
decider.lstm.weight_hh_l0: 0.0017685274360701442 0.14608100056648254
decider.lstm.bias_ih_l0: 0.013055704534053802 0.1572374701499939
decider.lstm.bias_hh_l0: -0.005931733641773462 0.13918949663639069
decider.linear1.weight: 0.004016997758299112 0.11952852457761765
decider.linear1.bias: 0.011891715228557587 0.11531420052051544
decider.linear2.weight: 0.002165731741115451 0.052101533859968185
decider.linear2.bias: 0.003673107363283634 0.05568870157003403
decider.linear3.weight: -0.004092368297278881 0.054335255175828934
decider.linear3.bias: 0.01941426284611225 0.06274575740098953

Rewards:
183.7409
183.7409
183.7409
objective = 14.775741577148438
==== episode 7000/10000 ====
action = 0
probs = 0.9209 0.0777 0.0006 0.0009

action = 1
probs = 0.1127 0.8847 0.0009 0.0017

action = 1
probs = 0.0110 0.9860 0.0009 0.0021

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00012049026554450393 0.08260416239500046
encoder.encoder.weight_hh_l0: -0.0003344710567034781 0.08387695997953415
encoder.encoder.bias_ih_l0: 0.004520184360444546 0.08487651497125626
encoder.encoder.bias_hh_l0: 0.01451725885272026 0.08387290686368942
encoder.encoder.weight_ih_l0_reverse: 0.0008924159337766469 0.0846332535147667
encoder.encoder.weight_hh_l0_reverse: 0.003542689373716712 0.08335643261671066
encoder.encoder.bias_ih_l0_reverse: 0.023102087900042534 0.08331693708896637
encoder.encoder.bias_hh_l0_reverse: 0.01496765948832035 0.08236018568277359
decider.lstm.weight_ih_l0: -0.00013708192273043096 0.14616699516773224
decider.lstm.weight_hh_l0: 0.0018495620461180806 0.14609459042549133
decider.lstm.bias_ih_l0: 0.013329492881894112 0.15728972852230072
decider.lstm.bias_hh_l0: -0.005657947156578302 0.13916009664535522
decider.linear1.weight: 0.004023674875497818 0.11957190930843353
decider.linear1.bias: 0.012056493200361729 0.11531402170658112
decider.linear2.weight: 0.002216259017586708 0.05212543159723282
decider.linear2.bias: 0.003751493990421295 0.05571439489722252
decider.linear3.weight: -0.004162779077887535 0.054410502314567566
decider.linear3.bias: 0.01929921656847 0.06287708878517151

Rewards:
183.7409
183.7409
183.7409
objective = 13.419512748718262
==== episode 7100/10000 ====
action = 0
probs = 0.9322 0.0665 0.0005 0.0008

action = 1
probs = 0.1087 0.8887 0.0008 0.0017

action = 1
probs = 0.0094 0.9875 0.0008 0.0022

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011214178084628657 0.0826336145401001
encoder.encoder.weight_hh_l0: -0.00032919077784754336 0.08391857147216797
encoder.encoder.bias_ih_l0: 0.004662012681365013 0.08491209894418716
encoder.encoder.bias_hh_l0: 0.014659088104963303 0.08389908075332642
encoder.encoder.weight_ih_l0_reverse: 0.0009061103337444365 0.08466752618551254
encoder.encoder.weight_hh_l0_reverse: 0.003609774634242058 0.08339770138263702
encoder.encoder.bias_ih_l0_reverse: 0.023290084674954414 0.08335164189338684
encoder.encoder.bias_hh_l0_reverse: 0.015155660919845104 0.08234351873397827
decider.lstm.weight_ih_l0: -0.00010915463644778356 0.1461963802576065
decider.lstm.weight_hh_l0: 0.001898207701742649 0.14612005650997162
decider.lstm.bias_ih_l0: 0.013489609584212303 0.15732859075069427
decider.lstm.bias_hh_l0: -0.005497838370501995 0.1391957402229309
decider.linear1.weight: 0.004052713047713041 0.11962339282035828
decider.linear1.bias: 0.012265309691429138 0.11535442620515823
decider.linear2.weight: 0.0022509745322167873 0.05215362459421158
decider.linear2.bias: 0.0038121184334158897 0.055713385343551636
decider.linear3.weight: -0.004178163129836321 0.05449551343917847
decider.linear3.bias: 0.01930619776248932 0.06285058706998825

Rewards:
183.7409
183.7409
183.7409
objective = 12.292116165161133
==== episode 7200/10000 ====
action = 0
probs = 0.9243 0.0743 0.0006 0.0008

action = 1
probs = 0.0724 0.9254 0.0008 0.0014

action = 1
probs = 0.0065 0.9912 0.0007 0.0016

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00012346416770014912 0.08266367763280869
encoder.encoder.weight_hh_l0: -0.00032120506512001157 0.08397379517555237
encoder.encoder.bias_ih_l0: 0.00488632544875145 0.08495467156171799
encoder.encoder.bias_hh_l0: 0.014883400872349739 0.08395291119813919
encoder.encoder.weight_ih_l0_reverse: 0.0009303854894824326 0.08469922840595245
encoder.encoder.weight_hh_l0_reverse: 0.00366891548037529 0.08344017714262009
encoder.encoder.bias_ih_l0_reverse: 0.023497628048062325 0.08334873616695404
encoder.encoder.bias_hh_l0_reverse: 0.015363200567662716 0.08237678557634354
decider.lstm.weight_ih_l0: -7.657695095986128e-05 0.14622583985328674
decider.lstm.weight_hh_l0: 0.001955929445102811 0.1461295336484909
decider.lstm.bias_ih_l0: 0.013685855083167553 0.15739014744758606
decider.lstm.bias_hh_l0: -0.0053015947341918945 0.13918854296207428
decider.linear1.weight: 0.0040591927245259285 0.11965740472078323
decider.linear1.bias: 0.01236940547823906 0.11538366228342056
decider.linear2.weight: 0.002262699883431196 0.05216901749372482
decider.linear2.bias: 0.003843905869871378 0.05577727034687996
decider.linear3.weight: -0.004279810469597578 0.05474504083395004
decider.linear3.bias: 0.019361449405550957 0.06313500553369522

Rewards:
183.7409
183.7409
183.7409
objective = 10.108247756958008
==== episode 7300/10000 ====
action = 0
probs = 0.9240 0.0747 0.0005 0.0008

action = 1
probs = 0.0838 0.9142 0.0007 0.0013

action = 1
probs = 0.0070 0.9909 0.0006 0.0014

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001168002127087675 0.08265678584575653
encoder.encoder.weight_hh_l0: -0.00032501324312761426 0.08395334333181381
encoder.encoder.bias_ih_l0: 0.004787048790603876 0.08494989573955536
encoder.encoder.bias_hh_l0: 0.014784124679863453 0.08392798900604248
encoder.encoder.weight_ih_l0_reverse: 0.0009189575794152915 0.08468974381685257
encoder.encoder.weight_hh_l0_reverse: 0.003628803649917245 0.08341798931360245
encoder.encoder.bias_ih_l0_reverse: 0.02336575649678707 0.08333937078714371
encoder.encoder.bias_hh_l0_reverse: 0.015231333673000336 0.08239492028951645
decider.lstm.weight_ih_l0: -9.22317776712589e-05 0.14620943367481232
decider.lstm.weight_hh_l0: 0.0019280165433883667 0.1461256742477417
decider.lstm.bias_ih_l0: 0.013590432703495026 0.15733271837234497
decider.lstm.bias_hh_l0: -0.005397017579525709 0.13919386267662048
decider.linear1.weight: 0.0040532005950808525 0.11964499205350876
decider.linear1.bias: 0.012342683039605618 0.11534549295902252
decider.linear2.weight: 0.002328501082956791 0.052178192883729935
decider.linear2.bias: 0.0038952797185629606 0.055814098566770554
decider.linear3.weight: -0.004541858099400997 0.055018313229084015
decider.linear3.bias: 0.019272835925221443 0.0629734918475151

Rewards:
183.7409
183.7409
183.7409
objective = 10.888851165771484
==== episode 7400/10000 ====
action = 0
probs = 0.9013 0.0973 0.0006 0.0008

action = 1
probs = 0.0683 0.9301 0.0006 0.0010

action = 1
probs = 0.0063 0.9920 0.0005 0.0011

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011676311260089278 0.08267685770988464
encoder.encoder.weight_hh_l0: -0.00032157570240087807 0.08397753536701202
encoder.encoder.bias_ih_l0: 0.0048773386515676975 0.08498937636613846
encoder.encoder.bias_hh_l0: 0.014874415472149849 0.08397545665502548
encoder.encoder.weight_ih_l0_reverse: 0.0009197562467306852 0.08469587564468384
encoder.encoder.weight_hh_l0_reverse: 0.003610047046095133 0.08342001587152481
encoder.encoder.bias_ih_l0_reverse: 0.023360537365078926 0.08330154418945312
encoder.encoder.bias_hh_l0_reverse: 0.015226112678647041 0.08247962594032288
decider.lstm.weight_ih_l0: -8.040528337005526e-05 0.14621208608150482
decider.lstm.weight_hh_l0: 0.0019445911748334765 0.14611926674842834
decider.lstm.bias_ih_l0: 0.01366449799388647 0.15733309090137482
decider.lstm.bias_hh_l0: -0.005322947632521391 0.13915632665157318
decider.linear1.weight: 0.004040124826133251 0.11963358521461487
decider.linear1.bias: 0.01229008100926876 0.11531113088130951
decider.linear2.weight: 0.002349854912608862 0.052177537232637405
decider.linear2.bias: 0.003921825438737869 0.05586273968219757
decider.linear3.weight: -0.004729876294732094 0.05526939034461975
decider.linear3.bias: 0.01917942240834236 0.06319745630025864

Rewards:
183.7409
183.7409
183.7409
objective = 11.295683860778809
==== episode 7500/10000 ====
action = 0
probs = 0.8390 0.1590 0.0008 0.0012

action = 1
probs = 0.0394 0.9591 0.0005 0.0010

action = 1
probs = 0.0040 0.9946 0.0004 0.0010

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011049598106183112 0.0827273279428482
encoder.encoder.weight_hh_l0: -0.00031805303297005594 0.08404409140348434
encoder.encoder.bias_ih_l0: 0.005113499239087105 0.08503762632608414
encoder.encoder.bias_hh_l0: 0.015110577456653118 0.08402826637029648
encoder.encoder.weight_ih_l0_reverse: 0.0009559379541315138 0.08472342789173126
encoder.encoder.weight_hh_l0_reverse: 0.003680206136777997 0.08346693217754364
encoder.encoder.bias_ih_l0_reverse: 0.023612162098288536 0.08326398581266403
encoder.encoder.bias_hh_l0_reverse: 0.015477735549211502 0.08256399631500244
decider.lstm.weight_ih_l0: -4.233017534716055e-05 0.14624357223510742
decider.lstm.weight_hh_l0: 0.002030018949881196 0.14611363410949707
decider.lstm.bias_ih_l0: 0.013975240290164948 0.15738993883132935
decider.lstm.bias_hh_l0: -0.005012201145291328 0.1390841007232666
decider.linear1.weight: 0.004040529020130634 0.11964106559753418
decider.linear1.bias: 0.012341322377324104 0.11531513184309006
decider.linear2.weight: 0.0023754441644996405 0.05217099189758301
decider.linear2.bias: 0.003936791326850653 0.055899478495121
decider.linear3.weight: -0.004765767604112625 0.0553893968462944
decider.linear3.bias: 0.019233878701925278 0.06384140998125076

Rewards:
183.7409
183.7409
183.7409
objective = 13.634520530700684
==== episode 7600/10000 ====
action = 0
probs = 0.9114 0.0869 0.0006 0.0011

action = 1
probs = 0.0823 0.9154 0.0007 0.0015

action = 1
probs = 0.0077 0.9902 0.0006 0.0015

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00016605653217993677 0.08258222788572311
encoder.encoder.weight_hh_l0: -0.0003315942594781518 0.08385757356882095
encoder.encoder.bias_ih_l0: 0.004314027726650238 0.08485232293605804
encoder.encoder.bias_hh_l0: 0.014311103150248528 0.0838649645447731
encoder.encoder.weight_ih_l0_reverse: 0.0008970604394562542 0.08463975787162781
encoder.encoder.weight_hh_l0_reverse: 0.0034766914322972298 0.0833541601896286
encoder.encoder.bias_ih_l0_reverse: 0.02300545573234558 0.0833335593342781
encoder.encoder.bias_hh_l0_reverse: 0.014871028251945972 0.08237934112548828
decider.lstm.weight_ih_l0: -0.00016023237549234182 0.14615322649478912
decider.lstm.weight_hh_l0: 0.0018016386311501265 0.14607320725917816
decider.lstm.bias_ih_l0: 0.013198303058743477 0.15722720324993134
decider.lstm.bias_hh_l0: -0.005789151880890131 0.1392025202512741
decider.linear1.weight: 0.003999106585979462 0.11957000941038132
decider.linear1.bias: 0.012060696259140968 0.11527130752801895
decider.linear2.weight: 0.0022694715298712254 0.05215558782219887
decider.linear2.bias: 0.0037855729460716248 0.055858902633190155
decider.linear3.weight: -0.004770786501467228 0.055375903844833374
decider.linear3.bias: 0.01928769052028656 0.06319526582956314

Rewards:
183.7409
183.7409
183.7409
objective = 11.696615219116211
==== episode 7700/10000 ====
action = 0
probs = 0.9079 0.0903 0.0007 0.0011

action = 1
probs = 0.0644 0.9337 0.0007 0.0013

action = 1
probs = 0.0057 0.9927 0.0005 0.0011

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00017538762767799199 0.08260796964168549
encoder.encoder.weight_hh_l0: -0.0003366318705957383 0.08390836417675018
encoder.encoder.bias_ih_l0: 0.004527886398136616 0.08489543944597244
encoder.encoder.bias_hh_l0: 0.01452496275305748 0.08393510431051254
encoder.encoder.weight_ih_l0_reverse: 0.0009062711033038795 0.08466122299432755
encoder.encoder.weight_hh_l0_reverse: 0.0035125883296132088 0.08338133990764618
encoder.encoder.bias_ih_l0_reverse: 0.023145925253629684 0.08332455158233643
encoder.encoder.bias_hh_l0_reverse: 0.015011497773230076 0.08239439874887466
decider.lstm.weight_ih_l0: -0.0001282251178054139 0.1461798995733261
decider.lstm.weight_hh_l0: 0.001854993519373238 0.14609171450138092
decider.lstm.bias_ih_l0: 0.013394578360021114 0.15732207894325256
decider.lstm.bias_hh_l0: -0.005592876113951206 0.13918301463127136
decider.linear1.weight: 0.004003145266324282 0.11960142850875854
decider.linear1.bias: 0.012179695069789886 0.11530386656522751
decider.linear2.weight: 0.002296896418556571 0.052168846130371094
decider.linear2.bias: 0.0038321486208587885 0.055862121284008026
decider.linear3.weight: -0.004783974960446358 0.05548529699444771
decider.linear3.bias: 0.01933562010526657 0.06335602700710297

Rewards:
183.7409
183.7409
183.7409
objective = 10.564274787902832
==== episode 7800/10000 ====
action = 0
probs = 0.9226 0.0758 0.0006 0.0009

action = 1
probs = 0.0660 0.9323 0.0006 0.0011

action = 1
probs = 0.0062 0.9923 0.0004 0.0010

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00018210984126199037 0.0826219767332077
encoder.encoder.weight_hh_l0: -0.00033435161458328366 0.08393797278404236
encoder.encoder.bias_ih_l0: 0.004665018990635872 0.08491571247577667
encoder.encoder.bias_hh_l0: 0.014662091620266438 0.08396770060062408
encoder.encoder.weight_ih_l0_reverse: 0.0009055570117197931 0.08468476682901382
encoder.encoder.weight_hh_l0_reverse: 0.003550875000655651 0.08340789377689362
encoder.encoder.bias_ih_l0_reverse: 0.02326149493455887 0.08335451781749725
encoder.encoder.bias_hh_l0_reverse: 0.015127062797546387 0.08235280215740204
decider.lstm.weight_ih_l0: -0.0001111840465455316 0.14620357751846313
decider.lstm.weight_hh_l0: 0.0018727004062384367 0.14612668752670288
decider.lstm.bias_ih_l0: 0.01343812420964241 0.1574074625968933
decider.lstm.bias_hh_l0: -0.005549325607717037 0.13921886682510376
decider.linear1.weight: 0.004020455293357372 0.11963386088609695
decider.linear1.bias: 0.012237020768225193 0.11535884439945221
decider.linear2.weight: 0.002315385267138481 0.052185360342264175
decider.linear2.bias: 0.0038804616779088974 0.05588352680206299
decider.linear3.weight: -0.004853406455367804 0.05561359226703644
decider.linear3.bias: 0.01926669105887413 0.0630699023604393

Rewards:
183.7409
183.7409
183.7409
objective = 9.699939727783203
==== episode 7900/10000 ====
action = 0
probs = 0.9512 0.0478 0.0004 0.0006

action = 1
probs = 0.1172 0.8809 0.0007 0.0012

action = 1
probs = 0.0087 0.9898 0.0005 0.0011

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001702463923720643 0.08262765407562256
encoder.encoder.weight_hh_l0: -0.00033301295479759574 0.08393608033657074
encoder.encoder.bias_ih_l0: 0.004615990445017815 0.08489789813756943
encoder.encoder.bias_hh_l0: 0.014613060280680656 0.08390875160694122
encoder.encoder.weight_ih_l0_reverse: 0.0009166687377728522 0.08471574634313583
encoder.encoder.weight_hh_l0_reverse: 0.0036057273391634226 0.08343236893415451
encoder.encoder.bias_ih_l0_reverse: 0.023338699713349342 0.08343568444252014
encoder.encoder.bias_hh_l0_reverse: 0.015204270370304585 0.08223653584718704
decider.lstm.weight_ih_l0: -0.00011123489093733951 0.14621856808662415
decider.lstm.weight_hh_l0: 0.0018668188713490963 0.1461687535047531
decider.lstm.bias_ih_l0: 0.013401888310909271 0.15735994279384613
decider.lstm.bias_hh_l0: -0.0055855643004179 0.13932135701179504
decider.linear1.weight: 0.004046080633997917 0.11967705935239792
decider.linear1.bias: 0.012445393949747086 0.11538875848054886
decider.linear2.weight: 0.0023681181482970715 0.05221438407897949
decider.linear2.bias: 0.00395679147914052 0.055878471583127975
decider.linear3.weight: -0.004937648773193359 0.05574820563197136
decider.linear3.bias: 0.01917070522904396 0.062327854335308075

Rewards:
183.7409
183.7409
183.7409
objective = 11.461485862731934
==== episode 8000/10000 ====
action = 0
probs = 0.9476 0.0511 0.0005 0.0008

action = 1
probs = 0.1130 0.8850 0.0007 0.0013

action = 1
probs = 0.0076 0.9910 0.0004 0.0010

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00017712160479277372 0.08260288834571838
encoder.encoder.weight_hh_l0: -0.0003469659714028239 0.08390595763921738
encoder.encoder.bias_ih_l0: 0.0044633084908127785 0.08486553281545639
encoder.encoder.bias_hh_l0: 0.014460382051765919 0.0838988646864891
encoder.encoder.weight_ih_l0_reverse: 0.0009121049079112709 0.08469266444444656
encoder.encoder.weight_hh_l0_reverse: 0.003568147076293826 0.08340927213430405
encoder.encoder.bias_ih_l0_reverse: 0.02324318327009678 0.08341659605503082
encoder.encoder.bias_hh_l0_reverse: 0.01510875578969717 0.08224862813949585
decider.lstm.weight_ih_l0: -0.0001255624374607578 0.1461998075246811
decider.lstm.weight_hh_l0: 0.0018521102610975504 0.14614470303058624
decider.lstm.bias_ih_l0: 0.013347461819648743 0.15736378729343414
decider.lstm.bias_hh_l0: -0.005639994982630014 0.13930292427539825
decider.linear1.weight: 0.004032236989587545 0.11966048926115036
decider.linear1.bias: 0.012424686923623085 0.11535641551017761
decider.linear2.weight: 0.0023648813366889954 0.05221019685268402
decider.linear2.bias: 0.003934209700673819 0.05587533861398697
decider.linear3.weight: -0.004943571984767914 0.05580674111843109
decider.linear3.bias: 0.019230887293815613 0.0625024065375328

Rewards:
183.7409
183.7409
183.7409
objective = 11.330798149108887
==== episode 8100/10000 ====
action = 0
probs = 0.9784 0.0210 0.0002 0.0004

action = 0
probs = 0.3591 0.6385 0.0008 0.0016

action = 1
probs = 0.0147 0.9830 0.0007 0.0016

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001345940981991589 0.08261727541685104
encoder.encoder.weight_hh_l0: -0.00033713210723362863 0.08389142900705338
encoder.encoder.bias_ih_l0: 0.004392847418785095 0.08484235405921936
encoder.encoder.bias_hh_l0: 0.014389917254447937 0.08375393599271774
encoder.encoder.weight_ih_l0_reverse: 0.0009545205975882709 0.08478083461523056
encoder.encoder.weight_hh_l0_reverse: 0.003743208944797516 0.08349915593862534
encoder.encoder.bias_ih_l0_reverse: 0.023565208539366722 0.08359362185001373
encoder.encoder.bias_hh_l0_reverse: 0.015430780127644539 0.08207415789365768
decider.lstm.weight_ih_l0: -0.0001229689223691821 0.14623239636421204
decider.lstm.weight_hh_l0: 0.00183329195715487 0.14622288942337036
decider.lstm.bias_ih_l0: 0.013262651860713959 0.1572028249502182
decider.lstm.bias_hh_l0: -0.005724804475903511 0.13951613008975983
decider.linear1.weight: 0.004079807084053755 0.11971461772918701
decider.linear1.bias: 0.012611917220056057 0.11537449061870575
decider.linear2.weight: 0.0024141089525073767 0.05224065110087395
decider.linear2.bias: 0.004010987468063831 0.05587688088417053
decider.linear3.weight: -0.005031263455748558 0.05589968338608742
decider.linear3.bias: 0.019122354686260223 0.06102748215198517

Rewards:
153.4407
153.4407
153.4407
objective = 54.370540618896484
==== episode 8200/10000 ====
action = 0
probs = 0.9776 0.0217 0.0002 0.0004

action = 0
probs = 0.3030 0.6944 0.0008 0.0018

action = 1
probs = 0.0167 0.9802 0.0008 0.0022

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001486768596805632 0.08261848241090775
encoder.encoder.weight_hh_l0: -0.0003232973685953766 0.08388205617666245
encoder.encoder.bias_ih_l0: 0.004338174592703581 0.08482775092124939
encoder.encoder.bias_hh_l0: 0.01433524303138256 0.0837714821100235
encoder.encoder.weight_ih_l0_reverse: 0.0009147775126621127 0.08475147932767868
encoder.encoder.weight_hh_l0_reverse: 0.0036409643944352865 0.08345911651849747
encoder.encoder.bias_ih_l0_reverse: 0.023337559774518013 0.08356533199548721
encoder.encoder.bias_hh_l0_reverse: 0.015203132294118404 0.08209452778100967
decider.lstm.weight_ih_l0: -0.00014693921548314393 0.14621931314468384
decider.lstm.weight_hh_l0: 0.0017914570635184646 0.14621536433696747
decider.lstm.bias_ih_l0: 0.013089845888316631 0.15726879239082336
decider.lstm.bias_hh_l0: -0.005897605326026678 0.13947992026805878
decider.linear1.weight: 0.004084988962858915 0.11967938393354416
decider.linear1.bias: 0.012401600368320942 0.11541591584682465
decider.linear2.weight: 0.002367701381444931 0.052219320088624954
decider.linear2.bias: 0.003956906497478485 0.055867183953523636
decider.linear3.weight: -0.005024824291467667 0.055941205471754074
decider.linear3.bias: 0.019192643463611603 0.06114276498556137

Rewards:
153.4407
153.4407
153.4407
objective = 63.24500274658203
==== episode 8300/10000 ====
action = 0
probs = 0.9742 0.0249 0.0004 0.0006

action = 1
probs = 0.3296 0.6661 0.0014 0.0030

action = 1
probs = 0.0352 0.9599 0.0013 0.0037

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001815668074414134 0.08246521651744843
encoder.encoder.weight_hh_l0: -0.0003503577900119126 0.08368481695652008
encoder.encoder.bias_ih_l0: 0.0034603257663547993 0.0846041589975357
encoder.encoder.bias_hh_l0: 0.01345739420503378 0.08360844105482101
encoder.encoder.weight_ih_l0_reverse: 0.0008369232527911663 0.0845978707075119
encoder.encoder.weight_hh_l0_reverse: 0.003377859480679035 0.08329226076602936
encoder.encoder.bias_ih_l0_reverse: 0.022459721192717552 0.08352840691804886
encoder.encoder.bias_hh_l0_reverse: 0.014325293712317944 0.08200500905513763
decider.lstm.weight_ih_l0: -0.00029894409817643464 0.14608582854270935
decider.lstm.weight_hh_l0: 0.001577212824486196 0.14609229564666748
decider.lstm.bias_ih_l0: 0.012283515185117722 0.15708039700984955
decider.lstm.bias_hh_l0: -0.006703936494886875 0.1393856704235077
decider.linear1.weight: 0.004037701059132814 0.11954384297132492
decider.linear1.bias: 0.011787358671426773 0.11539284139871597
decider.linear2.weight: 0.0022088487166911364 0.052151456475257874
decider.linear2.bias: 0.0036750079598277807 0.05575650930404663
decider.linear3.weight: -0.004844570066779852 0.055730197578668594
decider.linear3.bias: 0.019550029188394547 0.061430349946022034

Rewards:
183.7409
183.7409
183.7409
objective = 29.000579833984375
==== episode 8400/10000 ====
action = 0
probs = 0.9540 0.0446 0.0006 0.0009

action = 1
probs = 0.1161 0.8806 0.0011 0.0021

action = 1
probs = 0.0115 0.9858 0.0008 0.0020

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00018624283256940544 0.08253995329141617
encoder.encoder.weight_hh_l0: -0.00035836841561831534 0.08378442376852036
encoder.encoder.bias_ih_l0: 0.003884843783453107 0.08476636558771133
encoder.encoder.bias_hh_l0: 0.01388191431760788 0.08382219821214676
encoder.encoder.weight_ih_l0_reverse: 0.0008207059581764042 0.08460276573896408
encoder.encoder.weight_hh_l0_reverse: 0.0033281196374446154 0.08328770101070404
encoder.encoder.bias_ih_l0_reverse: 0.02247115969657898 0.08339804410934448
encoder.encoder.bias_hh_l0_reverse: 0.014336732216179371 0.08220674842596054
decider.lstm.weight_ih_l0: -0.00024062975717242807 0.14612148702144623
decider.lstm.weight_hh_l0: 0.0016817566938698292 0.14609196782112122
decider.lstm.bias_ih_l0: 0.01275377906858921 0.157279372215271
decider.lstm.bias_hh_l0: -0.006233664695173502 0.13923214375972748
decider.linear1.weight: 0.004037713166326284 0.11959464102983475
decider.linear1.bias: 0.012003842741250992 0.11541295051574707
decider.linear2.weight: 0.00223144656047225 0.0521698072552681
decider.linear2.bias: 0.003712620120495558 0.05574868246912956
decider.linear3.weight: -0.004844733513891697 0.05583738535642624
decider.linear3.bias: 0.01954692229628563 0.06260769069194794

Rewards:
183.7409
183.7409
183.7409
objective = 11.547882080078125
==== episode 8500/10000 ====
action = 0
probs = 0.9450 0.0536 0.0006 0.0009

action = 1
probs = 0.0758 0.9219 0.0008 0.0015

action = 1
probs = 0.0076 0.9906 0.0005 0.0013

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00017514999490231276 0.08260896801948547
encoder.encoder.weight_hh_l0: -0.0003672835591714829 0.08387400954961777
encoder.encoder.bias_ih_l0: 0.0042883241549134254 0.08488589525222778
encoder.encoder.bias_hh_l0: 0.014285393990576267 0.08393435925245285
encoder.encoder.weight_ih_l0_reverse: 0.0008367712143808603 0.0846472755074501
encoder.encoder.weight_hh_l0_reverse: 0.0033982230816036463 0.08333443105220795
encoder.encoder.bias_ih_l0_reverse: 0.022742513567209244 0.0833725705742836
encoder.encoder.bias_hh_l0_reverse: 0.01460808515548706 0.0822899118065834
decider.lstm.weight_ih_l0: -0.0001860547054093331 0.1461743414402008
decider.lstm.weight_hh_l0: 0.0017678430303931236 0.14612506330013275
decider.lstm.bias_ih_l0: 0.013142673298716545 0.15739163756370544
decider.lstm.bias_hh_l0: -0.005844774190336466 0.1392277032136917
decider.linear1.weight: 0.004041023086756468 0.11965227127075195
decider.linear1.bias: 0.012205646373331547 0.11543812602758408
decider.linear2.weight: 0.002282174536958337 0.052196379750967026
decider.linear2.bias: 0.0038030920550227165 0.05579858273267746
decider.linear3.weight: -0.004922916647046804 0.05594078451395035
decider.linear3.bias: 0.019389059394598007 0.06287364661693573

Rewards:
183.7409
183.7409
183.7409
objective = 9.027397155761719
==== episode 8600/10000 ====
action = 0
probs = 0.9540 0.0447 0.0005 0.0007

action = 1
probs = 0.0712 0.9264 0.0008 0.0016

action = 1
probs = 0.0065 0.9914 0.0005 0.0015

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00017006322741508484 0.08265314996242523
encoder.encoder.weight_hh_l0: -0.00036141439341008663 0.08392471820116043
encoder.encoder.bias_ih_l0: 0.004500690847635269 0.08493677526712418
encoder.encoder.bias_hh_l0: 0.014497761614620686 0.08397144079208374
encoder.encoder.weight_ih_l0_reverse: 0.0008543760050088167 0.08469554036855698
encoder.encoder.weight_hh_l0_reverse: 0.003461001440882683 0.08338333666324615
encoder.encoder.bias_ih_l0_reverse: 0.022982997819781303 0.08341675251722336
encoder.encoder.bias_hh_l0_reverse: 0.014848574995994568 0.08228418231010437
decider.lstm.weight_ih_l0: -0.00015791160694789141 0.14621497690677643
decider.lstm.weight_hh_l0: 0.0018149776151403785 0.14615793526172638
decider.lstm.bias_ih_l0: 0.013315686956048012 0.15746033191680908
decider.lstm.bias_hh_l0: -0.005671754479408264 0.13928958773612976
decider.linear1.weight: 0.004063625354319811 0.11970596015453339
decider.linear1.bias: 0.012387759052217007 0.11549206078052521
decider.linear2.weight: 0.0022902078926563263 0.05222324654459953
decider.linear2.bias: 0.0038345411885529757 0.05577678605914116
decider.linear3.weight: -0.004912474192678928 0.05601697415113449
decider.linear3.bias: 0.019439302384853363 0.06287389993667603

Rewards:
183.7409
183.7409
183.7409
objective = 8.088295936584473
==== episode 8700/10000 ====
action = 0
probs = 0.9513 0.0476 0.0004 0.0007

action = 1
probs = 0.0572 0.9410 0.0006 0.0013

action = 1
probs = 0.0056 0.9928 0.0004 0.0012

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00016169770970009267 0.08271428942680359
encoder.encoder.weight_hh_l0: -0.0003637363261077553 0.08400449901819229
encoder.encoder.bias_ih_l0: 0.004860533867031336 0.08502659201622009
encoder.encoder.bias_hh_l0: 0.014857604168355465 0.08404072374105453
encoder.encoder.weight_ih_l0_reverse: 0.0008627022034488618 0.08473499119281769
encoder.encoder.weight_hh_l0_reverse: 0.003516246797516942 0.0834236592054367
encoder.encoder.bias_ih_l0_reverse: 0.023185158148407936 0.08340319991111755
encoder.encoder.bias_hh_l0_reverse: 0.0150507353246212 0.08232636004686356
decider.lstm.weight_ih_l0: -0.00011761463974835351 0.14625753462314606
decider.lstm.weight_hh_l0: 0.0018767390865832567 0.14618927240371704
decider.lstm.bias_ih_l0: 0.013569739647209644 0.15755309164524078
decider.lstm.bias_hh_l0: -0.005417700856924057 0.13929180800914764
decider.linear1.weight: 0.00407782755792141 0.11975204944610596
decider.linear1.bias: 0.01252169068902731 0.11552461236715317
decider.linear2.weight: 0.002326562535017729 0.05224239453673363
decider.linear2.bias: 0.003898667637258768 0.05581522360444069
decider.linear3.weight: -0.004972077906131744 0.05609019100666046
decider.linear3.bias: 0.019322358071804047 0.0628797635436058

Rewards:
183.7409
183.7409
183.7409
objective = 7.228166580200195
==== episode 8800/10000 ====
action = 0
probs = 0.9731 0.0262 0.0003 0.0004

action = 1
probs = 0.1413 0.8563 0.0008 0.0016

action = 1
probs = 0.0139 0.9838 0.0006 0.0017

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00016017205780372024 0.08267373591661453
encoder.encoder.weight_hh_l0: -0.00035336855216883123 0.08393234014511108
encoder.encoder.bias_ih_l0: 0.004496296867728233 0.08492874354124069
encoder.encoder.bias_hh_l0: 0.014493372291326523 0.0839252695441246
encoder.encoder.weight_ih_l0_reverse: 0.0008445830317214131 0.08472994714975357
encoder.encoder.weight_hh_l0_reverse: 0.0034809766802936792 0.08340456336736679
encoder.encoder.bias_ih_l0_reverse: 0.02298899181187153 0.08348412811756134
encoder.encoder.bias_hh_l0_reverse: 0.014854571782052517 0.0822087824344635
decider.lstm.weight_ih_l0: -0.00016501921345479786 0.14622953534126282
decider.lstm.weight_hh_l0: 0.0018035046523436904 0.1462259739637375
decider.lstm.bias_ih_l0: 0.013153841719031334 0.1575452983379364
decider.lstm.bias_hh_l0: -0.005833595525473356 0.13932594656944275
decider.linear1.weight: 0.004095381125807762 0.11973439157009125
decider.linear1.bias: 0.012380501255393028 0.11553224176168442
decider.linear2.weight: 0.0023359940387308598 0.052249424159526825
decider.linear2.bias: 0.003903698641806841 0.05583035200834274
decider.linear3.weight: -0.005035796668380499 0.05606680363416672
decider.linear3.bias: 0.019193042069673538 0.06169098988175392

Rewards:
183.7409
183.7409
183.7409
objective = 12.169794082641602
==== episode 8900/10000 ====
action = 0
probs = 0.9669 0.0319 0.0005 0.0007

action = 1
probs = 0.1238 0.8731 0.0010 0.0020

action = 1
probs = 0.0120 0.9855 0.0006 0.0019

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001899303460959345 0.08258822560310364
encoder.encoder.weight_hh_l0: -0.0003652038867585361 0.08384048193693161
encoder.encoder.bias_ih_l0: 0.004088393412530422 0.08482429385185242
encoder.encoder.bias_hh_l0: 0.014085465110838413 0.08387944847345352
encoder.encoder.weight_ih_l0_reverse: 0.0008274883730337024 0.08465424925088882
encoder.encoder.weight_hh_l0_reverse: 0.0033624107018113136 0.08332787454128265
encoder.encoder.bias_ih_l0_reverse: 0.022609176114201546 0.0834498405456543
encoder.encoder.bias_hh_l0_reverse: 0.01447475515305996 0.08219346404075623
decider.lstm.weight_ih_l0: -0.00022278769756667316 0.1461625099182129
decider.lstm.weight_hh_l0: 0.001729463809169829 0.14615961909294128
decider.lstm.bias_ih_l0: 0.012832170352339745 0.1574396938085556
decider.lstm.bias_hh_l0: -0.006155258975923061 0.13926321268081665
decider.linear1.weight: 0.004073427990078926 0.11966389417648315
decider.linear1.bias: 0.012164940126240253 0.11547251790761948
decider.linear2.weight: 0.0022463416680693626 0.05221439525485039
decider.linear2.bias: 0.0037448243238031864 0.05577123537659645
decider.linear3.weight: -0.004931060131639242 0.05597541853785515
decider.linear3.bias: 0.019480004906654358 0.06221063435077667

Rewards:
183.7409
183.7409
183.7409
objective = 11.267156600952148
==== episode 9000/10000 ====
action = 1
probs = 0.9728 0.0264 0.0004 0.0005

action = 0
probs = 0.2779 0.7196 0.0009 0.0016

action = 1
probs = 0.0090 0.9893 0.0004 0.0013

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00015460379654541612 0.08271225541830063
encoder.encoder.weight_hh_l0: -0.00036504611489363015 0.08398238569498062
encoder.encoder.bias_ih_l0: 0.004687422886490822 0.08498705178499222
encoder.encoder.bias_hh_l0: 0.014684495516121387 0.08398602157831192
encoder.encoder.weight_ih_l0_reverse: 0.0008690233225934207 0.08476049453020096
encoder.encoder.weight_hh_l0_reverse: 0.0035138006787747145 0.0834379568696022
encoder.encoder.bias_ih_l0_reverse: 0.02313944697380066 0.08348590135574341
encoder.encoder.bias_hh_l0_reverse: 0.015005025081336498 0.08225144445896149
decider.lstm.weight_ih_l0: -0.00014212926907930523 0.1462583690881729
decider.lstm.weight_hh_l0: 0.00185095751658082 0.14624029397964478
decider.lstm.bias_ih_l0: 0.013369943015277386 0.15759143233299255
decider.lstm.bias_hh_l0: -0.005617481656372547 0.13933660089969635
decider.linear1.weight: 0.004092018119990826 0.11978092789649963
decider.linear1.bias: 0.01260296255350113 0.11552926152944565
decider.linear2.weight: 0.002338188700377941 0.05226706713438034
decider.linear2.bias: 0.0039025507867336273 0.055801961570978165
decider.linear3.weight: -0.005004268139600754 0.05613222345709801
decider.linear3.bias: 0.01933184266090393 0.06212220340967178

Rewards:
151.0950
151.0950
151.0950
objective = 248.09188842773438
==== episode 9100/10000 ====
action = 0
probs = 0.9673 0.0318 0.0004 0.0005

action = 1
probs = 0.0886 0.9095 0.0007 0.0013

action = 1
probs = 0.0070 0.9916 0.0004 0.0011

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00016095936007332057 0.08270888775587082
encoder.encoder.weight_hh_l0: -0.00037195516051724553 0.08398571610450745
encoder.encoder.bias_ih_l0: 0.0046782586723566055 0.08499156683683395
encoder.encoder.bias_hh_l0: 0.014675328508019447 0.0840063989162445
encoder.encoder.weight_ih_l0_reverse: 0.0008691205875948071 0.08474933356046677
encoder.encoder.weight_hh_l0_reverse: 0.0034982000943273306 0.08342558890581131
encoder.encoder.bias_ih_l0_reverse: 0.0230955071747303 0.08346273005008698
encoder.encoder.bias_hh_l0_reverse: 0.01496108714491129 0.08226422220468521
decider.lstm.weight_ih_l0: -0.00014131914940662682 0.146254763007164
decider.lstm.weight_hh_l0: 0.0018497639102861285 0.1462351679801941
decider.lstm.bias_ih_l0: 0.01339247077703476 0.1575927734375
decider.lstm.bias_hh_l0: -0.005594964604824781 0.13932162523269653
decider.linear1.weight: 0.004078380297869444 0.11978141218423843
decider.linear1.bias: 0.012640375643968582 0.11550392210483551
decider.linear2.weight: 0.0023628859780728817 0.05227276310324669
decider.linear2.bias: 0.003943059593439102 0.05583158880472183
decider.linear3.weight: -0.00507176760584116 0.05617249011993408
decider.linear3.bias: 0.01919572800397873 0.06224628537893295

Rewards:
183.7409
183.7409
183.7409
objective = 8.365230560302734
==== episode 9200/10000 ====
action = 0
probs = 0.9679 0.0314 0.0003 0.0004

action = 1
probs = 0.0536 0.9451 0.0004 0.0009

action = 1
probs = 0.0045 0.9946 0.0002 0.0007

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00014346823445521295 0.0828283280134201
encoder.encoder.weight_hh_l0: -0.00036533601814880967 0.08414964377880096
encoder.encoder.bias_ih_l0: 0.005404921248555183 0.08515975624322891
encoder.encoder.bias_hh_l0: 0.015401993878185749 0.08416543155908585
encoder.encoder.weight_ih_l0_reverse: 0.0009146510856226087 0.08484435826539993
encoder.encoder.weight_hh_l0_reverse: 0.0036620672326534986 0.08353379368782043
encoder.encoder.bias_ih_l0_reverse: 0.023673173040151596 0.08346657454967499
encoder.encoder.bias_hh_l0_reverse: 0.015538753941655159 0.08231083303689957
decider.lstm.weight_ih_l0: -3.747742448467761e-05 0.14635862410068512
decider.lstm.weight_hh_l0: 0.001986454473808408 0.1463019996881485
decider.lstm.bias_ih_l0: 0.01401870884001255 0.1577650010585785
decider.lstm.bias_hh_l0: -0.004968734458088875 0.1393805891275406
decider.linear1.weight: 0.004098938312381506 0.11989624053239822
decider.linear1.bias: 0.012987102381885052 0.11560624837875366
decider.linear2.weight: 0.0024345736019313335 0.052318017929792404
decider.linear2.bias: 0.0040748403407633305 0.05586545169353485
decider.linear3.weight: -0.005130406003445387 0.056322693824768066
decider.linear3.bias: 0.019080961123108864 0.062393177300691605

Rewards:
183.7409
183.7409
183.7409
objective = 5.794919967651367
==== episode 9300/10000 ====
action = 0
probs = 0.9732 0.0260 0.0004 0.0004

action = 1
probs = 0.0618 0.9367 0.0005 0.0009

action = 1
probs = 0.0045 0.9945 0.0002 0.0007

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00015333473857026547 0.08281046152114868
encoder.encoder.weight_hh_l0: -0.0003716706996783614 0.08413009345531464
encoder.encoder.bias_ih_l0: 0.005293684545904398 0.08513639122247696
encoder.encoder.bias_hh_l0: 0.015290754847228527 0.08415010571479797
encoder.encoder.weight_ih_l0_reverse: 0.000909339461941272 0.08483635634183884
encoder.encoder.weight_hh_l0_reverse: 0.0036298721097409725 0.0835183635354042
encoder.encoder.bias_ih_l0_reverse: 0.023579664528369904 0.08348264545202255
encoder.encoder.bias_hh_l0_reverse: 0.015445242635905743 0.08227796852588654
decider.lstm.weight_ih_l0: -5.4537205869564787e-05 0.14634448289871216
decider.lstm.weight_hh_l0: 0.001961866393685341 0.14629538357257843
decider.lstm.bias_ih_l0: 0.01392902247607708 0.15773595869541168
decider.lstm.bias_hh_l0: -0.005058418959379196 0.1393817812204361
decider.linear1.weight: 0.004090951289981604 0.11989717930555344
decider.linear1.bias: 0.013002484105527401 0.1156095564365387
decider.linear2.weight: 0.002411013003438711 0.05232090502977371
decider.linear2.bias: 0.004039714578539133 0.055814050137996674
decider.linear3.weight: -0.005088303238153458 0.056322649121284485
decider.linear3.bias: 0.01925087347626686 0.06234092265367508

Rewards:
183.7409
183.7409
183.7409
objective = 6.002716064453125
==== episode 9400/10000 ====
action = 0
probs = 0.9799 0.0195 0.0003 0.0003

action = 1
probs = 0.0778 0.9208 0.0005 0.0009

action = 1
probs = 0.0048 0.9943 0.0002 0.0006

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00013199358363635838 0.08285437524318695
encoder.encoder.weight_hh_l0: -0.0003683680552057922 0.08417389541864395
encoder.encoder.bias_ih_l0: 0.005412544123828411 0.08518063277006149
encoder.encoder.bias_hh_l0: 0.015409614890813828 0.0841602012515068
encoder.encoder.weight_ih_l0_reverse: 0.0009259076905436814 0.08488276600837708
encoder.encoder.weight_hh_l0_reverse: 0.0036914008669555187 0.0835612490773201
encoder.encoder.bias_ih_l0_reverse: 0.023749032989144325 0.08352770656347275
encoder.encoder.bias_hh_l0_reverse: 0.015614612028002739 0.08226168155670166
decider.lstm.weight_ih_l0: -2.9751248803222552e-05 0.146375834941864
decider.lstm.weight_hh_l0: 0.0019940419588238 0.14633844792842865
decider.lstm.bias_ih_l0: 0.014064518734812737 0.15775328874588013
decider.lstm.bias_hh_l0: -0.004922928288578987 0.1394253522157669
decider.linear1.weight: 0.004101617261767387 0.11995244026184082
decider.linear1.bias: 0.013219846412539482 0.11562612652778625
decider.linear2.weight: 0.0024686064571142197 0.05235087126493454
decider.linear2.bias: 0.004127689637243748 0.0558277890086174
decider.linear3.weight: -0.005142467096447945 0.05639956519007683
decider.linear3.bias: 0.01914997212588787 0.06195426732301712

Rewards:
183.7409
183.7409
183.7409
objective = 6.649074077606201
==== episode 9500/10000 ====
action = 0
probs = 0.9807 0.0187 0.0003 0.0003

action = 1
probs = 0.0847 0.9136 0.0007 0.0010

action = 1
probs = 0.0058 0.9929 0.0004 0.0008

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00014467853179667145 0.08282718062400818
encoder.encoder.weight_hh_l0: -0.0003533190465532243 0.08412361890077591
encoder.encoder.bias_ih_l0: 0.005208723247051239 0.08513975143432617
encoder.encoder.bias_hh_l0: 0.015205792151391506 0.08414281904697418
encoder.encoder.weight_ih_l0_reverse: 0.0008981141145341098 0.08485762029886246
encoder.encoder.weight_hh_l0_reverse: 0.003619064576923847 0.0835292711853981
encoder.encoder.bias_ih_l0_reverse: 0.0235599372535944 0.08352381736040115
encoder.encoder.bias_hh_l0_reverse: 0.015425513498485088 0.08227062225341797
decider.lstm.weight_ih_l0: -5.425047129392624e-05 0.14634990692138672
decider.lstm.weight_hh_l0: 0.001962154870852828 0.1463230699300766
decider.lstm.bias_ih_l0: 0.013869864866137505 0.15774472057819366
decider.lstm.bias_hh_l0: -0.005117580760270357 0.13940873742103577
decider.linear1.weight: 0.004111641086637974 0.11990764737129211
decider.linear1.bias: 0.01300924550741911 0.1156318262219429
decider.linear2.weight: 0.0024104341864585876 0.05232790857553482
decider.linear2.bias: 0.0040457407012581825 0.055765461176633835
decider.linear3.weight: -0.005057882517576218 0.056327175348997116
decider.linear3.bias: 0.019316885620355606 0.06196455657482147

Rewards:
183.7409
183.7409
183.7409
objective = 7.166622161865234
==== episode 9600/10000 ====
action = 0
probs = 0.9842 0.0153 0.0003 0.0003

action = 1
probs = 0.0775 0.9207 0.0008 0.0010

action = 1
probs = 0.0048 0.9941 0.0004 0.0007

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00012445032189134508 0.08287602663040161
encoder.encoder.weight_hh_l0: -0.00034860504092648625 0.08417490124702454
encoder.encoder.bias_ih_l0: 0.0054112267680466175 0.08519444614648819
encoder.encoder.bias_hh_l0: 0.015408294275403023 0.0841779112815857
encoder.encoder.weight_ih_l0_reverse: 0.0009110277169384062 0.08489374816417694
encoder.encoder.weight_hh_l0_reverse: 0.0036708777770400047 0.08356669545173645
encoder.encoder.bias_ih_l0_reverse: 0.023739052936434746 0.08353440463542938
encoder.encoder.bias_hh_l0_reverse: 0.01560463197529316 0.0822812095284462
decider.lstm.weight_ih_l0: -2.426855280646123e-05 0.14638441801071167
decider.lstm.weight_hh_l0: 0.002003836678341031 0.14634452760219574
decider.lstm.bias_ih_l0: 0.014063399285078049 0.15778957307338715
decider.lstm.bias_hh_l0: -0.0049240500666201115 0.1394379436969757
decider.linear1.weight: 0.004121511243283749 0.11996667087078094
decider.linear1.bias: 0.01321293693035841 0.1156805083155632
decider.linear2.weight: 0.002431404311209917 0.052353378385305405
decider.linear2.bias: 0.004063231870532036 0.055726323276758194
decider.linear3.weight: -0.005016352981328964 0.056381624191999435
decider.linear3.bias: 0.019428543746471405 0.061994973570108414

Rewards:
183.7409
183.7409
183.7409
objective = 6.399736404418945
==== episode 9700/10000 ====
action = 0
probs = 0.9866 0.0129 0.0003 0.0002

action = 1
probs = 0.1012 0.8970 0.0008 0.0010

action = 1
probs = 0.0054 0.9935 0.0004 0.0007

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011558386904653162 0.08288196474313736
encoder.encoder.weight_hh_l0: -0.0003494054253678769 0.08417745679616928
encoder.encoder.bias_ih_l0: 0.005363614298403263 0.08519946783781052
encoder.encoder.bias_hh_l0: 0.015360681340098381 0.08416703343391418
encoder.encoder.weight_ih_l0_reverse: 0.0009153400314971805 0.08490625023841858
encoder.encoder.weight_hh_l0_reverse: 0.0036788261495530605 0.08357249945402145
encoder.encoder.bias_ih_l0_reverse: 0.023737596347928047 0.08356600254774094
encoder.encoder.bias_hh_l0_reverse: 0.015603180043399334 0.08225303143262863
decider.lstm.weight_ih_l0: -2.3279711967916228e-05 0.14638866484165192
decider.lstm.weight_hh_l0: 0.00200212886556983 0.14636600017547607
decider.lstm.bias_ih_l0: 0.014062333852052689 0.15776439011096954
decider.lstm.bias_hh_l0: -0.004925113637000322 0.13945640623569489
decider.linear1.weight: 0.00411971565335989 0.1199832633137703
decider.linear1.bias: 0.013308577239513397 0.11567200720310211
decider.linear2.weight: 0.0024673156440258026 0.052368663251399994
decider.linear2.bias: 0.0041165598668158054 0.05574220046401024
decider.linear3.weight: -0.0050657810643315315 0.05641157180070877
decider.linear3.bias: 0.019321322441101074 0.06167750433087349

Rewards:
183.7409
183.7409
183.7409
objective = 7.881104946136475
==== episode 9800/10000 ====
action = 0
probs = 0.9864 0.0132 0.0002 0.0002

action = 1
probs = 0.0723 0.9264 0.0006 0.0008

action = 1
probs = 0.0042 0.9949 0.0003 0.0006

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001015572197502479 0.08295261859893799
encoder.encoder.weight_hh_l0: -0.00034531112760305405 0.08426742255687714
encoder.encoder.bias_ih_l0: 0.005758835468441248 0.08528883010149002
encoder.encoder.bias_hh_l0: 0.015755902975797653 0.08425430208444595
encoder.encoder.weight_ih_l0_reverse: 0.0009376364178024232 0.08495288342237473
encoder.encoder.weight_hh_l0_reverse: 0.003749677911400795 0.08362437784671783
encoder.encoder.bias_ih_l0_reverse: 0.0240064337849617 0.08355159312486649
encoder.encoder.bias_hh_l0_reverse: 0.015872010961174965 0.08229159563779831
decider.lstm.weight_ih_l0: 2.2795535187469795e-05 0.14644108712673187
decider.lstm.weight_hh_l0: 0.0020592100918293 0.14639714360237122
decider.lstm.bias_ih_l0: 0.01434183120727539 0.15787041187286377
decider.lstm.bias_hh_l0: -0.0046456134878098965 0.13947799801826477
decider.linear1.weight: 0.004126491025090218 0.12004309147596359
decider.linear1.bias: 0.013480927795171738 0.11572201550006866
decider.linear2.weight: 0.002500273287296295 0.05239129438996315
decider.linear2.bias: 0.004175569862127304 0.05579066649079323
decider.linear3.weight: -0.005117403343319893 0.05649220198392868
decider.linear3.bias: 0.019206024706363678 0.06176094338297844

Rewards:
183.7409
183.7409
183.7409
objective = 5.838448524475098
==== episode 9900/10000 ====
action = 0
probs = 0.9862 0.0133 0.0003 0.0003

action = 1
probs = 0.0709 0.9266 0.0011 0.0015

action = 1
probs = 0.0046 0.9931 0.0007 0.0016

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001320719748036936 0.08287394791841507
encoder.encoder.weight_hh_l0: -0.0003071346727665514 0.08414438366889954
encoder.encoder.bias_ih_l0: 0.00526458490639925 0.08516216278076172
encoder.encoder.bias_hh_l0: 0.015261651016771793 0.08416738361120224
encoder.encoder.weight_ih_l0_reverse: 0.0008767019025981426 0.08488376438617706
encoder.encoder.weight_hh_l0_reverse: 0.0035901968367397785 0.08354778587818146
encoder.encoder.bias_ih_l0_reverse: 0.023578345775604248 0.08354581892490387
encoder.encoder.bias_hh_l0_reverse: 0.015443923883140087 0.08231966197490692
decider.lstm.weight_ih_l0: -4.449248081073165e-05 0.14637073874473572
decider.lstm.weight_hh_l0: 0.0019893450662493706 0.1463266760110855
decider.lstm.bias_ih_l0: 0.013880016282200813 0.15778756141662598
decider.lstm.bias_hh_l0: -0.005107434466481209 0.1394701451063156
decider.linear1.weight: 0.004147261381149292 0.11994417011737823
decider.linear1.bias: 0.013050396926701069 0.11573179066181183
decider.linear2.weight: 0.0023283236660063267 0.05234738066792488
decider.linear2.bias: 0.003921722527593374 0.055620867758989334
decider.linear3.weight: -0.004872020334005356 0.056340791285037994
decider.linear3.bias: 0.01985069550573826 0.06238681823015213

Rewards:
183.7409
183.7409
183.7409
objective = 5.950313568115234
==== episode 10000/10000 ====
action = 0
probs = 0.9808 0.0184 0.0004 0.0004

action = 1
probs = 0.0498 0.9479 0.0009 0.0014

action = 1
probs = 0.0034 0.9946 0.0006 0.0013

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00014737792662344873 0.08285219222307205
encoder.encoder.weight_hh_l0: -0.0003180458734277636 0.08412699401378632
encoder.encoder.bias_ih_l0: 0.005217591300606728 0.0851476714015007
encoder.encoder.bias_hh_l0: 0.015214658342301846 0.08419102430343628
encoder.encoder.weight_ih_l0_reverse: 0.0008726778323762119 0.08485778421163559
encoder.encoder.weight_hh_l0_reverse: 0.003557726973667741 0.08352290093898773
encoder.encoder.bias_ih_l0_reverse: 0.023512104526162148 0.08348682522773743
encoder.encoder.bias_hh_l0_reverse: 0.015377680771052837 0.08237041532993317
decider.lstm.weight_ih_l0: -4.770463056047447e-05 0.1463526487350464
decider.lstm.weight_hh_l0: 0.001978677697479725 0.14628469944000244
decider.lstm.bias_ih_l0: 0.013876639306545258 0.15776771306991577
decider.lstm.bias_hh_l0: -0.005110805854201317 0.13943855464458466
decider.linear1.weight: 0.004124066326767206 0.11991680413484573
decider.linear1.bias: 0.01296521257609129 0.11568441241979599
decider.linear2.weight: 0.002286971313878894 0.0523279644548893
decider.linear2.bias: 0.003865554928779602 0.055637504905462265
decider.linear3.weight: -0.004833117127418518 0.05629761144518852
decider.linear3.bias: 0.019942041486501694 0.06287787854671478

Rewards:
183.7409
183.7409
183.7409
objective = 4.7974066734313965
[INFO] : learning runtime (h:mm:ss): 0:02:22
[INFO] : learning end time: 12/17/2023 12:13:45 PM
