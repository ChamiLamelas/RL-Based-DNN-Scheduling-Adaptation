Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 06:37:56 PM
==== episode 1/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035160875995643437 0.08450309187173843
encoder.encoder.weight_hh_l0: -0.00020427064737305045 0.0862223207950592
encoder.encoder.bias_ih_l0: 0.008665014058351517 0.08549880236387253
encoder.encoder.bias_hh_l0: 0.018662089481949806 0.08466679602861404
encoder.encoder.weight_ih_l0_reverse: 0.0015372976195067167 0.08606104552745819
encoder.encoder.weight_hh_l0_reverse: 0.0029251037631183863 0.08476301282644272
encoder.encoder.bias_ih_l0_reverse: 0.023690924048423767 0.08426780253648758
encoder.encoder.bias_hh_l0_reverse: 0.015556471422314644 0.082919642329216
decider.lstm.weight_ih_l0: -2.0613855667761527e-05 0.1478523164987564
decider.lstm.weight_hh_l0: -0.002218451350927353 0.14635126292705536
decider.lstm.bias_ih_l0: 0.02020852081477642 0.15330742299556732
decider.lstm.bias_hh_l0: 0.0012210221029818058 0.14422865211963654
decider.linear1.weight: 0.0007359982701018453 0.12247231602668762
decider.linear1.bias: 0.017205456271767616 0.11711562424898148
decider.linear2.weight: 0.007849322631955147 0.060505460947752
decider.linear2.bias: 0.007335712667554617 0.06289131939411163
decider.linear3.weight: -0.04230334982275963 0.09962079674005508
decider.linear3.bias: -0.03156103193759918 0.057883575558662415

Rewards:
166.6321
166.6321
166.6321
objective = 0.0008111204952001572
==== episode 100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003515269490890205 0.08472945541143417
encoder.encoder.weight_hh_l0: -0.0002549012133385986 0.08677570521831512
encoder.encoder.bias_ih_l0: 0.010237914510071278 0.08577441424131393
encoder.encoder.bias_hh_l0: 0.020234985277056694 0.08502640575170517
encoder.encoder.weight_ih_l0_reverse: 0.0015542027540504932 0.08623852580785751
encoder.encoder.weight_hh_l0_reverse: 0.003098784014582634 0.08501827716827393
encoder.encoder.bias_ih_l0_reverse: 0.02471473254263401 0.08449354022741318
encoder.encoder.bias_hh_l0_reverse: 0.01658027619123459 0.0832146555185318
decider.lstm.weight_ih_l0: 0.00011593117960728705 0.1481955498456955
decider.lstm.weight_hh_l0: -0.0024624280631542206 0.1466158777475357
decider.lstm.bias_ih_l0: 0.02210637927055359 0.1536768078804016
decider.lstm.bias_hh_l0: 0.003118883352726698 0.14437362551689148
decider.linear1.weight: 0.0007147850701585412 0.12275838106870651
decider.linear1.bias: 0.01827358640730381 0.11743037402629852
decider.linear2.weight: 0.008193746209144592 0.060672540217638016
decider.linear2.bias: 0.00781761109828949 0.0632980465888977
decider.linear3.weight: -0.04230702668428421 0.09984800964593887
decider.linear3.bias: -0.031564801931381226 0.05985420569777489

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763917210511863 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.0002592774690128863 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361084714531898 0.08579018712043762
encoder.encoder.bias_hh_l0: 0.02035815827548504 0.08504932373762131
encoder.encoder.weight_ih_l0_reverse: 0.0015557360602542758 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124940142035484 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.024814868345856667 0.08450941741466522
encoder.encoder.bias_hh_l0_reverse: 0.016680410131812096 0.08324436098337173
decider.lstm.weight_ih_l0: 0.00012515961134340614 0.14821836352348328
decider.lstm.weight_hh_l0: -0.002497534267604351 0.14663484692573547
decider.lstm.bias_ih_l0: 0.022249383851885796 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032618907280266285 0.14436176419258118
decider.linear1.weight: 0.0007079931674525142 0.12277998775243759
decider.linear1.bias: 0.018381888046860695 0.11745066195726395
decider.linear2.weight: 0.008251426741480827 0.06068645790219307
decider.linear2.bias: 0.007896851748228073 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988043457269669
decider.linear3.bias: -0.031564824283123016 0.059987667948007584

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 1000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 1100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 1200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 1300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 1400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 1500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 1600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 1700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 1800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 1900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 2000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 2100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 2200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 2300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 2400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 2500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 2600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 2700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 2800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 2900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 3000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 3100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 3200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 3300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 3400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 3500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 3600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 3700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 3800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 3900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 4000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 4100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 4200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 4300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 4400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 4500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 4600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 4700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 4800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 4900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 5000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 5100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 5200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 5300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 5400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 5500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 5600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 5700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 5800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 5900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 6000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 6100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 6200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 6300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 6400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 6500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 6600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 6700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 6800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 6900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 7000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 7100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 7200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 7300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 7400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 7500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 7600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 7700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 7800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 7900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 8000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 8100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 8200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 8300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 8400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 8500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 8600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 8700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 8800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 8900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 9000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 9100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 9200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 9300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 9400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 9500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 9600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 9700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 9800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 9900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
==== episode 10000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034763794974423945 0.08473712205886841
encoder.encoder.weight_hh_l0: -0.00025927842943929136 0.08681770414113998
encoder.encoder.bias_ih_l0: 0.010361102409660816 0.08579017966985703
encoder.encoder.bias_hh_l0: 0.020358175039291382 0.08504931628704071
encoder.encoder.weight_ih_l0_reverse: 0.0015557358274236321 0.08625351637601852
encoder.encoder.weight_hh_l0_reverse: 0.0031124958768486977 0.08503804355859756
encoder.encoder.bias_ih_l0_reverse: 0.02481488138437271 0.08450942486524582
encoder.encoder.bias_hh_l0_reverse: 0.01668042130768299 0.08324436098337173
decider.lstm.weight_ih_l0: 0.0001251602079719305 0.14821836352348328
decider.lstm.weight_hh_l0: -0.0024975405540317297 0.14663484692573547
decider.lstm.bias_ih_l0: 0.02224939502775669 0.15371334552764893
decider.lstm.bias_hh_l0: 0.0032619060948491096 0.14436174929141998
decider.linear1.weight: 0.0007079914212226868 0.12277998775243759
decider.linear1.bias: 0.01838190294802189 0.11745065450668335
decider.linear2.weight: 0.008251437917351723 0.06068645790219307
decider.linear2.bias: 0.007896868512034416 0.06331638991832733
decider.linear3.weight: -0.0423070453107357 0.09988044202327728
decider.linear3.bias: -0.031564824283123016 0.059987686574459076

Rewards:
166.6321
166.6321
166.6321
objective = 1.9864095520460978e-05
[INFO] : learning runtime (h:mm:ss): 0:02:25
[INFO] : learning end time: 12/17/2023 06:40:20 PM
