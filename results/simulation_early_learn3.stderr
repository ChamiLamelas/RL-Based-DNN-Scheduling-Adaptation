Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(18, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/18/2023 10:10:37 AM
==== episode 1/75000 ====
action = 0
probs = 0.2580 0.2536 0.2070 0.2813

action = 0
probs = 0.2678 0.2576 0.1782 0.2965

action = 0
probs = 0.2725 0.2087 0.2096 0.3092

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004969098954461515 0.08069701492786407
encoder.encoder.weight_hh_l0: -0.00019702877034433186 0.0817427784204483
encoder.encoder.bias_ih_l0: -0.007158351596444845 0.08529666811227798
encoder.encoder.bias_hh_l0: 0.005913643632084131 0.08270575106143951
encoder.encoder.weight_ih_l0_reverse: 0.00043405889300629497 0.08245013654232025
encoder.encoder.weight_hh_l0_reverse: 0.0005472507909871638 0.08147497475147247
encoder.encoder.bias_ih_l0_reverse: 0.006771169602870941 0.07966497540473938
encoder.encoder.bias_hh_l0_reverse: 0.007065817713737488 0.08426670730113983
decider.lstm.weight_ih_l0: -0.0014921411639079452 0.1448039412498474
decider.lstm.weight_hh_l0: 0.0018998222658410668 0.14437223970890045
decider.lstm.bias_ih_l0: -0.031136522069573402 0.14021727442741394
decider.lstm.bias_hh_l0: 0.004684271290898323 0.15232859551906586
decider.linear1.weight: 0.0034030787646770477 0.11740315705537796
decider.linear1.bias: -0.002649693749845028 0.11449259519577026
decider.linear2.weight: 0.00037479313323274255 0.05117291584610939
decider.linear2.bias: -0.0016895374283194542 0.051762066781520844
decider.linear3.weight: 0.00025153334718197584 0.05124322697520256
decider.linear3.bias: -0.01404849998652935 0.022185705602169037

Rewards:
62.9344
62.9344
62.9344
objective = 83.34083557128906
==== episode 100/75000 ====
action = 0
probs = 0.2634 0.2291 0.1822 0.3254

action = 3
probs = 0.3005 0.2238 0.1907 0.2851

action = 3
probs = 0.3173 0.2066 0.2065 0.2696

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000521091278642416 0.08069299161434174
encoder.encoder.weight_hh_l0: -0.0002013068151427433 0.0817537009716034
encoder.encoder.bias_ih_l0: -0.0070624640211462975 0.08518945425748825
encoder.encoder.bias_hh_l0: 0.006009530741721392 0.08269105106592178
encoder.encoder.weight_ih_l0_reverse: 0.0004442050994839519 0.08247721940279007
encoder.encoder.weight_hh_l0_reverse: 0.0005303526995703578 0.08146543055772781
encoder.encoder.bias_ih_l0_reverse: 0.006621065083891153 0.07970443367958069
encoder.encoder.bias_hh_l0_reverse: 0.006915714591741562 0.08432309329509735
decider.lstm.weight_ih_l0: -0.0015002256259322166 0.14481335878372192
decider.lstm.weight_hh_l0: 0.0019015308935195208 0.14439532160758972
decider.lstm.bias_ih_l0: -0.03121194615960121 0.1403639167547226
decider.lstm.bias_hh_l0: 0.004608852788805962 0.15224000811576843
decider.linear1.weight: 0.0034243855625391006 0.1173941120505333
decider.linear1.bias: -0.002792735118418932 0.11460720002651215
decider.linear2.weight: 0.00037223511026240885 0.05117088556289673
decider.linear2.bias: -0.0016963580856099725 0.05188193917274475
decider.linear3.weight: 5.23602357134223e-05 0.05123328045010567
decider.linear3.bias: -0.014184449799358845 0.021688338369131088

Rewards:
60.9134
60.9134
60.9134
objective = 79.18919372558594
==== episode 200/75000 ====
action = 3
probs = 0.2309 0.2234 0.1761 0.3695

action = 3
probs = 0.2590 0.2054 0.1907 0.3448

action = 0
probs = 0.2864 0.1810 0.2424 0.2902

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005021258257329464 0.08071035146713257
encoder.encoder.weight_hh_l0: -0.0002036350197158754 0.08177164942026138
encoder.encoder.bias_ih_l0: -0.006918354891240597 0.08510737121105194
encoder.encoder.bias_hh_l0: 0.0061536431312561035 0.08268740028142929
encoder.encoder.weight_ih_l0_reverse: 0.0004779733717441559 0.08247682452201843
encoder.encoder.weight_hh_l0_reverse: 0.0005416868953034282 0.08146585524082184
encoder.encoder.bias_ih_l0_reverse: 0.006640568841248751 0.07966037839651108
encoder.encoder.bias_hh_l0_reverse: 0.0069352202117443085 0.08447682857513428
decider.lstm.weight_ih_l0: -0.0014995289966464043 0.14481879770755768
decider.lstm.weight_hh_l0: 0.0018973465776070952 0.14439263939857483
decider.lstm.bias_ih_l0: -0.031123491004109383 0.14048194885253906
decider.lstm.bias_hh_l0: 0.004697302356362343 0.1520421802997589
decider.linear1.weight: 0.003414805745705962 0.11739981919527054
decider.linear1.bias: -0.0027312245219945908 0.11468825489282608
decider.linear2.weight: 0.00036442663986235857 0.051177799701690674
decider.linear2.bias: -0.0017132512293756008 0.05190654844045639
decider.linear3.weight: 5.498179234564304e-06 0.05122252181172371
decider.linear3.bias: -0.014210378751158714 0.02073531597852707

Rewards:
61.0211
61.0211
61.0211
objective = 67.34112548828125
==== episode 300/75000 ====
action = 3
probs = 0.2147 0.2985 0.1767 0.3101

action = 0
probs = 0.2820 0.2440 0.1984 0.2756

action = 2
probs = 0.3262 0.2084 0.2239 0.2415

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00048628830700181425 0.08069857209920883
encoder.encoder.weight_hh_l0: -0.00021006092720199376 0.0817979946732521
encoder.encoder.bias_ih_l0: -0.007127820514142513 0.08506743609905243
encoder.encoder.bias_hh_l0: 0.005944177974015474 0.08263269066810608
encoder.encoder.weight_ih_l0_reverse: 0.0004634429351426661 0.08247340470552444
encoder.encoder.weight_hh_l0_reverse: 0.0005251027178019285 0.08146768063306808
encoder.encoder.bias_ih_l0_reverse: 0.006519407499581575 0.07969409972429276
encoder.encoder.bias_hh_l0_reverse: 0.006814058870077133 0.08449895679950714
decider.lstm.weight_ih_l0: -0.0015126235084608197 0.14479082822799683
decider.lstm.weight_hh_l0: 0.001964813331142068 0.14441627264022827
decider.lstm.bias_ih_l0: -0.03143502399325371 0.1405070573091507
decider.lstm.bias_hh_l0: 0.0043857647106051445 0.15213237702846527
decider.linear1.weight: 0.003423130139708519 0.1173706203699112
decider.linear1.bias: -0.0028146356344223022 0.11463546752929688
decider.linear2.weight: 0.00028981338255107403 0.051179107278585434
decider.linear2.bias: -0.001860322430729866 0.05191245675086975
decider.linear3.weight: 1.5515717677772045e-05 0.05119498074054718
decider.linear3.bias: -0.014135262928903103 0.022228356450796127

Rewards:
74.2016
74.2016
74.2016
objective = 97.27789306640625
==== episode 400/75000 ====
action = 0
probs = 0.2005 0.2995 0.1944 0.3055

action = 0
probs = 0.3104 0.2216 0.2291 0.2389

action = 3
probs = 0.3397 0.2064 0.2392 0.2147

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00047311399248428643 0.08070377260446548
encoder.encoder.weight_hh_l0: -0.00021427850879263133 0.08181602507829666
encoder.encoder.bias_ih_l0: -0.007094613276422024 0.0850524827837944
encoder.encoder.bias_hh_l0: 0.0059773847460746765 0.08264830708503723
encoder.encoder.weight_ih_l0_reverse: 0.00047097966307774186 0.08248364925384521
encoder.encoder.weight_hh_l0_reverse: 0.0005197172868065536 0.08146519213914871
encoder.encoder.bias_ih_l0_reverse: 0.00653000408783555 0.07975025475025177
encoder.encoder.bias_hh_l0_reverse: 0.006824655458331108 0.08457769453525543
decider.lstm.weight_ih_l0: -0.0015170362312346697 0.14479491114616394
decider.lstm.weight_hh_l0: 0.0020297642331570387 0.1444092094898224
decider.lstm.bias_ih_l0: -0.03161502629518509 0.14051271975040436
decider.lstm.bias_hh_l0: 0.004205767996609211 0.15211555361747742
decider.linear1.weight: 0.0034146453253924847 0.11736641824245453
decider.linear1.bias: -0.0027740723453462124 0.11458246409893036
decider.linear2.weight: 0.00024105938791763037 0.051189132034778595
decider.linear2.bias: -0.001954359235242009 0.05184022709727287
decider.linear3.weight: 9.743962436914444e-06 0.0511833056807518
decider.linear3.bias: -0.014122942462563515 0.022574057802557945

Rewards:
59.2883
59.2883
59.2883
objective = 85.28245544433594
==== episode 500/75000 ====
action = 3
probs = 0.2049 0.3066 0.2115 0.2769

action = 2
probs = 0.3019 0.2352 0.2522 0.2108

action = 0
probs = 0.3781 0.2103 0.2245 0.1871

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004641285922843963 0.08071690797805786
encoder.encoder.weight_hh_l0: -0.00022105197422206402 0.0818328857421875
encoder.encoder.bias_ih_l0: -0.007059853058308363 0.08502930402755737
encoder.encoder.bias_hh_l0: 0.006012143567204475 0.08262565732002258
encoder.encoder.weight_ih_l0_reverse: 0.00047234847443178296 0.08251400291919708
encoder.encoder.weight_hh_l0_reverse: 0.0005138340056873858 0.08146800845861435
encoder.encoder.bias_ih_l0_reverse: 0.006504021119326353 0.07978197187185287
encoder.encoder.bias_hh_l0_reverse: 0.006798671558499336 0.08457990735769272
decider.lstm.weight_ih_l0: -0.0015125867212191224 0.14480049908161163
decider.lstm.weight_hh_l0: 0.002023727633059025 0.14441290497779846
decider.lstm.bias_ih_l0: -0.031549543142318726 0.14048150181770325
decider.lstm.bias_hh_l0: 0.004271256737411022 0.15227341651916504
decider.linear1.weight: 0.0034242658875882626 0.11738218367099762
decider.linear1.bias: -0.00279430253431201 0.11455299705266953
decider.linear2.weight: 0.0002291123237228021 0.051193784922361374
decider.linear2.bias: -0.001975849736481905 0.05180322006344795
decider.linear3.weight: 7.965601980686188e-06 0.05120760202407837
decider.linear3.bias: -0.014110432006418705 0.023208102211356163

Rewards:
58.8011
58.8011
58.8011
objective = 71.2319564819336
==== episode 600/75000 ====
action = 3
probs = 0.2157 0.2941 0.2467 0.2435

action = 0
probs = 0.3158 0.2362 0.2685 0.1795

action = 1
probs = 0.4153 0.2147 0.2227 0.1473

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00046973515418358147 0.0807252749800682
encoder.encoder.weight_hh_l0: -0.0002371768350712955 0.08186127990484238
encoder.encoder.bias_ih_l0: -0.006791981402784586 0.08504609018564224
encoder.encoder.bias_hh_l0: 0.006280013360083103 0.08265762031078339
encoder.encoder.weight_ih_l0_reverse: 0.00047999992966651917 0.08256065845489502
encoder.encoder.weight_hh_l0_reverse: 0.000517192471306771 0.08149129897356033
encoder.encoder.bias_ih_l0_reverse: 0.006529058795422316 0.07987793534994125
encoder.encoder.bias_hh_l0_reverse: 0.006823712028563023 0.08460419625043869
decider.lstm.weight_ih_l0: -0.0015165965305641294 0.14483006298542023
decider.lstm.weight_hh_l0: 0.0018984507769346237 0.14440137147903442
decider.lstm.bias_ih_l0: -0.03127991408109665 0.14040981233119965
decider.lstm.bias_hh_l0: 0.004540875554084778 0.15254363417625427
decider.linear1.weight: 0.00339339068159461 0.11740647256374359
decider.linear1.bias: -0.0026947790756821632 0.11451321095228195
decider.linear2.weight: 0.00022722480935044587 0.05120290443301201
decider.linear2.bias: -0.0020114772487431765 0.05176820605993271
decider.linear3.weight: -1.6096746549010277e-06 0.05120816454291344
decider.linear3.bias: -0.014112806878983974 0.02412450686097145

Rewards:
60.0766
60.0766
60.0766
objective = 82.18727111816406
==== episode 700/75000 ====
action = 1
probs = 0.2383 0.2876 0.2300 0.2441

action = 0
probs = 0.3556 0.2175 0.2373 0.1896

action = 0
probs = 0.4292 0.2006 0.2054 0.1649

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000496012915391475 0.08073603361845016
encoder.encoder.weight_hh_l0: -0.0002249175449833274 0.08184902369976044
encoder.encoder.bias_ih_l0: -0.006750396452844143 0.08504877984523773
encoder.encoder.bias_hh_l0: 0.006321593187749386 0.08269771188497543
encoder.encoder.weight_ih_l0_reverse: 0.0004754117107950151 0.08257704973220825
encoder.encoder.weight_hh_l0_reverse: 0.0005127440090291202 0.08149772137403488
encoder.encoder.bias_ih_l0_reverse: 0.00645576324313879 0.07992333918809891
encoder.encoder.bias_hh_l0_reverse: 0.006750417407602072 0.08456157147884369
decider.lstm.weight_ih_l0: -0.0015197375323623419 0.14484016597270966
decider.lstm.weight_hh_l0: 0.0019225524738430977 0.14440500736236572
decider.lstm.bias_ih_l0: -0.03130321949720383 0.1403954178094864
decider.lstm.bias_hh_l0: 0.004517572931945324 0.15256428718566895
decider.linear1.weight: 0.003425035160034895 0.11739754676818848
decider.linear1.bias: -0.002790813334286213 0.11451023817062378
decider.linear2.weight: 0.00019299471750855446 0.05120076984167099
decider.linear2.bias: -0.002067181281745434 0.051786694675683975
decider.linear3.weight: -1.0843388736248016e-05 0.05115320160984993
decider.linear3.bias: -0.014128003269433975 0.023971447721123695

Rewards:
60.4191
60.4191
60.4191
objective = 62.95978927612305
==== episode 800/75000 ====
action = 0
probs = 0.2419 0.3025 0.2290 0.2266

action = 0
probs = 0.3420 0.2153 0.2654 0.1773

action = 0
probs = 0.3472 0.2144 0.2567 0.1817

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004923500237055123 0.08075576275587082
encoder.encoder.weight_hh_l0: -0.00022601652017328888 0.08186230063438416
encoder.encoder.bias_ih_l0: -0.006839570123702288 0.08500882983207703
encoder.encoder.bias_hh_l0: 0.006232419982552528 0.08264247328042984
encoder.encoder.weight_ih_l0_reverse: 0.0004750253283418715 0.08259455114603043
encoder.encoder.weight_hh_l0_reverse: 0.0005124384770169854 0.08151664584875107
encoder.encoder.bias_ih_l0_reverse: 0.006356397643685341 0.0799134373664856
encoder.encoder.bias_hh_l0_reverse: 0.006651052739471197 0.08457181602716446
decider.lstm.weight_ih_l0: -0.0015202341601252556 0.14483024179935455
decider.lstm.weight_hh_l0: 0.0019530216231942177 0.14440031349658966
decider.lstm.bias_ih_l0: -0.03137045353651047 0.14051154255867004
decider.lstm.bias_hh_l0: 0.004450338892638683 0.15254202485084534
decider.linear1.weight: 0.00350361131131649 0.11738251894712448
decider.linear1.bias: -0.0030162278562784195 0.11455690115690231
decider.linear2.weight: 0.0001455415622331202 0.05118962377309799
decider.linear2.bias: -0.0021531488746404648 0.051773328334093094
decider.linear3.weight: 3.814697265625e-06 0.051103007048368454
decider.linear3.bias: -0.014109021052718163 0.024044359102845192

Rewards:
62.9344
62.9344
62.9344
objective = 74.47566986083984
==== episode 900/75000 ====
action = 2
probs = 0.1876 0.3268 0.2461 0.2394

action = 3
probs = 0.2506 0.2748 0.2650 0.2096

action = 0
probs = 0.3352 0.2378 0.2438 0.1831

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00050525733968243 0.08072713017463684
encoder.encoder.weight_hh_l0: -0.00018361619731877 0.08183775842189789
encoder.encoder.bias_ih_l0: -0.0069961389526724815 0.08506226539611816
encoder.encoder.bias_hh_l0: 0.006075850687921047 0.08273114264011383
encoder.encoder.weight_ih_l0_reverse: 0.0004801465547643602 0.08253585547208786
encoder.encoder.weight_hh_l0_reverse: 0.0005274845752865076 0.08151932060718536
encoder.encoder.bias_ih_l0_reverse: 0.0063709840178489685 0.07985442876815796
encoder.encoder.bias_hh_l0_reverse: 0.0066656372509896755 0.08472476899623871
decider.lstm.weight_ih_l0: -0.0015214106533676386 0.1448109745979309
decider.lstm.weight_hh_l0: 0.0020503392443060875 0.14432081580162048
decider.lstm.bias_ih_l0: -0.03161828964948654 0.1404324173927307
decider.lstm.bias_hh_l0: 0.0042025065049529076 0.1522810459136963
decider.linear1.weight: 0.003483317792415619 0.11736203730106354
decider.linear1.bias: -0.002967594191431999 0.11452573537826538
decider.linear2.weight: 0.00013291704817675054 0.051194578409194946
decider.linear2.bias: -0.002198898931965232 0.051769424229860306
decider.linear3.weight: 1.9677449017763138e-05 0.05107505992054939
decider.linear3.bias: -0.014059162698686123 0.023721277713775635

Rewards:
75.7722
75.7722
75.7722
objective = 102.48477172851562
==== episode 1000/75000 ====
action = 2
probs = 0.1814 0.3446 0.2503 0.2237

action = 2
probs = 0.2489 0.2825 0.2817 0.1869

action = 1
probs = 0.3433 0.2324 0.2620 0.1623

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004895962192676961 0.08074589818716049
encoder.encoder.weight_hh_l0: -0.00018848624313250184 0.08186456561088562
encoder.encoder.bias_ih_l0: -0.00697759073227644 0.08500725775957108
encoder.encoder.bias_hh_l0: 0.006094394717365503 0.08271018415689468
encoder.encoder.weight_ih_l0_reverse: 0.0004888108232989907 0.08255861699581146
encoder.encoder.weight_hh_l0_reverse: 0.0005242624902166426 0.08153636008501053
encoder.encoder.bias_ih_l0_reverse: 0.006308761890977621 0.07986991107463837
encoder.encoder.bias_hh_l0_reverse: 0.006603416055440903 0.08477572351694107
decider.lstm.weight_ih_l0: -0.0015197843313217163 0.1448085457086563
decider.lstm.weight_hh_l0: 0.0020463932305574417 0.1443384736776352
decider.lstm.bias_ih_l0: -0.031576987355947495 0.14045394957065582
decider.lstm.bias_hh_l0: 0.0042438022792339325 0.15230746567249298
decider.linear1.weight: 0.0034608514979481697 0.11737138032913208
decider.linear1.bias: -0.0028938185423612595 0.11451204866170883
decider.linear2.weight: 0.00014628717326559126 0.05120255798101425
decider.linear2.bias: -0.002171216532588005 0.05177838355302811
decider.linear3.weight: 6.176764145493507e-06 0.05111340433359146
decider.linear3.bias: -0.01406807266175747 0.024285702034831047

Rewards:
72.2231
72.2231
72.2231
objective = 98.98433685302734
==== episode 1100/75000 ====
action = 0
probs = 0.1578 0.3566 0.2614 0.2242

action = 2
probs = 0.2409 0.3054 0.2576 0.1961

action = 0
probs = 0.3184 0.2544 0.2548 0.1724

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004934905446134508 0.08075332641601562
encoder.encoder.weight_hh_l0: -0.0001743326138239354 0.08186439424753189
encoder.encoder.bias_ih_l0: -0.006906930822879076 0.08506786078214645
encoder.encoder.bias_hh_l0: 0.0061650583520531654 0.0827874019742012
encoder.encoder.weight_ih_l0_reverse: 0.0005089367623440921 0.08255524188280106
encoder.encoder.weight_hh_l0_reverse: 0.0005322687793523073 0.08157403022050858
encoder.encoder.bias_ih_l0_reverse: 0.006336476653814316 0.079859659075737
encoder.encoder.bias_hh_l0_reverse: 0.006631131749600172 0.08486659824848175
decider.lstm.weight_ih_l0: -0.0015280017396435142 0.14480365812778473
decider.lstm.weight_hh_l0: 0.0019801887683570385 0.144240140914917
decider.lstm.bias_ih_l0: -0.03145189583301544 0.14055705070495605
decider.lstm.bias_hh_l0: 0.0043688928708434105 0.15232130885124207
decider.linear1.weight: 0.003439782653003931 0.11738721281290054
decider.linear1.bias: -0.002831275574862957 0.11446432769298553
decider.linear2.weight: 0.00016917812172323465 0.051209092140197754
decider.linear2.bias: -0.0021484363824129105 0.05181881785392761
decider.linear3.weight: 1.0464107617735863e-05 0.051134735345840454
decider.linear3.bias: -0.014047637581825256 0.02423337660729885

Rewards:
62.4311
62.4311
62.4311
objective = 90.469482421875
==== episode 1200/75000 ====
action = 2
probs = 0.1385 0.3585 0.2649 0.2381

action = 1
probs = 0.1797 0.3147 0.2824 0.2232

action = 2
probs = 0.2564 0.2591 0.2940 0.1905

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00047432410065084696 0.08076304197311401
encoder.encoder.weight_hh_l0: -0.00016530422726646066 0.08187064528465271
encoder.encoder.bias_ih_l0: -0.006995804142206907 0.08503592759370804
encoder.encoder.bias_hh_l0: 0.006076186895370483 0.0827532485127449
encoder.encoder.weight_ih_l0_reverse: 0.0005105829332023859 0.08255454152822495
encoder.encoder.weight_hh_l0_reverse: 0.0005403546383604407 0.0815797746181488
encoder.encoder.bias_ih_l0_reverse: 0.006333502009510994 0.07976415008306503
encoder.encoder.bias_hh_l0_reverse: 0.006628156173974276 0.08494687080383301
decider.lstm.weight_ih_l0: -0.0015286740381270647 0.1447923481464386
decider.lstm.weight_hh_l0: 0.002007307019084692 0.1442481428384781
decider.lstm.bias_ih_l0: -0.031557708978652954 0.14058060944080353
decider.lstm.bias_hh_l0: 0.00426308810710907 0.15210214257240295
decider.linear1.weight: 0.0034441673196852207 0.11737726628780365
decider.linear1.bias: -0.0028541963547468185 0.11451398581266403
decider.linear2.weight: 0.00014941883273422718 0.05121114104986191
decider.linear2.bias: -0.0021940283477306366 0.05184933915734291
decider.linear3.weight: 1.832796260714531e-05 0.051112763583660126
decider.linear3.bias: -0.01402480062097311 0.023603547364473343

Rewards:
59.3096
59.3096
59.3096
objective = 73.31959533691406
==== episode 1300/75000 ====
action = 1
probs = 0.1337 0.3420 0.2445 0.2799

action = 1
probs = 0.1707 0.2833 0.2704 0.2756

action = 2
probs = 0.2345 0.2574 0.2977 0.2104

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004766681231558323 0.08077219128608704
encoder.encoder.weight_hh_l0: -0.00015679305943194777 0.08186699450016022
encoder.encoder.bias_ih_l0: -0.006913631223142147 0.08507160097360611
encoder.encoder.bias_hh_l0: 0.006158357951790094 0.0827757716178894
encoder.encoder.weight_ih_l0_reverse: 0.0005228203372098505 0.08256297558546066
encoder.encoder.weight_hh_l0_reverse: 0.0005490886978805065 0.08159364759922028
encoder.encoder.bias_ih_l0_reverse: 0.006394465919584036 0.07975850999355316
encoder.encoder.bias_hh_l0_reverse: 0.006689122878015041 0.08496162295341492
decider.lstm.weight_ih_l0: -0.0015308677684515715 0.1447974592447281
decider.lstm.weight_hh_l0: 0.001991884084418416 0.14423668384552002
decider.lstm.bias_ih_l0: -0.031513020396232605 0.1405622959136963
decider.lstm.bias_hh_l0: 0.004307771101593971 0.15205354988574982
decider.linear1.weight: 0.003463214263319969 0.11737697571516037
decider.linear1.bias: -0.002973010763525963 0.11455009132623672
decider.linear2.weight: 0.00013064459199085832 0.051207881420850754
decider.linear2.bias: -0.002234203275293112 0.05190723016858101
decider.linear3.weight: 2.729578409343958e-05 0.051081642508506775
decider.linear3.bias: -0.014008906669914722 0.02275116741657257

Rewards:
74.4454
74.4454
74.4454
objective = 87.99220275878906
==== episode 1400/75000 ====
action = 1
probs = 0.1454 0.3209 0.2514 0.2823

action = 3
probs = 0.1992 0.2463 0.2729 0.2816

action = 1
probs = 0.2689 0.2353 0.2873 0.2086

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00048703126958571374 0.0807885080575943
encoder.encoder.weight_hh_l0: -0.0001523841347079724 0.08187490701675415
encoder.encoder.bias_ih_l0: -0.0068917046301066875 0.08505778014659882
encoder.encoder.bias_hh_l0: 0.006180281285196543 0.0827590674161911
encoder.encoder.weight_ih_l0_reverse: 0.0005076302331872284 0.08260519057512283
encoder.encoder.weight_hh_l0_reverse: 0.0005222035688348114 0.08159555494785309
encoder.encoder.bias_ih_l0_reverse: 0.006245718337595463 0.0798315778374672
encoder.encoder.bias_hh_l0_reverse: 0.006540375761687756 0.08492351323366165
decider.lstm.weight_ih_l0: -0.0015350362518802285 0.14481288194656372
decider.lstm.weight_hh_l0: 0.002088821493089199 0.14423707127571106
decider.lstm.bias_ih_l0: -0.03184335678815842 0.14060156047344208
decider.lstm.bias_hh_l0: 0.0039774393662810326 0.1520223617553711
decider.linear1.weight: 0.0034921285696327686 0.11735830456018448
decider.linear1.bias: -0.0031545800156891346 0.11453097313642502
decider.linear2.weight: 0.00010690290946513414 0.05120328441262245
decider.linear2.bias: -0.0022795572876930237 0.05180247873067856
decider.linear3.weight: 2.3140222765505314e-05 0.05103854089975357
decider.linear3.bias: -0.014012467116117477 0.022707566618919373

Rewards:
74.3234
74.3234
74.3234
objective = 95.40520477294922
==== episode 1500/75000 ====
action = 3
probs = 0.1402 0.3200 0.2579 0.2819

action = 3
probs = 0.1982 0.2368 0.2926 0.2725

action = 1
probs = 0.2721 0.2277 0.2969 0.2033

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000472922227345407 0.08082450181245804
encoder.encoder.weight_hh_l0: -0.00016852979024406523 0.0818910300731659
encoder.encoder.bias_ih_l0: -0.006879342719912529 0.08497407287359238
encoder.encoder.bias_hh_l0: 0.006192643661051989 0.08268526196479797
encoder.encoder.weight_ih_l0_reverse: 0.0005083833239041269 0.0826270654797554
encoder.encoder.weight_hh_l0_reverse: 0.0005111597129143775 0.08160024136304855
encoder.encoder.bias_ih_l0_reverse: 0.0061836750246584415 0.07980778813362122
encoder.encoder.bias_hh_l0_reverse: 0.006478331983089447 0.08498742431402206
decider.lstm.weight_ih_l0: -0.0015329989837482572 0.14480498433113098
decider.lstm.weight_hh_l0: 0.0021583945490419865 0.14427898824214935
decider.lstm.bias_ih_l0: -0.032032616436481476 0.14058145880699158
decider.lstm.bias_hh_l0: 0.0037881750613451004 0.15192732214927673
decider.linear1.weight: 0.003481911029666662 0.11734385043382645
decider.linear1.bias: -0.0031202277168631554 0.11456988751888275
decider.linear2.weight: 0.00010835374996531755 0.051208801567554474
decider.linear2.bias: -0.0022671085316687822 0.05180737376213074
decider.linear3.weight: 1.5550176613032818e-05 0.051035746932029724
decider.linear3.bias: -0.014014317654073238 0.02264978364109993

Rewards:
57.6652
57.6652
57.6652
objective = 77.77304077148438
==== episode 1600/75000 ====
action = 1
probs = 0.1322 0.3590 0.2367 0.2721

action = 1
probs = 0.1988 0.2459 0.2930 0.2623

action = 1
probs = 0.2673 0.2352 0.3041 0.1934

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00044862052891403437 0.08083595335483551
encoder.encoder.weight_hh_l0: -0.00018084945622831583 0.08190182596445084
encoder.encoder.bias_ih_l0: -0.006967941764742136 0.08491511642932892
encoder.encoder.bias_hh_l0: 0.0061040460132062435 0.08270058035850525
encoder.encoder.weight_ih_l0_reverse: 0.0004931783769279718 0.08262021839618683
encoder.encoder.weight_hh_l0_reverse: 0.0005159961292520165 0.08160713315010071
encoder.encoder.bias_ih_l0_reverse: 0.006157285068184137 0.07970736920833588
encoder.encoder.bias_hh_l0_reverse: 0.0064519415609538555 0.08514635264873505
decider.lstm.weight_ih_l0: -0.0015256839105859399 0.14478333294391632
decider.lstm.weight_hh_l0: 0.0021616569720208645 0.1443113535642624
decider.lstm.bias_ih_l0: -0.03206158056855202 0.14062651991844177
decider.lstm.bias_hh_l0: 0.0037592165172100067 0.1518370360136032
decider.linear1.weight: 0.0034627681598067284 0.11734803020954132
decider.linear1.bias: -0.003040696494281292 0.11457216739654541
decider.linear2.weight: 0.00012675434118136764 0.05121959000825882
decider.linear2.bias: -0.002216184977442026 0.05185222253203392
decider.linear3.weight: 2.85531859844923e-06 0.051089245826005936
decider.linear3.bias: -0.014023390598595142 0.02309589833021164

Rewards:
57.3517
57.3517
57.3517
objective = 74.07183837890625
==== episode 1700/75000 ====
action = 2
probs = 0.1228 0.3780 0.2406 0.2585

action = 2
probs = 0.1779 0.2563 0.3168 0.2490

action = 2
probs = 0.2296 0.2366 0.3431 0.1907

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004161954275332391 0.08084434270858765
encoder.encoder.weight_hh_l0: -0.00019154434266965836 0.08191463351249695
encoder.encoder.bias_ih_l0: -0.007040292955935001 0.08491251617670059
encoder.encoder.bias_hh_l0: 0.006031696684658527 0.08269312232732773
encoder.encoder.weight_ih_l0_reverse: 0.00048608629731461406 0.08260568231344223
encoder.encoder.weight_hh_l0_reverse: 0.0005273896967992187 0.08158475905656815
encoder.encoder.bias_ih_l0_reverse: 0.006215041037648916 0.07960515469312668
encoder.encoder.bias_hh_l0_reverse: 0.006509694736450911 0.0852353572845459
decider.lstm.weight_ih_l0: -0.0015203272923827171 0.14476771652698517
decider.lstm.weight_hh_l0: 0.002146473154425621 0.1443452537059784
decider.lstm.bias_ih_l0: -0.03202218562364578 0.14071527123451233
decider.lstm.bias_hh_l0: 0.003798610530793667 0.15172874927520752
decider.linear1.weight: 0.0034366585314273834 0.11734995990991592
decider.linear1.bias: -0.002884505782276392 0.11456336826086044
decider.linear2.weight: 0.00012429904018063098 0.05123280733823776
decider.linear2.bias: -0.0022169845178723335 0.05188514292240143
decider.linear3.weight: -1.0091578587889671e-05 0.05112462118268013
decider.linear3.bias: -0.014050227589905262 0.023239970207214355

Rewards:
67.4559
67.4559
67.4559
objective = 81.93385314941406
==== episode 1800/75000 ====
action = 2
probs = 0.1196 0.3959 0.2397 0.2448

action = 2
probs = 0.1875 0.2666 0.3259 0.2200

action = 2
probs = 0.2482 0.2340 0.3571 0.1607

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0003928326768800616 0.08088479936122894
encoder.encoder.weight_hh_l0: -0.00020577297254931182 0.0819539949297905
encoder.encoder.bias_ih_l0: -0.0068475473672151566 0.08489780128002167
encoder.encoder.bias_hh_l0: 0.006224445067346096 0.0827520415186882
encoder.encoder.weight_ih_l0_reverse: 0.0005064157885499299 0.08264504373073578
encoder.encoder.weight_hh_l0_reverse: 0.0005235763965174556 0.08160924911499023
encoder.encoder.bias_ih_l0_reverse: 0.006205608136951923 0.07963333278894424
encoder.encoder.bias_hh_l0_reverse: 0.006500263698399067 0.08530792593955994
decider.lstm.weight_ih_l0: -0.0015184194780886173 0.14478574693202972
decider.lstm.weight_hh_l0: 0.002133170375600457 0.1443249136209488
decider.lstm.bias_ih_l0: -0.031972162425518036 0.14079633355140686
decider.lstm.bias_hh_l0: 0.003848632797598839 0.15178926289081573
decider.linear1.weight: 0.00341960322111845 0.11736512184143066
decider.linear1.bias: -0.0027841338887810707 0.11453209817409515
decider.linear2.weight: 0.0001670116325840354 0.051243387162685394
decider.linear2.bias: -0.002142222598195076 0.05187445133924484
decider.linear3.weight: -2.9932823963463306e-05 0.051183246076107025
decider.linear3.bias: -0.014067176729440689 0.023992391303181648

Rewards:
67.4559
67.4559
67.4559
objective = 80.48274993896484
==== episode 1900/75000 ====
action = 1
probs = 0.1149 0.4186 0.2565 0.2100

action = 0
probs = 0.1911 0.2701 0.3638 0.1750

action = 2
probs = 0.2484 0.2546 0.3646 0.1325

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00035209624911658466 0.08095339685678482
encoder.encoder.weight_hh_l0: -0.0002438793599139899 0.08202149718999863
encoder.encoder.bias_ih_l0: -0.006482691504061222 0.08487723767757416
encoder.encoder.bias_hh_l0: 0.006589300464838743 0.0828469917178154
encoder.encoder.weight_ih_l0_reverse: 0.0005359846400097013 0.08269699662923813
encoder.encoder.weight_hh_l0_reverse: 0.0005281232297420502 0.081638403236866
encoder.encoder.bias_ih_l0_reverse: 0.006305758375674486 0.07965929806232452
encoder.encoder.bias_hh_l0_reverse: 0.006600409746170044 0.08534608036279678
decider.lstm.weight_ih_l0: -0.0015139752067625523 0.1448216289281845
decider.lstm.weight_hh_l0: 0.0020985102746635675 0.14433132112026215
decider.lstm.bias_ih_l0: -0.031586531549692154 0.1409585326910019
decider.lstm.bias_hh_l0: 0.004234252497553825 0.15193194150924683
decider.linear1.weight: 0.003393277060240507 0.11741212010383606
decider.linear1.bias: -0.0026099542155861855 0.11450810730457306
decider.linear2.weight: 0.00020672865503001958 0.051262617111206055
decider.linear2.bias: -0.0020662639290094376 0.05190875753760338
decider.linear3.weight: -7.127085700631142e-05 0.051252372562885284
decider.linear3.bias: -0.014101204462349415 0.025085631757974625

Rewards:
71.0584
71.0584
71.0584
objective = 83.7211685180664
==== episode 2000/75000 ====
action = 3
probs = 0.1048 0.4229 0.2533 0.2191

action = 3
probs = 0.1703 0.2826 0.3599 0.1872

action = 1
probs = 0.2208 0.2743 0.3815 0.1234

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0003275544149801135 0.08097098022699356
encoder.encoder.weight_hh_l0: -0.0002540330751799047 0.08204498142004013
encoder.encoder.bias_ih_l0: -0.0063048782758414745 0.08492632210254669
encoder.encoder.bias_hh_l0: 0.0067671118304133415 0.08291888982057571
encoder.encoder.weight_ih_l0_reverse: 0.0005608789506368339 0.08271323889493942
encoder.encoder.weight_hh_l0_reverse: 0.000537749903742224 0.08164412528276443
encoder.encoder.bias_ih_l0_reverse: 0.006382327992469072 0.07964366674423218
encoder.encoder.bias_hh_l0_reverse: 0.00667697936296463 0.08539608120918274
decider.lstm.weight_ih_l0: -0.0015119788004085422 0.14483477175235748
decider.lstm.weight_hh_l0: 0.002067896071821451 0.144317165017128
decider.lstm.bias_ih_l0: -0.03150036931037903 0.14111556112766266
decider.lstm.bias_hh_l0: 0.004320411942899227 0.15183377265930176
decider.linear1.weight: 0.0033840355463325977 0.11743135005235672
decider.linear1.bias: -0.002473294734954834 0.11445624381303787
decider.linear2.weight: 0.00022954714950174093 0.05128059536218643
decider.linear2.bias: -0.002027153503149748 0.051982663571834564
decider.linear3.weight: -8.651707321405411e-05 0.05129721760749817
decider.linear3.bias: -0.014124243520200253 0.025084279477596283

Rewards:
57.6652
57.6652
57.6652
objective = 86.25765228271484
==== episode 2100/75000 ====
action = 2
probs = 0.0955 0.4098 0.2538 0.2409

action = 1
probs = 0.1526 0.2994 0.3491 0.1989

action = 1
probs = 0.2028 0.2735 0.3917 0.1320

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0003417835687287152 0.08095695823431015
encoder.encoder.weight_hh_l0: -0.00023098506790120155 0.0820334181189537
encoder.encoder.bias_ih_l0: -0.006434504874050617 0.0849352478981018
encoder.encoder.bias_hh_l0: 0.006637487094849348 0.0829065814614296
encoder.encoder.weight_ih_l0_reverse: 0.0005631999811157584 0.08270508795976639
encoder.encoder.weight_hh_l0_reverse: 0.0005491568590514362 0.0816522091627121
encoder.encoder.bias_ih_l0_reverse: 0.0064086648635566235 0.07961344718933105
encoder.encoder.bias_hh_l0_reverse: 0.006703317631036043 0.08546900749206543
decider.lstm.weight_ih_l0: -0.0015129995299503207 0.14481930434703827
decider.lstm.weight_hh_l0: 0.0020653014071285725 0.1443062275648117
decider.lstm.bias_ih_l0: -0.031557366251945496 0.14113140106201172
decider.lstm.bias_hh_l0: 0.004263414070010185 0.1517275869846344
decider.linear1.weight: 0.0033852194901555777 0.11742336302995682
decider.linear1.bias: -0.0024748193100094795 0.11447522789239883
decider.linear2.weight: 0.00023442323436029255 0.05127844586968422
decider.linear2.bias: -0.002031122799962759 0.052008990198373795
decider.linear3.weight: -8.937565144151449e-05 0.05126824229955673
decider.linear3.bias: -0.014132600277662277 0.024615498259663582

Rewards:
65.6652
65.6652
65.6652
objective = 84.7887191772461
==== episode 2200/75000 ====
action = 3
probs = 0.1118 0.3706 0.2844 0.2331

action = 2
probs = 0.1699 0.2712 0.3690 0.1900

action = 2
probs = 0.2082 0.2762 0.3919 0.1237

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00035008875420317054 0.08102814853191376
encoder.encoder.weight_hh_l0: -0.00023390563728753477 0.08207164704799652
encoder.encoder.bias_ih_l0: -0.006253616884350777 0.08489657938480377
encoder.encoder.bias_hh_l0: 0.006818375550210476 0.08283413201570511
encoder.encoder.weight_ih_l0_reverse: 0.0005630803061649203 0.08278173953294754
encoder.encoder.weight_hh_l0_reverse: 0.000528554548509419 0.08169331401586533
encoder.encoder.bias_ih_l0_reverse: 0.006233261898159981 0.07968662679195404
encoder.encoder.bias_hh_l0_reverse: 0.006527914199978113 0.08536911755800247
decider.lstm.weight_ih_l0: -0.0015156861627474427 0.14485514163970947
decider.lstm.weight_hh_l0: 0.0020645596086978912 0.14433418214321136
decider.lstm.bias_ih_l0: -0.03163624554872513 0.14124345779418945
decider.lstm.bias_hh_l0: 0.004184544086456299 0.15185707807540894
decider.linear1.weight: 0.003419162705540657 0.11741018295288086
decider.linear1.bias: -0.0026991860941052437 0.11441747844219208
decider.linear2.weight: 0.0001849666005000472 0.0512692853808403
decider.linear2.bias: -0.002130690962076187 0.051958128809928894
decider.linear3.weight: -7.519451901316643e-05 0.05118502676486969
decider.linear3.bias: -0.014123668894171715 0.024799710139632225

Rewards:
64.4580
64.4580
64.4580
objective = 72.83734130859375
==== episode 2300/75000 ====
action = 1
probs = 0.1204 0.3998 0.2533 0.2264

action = 2
probs = 0.1967 0.2837 0.3406 0.1790

action = 2
probs = 0.2383 0.2777 0.3636 0.1204

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00038182936259545386 0.08100610226392746
encoder.encoder.weight_hh_l0: -0.00021250381541904062 0.08205166459083557
encoder.encoder.bias_ih_l0: -0.006488754414021969 0.08485666662454605
encoder.encoder.bias_hh_l0: 0.0065832422114908695 0.08285302668809891
encoder.encoder.weight_ih_l0_reverse: 0.0005467933369800448 0.08277939260005951
encoder.encoder.weight_hh_l0_reverse: 0.0005131637444719672 0.08169332891702652
encoder.encoder.bias_ih_l0_reverse: 0.006090971175581217 0.07972990721464157
encoder.encoder.bias_hh_l0_reverse: 0.006385623011738062 0.08528296649456024
decider.lstm.weight_ih_l0: -0.0015185769880190492 0.1448523849248886
decider.lstm.weight_hh_l0: 0.0021073161624372005 0.1442967802286148
decider.lstm.bias_ih_l0: -0.03179788589477539 0.14115948975086212
decider.lstm.bias_hh_l0: 0.0040229130536317825 0.1519395262002945
decider.linear1.weight: 0.0034492388367652893 0.11738864332437515
decider.linear1.bias: -0.0028714099898934364 0.11437206715345383
decider.linear2.weight: 0.00017236702842637897 0.05125657841563225
decider.linear2.bias: -0.0021569826640188694 0.05198359861969948
decider.linear3.weight: -6.927363574504852e-05 0.051154352724552155
decider.linear3.bias: -0.01410321332514286 0.025155454874038696

Rewards:
70.1874
70.1874
70.1874
objective = 70.31137084960938
==== episode 2400/75000 ====
action = 1
probs = 0.1110 0.4145 0.2360 0.2384

action = 1
probs = 0.2043 0.2919 0.3062 0.1976

action = 1
probs = 0.2389 0.3003 0.3323 0.1285

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00040325464215129614 0.08100388944149017
encoder.encoder.weight_hh_l0: -0.00020368055265862495 0.08205974102020264
encoder.encoder.bias_ih_l0: -0.006367481779307127 0.08485954999923706
encoder.encoder.bias_hh_l0: 0.006704516243189573 0.08292219042778015
encoder.encoder.weight_ih_l0_reverse: 0.0005511243361979723 0.08278097212314606
encoder.encoder.weight_hh_l0_reverse: 0.0005150229553692043 0.08170555531978607
encoder.encoder.bias_ih_l0_reverse: 0.006154593545943499 0.07978574931621552
encoder.encoder.bias_hh_l0_reverse: 0.0064492481760680676 0.08533888310194016
decider.lstm.weight_ih_l0: -0.0015220993664115667 0.1448674499988556
decider.lstm.weight_hh_l0: 0.0021103867329657078 0.1442815214395523
decider.lstm.bias_ih_l0: -0.031780216842889786 0.14115668833255768
decider.lstm.bias_hh_l0: 0.0040405793115496635 0.15192581713199615
decider.linear1.weight: 0.0034450951498001814 0.11738362163305283
decider.linear1.bias: -0.0029008081182837486 0.11435012519359589
decider.linear2.weight: 0.00018184763030149043 0.05126386508345604
decider.linear2.bias: -0.0021386928856372833 0.05201322212815285
decider.linear3.weight: -6.785267032682896e-05 0.05117112398147583
decider.linear3.bias: -0.014090347103774548 0.0249276552349329

Rewards:
57.3517
57.3517
57.3517
objective = 63.368011474609375
==== episode 2500/75000 ====
action = 1
probs = 0.1074 0.3921 0.2519 0.2486

action = 2
probs = 0.2207 0.2751 0.3129 0.1913

action = 1
probs = 0.2773 0.2736 0.3263 0.1229

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00039434555219486356 0.08102834224700928
encoder.encoder.weight_hh_l0: -0.00021217140601947904 0.08208423852920532
encoder.encoder.bias_ih_l0: -0.0061975568532943726 0.08483899384737015
encoder.encoder.bias_hh_l0: 0.006874442100524902 0.0828840583562851
encoder.encoder.weight_ih_l0_reverse: 0.0005782492808066308 0.08281505852937698
encoder.encoder.weight_hh_l0_reverse: 0.0005117623950354755 0.0817108303308487
encoder.encoder.bias_ih_l0_reverse: 0.006208306644111872 0.07986392825841904
encoder.encoder.bias_hh_l0_reverse: 0.006502961274236441 0.08532088994979858
decider.lstm.weight_ih_l0: -0.001526090782135725 0.1448945850133896
decider.lstm.weight_hh_l0: 0.0021252832375466824 0.14428278803825378
decider.lstm.bias_ih_l0: -0.03187449276447296 0.1411452740430832
decider.lstm.bias_hh_l0: 0.003946305252611637 0.1518850028514862
decider.linear1.weight: 0.0034380280412733555 0.11738474667072296
decider.linear1.bias: -0.002893690951168537 0.11437982320785522
decider.linear2.weight: 0.00018937049026135355 0.05126792564988136
decider.linear2.bias: -0.0021307701244950294 0.051935844123363495
decider.linear3.weight: -7.909000851213932e-05 0.051179904490709305
decider.linear3.bias: -0.01407705619931221 0.024827715009450912

Rewards:
58.9915
58.9915
58.9915
objective = 66.74748229980469
==== episode 2600/75000 ====
action = 3
probs = 0.0907 0.4086 0.2468 0.2539

action = 2
probs = 0.1675 0.3120 0.2944 0.2262

action = 0
probs = 0.2396 0.2920 0.3284 0.1401

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000391738343751058 0.08103965222835541
encoder.encoder.weight_hh_l0: -0.00018941248708870262 0.08209740370512009
encoder.encoder.bias_ih_l0: -0.006164231337606907 0.08482740819454193
encoder.encoder.bias_hh_l0: 0.006907764356583357 0.08295831084251404
encoder.encoder.weight_ih_l0_reverse: 0.0006097153527662158 0.08280622214078903
encoder.encoder.weight_hh_l0_reverse: 0.0005380851798690856 0.08174905925989151
encoder.encoder.bias_ih_l0_reverse: 0.0064154015854001045 0.07984641939401627
encoder.encoder.bias_hh_l0_reverse: 0.006710059009492397 0.08554420620203018
decider.lstm.weight_ih_l0: -0.001522346748970449 0.1448947936296463
decider.lstm.weight_hh_l0: 0.002101137302815914 0.14428983628749847
decider.lstm.bias_ih_l0: -0.03177887946367264 0.14108237624168396
decider.lstm.bias_hh_l0: 0.0040419213473796844 0.1517786979675293
decider.linear1.weight: 0.0034313397482037544 0.11739816516637802
decider.linear1.bias: -0.002880329266190529 0.1144680604338646
decider.linear2.weight: 0.00020972128550056368 0.051272835582494736
decider.linear2.bias: -0.0021025058813393116 0.0519864484667778
decider.linear3.weight: -8.989870548248291e-05 0.05117489770054817
decider.linear3.bias: -0.014111822471022606 0.02444295771420002

Rewards:
58.8011
58.8011
58.8011
objective = 78.84203338623047
==== episode 2700/75000 ====
action = 3
probs = 0.0907 0.4483 0.2305 0.2305

action = 3
probs = 0.1587 0.3479 0.2685 0.2248

action = 2
probs = 0.2290 0.3010 0.3156 0.1544

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004216791712678969 0.08111834526062012
encoder.encoder.weight_hh_l0: -0.00017765235679689795 0.08213631063699722
encoder.encoder.bias_ih_l0: -0.0059544360265135765 0.0848086029291153
encoder.encoder.bias_hh_l0: 0.0071175592020154 0.08300839364528656
encoder.encoder.weight_ih_l0_reverse: 0.0005922862910665572 0.08284683525562286
encoder.encoder.weight_hh_l0_reverse: 0.0005528753390535712 0.08182613551616669
encoder.encoder.bias_ih_l0_reverse: 0.006508761551231146 0.0798751562833786
encoder.encoder.bias_hh_l0_reverse: 0.006803417112678289 0.08571766316890717
decider.lstm.weight_ih_l0: -0.0015149920945987105 0.14491009712219238
decider.lstm.weight_hh_l0: 0.0020458472426980734 0.14434632658958435
decider.lstm.bias_ih_l0: -0.03151937201619148 0.14123211801052094
decider.lstm.bias_hh_l0: 0.0043014297261834145 0.1517833024263382
decider.linear1.weight: 0.003443752182647586 0.11741682887077332
decider.linear1.bias: -0.002958061173558235 0.11452876031398773
decider.linear2.weight: 0.00023073684133123606 0.051266662776470184
decider.linear2.bias: -0.0020694597624242306 0.05202580615878105
decider.linear3.weight: -8.532323408871889e-05 0.051144372671842575
decider.linear3.bias: -0.014121060259640217 0.02464587241411209

Rewards:
67.0909
67.0909
67.0909
objective = 91.98515319824219
==== episode 2800/75000 ====
action = 1
probs = 0.0990 0.3693 0.2861 0.2455

action = 2
probs = 0.1548 0.3104 0.2965 0.2384

action = 1
probs = 0.2018 0.2917 0.3425 0.1640

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004569232987705618 0.08114610612392426
encoder.encoder.weight_hh_l0: -0.00015704498218838125 0.08215714991092682
encoder.encoder.bias_ih_l0: -0.00584154250100255 0.08480103313922882
encoder.encoder.bias_hh_l0: 0.007230447139590979 0.08289637416601181
encoder.encoder.weight_ih_l0_reverse: 0.0006056809215806425 0.08290570974349976
encoder.encoder.weight_hh_l0_reverse: 0.0005550463683903217 0.08186547458171844
encoder.encoder.bias_ih_l0_reverse: 0.006536481436342001 0.07991489768028259
encoder.encoder.bias_hh_l0_reverse: 0.0068311369977891445 0.08569924533367157
decider.lstm.weight_ih_l0: -0.0015230774879455566 0.14492490887641907
decider.lstm.weight_hh_l0: 0.002014972036704421 0.14435145258903503
decider.lstm.bias_ih_l0: -0.03160075098276138 0.14114809036254883
decider.lstm.bias_hh_l0: 0.004220046103000641 0.15180949866771698
decider.linear1.weight: 0.0034851364325731993 0.11740099638700485
decider.linear1.bias: -0.003120661247521639 0.11439888924360275
decider.linear2.weight: 0.00015342603728640825 0.0512600801885128
decider.linear2.bias: -0.0022369595244526863 0.052000388503074646
decider.linear3.weight: -7.44406133890152e-05 0.05105209723114967
decider.linear3.bias: -0.01412970945239067 0.023990917950868607

Rewards:
58.9915
58.9915
58.9915
objective = 67.7239990234375
==== episode 2900/75000 ====
action = 1
probs = 0.0907 0.3857 0.2846 0.2389

action = 3
probs = 0.1357 0.3282 0.2721 0.2640

action = 2
probs = 0.1935 0.3079 0.3045 0.1941

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00046672712778672576 0.08115063607692719
encoder.encoder.weight_hh_l0: -0.00014032139733899385 0.08215659111738205
encoder.encoder.bias_ih_l0: -0.005691232159733772 0.08493170142173767
encoder.encoder.bias_hh_l0: 0.007380760740488768 0.08304622769355774
encoder.encoder.weight_ih_l0_reverse: 0.0006265932461246848 0.08287857472896576
encoder.encoder.weight_hh_l0_reverse: 0.0006073950789868832 0.08190065622329712
encoder.encoder.bias_ih_l0_reverse: 0.006886981427669525 0.07995865494012833
encoder.encoder.bias_hh_l0_reverse: 0.007181634660810232 0.08585143089294434
decider.lstm.weight_ih_l0: -0.0015182659262791276 0.14495347440242767
decider.lstm.weight_hh_l0: 0.001957537140697241 0.14433732628822327
decider.lstm.bias_ih_l0: -0.03136344254016876 0.14121297001838684
decider.lstm.bias_hh_l0: 0.004457362927496433 0.15178737044334412
decider.linear1.weight: 0.0034745335578918457 0.11743543297052383
decider.linear1.bias: -0.003154064528644085 0.11447173357009888
decider.linear2.weight: 0.00016951773432083428 0.05126118287444115
decider.linear2.bias: -0.0022007571533322334 0.05201146379113197
decider.linear3.weight: -7.436878513544798e-05 0.051059380173683167
decider.linear3.bias: -0.014142829924821854 0.02380712889134884

Rewards:
69.5795
69.5795
69.5795
objective = 80.56389617919922
==== episode 3000/75000 ====
action = 2
probs = 0.0823 0.3785 0.2527 0.2865

action = 0
probs = 0.1305 0.3074 0.2382 0.3239

action = 1
probs = 0.2000 0.3212 0.2732 0.2056

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00048241153126582503 0.08117759227752686
encoder.encoder.weight_hh_l0: -0.00013192137703299522 0.08218485116958618
encoder.encoder.bias_ih_l0: -0.005338179413229227 0.08494541794061661
encoder.encoder.bias_hh_l0: 0.007733811158686876 0.08307123929262161
encoder.encoder.weight_ih_l0_reverse: 0.0006421945872716606 0.08292556554079056
encoder.encoder.weight_hh_l0_reverse: 0.0006293146871030331 0.08195199072360992
encoder.encoder.bias_ih_l0_reverse: 0.007044981699436903 0.0799650028347969
encoder.encoder.bias_hh_l0_reverse: 0.00733963493257761 0.08588907122612
decider.lstm.weight_ih_l0: -0.001514817588031292 0.1449912041425705
decider.lstm.weight_hh_l0: 0.001893584500066936 0.1443929225206375
decider.lstm.bias_ih_l0: -0.031161410734057426 0.1413486748933792
decider.lstm.bias_hh_l0: 0.004659402184188366 0.1517511010169983
decider.linear1.weight: 0.003458224004134536 0.11746787279844284
decider.linear1.bias: -0.003125724382698536 0.11446826905012131
decider.linear2.weight: 0.00019113124290015548 0.05127512291073799
decider.linear2.bias: -0.0021637575700879097 0.05204705893993378
decider.linear3.weight: -7.409148383885622e-05 0.05114182457327843
decider.linear3.bias: -0.01411526370793581 0.023053165525197983

Rewards:
71.2714
71.2714
71.2714
objective = 108.03093719482422
==== episode 3100/75000 ====
action = 3
probs = 0.0707 0.4144 0.2196 0.2953

action = 1
probs = 0.1098 0.3198 0.1999 0.3705

action = 2
probs = 0.1850 0.3213 0.2416 0.2521

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004422157071530819 0.08118118345737457
encoder.encoder.weight_hh_l0: -0.0001544971892144531 0.08219204097986221
encoder.encoder.bias_ih_l0: -0.005097131710499525 0.08498967438936234
encoder.encoder.bias_hh_l0: 0.00797486025840044 0.0831938236951828
encoder.encoder.weight_ih_l0_reverse: 0.0006704809493385255 0.08288764953613281
encoder.encoder.weight_hh_l0_reverse: 0.0007435645675286651 0.08199227601289749
encoder.encoder.bias_ih_l0_reverse: 0.007507889531552792 0.07990191876888275
encoder.encoder.bias_hh_l0_reverse: 0.007802543696016073 0.08620718866586685
decider.lstm.weight_ih_l0: -0.0014725172659382224 0.14499588310718536
decider.lstm.weight_hh_l0: 0.0018056458793580532 0.14442768692970276
decider.lstm.bias_ih_l0: -0.030566709116101265 0.14134998619556427
decider.lstm.bias_hh_l0: 0.005254111252725124 0.15159431099891663
decider.linear1.weight: 0.0034116448368877172 0.11752304434776306
decider.linear1.bias: -0.002882022876292467 0.11453616619110107
decider.linear2.weight: 0.00025941780768334866 0.05129052326083183
decider.linear2.bias: -0.002033534925431013 0.052113186568021774
decider.linear3.weight: -8.210644591599703e-05 0.05126113072037697
decider.linear3.bias: -0.014126339927315712 0.02258995734155178

Rewards:
63.3518
63.3518
63.3518
objective = 79.83158874511719
==== episode 3200/75000 ====
action = 1
probs = 0.0772 0.4251 0.2216 0.2761

action = 1
probs = 0.1289 0.3391 0.2067 0.3252

action = 0
probs = 0.2162 0.3133 0.2501 0.2204

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00047459648340009153 0.08115777373313904
encoder.encoder.weight_hh_l0: -0.00014457378711085767 0.08216831088066101
encoder.encoder.bias_ih_l0: -0.005404170602560043 0.0849795714020729
encoder.encoder.bias_hh_l0: 0.007667819038033485 0.0831371322274208
encoder.encoder.weight_ih_l0_reverse: 0.0006467239581979811 0.08287525922060013
encoder.encoder.weight_hh_l0_reverse: 0.000663993414491415 0.08195743709802628
encoder.encoder.bias_ih_l0_reverse: 0.007170600816607475 0.07994958758354187
encoder.encoder.bias_hh_l0_reverse: 0.007465254981070757 0.0860150009393692
decider.lstm.weight_ih_l0: -0.001522970967926085 0.14498239755630493
decider.lstm.weight_hh_l0: 0.0018386391457170248 0.14442254602909088
decider.lstm.bias_ih_l0: -0.031144430860877037 0.1413947343826294
decider.lstm.bias_hh_l0: 0.004676384851336479 0.15168489515781403
decider.linear1.weight: 0.0034274111967533827 0.11748137325048447
decider.linear1.bias: -0.00309752207249403 0.11449927091598511
decider.linear2.weight: 0.00019544753013178706 0.05127636715769768
decider.linear2.bias: -0.002140861237421632 0.052023038268089294
decider.linear3.weight: -7.438927423208952e-05 0.05115463584661484
decider.linear3.bias: -0.014099044725298882 0.023257695138454437

Rewards:
58.9492
58.9492
58.9492
objective = 68.15560913085938
==== episode 3300/75000 ====
action = 3
probs = 0.0644 0.4354 0.2211 0.2790

action = 3
probs = 0.1093 0.3618 0.2023 0.3266

action = 1
probs = 0.1986 0.3585 0.2413 0.2016

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004768344515468925 0.08120903372764587
encoder.encoder.weight_hh_l0: -0.0001309520157519728 0.0822189524769783
encoder.encoder.bias_ih_l0: -0.005143644753843546 0.08497919887304306
encoder.encoder.bias_hh_l0: 0.007928350009024143 0.08320441842079163
encoder.encoder.weight_ih_l0_reverse: 0.0006723263650201261 0.08293156325817108
encoder.encoder.weight_hh_l0_reverse: 0.000690366723574698 0.08199410885572433
encoder.encoder.bias_ih_l0_reverse: 0.007359268609434366 0.07994859665632248
encoder.encoder.bias_hh_l0_reverse: 0.007653924636542797 0.08608049899339676
decider.lstm.weight_ih_l0: -0.0015114020789042115 0.14501847326755524
decider.lstm.weight_hh_l0: 0.0017577634425833821 0.1444425880908966
decider.lstm.bias_ih_l0: -0.030824968591332436 0.14146877825260162
decider.lstm.bias_hh_l0: 0.004995851777493954 0.15168079733848572
decider.linear1.weight: 0.003385472809895873 0.11752037703990936
decider.linear1.bias: -0.002852878998965025 0.11446801573038101
decider.linear2.weight: 0.0002625261840876192 0.0513019785284996
decider.linear2.bias: -0.002008242066949606 0.052102163434028625
decider.linear3.weight: -0.00010758452117443085 0.05126700922846794
decider.linear3.bias: -0.014159051701426506 0.023460958153009415

Rewards:
57.6652
57.6652
57.6652
objective = 65.76052856445312
==== episode 3400/75000 ====
action = 1
probs = 0.0560 0.4098 0.2537 0.2804

action = 3
probs = 0.0949 0.3452 0.2315 0.3284

action = 1
probs = 0.1594 0.3689 0.2611 0.2106

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004539546207524836 0.08121930807828903
encoder.encoder.weight_hh_l0: -0.00014345606905408204 0.08222147822380066
encoder.encoder.bias_ih_l0: -0.00531288655474782 0.08490800857543945
encoder.encoder.bias_hh_l0: 0.007759109139442444 0.08317506313323975
encoder.encoder.weight_ih_l0_reverse: 0.0006926747155375779 0.08293412625789642
encoder.encoder.weight_hh_l0_reverse: 0.0007039548945613205 0.08199523389339447
encoder.encoder.bias_ih_l0_reverse: 0.0073837097734212875 0.07987320423126221
encoder.encoder.bias_hh_l0_reverse: 0.0076783690601587296 0.08621110767126083
decider.lstm.weight_ih_l0: -0.0015116772847250104 0.14499182999134064
decider.lstm.weight_hh_l0: 0.0017452319152653217 0.14445146918296814
decider.lstm.bias_ih_l0: -0.03084259107708931 0.14153321087360382
decider.lstm.bias_hh_l0: 0.004978235810995102 0.15162625908851624
decider.linear1.weight: 0.0033691253047436476 0.11751078069210052
decider.linear1.bias: -0.002681091893464327 0.11451201885938644
decider.linear2.weight: 0.0002683496568351984 0.051314935088157654
decider.linear2.bias: -0.0020046778954565525 0.05215458944439888
decider.linear3.weight: -0.00014351389836519957 0.051287941634655
decider.linear3.bias: -0.014242777600884438 0.02332872897386551

Rewards:
74.3234
74.3234
74.3234
objective = 74.39134979248047
==== episode 3500/75000 ====
action = 3
probs = 0.0557 0.4592 0.2254 0.2596

action = 2
probs = 0.0910 0.3899 0.2101 0.3090

action = 1
probs = 0.1692 0.3757 0.2744 0.1808

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00048560253344476223 0.08121893554925919
encoder.encoder.weight_hh_l0: -0.0001265500468434766 0.08222074061632156
encoder.encoder.bias_ih_l0: -0.005459758918732405 0.08483424782752991
encoder.encoder.bias_hh_l0: 0.007612235378473997 0.08315587043762207
encoder.encoder.weight_ih_l0_reverse: 0.0006460886797867715 0.08293309062719345
encoder.encoder.weight_hh_l0_reverse: 0.0006349272443912923 0.08197800070047379
encoder.encoder.bias_ih_l0_reverse: 0.006957193370908499 0.07983028143644333
encoder.encoder.bias_hh_l0_reverse: 0.007251848466694355 0.08601619303226471
decider.lstm.weight_ih_l0: -0.0015053261304274201 0.1449580043554306
decider.lstm.weight_hh_l0: 0.0017282714834436774 0.1445046216249466
decider.lstm.bias_ih_l0: -0.030647827312350273 0.14136233925819397
decider.lstm.bias_hh_l0: 0.005173000507056713 0.1516556739807129
decider.linear1.weight: 0.00335821695625782 0.1175362691283226
decider.linear1.bias: -0.002590067684650421 0.11438912898302078
decider.linear2.weight: 0.0002784537791740149 0.05132683739066124
decider.linear2.bias: -0.001962372101843357 0.052195705473423004
decider.linear3.weight: -0.0001559155061841011 0.051350437104701996
decider.linear3.bias: -0.014248725958168507 0.023968812078237534

Rewards:
70.1874
70.1874
70.1874
objective = 90.95818328857422
==== episode 3600/75000 ====
action = 1
probs = 0.0637 0.4219 0.2636 0.2507

action = 2
probs = 0.1109 0.3691 0.2319 0.2881

action = 3
probs = 0.1939 0.3558 0.2907 0.1596

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005329051637090743 0.08126357942819595
encoder.encoder.weight_hh_l0: -0.0001108149517676793 0.082265205681324
encoder.encoder.bias_ih_l0: -0.005252606701105833 0.08481721580028534
encoder.encoder.bias_hh_l0: 0.00781938899308443 0.08309071511030197
encoder.encoder.weight_ih_l0_reverse: 0.0006409335765056312 0.08301500976085663
encoder.encoder.weight_hh_l0_reverse: 0.0005912622436881065 0.0820041373372078
encoder.encoder.bias_ih_l0_reverse: 0.006827726028859615 0.0799330398440361
encoder.encoder.bias_hh_l0_reverse: 0.007122381590306759 0.08583659678697586
decider.lstm.weight_ih_l0: -0.0015222192741930485 0.14499089121818542
decider.lstm.weight_hh_l0: 0.0017483161063864827 0.14449426531791687
decider.lstm.bias_ih_l0: -0.0308516975492239 0.1413946896791458
decider.lstm.bias_hh_l0: 0.004969140514731407 0.1517709642648697
decider.linear1.weight: 0.0033941303845494986 0.1175217553973198
decider.linear1.bias: -0.0027840356342494488 0.11424829810857773
decider.linear2.weight: 0.00021579305757768452 0.05132221803069115
decider.linear2.bias: -0.002088430803269148 0.05204658955335617
decider.linear3.weight: -0.00013505551032721996 0.05129420384764671
decider.linear3.bias: -0.014193790033459663 0.02424313686788082

Rewards:
68.7666
68.7666
68.7666
objective = 95.33776092529297
==== episode 3700/75000 ====
action = 2
probs = 0.0620 0.4041 0.2774 0.2565

action = 1
probs = 0.1130 0.3650 0.2421 0.2798

action = 1
probs = 0.2002 0.3520 0.2931 0.1547

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005259157042019069 0.08123590797185898
encoder.encoder.weight_hh_l0: -0.00012049221550114453 0.08227242529392242
encoder.encoder.bias_ih_l0: -0.005339392460882664 0.08480493724346161
encoder.encoder.bias_hh_l0: 0.007732602301985025 0.08304674178361893
encoder.encoder.weight_ih_l0_reverse: 0.0006484704790636897 0.08300761878490448
encoder.encoder.weight_hh_l0_reverse: 0.0005673248087987304 0.08198253065347672
encoder.encoder.bias_ih_l0_reverse: 0.006729398854076862 0.07997319847345352
encoder.encoder.bias_hh_l0_reverse: 0.007024053018540144 0.08575068414211273
decider.lstm.weight_ih_l0: -0.001532367430627346 0.1449888050556183
decider.lstm.weight_hh_l0: 0.0018053477397188544 0.14447437226772308
decider.lstm.bias_ih_l0: -0.031075509265065193 0.14135348796844482
decider.lstm.bias_hh_l0: 0.004745332524180412 0.15177851915359497
decider.linear1.weight: 0.0033958125859498978 0.11750803887844086
decider.linear1.bias: -0.0028013428673148155 0.11423484236001968
decider.linear2.weight: 0.00021018748520873487 0.0513235367834568
decider.linear2.bias: -0.0020984651055186987 0.052003104239702225
decider.linear3.weight: -0.00014007161371409893 0.05129731073975563
decider.linear3.bias: -0.014191897585988045 0.024277884513139725

Rewards:
65.6652
65.6652
65.6652
objective = 72.98513793945312
==== episode 3800/75000 ====
action = 2
probs = 0.0620 0.3756 0.2901 0.2723

action = 1
probs = 0.1137 0.3205 0.2741 0.2917

action = 0
probs = 0.1959 0.2931 0.3574 0.1536

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00047015148447826505 0.0812491774559021
encoder.encoder.weight_hh_l0: -0.00014236854622140527 0.08227554708719254
encoder.encoder.bias_ih_l0: -0.005368199665099382 0.0847950205206871
encoder.encoder.bias_hh_l0: 0.007703795097768307 0.0829959586262703
encoder.encoder.weight_ih_l0_reverse: 0.0006761398981325328 0.08302014321088791
encoder.encoder.weight_hh_l0_reverse: 0.0005539539852179587 0.08196782320737839
encoder.encoder.bias_ih_l0_reverse: 0.006675535347312689 0.0800292044878006
encoder.encoder.bias_hh_l0_reverse: 0.006970191840082407 0.08562576025724411
decider.lstm.weight_ih_l0: -0.0015307246940210462 0.14497990906238556
decider.lstm.weight_hh_l0: 0.0018352570477873087 0.1444912701845169
decider.lstm.bias_ih_l0: -0.03119799867272377 0.14131085574626923
decider.lstm.bias_hh_l0: 0.0046228524297475815 0.15164943039417267
decider.linear1.weight: 0.0033940006978809834 0.11749177426099777
decider.linear1.bias: -0.0027216151356697083 0.11424680799245834
decider.linear2.weight: 0.00017488702724222094 0.05133180320262909
decider.linear2.bias: -0.0021594311110675335 0.05197608843445778
decider.linear3.weight: -0.00014233659021556377 0.05129729583859444
decider.linear3.bias: -0.014182882383465767 0.023743588477373123

Rewards:
75.0330
75.0330
75.0330
objective = 100.17979431152344
==== episode 3900/75000 ====
action = 1
probs = 0.0512 0.3739 0.3047 0.2701

action = 3
probs = 0.1006 0.3208 0.2971 0.2815

action = 2
probs = 0.1879 0.2880 0.3855 0.1386

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00043334110523574054 0.0812842920422554
encoder.encoder.weight_hh_l0: -0.00015550774696748704 0.08230281621217728
encoder.encoder.bias_ih_l0: -0.005289631895720959 0.08478959649801254
encoder.encoder.bias_hh_l0: 0.007782362401485443 0.08305763453245163
encoder.encoder.weight_ih_l0_reverse: 0.0007119758520275354 0.08304575830698013
encoder.encoder.weight_hh_l0_reverse: 0.0005620209267362952 0.08199290931224823
encoder.encoder.bias_ih_l0_reverse: 0.00682576559484005 0.08003251999616623
encoder.encoder.bias_hh_l0_reverse: 0.0071204183623194695 0.0857214629650116
decider.lstm.weight_ih_l0: -0.0015208898112177849 0.14499089121818542
decider.lstm.weight_hh_l0: 0.0018008295446634293 0.14448809623718262
decider.lstm.bias_ih_l0: -0.03100656345486641 0.14139769971370697
decider.lstm.bias_hh_l0: 0.004814282059669495 0.1516208052635193
decider.linear1.weight: 0.003330616047605872 0.11753703653812408
decider.linear1.bias: -0.002414824441075325 0.11423670500516891
decider.linear2.weight: 0.00023924365814309567 0.051359836012125015
decider.linear2.bias: -0.0020396828185766935 0.0520109124481678
decider.linear3.weight: -0.00018952717073261738 0.051412519067525864
decider.linear3.bias: -0.014251300133764744 0.023962771520018578

Rewards:
69.5795
69.5795
69.5795
objective = 74.31779479980469
==== episode 4000/75000 ====
action = 3
probs = 0.0560 0.3396 0.3124 0.2921

action = 3
probs = 0.1020 0.3100 0.2811 0.3069

action = 1
probs = 0.2020 0.3053 0.3605 0.1323

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000487938872538507 0.08123531192541122
encoder.encoder.weight_hh_l0: -0.00012839217379223555 0.08227316290140152
encoder.encoder.bias_ih_l0: -0.005388026125729084 0.0848238468170166
encoder.encoder.bias_hh_l0: 0.0076839677058160305 0.08304868638515472
encoder.encoder.weight_ih_l0_reverse: 0.0007066811667755246 0.08302848786115646
encoder.encoder.weight_hh_l0_reverse: 0.0005560787976719439 0.08198094367980957
encoder.encoder.bias_ih_l0_reverse: 0.006756350863724947 0.08002795279026031
encoder.encoder.bias_hh_l0_reverse: 0.0070510003715753555 0.08570203185081482
decider.lstm.weight_ih_l0: -0.0015419876435771585 0.14500613510608673
decider.lstm.weight_hh_l0: 0.001840152544900775 0.14444582164287567
decider.lstm.bias_ih_l0: -0.03124978579580784 0.14143267273902893
decider.lstm.bias_hh_l0: 0.00457106065005064 0.15159325301647186
decider.linear1.weight: 0.003394987201318145 0.11750709265470505
decider.linear1.bias: -0.002752662170678377 0.11422142386436462
decider.linear2.weight: 0.00018356068176217377 0.051345471292734146
decider.linear2.bias: -0.0021497204434126616 0.0520051009953022
decider.linear3.weight: -0.00016606436111032963 0.051357053220272064
decider.linear3.bias: -0.014197926968336105 0.023612165823578835

Rewards:
57.6652
57.6652
57.6652
objective = 69.1715316772461
==== episode 4100/75000 ====
action = 2
probs = 0.0597 0.3336 0.3328 0.2739

action = 2
probs = 0.1190 0.3213 0.2915 0.2682

action = 0
probs = 0.2125 0.3242 0.3434 0.1199

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005003022379241884 0.0812436193227768
encoder.encoder.weight_hh_l0: -0.00013631324691232294 0.08230940252542496
encoder.encoder.bias_ih_l0: -0.0052732788026332855 0.08482679724693298
encoder.encoder.bias_hh_l0: 0.007798716425895691 0.08304989337921143
encoder.encoder.weight_ih_l0_reverse: 0.0007063533994369209 0.08306120336055756
encoder.encoder.weight_hh_l0_reverse: 0.0005339118652045727 0.08197757601737976
encoder.encoder.bias_ih_l0_reverse: 0.006733718328177929 0.08009153604507446
encoder.encoder.bias_hh_l0_reverse: 0.007028369233012199 0.08561579138040543
decider.lstm.weight_ih_l0: -0.001550148706883192 0.1450337916612625
decider.lstm.weight_hh_l0: 0.0018618057947605848 0.14440329372882843
decider.lstm.bias_ih_l0: -0.03132745996117592 0.14146879315376282
decider.lstm.bias_hh_l0: 0.004493392072618008 0.15167275071144104
decider.linear1.weight: 0.003391878679394722 0.1175127923488617
decider.linear1.bias: -0.0027590016834437847 0.11407893896102905
decider.linear2.weight: 0.00017506390577182174 0.051349274814128876
decider.linear2.bias: -0.0021749779116362333 0.05194510146975517
decider.linear3.weight: -0.00016291160136461258 0.05135146155953407
decider.linear3.bias: -0.014181426726281643 0.02434667758643627

Rewards:
57.6862
57.6862
57.6862
objective = 74.6402816772461
==== episode 4200/75000 ====
action = 2
probs = 0.0562 0.3444 0.3583 0.2411

action = 2
probs = 0.1103 0.3248 0.3271 0.2377

action = 1
probs = 0.1951 0.3121 0.3799 0.1129

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00048171280650421977 0.08127295970916748
encoder.encoder.weight_hh_l0: -0.00013700241106562316 0.08234066516160965
encoder.encoder.bias_ih_l0: -0.005266337189823389 0.08478708565235138
encoder.encoder.bias_hh_l0: 0.007805654313415289 0.08308043330907822
encoder.encoder.weight_ih_l0_reverse: 0.0007053872104734182 0.08307953923940659
encoder.encoder.weight_hh_l0_reverse: 0.0005364458193071187 0.0819818526506424
encoder.encoder.bias_ih_l0_reverse: 0.00674400432035327 0.08006413280963898
encoder.encoder.bias_hh_l0_reverse: 0.00703865522518754 0.08570735156536102
decider.lstm.weight_ih_l0: -0.0015485880430787802 0.14503340423107147
decider.lstm.weight_hh_l0: 0.001800491358153522 0.14439979195594788
decider.lstm.bias_ih_l0: -0.031155845150351524 0.1414768397808075
decider.lstm.bias_hh_l0: 0.0046650078147649765 0.15165963768959045
decider.linear1.weight: 0.003343567019328475 0.1175304502248764
decider.linear1.bias: -0.0025582159869372845 0.11411461979150772
decider.linear2.weight: 0.0002072182105621323 0.05136110633611679
decider.linear2.bias: -0.0021117907017469406 0.051956359297037125
decider.linear3.weight: -0.00019041728228330612 0.05137508362531662
decider.linear3.bias: -0.014259383082389832 0.02501911297440529

Rewards:
72.2231
72.2231
72.2231
objective = 79.64318084716797
==== episode 4300/75000 ====
action = 2
probs = 0.0551 0.3407 0.3630 0.2412

action = 2
probs = 0.1155 0.2955 0.3505 0.2385

action = 3
probs = 0.2019 0.2696 0.4122 0.1163

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00043796602403745055 0.08128933608531952
encoder.encoder.weight_hh_l0: -0.0001716627593850717 0.08236224949359894
encoder.encoder.bias_ih_l0: -0.005202512722462416 0.08477021008729935
encoder.encoder.bias_hh_l0: 0.007869481109082699 0.08303916454315186
encoder.encoder.weight_ih_l0_reverse: 0.0007209068862721324 0.0830821543931961
encoder.encoder.weight_hh_l0_reverse: 0.0005301654455251992 0.08197823911905289
encoder.encoder.bias_ih_l0_reverse: 0.00666034035384655 0.08011506497859955
encoder.encoder.bias_hh_l0_reverse: 0.006954990327358246 0.0856698527932167
decider.lstm.weight_ih_l0: -0.0015445039607584476 0.145024836063385
decider.lstm.weight_hh_l0: 0.0018285831902176142 0.14443448185920715
decider.lstm.bias_ih_l0: -0.031244687736034393 0.14151842892169952
decider.lstm.bias_hh_l0: 0.004576166160404682 0.1515657603740692
decider.linear1.weight: 0.0033295494504272938 0.11751312017440796
decider.linear1.bias: -0.0024892231449484825 0.1141711100935936
decider.linear2.weight: 0.0001991761673707515 0.05136756971478462
decider.linear2.bias: -0.0021222655195742846 0.05190471559762955
decider.linear3.weight: -0.00019369716756045818 0.05137186497449875
decider.linear3.bias: -0.014249335043132305 0.024808647111058235

Rewards:
65.2837
65.2837
65.2837
objective = 91.68415832519531
==== episode 4400/75000 ====
action = 2
probs = 0.0556 0.3680 0.3691 0.2073

action = 1
probs = 0.1258 0.3113 0.3453 0.2176

action = 0
probs = 0.2177 0.2674 0.4023 0.1125

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00043452694080770016 0.0812811478972435
encoder.encoder.weight_hh_l0: -0.00017978133109863847 0.08236246556043625
encoder.encoder.bias_ih_l0: -0.005250022280961275 0.08469713479280472
encoder.encoder.bias_hh_l0: 0.007821972481906414 0.08299661427736282
encoder.encoder.weight_ih_l0_reverse: 0.0007166363066062331 0.08306378126144409
encoder.encoder.weight_hh_l0_reverse: 0.0005209161899983883 0.08196516335010529
encoder.encoder.bias_ih_l0_reverse: 0.00657229870557785 0.08011669665575027
encoder.encoder.bias_hh_l0_reverse: 0.006866948679089546 0.08569681644439697
decider.lstm.weight_ih_l0: -0.001543090445920825 0.14501804113388062
decider.lstm.weight_hh_l0: 0.0018669519340619445 0.144435316324234
decider.lstm.bias_ih_l0: -0.03134744614362717 0.1414591521024704
decider.lstm.bias_hh_l0: 0.004473397508263588 0.1515934020280838
decider.linear1.weight: 0.0033216471783816814 0.11751069128513336
decider.linear1.bias: -0.002467233221977949 0.11419137567281723
decider.linear2.weight: 0.00021759927039965987 0.05137333273887634
decider.linear2.bias: -0.0020859558135271072 0.05187378078699112
decider.linear3.weight: -0.00019529496785253286 0.051401231437921524
decider.linear3.bias: -0.014246313832700253 0.025545870885252953

Rewards:
75.0330
75.0330
75.0330
objective = 92.24736022949219
==== episode 4500/75000 ====
action = 3
probs = 0.0603 0.3823 0.3476 0.2098

action = 3
probs = 0.1276 0.3420 0.3278 0.2026

action = 2
probs = 0.2072 0.3051 0.3840 0.1037

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004929431015625596 0.08124518394470215
encoder.encoder.weight_hh_l0: -0.00014121475396677852 0.08234693109989166
encoder.encoder.bias_ih_l0: -0.005456971935927868 0.08469241857528687
encoder.encoder.bias_hh_l0: 0.007615020032972097 0.0830032229423523
encoder.encoder.weight_ih_l0_reverse: 0.0006722254911437631 0.08306630700826645
encoder.encoder.weight_hh_l0_reverse: 0.0005124707240611315 0.08194908499717712
encoder.encoder.bias_ih_l0_reverse: 0.006442436017096043 0.08006563782691956
encoder.encoder.bias_hh_l0_reverse: 0.0067370873875916 0.08566595613956451
decider.lstm.weight_ih_l0: -0.0015546027570962906 0.145016610622406
decider.lstm.weight_hh_l0: 0.0018616600427776575 0.14438477158546448
decider.lstm.bias_ih_l0: -0.03141997754573822 0.1414162963628769
decider.lstm.bias_hh_l0: 0.004400859586894512 0.1516706347465515
decider.linear1.weight: 0.003362899413332343 0.11748350411653519
decider.linear1.bias: -0.0027000242844223976 0.11414462327957153
decider.linear2.weight: 0.00017381974612362683 0.051353879272937775
decider.linear2.bias: -0.0021602981723845005 0.05195380747318268
decider.linear3.weight: -0.00019066547974944115 0.05130299553275108
decider.linear3.bias: -0.014244829304516315 0.02579505741596222

Rewards:
67.0909
67.0909
67.0909
objective = 92.03743743896484
==== episode 4600/75000 ====
action = 2
probs = 0.0586 0.4112 0.3178 0.2125

action = 2
probs = 0.1300 0.3309 0.3108 0.2283

action = 2
probs = 0.2122 0.2959 0.3718 0.1202

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00048220710596069694 0.08124741166830063
encoder.encoder.weight_hh_l0: -0.00014131750504020602 0.08232913911342621
encoder.encoder.bias_ih_l0: -0.005576097872108221 0.08464228361845016
encoder.encoder.bias_hh_l0: 0.007495896425098181 0.08296459168195724
encoder.encoder.weight_ih_l0_reverse: 0.0006642077933065593 0.08303210139274597
encoder.encoder.weight_hh_l0_reverse: 0.0005057431990280747 0.08195080608129501
encoder.encoder.bias_ih_l0_reverse: 0.006277478765696287 0.08005844056606293
encoder.encoder.bias_hh_l0_reverse: 0.006572131533175707 0.08567260205745697
decider.lstm.weight_ih_l0: -0.0015545007772743702 0.14500495791435242
decider.lstm.weight_hh_l0: 0.0019201230024918914 0.1444217413663864
decider.lstm.bias_ih_l0: -0.03173748776316643 0.14151334762573242
decider.lstm.bias_hh_l0: 0.004083349369466305 0.15153224766254425
decider.linear1.weight: 0.0033566663041710854 0.11746030300855637
decider.linear1.bias: -0.002730604726821184 0.11420157551765442
decider.linear2.weight: 0.00016853708075359464 0.05135638266801834
decider.linear2.bias: -0.002166108228266239 0.051942165940999985
decider.linear3.weight: -0.00018662831280380487 0.05130486562848091
decider.linear3.bias: -0.014228982850909233 0.025486445054411888

Rewards:
67.4559
67.4559
67.4559
objective = 74.30271911621094
==== episode 4700/75000 ====
action = 3
probs = 0.0652 0.4227 0.2869 0.2252

action = 1
probs = 0.1351 0.3526 0.2808 0.2315

action = 2
probs = 0.2238 0.2872 0.3653 0.1237

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000529827899299562 0.0812210664153099
encoder.encoder.weight_hh_l0: -0.00012594761210493743 0.08230740576982498
encoder.encoder.bias_ih_l0: -0.005731843411922455 0.08464141190052032
encoder.encoder.bias_hh_l0: 0.007340150885283947 0.08293452858924866
encoder.encoder.weight_ih_l0_reverse: 0.0006265530828386545 0.08301203697919846
encoder.encoder.weight_hh_l0_reverse: 0.0004910188727080822 0.08195123076438904
encoder.encoder.bias_ih_l0_reverse: 0.0061108716763556 0.08006016910076141
encoder.encoder.bias_hh_l0_reverse: 0.006405523046851158 0.08559117466211319
decider.lstm.weight_ih_l0: -0.0015638675540685654 0.14499938488006592
decider.lstm.weight_hh_l0: 0.0019531440921127796 0.1444234848022461
decider.lstm.bias_ih_l0: -0.031940560787916183 0.14153313636779785
decider.lstm.bias_hh_l0: 0.003880266100168228 0.15154539048671722
decider.linear1.weight: 0.0034011572133749723 0.11742446571588516
decider.linear1.bias: -0.0030111512169241905 0.11415815353393555
decider.linear2.weight: 0.000138056930154562 0.0513337180018425
decider.linear2.bias: -0.0022349078208208084 0.05194845423102379
decider.linear3.weight: -0.00015279848594218493 0.05122211575508118
decider.linear3.bias: -0.014157270081341267 0.02527516894042492

Rewards:
63.3518
63.3518
63.3518
objective = 74.75582122802734
==== episode 4800/75000 ====
action = 2
probs = 0.0681 0.4284 0.2859 0.2176

action = 0
probs = 0.1395 0.3529 0.3005 0.2071

action = 3
probs = 0.2076 0.3077 0.3738 0.1108

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005361530347727239 0.08126133680343628
encoder.encoder.weight_hh_l0: -0.0001327905192738399 0.08234767615795135
encoder.encoder.bias_ih_l0: -0.005560312885791063 0.0846269503235817
encoder.encoder.bias_hh_l0: 0.007511681877076626 0.08297321200370789
encoder.encoder.weight_ih_l0_reverse: 0.0006069999071769416 0.08307049423456192
encoder.encoder.weight_hh_l0_reverse: 0.00048223836347460747 0.08197013288736343
encoder.encoder.bias_ih_l0_reverse: 0.006092838943004608 0.0800563171505928
encoder.encoder.bias_hh_l0_reverse: 0.006387491710484028 0.0855160653591156
decider.lstm.weight_ih_l0: -0.0015680509386584163 0.1450161635875702
decider.lstm.weight_hh_l0: 0.001881441567093134 0.14441345632076263
decider.lstm.bias_ih_l0: -0.031657591462135315 0.14162816107273102
decider.lstm.bias_hh_l0: 0.004163236357271671 0.15169456601142883
decider.linear1.weight: 0.0033932956866919994 0.11743951588869095
decider.linear1.bias: -0.0029830564744770527 0.11410217732191086
decider.linear2.weight: 0.00013572632451541722 0.05133771896362305
decider.linear2.bias: -0.0022418848238885403 0.0520080141723156
decider.linear3.weight: -0.00016216561198234558 0.051216043531894684
decider.linear3.bias: -0.014194387011229992 0.025735095143318176

Rewards:
57.1015
57.1015
57.1015
objective = 103.19621276855469
==== episode 4900/75000 ====
action = 1
probs = 0.0705 0.4301 0.2969 0.2026

action = 2
probs = 0.1576 0.3222 0.3280 0.1922

action = 2
probs = 0.2325 0.2892 0.3722 0.1061

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005237057921476662 0.08121538907289505
encoder.encoder.weight_hh_l0: -0.00013708672486245632 0.08231203258037567
encoder.encoder.bias_ih_l0: -0.005791455507278442 0.08463248610496521
encoder.encoder.bias_hh_l0: 0.00728053692728281 0.08294703811407089
encoder.encoder.weight_ih_l0_reverse: 0.0005829663714393973 0.08303312212228775
encoder.encoder.weight_hh_l0_reverse: 0.0004718145646620542 0.08191575109958649
encoder.encoder.bias_ih_l0_reverse: 0.005967841017991304 0.08003966510295868
encoder.encoder.bias_hh_l0_reverse: 0.006262494251132011 0.08539577573537827
decider.lstm.weight_ih_l0: -0.0015603001229465008 0.14499691128730774
decider.lstm.weight_hh_l0: 0.00190281355753541 0.14437547326087952
decider.lstm.bias_ih_l0: -0.03175533562898636 0.1415916383266449
decider.lstm.bias_hh_l0: 0.004065503366291523 0.15175120532512665
decider.linear1.weight: 0.0033759805373847485 0.11743581295013428
decider.linear1.bias: -0.002966717816889286 0.1141151562333107
decider.linear2.weight: 0.0001197679084725678 0.051340945065021515
decider.linear2.bias: -0.0022697588428854942 0.05194318667054176
decider.linear3.weight: -0.00015912798698991537 0.05122107267379761
decider.linear3.bias: -0.014165785163640976 0.02607867307960987

Rewards:
70.1874
70.1874
70.1874
objective = 68.94349670410156
==== episode 5000/75000 ====
action = 1
probs = 0.0685 0.4592 0.2611 0.2113

action = 2
probs = 0.1643 0.3303 0.3010 0.2043

action = 3
probs = 0.2614 0.2805 0.3467 0.1114

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005464152782224119 0.08117461949586868
encoder.encoder.weight_hh_l0: -0.00011781577632064 0.0822853296995163
encoder.encoder.bias_ih_l0: -0.005947829224169254 0.08465214818716049
encoder.encoder.bias_hh_l0: 0.0071241650730371475 0.0829598680138588
encoder.encoder.weight_ih_l0_reverse: 0.0005683196359314024 0.08301310986280441
encoder.encoder.weight_hh_l0_reverse: 0.0004661259881686419 0.08190540969371796
encoder.encoder.bias_ih_l0_reverse: 0.005884577985852957 0.08006224781274796
encoder.encoder.bias_hh_l0_reverse: 0.006179231218993664 0.0853307768702507
decider.lstm.weight_ih_l0: -0.0015636285534128547 0.14499050378799438
decider.lstm.weight_hh_l0: 0.0019162826938554645 0.14438270032405853
decider.lstm.bias_ih_l0: -0.031818144023418427 0.1415715515613556
decider.lstm.bias_hh_l0: 0.004002693109214306 0.1517375111579895
decider.linear1.weight: 0.0033905578311532736 0.1174338310956955
decider.linear1.bias: -0.00306671392172575 0.11410863697528839
decider.linear2.weight: 9.437729750061408e-05 0.05133999511599541
decider.linear2.bias: -0.002297379309311509 0.05195073038339615
decider.linear3.weight: -0.00014335138257592916 0.05125139653682709
decider.linear3.bias: -0.014087265357375145 0.025875311344861984

Rewards:
68.7666
68.7666
68.7666
objective = 95.6740951538086
==== episode 5100/75000 ====
action = 1
probs = 0.0753 0.4553 0.2589 0.2104

action = 0
probs = 0.1906 0.3044 0.3099 0.1950

action = 2
probs = 0.2818 0.2654 0.3532 0.0996

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005393685423769057 0.08123240619897842
encoder.encoder.weight_hh_l0: -0.00014678864681627601 0.08234640210866928
encoder.encoder.bias_ih_l0: -0.005535622593015432 0.08465800434350967
encoder.encoder.bias_hh_l0: 0.007536370772868395 0.08302195370197296
encoder.encoder.weight_ih_l0_reverse: 0.0005812192102894187 0.08308720588684082
encoder.encoder.weight_hh_l0_reverse: 0.0004589786985889077 0.08193749934434891
encoder.encoder.bias_ih_l0_reverse: 0.005913592875003815 0.08013489097356796
encoder.encoder.bias_hh_l0_reverse: 0.006208247039467096 0.08526306599378586
decider.lstm.weight_ih_l0: -0.0015640802448615432 0.14502336084842682
decider.lstm.weight_hh_l0: 0.001835683360695839 0.14439962804317474
decider.lstm.bias_ih_l0: -0.03150855004787445 0.14170899987220764
decider.lstm.bias_hh_l0: 0.004312282428145409 0.15192463994026184
decider.linear1.weight: 0.0033828821033239365 0.11745352298021317
decider.linear1.bias: -0.0030539091676473618 0.11403128504753113
decider.linear2.weight: 8.234265260398388e-05 0.05135154351592064
decider.linear2.bias: -0.002326440531760454 0.05190752446651459
decider.linear3.weight: -0.00014152424409985542 0.051277920603752136
decider.linear3.bias: -0.014042260125279427 0.026139408349990845

Rewards:
71.0584
71.0584
71.0584
objective = 82.54510498046875
==== episode 5200/75000 ====
action = 2
probs = 0.0884 0.4389 0.2639 0.2088

action = 2
probs = 0.2088 0.2842 0.2909 0.2161

action = 3
probs = 0.3016 0.2395 0.3441 0.1148

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005242795450612903 0.08125796169042587
encoder.encoder.weight_hh_l0: -0.00017192096856888384 0.08236461132764816
encoder.encoder.bias_ih_l0: -0.005346715450286865 0.084689661860466
encoder.encoder.bias_hh_l0: 0.007725277449935675 0.08299943059682846
encoder.encoder.weight_ih_l0_reverse: 0.0005881659453734756 0.08309587091207504
encoder.encoder.weight_hh_l0_reverse: 0.0004574212071020156 0.08195019513368607
encoder.encoder.bias_ih_l0_reverse: 0.0059189083985984325 0.08024831116199493
encoder.encoder.bias_hh_l0_reverse: 0.006213562563061714 0.08518213778734207
decider.lstm.weight_ih_l0: -0.001571964006870985 0.14505283534526825
decider.lstm.weight_hh_l0: 0.0019026832887902856 0.14442633092403412
decider.lstm.bias_ih_l0: -0.031720034778118134 0.1417372077703476
decider.lstm.bias_hh_l0: 0.004100801423192024 0.15185444056987762
decider.linear1.weight: 0.003416568972170353 0.1174238920211792
decider.linear1.bias: -0.003203148487955332 0.1140403151512146
decider.linear2.weight: 4.322062886785716e-05 0.05134313926100731
decider.linear2.bias: -0.002424611710011959 0.051822759211063385
decider.linear3.weight: -0.00011641345918178558 0.05121209844946861
decider.linear3.bias: -0.01397633459419012 0.02575751766562462

Rewards:
65.2837
65.2837
65.2837
objective = 102.96627807617188
==== episode 5300/75000 ====
action = 1
probs = 0.0779 0.4516 0.2686 0.2020

action = 3
probs = 0.1829 0.2961 0.3008 0.2202

action = 1
probs = 0.2703 0.2492 0.3583 0.1221

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005553850205615163 0.08127207309007645
encoder.encoder.weight_hh_l0: -0.00013890628179069608 0.08235756307840347
encoder.encoder.bias_ih_l0: -0.005500123370438814 0.08466767519712448
encoder.encoder.bias_hh_l0: 0.007571870926767588 0.08303101360797882
encoder.encoder.weight_ih_l0_reverse: 0.0005858298973180354 0.08309512585401535
encoder.encoder.weight_hh_l0_reverse: 0.0004607549635693431 0.08198162168264389
encoder.encoder.bias_ih_l0_reverse: 0.005917221307754517 0.08019428700208664
encoder.encoder.bias_hh_l0_reverse: 0.006211875472217798 0.08535940200090408
decider.lstm.weight_ih_l0: -0.0015759447123855352 0.1450410634279251
decider.lstm.weight_hh_l0: 0.0019152190070599318 0.14443311095237732
decider.lstm.bias_ih_l0: -0.031829215586185455 0.14173933863639832
decider.lstm.bias_hh_l0: 0.003991621546447277 0.15173454582691193
decider.linear1.weight: 0.003420687047764659 0.11742587387561798
decider.linear1.bias: -0.003282116260379553 0.11412303894758224
decider.linear2.weight: 5.177164712222293e-05 0.05133877694606781
decider.linear2.bias: -0.0023871941957622766 0.051875270903110504
decider.linear3.weight: -0.00014204077888280153 0.051183730363845825
decider.linear3.bias: -0.014056199230253696 0.025794684886932373

Rewards:
74.3234
74.3234
74.3234
objective = 91.60781860351562
==== episode 5400/75000 ====
action = 2
probs = 0.0806 0.4457 0.2808 0.1929

action = 1
probs = 0.1786 0.2913 0.3066 0.2235

action = 0
probs = 0.2661 0.2374 0.3676 0.1289

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005547354812733829 0.08127029240131378
encoder.encoder.weight_hh_l0: -0.00014753112918697298 0.08236075937747955
encoder.encoder.bias_ih_l0: -0.0054751974530518055 0.08468857407569885
encoder.encoder.bias_hh_l0: 0.007596798241138458 0.08299366384744644
encoder.encoder.weight_ih_l0_reverse: 0.0005755454185418785 0.08310462534427643
encoder.encoder.weight_hh_l0_reverse: 0.0004615016805473715 0.08198007941246033
encoder.encoder.bias_ih_l0_reverse: 0.005904149729758501 0.0802384465932846
encoder.encoder.bias_hh_l0_reverse: 0.006198802962899208 0.08532451838254929
decider.lstm.weight_ih_l0: -0.0015801205299794674 0.14503777027130127
decider.lstm.weight_hh_l0: 0.0019189661834388971 0.14444588124752045
decider.lstm.bias_ih_l0: -0.03185470029711723 0.14162974059581757
decider.lstm.bias_hh_l0: 0.003966137766838074 0.15173658728599548
decider.linear1.weight: 0.003418792737647891 0.1174173355102539
decider.linear1.bias: -0.00325830839574337 0.1141844242811203
decider.linear2.weight: 5.064718425273895e-05 0.05134429410099983
decider.linear2.bias: -0.0023904521949589252 0.05183517932891846
decider.linear3.weight: -0.00014827633276581764 0.05118066817522049
decider.linear3.bias: -0.014069456607103348 0.025832900777459145

Rewards:
75.0330
75.0330
75.0330
objective = 95.72557067871094
==== episode 5500/75000 ====
action = 2
probs = 0.0659 0.4866 0.2713 0.1763

action = 1
probs = 0.1456 0.3247 0.3198 0.2099

action = 3
probs = 0.2071 0.2383 0.4288 0.1258

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005080655100755394 0.08132674545049667
encoder.encoder.weight_hh_l0: -0.0001681613939581439 0.08242341876029968
encoder.encoder.bias_ih_l0: -0.005280765239149332 0.08467289060354233
encoder.encoder.bias_hh_l0: 0.007791231852024794 0.08306590467691422
encoder.encoder.weight_ih_l0_reverse: 0.0005997717380523682 0.08311247080564499
encoder.encoder.weight_hh_l0_reverse: 0.0004686884640250355 0.08199800550937653
encoder.encoder.bias_ih_l0_reverse: 0.00597691023722291 0.08018340170383453
encoder.encoder.bias_hh_l0_reverse: 0.0062715644016861916 0.08549433201551437
decider.lstm.weight_ih_l0: -0.0015687651466578245 0.14503580331802368
decider.lstm.weight_hh_l0: 0.0018240960780531168 0.1444999873638153
decider.lstm.bias_ih_l0: -0.03165234252810478 0.14180544018745422
decider.lstm.bias_hh_l0: 0.004168501123785973 0.15162457525730133
decider.linear1.weight: 0.0033321543596684933 0.11745588481426239
decider.linear1.bias: -0.002902025356888771 0.11420474201440811
decider.linear2.weight: 0.00016866251826286316 0.051373228430747986
decider.linear2.bias: -0.002141593722626567 0.051981426775455475
decider.linear3.weight: -0.0002098641125485301 0.05134521424770355
decider.linear3.bias: -0.014191925525665283 0.026216618716716766

Rewards:
70.4456
70.4456
70.4456
objective = 105.72765350341797
==== episode 5600/75000 ====
action = 1
probs = 0.0647 0.4910 0.2542 0.1901

action = 0
probs = 0.1325 0.3378 0.3161 0.2136

action = 2
probs = 0.1833 0.2399 0.4586 0.1182

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005455070058815181 0.08135459572076797
encoder.encoder.weight_hh_l0: -0.00015349205932579935 0.08245610445737839
encoder.encoder.bias_ih_l0: -0.005212169140577316 0.08469032496213913
encoder.encoder.bias_hh_l0: 0.007859823293983936 0.08315589278936386
encoder.encoder.weight_ih_l0_reverse: 0.0005930410698056221 0.08313729614019394
encoder.encoder.weight_hh_l0_reverse: 0.00046723545528948307 0.08203483372926712
encoder.encoder.bias_ih_l0_reverse: 0.006007694639265537 0.08015844225883484
encoder.encoder.bias_hh_l0_reverse: 0.006302353460341692 0.08549368381500244
decider.lstm.weight_ih_l0: -0.0015720262890681624 0.14504973590373993
decider.lstm.weight_hh_l0: 0.00178169971331954 0.14450214803218842
decider.lstm.bias_ih_l0: -0.031510740518569946 0.14197364449501038
decider.lstm.bias_hh_l0: 0.0043101124465465546 0.15160343050956726
decider.linear1.weight: 0.003331543877720833 0.11746537685394287
decider.linear1.bias: -0.0029152468778192997 0.11415690928697586
decider.linear2.weight: 0.00018804031424224377 0.051371701061725616
decider.linear2.bias: -0.0021249447017908096 0.05207611620426178
decider.linear3.weight: -0.0002239036839455366 0.05134015902876854
decider.linear3.bias: -0.014203982427716255 0.026059268042445183

Rewards:
71.0584
71.0584
71.0584
objective = 83.17815399169922
==== episode 5700/75000 ====
action = 1
probs = 0.0616 0.4738 0.2665 0.1980

action = 3
probs = 0.1202 0.3421 0.3272 0.2106

action = 0
probs = 0.1694 0.2462 0.4642 0.1202

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005664566997438669 0.08141115307807922
encoder.encoder.weight_hh_l0: -0.00016061263158917427 0.08251723647117615
encoder.encoder.bias_ih_l0: -0.0049521429464221 0.08472353965044022
encoder.encoder.bias_hh_l0: 0.008119849488139153 0.08320899307727814
encoder.encoder.weight_ih_l0_reverse: 0.0005962537252344191 0.0831863209605217
encoder.encoder.weight_hh_l0_reverse: 0.0004723604070022702 0.08208253979682922
encoder.encoder.bias_ih_l0_reverse: 0.0060904440470039845 0.08019385486841202
encoder.encoder.bias_hh_l0_reverse: 0.006385103799402714 0.08556061238050461
decider.lstm.weight_ih_l0: -0.0015785410068929195 0.1450698971748352
decider.lstm.weight_hh_l0: 0.0017203198513016105 0.14453841745853424
decider.lstm.bias_ih_l0: -0.0313350185751915 0.1420861929655075
decider.lstm.bias_hh_l0: 0.004485831595957279 0.15160982310771942
decider.linear1.weight: 0.0033155810087919235 0.11747940629720688
decider.linear1.bias: -0.0029075704514980316 0.11414536833763123
decider.linear2.weight: 0.00020607330952771008 0.05137469992041588
decider.linear2.bias: -0.002093528863042593 0.05211004614830017
decider.linear3.weight: -0.000241447938606143 0.05134402960538864
decider.linear3.bias: -0.014247107319533825 0.025923429057002068

Rewards:
74.3478
74.3478
74.3478
objective = 101.11935424804688
==== episode 5800/75000 ====
action = 0
probs = 0.0571 0.4848 0.2645 0.1936

action = 3
probs = 0.1215 0.3165 0.3676 0.1944

action = 1
probs = 0.1465 0.2189 0.5245 0.1101

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000518915883731097 0.08143581449985504
encoder.encoder.weight_hh_l0: -0.00019001110922545195 0.08254815638065338
encoder.encoder.bias_ih_l0: -0.004786847624927759 0.08479733020067215
encoder.encoder.bias_hh_l0: 0.008285143412649632 0.08321686834096909
encoder.encoder.weight_ih_l0_reverse: 0.000619580561760813 0.08316732197999954
encoder.encoder.weight_hh_l0_reverse: 0.00047840375918895006 0.08208122849464417
encoder.encoder.bias_ih_l0_reverse: 0.0060896300710737705 0.08018618822097778
encoder.encoder.bias_hh_l0_reverse: 0.006384288892149925 0.08556993305683136
decider.lstm.weight_ih_l0: -0.001567076425999403 0.14505217969417572
decider.lstm.weight_hh_l0: 0.0016722657019272447 0.14457885921001434
decider.lstm.bias_ih_l0: -0.031148593872785568 0.14203296601772308
decider.lstm.bias_hh_l0: 0.004672257229685783 0.15156403183937073
decider.linear1.weight: 0.0032756400760263205 0.1175227090716362
decider.linear1.bias: -0.0025527141988277435 0.11406109482049942
decider.linear2.weight: 0.00028051051776856184 0.05140765383839607
decider.linear2.bias: -0.0019342784071341157 0.05213839188218117
decider.linear3.weight: -0.00028105557430535555 0.0514850951731205
decider.linear3.bias: -0.014301508665084839 0.026080476120114326

Rewards:
61.1505
61.1505
61.1505
objective = 122.69902038574219
==== episode 5900/75000 ====
action = 1
probs = 0.0480 0.5146 0.2531 0.1842

action = 3
probs = 0.0922 0.3833 0.3246 0.2000

action = 1
probs = 0.1367 0.2217 0.5330 0.1087

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000502510869409889 0.08143448829650879
encoder.encoder.weight_hh_l0: -0.00019163569959346205 0.08255095779895782
encoder.encoder.bias_ih_l0: -0.004813390783965588 0.08479313552379608
encoder.encoder.bias_hh_l0: 0.008258599787950516 0.08324424177408218
encoder.encoder.weight_ih_l0_reverse: 0.0006248271092772484 0.08313584327697754
encoder.encoder.weight_hh_l0_reverse: 0.00047867954708635807 0.08206795901060104
encoder.encoder.bias_ih_l0_reverse: 0.006075217388570309 0.08015003055334091
encoder.encoder.bias_hh_l0_reverse: 0.006369875743985176 0.0856272280216217
decider.lstm.weight_ih_l0: -0.0015585004584863782 0.14502961933612823
decider.lstm.weight_hh_l0: 0.0016425650101155043 0.14457261562347412
decider.lstm.bias_ih_l0: -0.03098721243441105 0.14196287095546722
decider.lstm.bias_hh_l0: 0.004833634942770004 0.15158876776695251
decider.linear1.weight: 0.0032404339872300625 0.11755777150392532
decider.linear1.bias: -0.00223087752237916 0.11407500505447388
decider.linear2.weight: 0.0003424826427362859 0.05143418535590172
decider.linear2.bias: -0.0018084731418639421 0.05219193175435066
decider.linear3.weight: -0.00032151280902326107 0.05158345401287079
decider.linear3.bias: -0.014361348934471607 0.026324812322854996

Rewards:
74.3234
74.3234
74.3234
objective = 93.66264343261719
==== episode 6000/75000 ====
action = 3
probs = 0.0504 0.4815 0.2538 0.2143

action = 3
probs = 0.0950 0.3755 0.2952 0.2342

action = 2
probs = 0.1297 0.2024 0.5612 0.1068

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004995642811991274 0.08144911378622055
encoder.encoder.weight_hh_l0: -0.00020968227181583643 0.08258869498968124
encoder.encoder.bias_ih_l0: -0.0046170493587851524 0.08487553894519806
encoder.encoder.bias_hh_l0: 0.0084549430757761 0.08319887518882751
encoder.encoder.weight_ih_l0_reverse: 0.0006255782791413367 0.08313632756471634
encoder.encoder.weight_hh_l0_reverse: 0.0004757489950861782 0.08207310736179352
encoder.encoder.bias_ih_l0_reverse: 0.006050674244761467 0.08024787902832031
encoder.encoder.bias_hh_l0_reverse: 0.006345330271869898 0.08555074036121368
decider.lstm.weight_ih_l0: -0.0015653190203011036 0.1450491100549698
decider.lstm.weight_hh_l0: 0.0016332478262484074 0.14460231363773346
decider.lstm.bias_ih_l0: -0.031204283237457275 0.14193131029605865
decider.lstm.bias_hh_l0: 0.004616573452949524 0.15158136188983917
decider.linear1.weight: 0.0032424158416688442 0.11754220724105835
decider.linear1.bias: -0.002321508713066578 0.1139991357922554
decider.linear2.weight: 0.0003279173106420785 0.05143904685974121
decider.linear2.bias: -0.0018441363936290145 0.05212195962667465
decider.linear3.weight: -0.0003083465853706002 0.051593415439128876
decider.linear3.bias: -0.014317614957690239 0.025561604648828506

Rewards:
67.0909
67.0909
67.0909
objective = 79.82630920410156
==== episode 6100/75000 ====
action = 3
probs = 0.0463 0.4388 0.2636 0.2513

action = 1
probs = 0.0893 0.3348 0.2964 0.2796

action = 1
probs = 0.1227 0.1759 0.5889 0.1125

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00045722766662947834 0.0814237892627716
encoder.encoder.weight_hh_l0: -0.00023126887390390038 0.08258150517940521
encoder.encoder.bias_ih_l0: -0.0045709931291639805 0.08494648337364197
encoder.encoder.bias_hh_l0: 0.008500996977090836 0.08317695558071136
encoder.encoder.weight_ih_l0_reverse: 0.0006493758992291987 0.0830979198217392
encoder.encoder.weight_hh_l0_reverse: 0.00047705305041745305 0.08205350488424301
encoder.encoder.bias_ih_l0_reverse: 0.00607604393735528 0.08030666410923004
encoder.encoder.bias_hh_l0_reverse: 0.006370702292770147 0.08551491051912308
decider.lstm.weight_ih_l0: -0.0015555130084976554 0.14503858983516693
decider.lstm.weight_hh_l0: 0.0016233798814937472 0.14460882544517517
decider.lstm.bias_ih_l0: -0.031194789335131645 0.14185674488544464
decider.lstm.bias_hh_l0: 0.004626065492630005 0.15155397355556488
decider.linear1.weight: 0.0032299801241606474 0.11756015568971634
decider.linear1.bias: -0.002182315569370985 0.11396323144435883
decider.linear2.weight: 0.00033848409657366574 0.051461491733789444
decider.linear2.bias: -0.0018255715258419514 0.05212436988949776
decider.linear3.weight: -0.0003205742686986923 0.051685988903045654
decider.linear3.bias: -0.014308477751910686 0.02457132749259472

Rewards:
59.5008
59.5008
59.5008
objective = 83.56381225585938
==== episode 6200/75000 ====
action = 3
probs = 0.0413 0.4150 0.3095 0.2342

action = 2
probs = 0.0716 0.3455 0.3339 0.2490

action = 3
probs = 0.0986 0.2071 0.5796 0.1147

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004894715384580195 0.08146495372056961
encoder.encoder.weight_hh_l0: -0.00020199846767354757 0.08259127289056778
encoder.encoder.bias_ih_l0: -0.004663700237870216 0.08484934270381927
encoder.encoder.bias_hh_l0: 0.008408291265368462 0.08320670574903488
encoder.encoder.weight_ih_l0_reverse: 0.0006620365311391652 0.08314520120620728
encoder.encoder.weight_hh_l0_reverse: 0.000481228344142437 0.08209813386201859
encoder.encoder.bias_ih_l0_reverse: 0.006105219479650259 0.08021412789821625
encoder.encoder.bias_hh_l0_reverse: 0.0063998764380812645 0.08577225357294083
decider.lstm.weight_ih_l0: -0.0015606776578351855 0.145035982131958
decider.lstm.weight_hh_l0: 0.00163186714053154 0.14460362493991852
decider.lstm.bias_ih_l0: -0.03106115758419037 0.14173340797424316
decider.lstm.bias_hh_l0: 0.004759697243571281 0.15157632529735565
decider.linear1.weight: 0.003230372443795204 0.1175607293844223
decider.linear1.bias: -0.002113708760589361 0.11408534646034241
decider.linear2.weight: 0.0003486221539787948 0.05146309733390808
decider.linear2.bias: -0.0018194178119301796 0.05221562460064888
decider.linear3.weight: -0.00036763574462383986 0.05165170133113861
decider.linear3.bias: -0.01446099579334259 0.025094516575336456

Rewards:
66.6136
66.6136
66.6136
objective = 104.67431640625
==== episode 6300/75000 ====
action = 3
probs = 0.0376 0.4977 0.2639 0.2008

action = 2
probs = 0.0634 0.4181 0.2960 0.2225

action = 0
probs = 0.0963 0.2629 0.5223 0.1185

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004987844731658697 0.08145883679389954
encoder.encoder.weight_hh_l0: -0.0001471566647524014 0.08254199475049973
encoder.encoder.bias_ih_l0: -0.005013394169509411 0.08478458225727081
encoder.encoder.bias_hh_l0: 0.008058592677116394 0.08328437805175781
encoder.encoder.weight_ih_l0_reverse: 0.0006477844435721636 0.08312205970287323
encoder.encoder.weight_hh_l0_reverse: 0.00048284768126904964 0.08211276680231094
encoder.encoder.bias_ih_l0_reverse: 0.00600338913500309 0.08011148869991302
encoder.encoder.bias_hh_l0_reverse: 0.006298042368143797 0.08589152991771698
decider.lstm.weight_ih_l0: -0.0015597030287608504 0.14501264691352844
decider.lstm.weight_hh_l0: 0.0015993959968909621 0.144560769200325
decider.lstm.bias_ih_l0: -0.03110741265118122 0.1416303962469101
decider.lstm.bias_hh_l0: 0.00471344031393528 0.15157215297222137
decider.linear1.weight: 0.003208830952644348 0.1175636276602745
decider.linear1.bias: -0.002094680443406105 0.11417528241872787
decider.linear2.weight: 0.0003742535482160747 0.05146077275276184
decider.linear2.bias: -0.0017492335755378008 0.05229479447007179
decider.linear3.weight: -0.00039319670759141445 0.05166338384151459
decider.linear3.bias: -0.01452052965760231 0.02601950615644455

Rewards:
58.8011
58.8011
58.8011
objective = 101.20211791992188
==== episode 6400/75000 ====
action = 2
probs = 0.0363 0.5048 0.2689 0.1900

action = 1
probs = 0.0625 0.4214 0.3184 0.1977

action = 2
probs = 0.1038 0.2707 0.5130 0.1126

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004839700704906136 0.08147399127483368
encoder.encoder.weight_hh_l0: -0.00016211022739298642 0.08254888653755188
encoder.encoder.bias_ih_l0: -0.005079625640064478 0.0847858265042305
encoder.encoder.bias_hh_l0: 0.007992362603545189 0.08328786492347717
encoder.encoder.weight_ih_l0_reverse: 0.0006450667278841138 0.08312822133302689
encoder.encoder.weight_hh_l0_reverse: 0.0004740146396216005 0.0821128785610199
encoder.encoder.bias_ih_l0_reverse: 0.005930628627538681 0.08009349554777145
encoder.encoder.bias_hh_l0_reverse: 0.006225282792001963 0.08586936444044113
decider.lstm.weight_ih_l0: -0.001554488088004291 0.14500059187412262
decider.lstm.weight_hh_l0: 0.0016177097568288445 0.14457401633262634
decider.lstm.bias_ih_l0: -0.03111599013209343 0.14169472455978394
decider.lstm.bias_hh_l0: 0.004704867489635944 0.15164954960346222
decider.linear1.weight: 0.0031970578711479902 0.11756865680217743
decider.linear1.bias: -0.0021251030266284943 0.11419619619846344
decider.linear2.weight: 0.0003667789278551936 0.05145902931690216
decider.linear2.bias: -0.0017588756745681167 0.05231019854545593
decider.linear3.weight: -0.00040830776561051607 0.05164346098899841
decider.linear3.bias: -0.014538874849677086 0.026447059586644173

Rewards:
59.3096
59.3096
59.3096
objective = 56.2508544921875
==== episode 6500/75000 ====
action = 1
probs = 0.0346 0.5142 0.2690 0.1823

action = 3
probs = 0.0675 0.4159 0.3152 0.2013

action = 1
probs = 0.1142 0.2615 0.5119 0.1125

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000495038228109479 0.0815044492483139
encoder.encoder.weight_hh_l0: -0.0001681605790508911 0.08256838470697403
encoder.encoder.bias_ih_l0: -0.004958040546625853 0.0847812369465828
encoder.encoder.bias_hh_l0: 0.008113947696983814 0.08327984809875488
encoder.encoder.weight_ih_l0_reverse: 0.0006602222565561533 0.08315745741128922
encoder.encoder.weight_hh_l0_reverse: 0.0004779797454830259 0.08214657008647919
encoder.encoder.bias_ih_l0_reverse: 0.00600376958027482 0.08013519644737244
encoder.encoder.bias_hh_l0_reverse: 0.006298421416431665 0.08588416129350662
decider.lstm.weight_ih_l0: -0.001560308737680316 0.14501985907554626
decider.lstm.weight_hh_l0: 0.001635476015508175 0.1445896029472351
decider.lstm.bias_ih_l0: -0.031118473038077354 0.1416947990655899
decider.lstm.bias_hh_l0: 0.0047023845836520195 0.1516425907611847
decider.linear1.weight: 0.003189124632626772 0.11758020520210266
decider.linear1.bias: -0.002175532281398773 0.11421720683574677
decider.linear2.weight: 0.0003608839469961822 0.05146012082695961
decider.linear2.bias: -0.0017679749289527535 0.052266087383031845
decider.linear3.weight: -0.0004062980879098177 0.05164491385221481
decider.linear3.bias: -0.014523676596581936 0.026536060497164726

Rewards:
74.3234
74.3234
74.3234
objective = 89.41883850097656
==== episode 6600/75000 ====
action = 2
probs = 0.0404 0.4853 0.2850 0.1892

action = 3
probs = 0.0840 0.3611 0.3566 0.1983

action = 2
probs = 0.1413 0.2140 0.5346 0.1101

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004642873245757073 0.08142927289009094
encoder.encoder.weight_hh_l0: -0.00018027100304607302 0.08252479881048203
encoder.encoder.bias_ih_l0: -0.0052802241407334805 0.08480607718229294
encoder.encoder.bias_hh_l0: 0.0077917627058923244 0.08319935947656631
encoder.encoder.weight_ih_l0_reverse: 0.0006340434774756432 0.08312062174081802
encoder.encoder.weight_hh_l0_reverse: 0.00044041319051757455 0.08206726610660553
encoder.encoder.bias_ih_l0_reverse: 0.005738561041653156 0.08022064715623856
encoder.encoder.bias_hh_l0_reverse: 0.006033215206116438 0.08566012978553772
decider.lstm.weight_ih_l0: -0.0015706330304965377 0.14500440657138824
decider.lstm.weight_hh_l0: 0.001674913801252842 0.1445653885602951
decider.lstm.bias_ih_l0: -0.03171641007065773 0.14173468947410583
decider.lstm.bias_hh_l0: 0.004104445688426495 0.15165595710277557
decider.linear1.weight: 0.0031928697135299444 0.11752571165561676
decider.linear1.bias: -0.002415437251329422 0.1141454204916954
decider.linear2.weight: 0.00028193698381073773 0.051446106284856796
decider.linear2.bias: -0.00191848399117589 0.0521392785012722
decider.linear3.weight: -0.00036270462442189455 0.05156293138861656
decider.linear3.bias: -0.01440045889467001 0.02622312493622303

Rewards:
66.0932
66.0932
66.0932
objective = 77.09336853027344
==== episode 6700/75000 ====
action = 1
probs = 0.0391 0.4717 0.2798 0.2095

action = 1
probs = 0.0881 0.3312 0.3510 0.2297

action = 1
probs = 0.1314 0.1833 0.5696 0.1157

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004495690227486193 0.08143340796232224
encoder.encoder.weight_hh_l0: -0.00020048550504725426 0.08252537250518799
encoder.encoder.bias_ih_l0: -0.005212752148509026 0.08483044058084488
encoder.encoder.bias_hh_l0: 0.007859235629439354 0.0831853449344635
encoder.encoder.weight_ih_l0_reverse: 0.0006455458351410925 0.08312105387449265
encoder.encoder.weight_hh_l0_reverse: 0.0004422597703523934 0.08207529783248901
encoder.encoder.bias_ih_l0_reverse: 0.005748267751187086 0.08027541637420654
encoder.encoder.bias_hh_l0_reverse: 0.006042920984327793 0.08560455590486526
decider.lstm.weight_ih_l0: -0.001572007080540061 0.1450119912624359
decider.lstm.weight_hh_l0: 0.0016816665884107351 0.14458739757537842
decider.lstm.bias_ih_l0: -0.03179965913295746 0.1417747139930725
decider.lstm.bias_hh_l0: 0.0040211984887719154 0.15156397223472595
decider.linear1.weight: 0.0031967477407306433 0.11752548813819885
decider.linear1.bias: -0.002385207451879978 0.11414322257041931
decider.linear2.weight: 0.000292812823317945 0.051454827189445496
decider.linear2.bias: -0.0018977028084918857 0.052134353667497635
decider.linear3.weight: -0.00035851995926350355 0.051600515842437744
decider.linear3.bias: -0.014382174238562584 0.025425409898161888

Rewards:
57.3517
57.3517
57.3517
objective = 67.92633056640625
==== episode 6800/75000 ====
action = 1
probs = 0.0438 0.5171 0.2479 0.1913

action = 0
probs = 0.0982 0.3597 0.3102 0.2320

action = 3
probs = 0.1338 0.1874 0.5702 0.1087

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000428796251071617 0.08146966248750687
encoder.encoder.weight_hh_l0: -0.00021985468629281968 0.08254353702068329
encoder.encoder.bias_ih_l0: -0.0050800940953195095 0.08486458659172058
encoder.encoder.bias_hh_l0: 0.00799188856035471 0.08319344371557236
encoder.encoder.weight_ih_l0_reverse: 0.0006443498423323035 0.08313009887933731
encoder.encoder.weight_hh_l0_reverse: 0.00043764966540038586 0.0821007564663887
encoder.encoder.bias_ih_l0_reverse: 0.00568248238414526 0.0802960991859436
encoder.encoder.bias_hh_l0_reverse: 0.005977140739560127 0.08558729290962219
decider.lstm.weight_ih_l0: -0.0015718401409685612 0.14500956237316132
decider.lstm.weight_hh_l0: 0.0016997798811644316 0.14458805322647095
decider.lstm.bias_ih_l0: -0.031855225563049316 0.1418006867170334
decider.lstm.bias_hh_l0: 0.0039656395092606544 0.1515895426273346
decider.linear1.weight: 0.0032085906714200974 0.11753220111131668
decider.linear1.bias: -0.002401205711066723 0.11403554677963257
decider.linear2.weight: 0.0003039226867258549 0.051460232585668564
decider.linear2.bias: -0.0018719866639003158 0.05211303010582924
decider.linear3.weight: -0.00033873808570206165 0.05162270739674568
decider.linear3.bias: -0.01433938555419445 0.025946402922272682

Rewards:
60.2905
60.2905
60.2905
objective = 104.49895477294922
==== episode 6900/75000 ====
action = 1
probs = 0.0447 0.5437 0.2313 0.1802

action = 2
probs = 0.1030 0.3620 0.3278 0.2072

action = 0
probs = 0.1334 0.1813 0.5863 0.0991

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0003827889449894428 0.08145374059677124
encoder.encoder.weight_hh_l0: -0.0002522110298741609 0.0825575590133667
encoder.encoder.bias_ih_l0: -0.005061982665210962 0.08489403873682022
encoder.encoder.bias_hh_l0: 0.008009999059140682 0.08321841806173325
encoder.encoder.weight_ih_l0_reverse: 0.0006303004920482635 0.08311373740434647
encoder.encoder.weight_hh_l0_reverse: 0.00042787755955941975 0.08205225318670273
encoder.encoder.bias_ih_l0_reverse: 0.00565077131614089 0.08028484880924225
encoder.encoder.bias_hh_l0_reverse: 0.0059454310685396194 0.08551423251628876
decider.lstm.weight_ih_l0: -0.0015665814280509949 0.14500966668128967
decider.lstm.weight_hh_l0: 0.0016934211598709226 0.14459434151649475
decider.lstm.bias_ih_l0: -0.03171905130147934 0.14194229245185852
decider.lstm.bias_hh_l0: 0.004101821221411228 0.15168127417564392
decider.linear1.weight: 0.0032040178775787354 0.11755238473415375
decider.linear1.bias: -0.0021970439702272415 0.11398693174123764
decider.linear2.weight: 0.000324526394251734 0.05147932469844818
decider.linear2.bias: -0.0018339785747230053 0.05215134844183922
decider.linear3.weight: -0.0003541272599250078 0.05167131870985031
decider.linear3.bias: -0.014359151013195515 0.02639090083539486

Rewards:
73.2560
73.2560
73.2560
objective = 91.30999755859375
==== episode 7000/75000 ====
action = 3
probs = 0.0418 0.5365 0.2373 0.1844

action = 2
probs = 0.0921 0.3404 0.3587 0.2088

action = 0
probs = 0.1138 0.1477 0.6357 0.1029

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0003190519637428224 0.08150411397218704
encoder.encoder.weight_hh_l0: -0.00032431635190732777 0.08264711499214172
encoder.encoder.bias_ih_l0: -0.004523471463471651 0.08502772450447083
encoder.encoder.bias_hh_l0: 0.008548512123525143 0.08329375088214874
encoder.encoder.weight_ih_l0_reverse: 0.0006516203284263611 0.08313184976577759
encoder.encoder.weight_hh_l0_reverse: 0.00044466304825618863 0.08204169571399689
encoder.encoder.bias_ih_l0_reverse: 0.005917694419622421 0.08035173267126083
encoder.encoder.bias_hh_l0_reverse: 0.006212354172021151 0.08546575903892517
decider.lstm.weight_ih_l0: -0.0015450516948476434 0.1450485736131668
decider.lstm.weight_hh_l0: 0.0016406943323090672 0.14467217028141022
decider.lstm.bias_ih_l0: -0.031241804361343384 0.14234410226345062
decider.lstm.bias_hh_l0: 0.004579056985676289 0.15175074338912964
decider.linear1.weight: 0.0031798756681382656 0.11758745461702347
decider.linear1.bias: -0.001973254606127739 0.1140798032283783
decider.linear2.weight: 0.00034074875293299556 0.05149729922413826
decider.linear2.bias: -0.0018035173416137695 0.052176300436258316
decider.linear3.weight: -0.0003743745619431138 0.05172133073210716
decider.linear3.bias: -0.014404459856450558 0.0259169340133667

Rewards:
58.8011
58.8011
58.8011
objective = 95.82488250732422
==== episode 7100/75000 ====
action = 2
probs = 0.0346 0.5353 0.2290 0.2012

action = 3
probs = 0.0762 0.3113 0.3683 0.2443

action = 2
probs = 0.0971 0.1350 0.6439 0.1240

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00028750879573635757 0.08152293413877487
encoder.encoder.weight_hh_l0: -0.0003345669247210026 0.08268694579601288
encoder.encoder.bias_ih_l0: -0.0043152738362550735 0.08511683344841003
encoder.encoder.bias_hh_l0: 0.008756710216403008 0.08337490260601044
encoder.encoder.weight_ih_l0_reverse: 0.0006915599224157631 0.08312702178955078
encoder.encoder.weight_hh_l0_reverse: 0.00045243377098813653 0.08204475045204163
encoder.encoder.bias_ih_l0_reverse: 0.0060764700174331665 0.08037055283784866
encoder.encoder.bias_hh_l0_reverse: 0.006371128838509321 0.08546911180019379
decider.lstm.weight_ih_l0: -0.0015375524526461959 0.14505654573440552
decider.lstm.weight_hh_l0: 0.0015960827004164457 0.1446869671344757
decider.lstm.bias_ih_l0: -0.03087129443883896 0.14245383441448212
decider.lstm.bias_hh_l0: 0.004949565976858139 0.15175442397594452
decider.linear1.weight: 0.00315491808578372 0.11763759702444077
decider.linear1.bias: -0.00170211773365736 0.11431491374969482
decider.linear2.weight: 0.0003650056023616344 0.05151672661304474
decider.linear2.bias: -0.001763148233294487 0.052248407155275345
decider.linear3.weight: -0.0004066178807988763 0.0518069714307785
decider.linear3.bias: -0.01447123009711504 0.02496502920985222

Rewards:
66.0932
66.0932
66.0932
objective = 73.23029327392578
==== episode 7200/75000 ====
action = 1
probs = 0.0319 0.5350 0.2157 0.2175

action = 3
probs = 0.0752 0.3068 0.3702 0.2479

action = 2
probs = 0.0932 0.1287 0.6632 0.1149

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0002568286727182567 0.08154300600290298
encoder.encoder.weight_hh_l0: -0.0003396055253688246 0.08271649479866028
encoder.encoder.bias_ih_l0: -0.004242159891873598 0.085142582654953
encoder.encoder.bias_hh_l0: 0.008829823695123196 0.08338955044746399
encoder.encoder.weight_ih_l0_reverse: 0.0007312199450097978 0.083144411444664
encoder.encoder.weight_hh_l0_reverse: 0.00044940871885046363 0.08207032829523087
encoder.encoder.bias_ih_l0_reverse: 0.006111349910497665 0.08040110766887665
encoder.encoder.bias_hh_l0_reverse: 0.006406005006283522 0.08550947159528732
decider.lstm.weight_ih_l0: -0.0015375755028799176 0.14506784081459045
decider.lstm.weight_hh_l0: 0.0015859612030908465 0.1446894407272339
decider.lstm.bias_ih_l0: -0.030809197574853897 0.1423807442188263
decider.lstm.bias_hh_l0: 0.005011660046875477 0.15181592106819153
decider.linear1.weight: 0.003155706450343132 0.11766822636127472
decider.linear1.bias: -0.0015442660078406334 0.11433247476816177
decider.linear2.weight: 0.0003930837847292423 0.051534537225961685
decider.linear2.bias: -0.0017167043406516314 0.052291933447122574
decider.linear3.weight: -0.000424829195253551 0.051862288266420364
decider.linear3.bias: -0.014475171454250813 0.024736063554883003

Rewards:
69.5795
69.5795
69.5795
objective = 56.38242721557617
==== episode 7300/75000 ====
action = 1
probs = 0.0318 0.5372 0.2191 0.2119

action = 1
probs = 0.0734 0.2992 0.3833 0.2441

action = 2
probs = 0.0841 0.1288 0.6579 0.1293

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00026240423903800547 0.08153603971004486
encoder.encoder.weight_hh_l0: -0.000340045167831704 0.08271144330501556
encoder.encoder.bias_ih_l0: -0.004329842980951071 0.08512291312217712
encoder.encoder.bias_hh_l0: 0.008742141537368298 0.08341021835803986
encoder.encoder.weight_ih_l0_reverse: 0.0007047422113828361 0.08314519375562668
encoder.encoder.weight_hh_l0_reverse: 0.00044686836190521717 0.08204469084739685
encoder.encoder.bias_ih_l0_reverse: 0.006018592044711113 0.08036307245492935
encoder.encoder.bias_hh_l0_reverse: 0.006313248537480831 0.0854572206735611
decider.lstm.weight_ih_l0: -0.0015413013752549887 0.14506758749485016
decider.lstm.weight_hh_l0: 0.0015761428512632847 0.1446908563375473
decider.lstm.bias_ih_l0: -0.030855735763907433 0.14254999160766602
decider.lstm.bias_hh_l0: 0.004965135827660561 0.15177515149116516
decider.linear1.weight: 0.003151368349790573 0.11764359474182129
decider.linear1.bias: -0.001707226037979126 0.11443337798118591
decider.linear2.weight: 0.00036364985862746835 0.05152218043804169
decider.linear2.bias: -0.0017659503500908613 0.05230390653014183
decider.linear3.weight: -0.00042545003816485405 0.05181074142456055
decider.linear3.bias: -0.01451658271253109 0.024594800546765327

Rewards:
74.4454
74.4454
74.4454
objective = 55.754478454589844
==== episode 7400/75000 ====
action = 3
probs = 0.0282 0.5541 0.2174 0.2003

action = 2
probs = 0.0625 0.3116 0.3864 0.2396

action = 3
probs = 0.0781 0.1166 0.6744 0.1309

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00022222049301490188 0.08154633641242981
encoder.encoder.weight_hh_l0: -0.0003628840495366603 0.08273334056138992
encoder.encoder.bias_ih_l0: -0.004150566644966602 0.08518145978450775
encoder.encoder.bias_hh_l0: 0.008921417407691479 0.08345228433609009
encoder.encoder.weight_ih_l0_reverse: 0.0007156037609092891 0.08312296122312546
encoder.encoder.weight_hh_l0_reverse: 0.00045184275950305164 0.08202654868364334
encoder.encoder.bias_ih_l0_reverse: 0.006198256276547909 0.08034665137529373
encoder.encoder.bias_hh_l0_reverse: 0.006492916028946638 0.0854644849896431
decider.lstm.weight_ih_l0: -0.0015339121455326676 0.14508071541786194
decider.lstm.weight_hh_l0: 0.0015595726436004043 0.14469780027866364
decider.lstm.bias_ih_l0: -0.03055936098098755 0.142592191696167
decider.lstm.bias_hh_l0: 0.005261505022644997 0.15187306702136993
decider.linear1.weight: 0.0031404108740389347 0.11768639087677002
decider.linear1.bias: -0.00143909128382802 0.11449462920427322
decider.linear2.weight: 0.00039991692756302655 0.05154920741915703
decider.linear2.bias: -0.0016905271913856268 0.052337393164634705
decider.linear3.weight: -0.00046313588973134756 0.051901329308748245
decider.linear3.bias: -0.0145845552906394 0.024608584120869637

Rewards:
66.6136
66.6136
66.6136
objective = 101.97560119628906
==== episode 7500/75000 ====
action = 1
probs = 0.0249 0.6087 0.1866 0.1799

action = 2
probs = 0.0609 0.2995 0.4029 0.2367

action = 2
probs = 0.0707 0.1119 0.6831 0.1344

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00013480625057127327 0.08162254095077515
encoder.encoder.weight_hh_l0: -0.0004128132131882012 0.08283156901597977
encoder.encoder.bias_ih_l0: -0.0037314584478735924 0.0853043794631958
encoder.encoder.bias_hh_l0: 0.009340529330074787 0.08357361704111099
encoder.encoder.weight_ih_l0_reverse: 0.0007947992999106646 0.08316666632890701
encoder.encoder.weight_hh_l0_reverse: 0.00045618179137818515 0.08207513391971588
encoder.encoder.bias_ih_l0_reverse: 0.006408010609447956 0.0803847387433052
encoder.encoder.bias_hh_l0_reverse: 0.006702670827507973 0.0855676680803299
decider.lstm.weight_ih_l0: -0.0015286809066310525 0.14510057866573334
decider.lstm.weight_hh_l0: 0.0015553829725831747 0.14471867680549622
decider.lstm.bias_ih_l0: -0.03005490079522133 0.14271676540374756
decider.lstm.bias_hh_l0: 0.005765968002378941 0.15198715031147003
decider.linear1.weight: 0.003138597123324871 0.11775681376457214
decider.linear1.bias: -0.0011338493786752224 0.11457452178001404
decider.linear2.weight: 0.0004488137492444366 0.051579270511865616
decider.linear2.bias: -0.0016049292171373963 0.05240779370069504
decider.linear3.weight: -0.0004979043733328581 0.05201301723718643
decider.linear3.bias: -0.014644013717770576 0.02478678897023201

Rewards:
70.1874
70.1874
70.1874
objective = 41.79808807373047
==== episode 7600/75000 ====
action = 1
probs = 0.0260 0.5315 0.2243 0.2182

action = 1
probs = 0.0575 0.2293 0.4796 0.2336

action = 3
probs = 0.0610 0.0827 0.7462 0.1102

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -7.700145215494558e-05 0.08164065331220627
encoder.encoder.weight_hh_l0: -0.0004792133695445955 0.08291107416152954
encoder.encoder.bias_ih_l0: -0.0032868357375264168 0.08546329289674759
encoder.encoder.bias_hh_l0: 0.009785152040421963 0.08367905765771866
encoder.encoder.weight_ih_l0_reverse: 0.000828320044092834 0.08319541811943054
encoder.encoder.weight_hh_l0_reverse: 0.0004691507201641798 0.08207986503839493
encoder.encoder.bias_ih_l0_reverse: 0.006819148547947407 0.08047492802143097
encoder.encoder.bias_hh_l0_reverse: 0.0071138059720396996 0.08550873398780823
decider.lstm.weight_ih_l0: -0.0015154671855270863 0.145132914185524
decider.lstm.weight_hh_l0: 0.001549960463307798 0.14478132128715515
decider.lstm.bias_ih_l0: -0.029543299227952957 0.14282001554965973
decider.lstm.bias_hh_l0: 0.006277570500969887 0.15215732157230377
decider.linear1.weight: 0.003135710721835494 0.11780264228582382
decider.linear1.bias: -0.0009406781755387783 0.11455750465393066
decider.linear2.weight: 0.00047828053357079625 0.05159485712647438
decider.linear2.bias: -0.0015510980738326907 0.05241507664322853
decider.linear3.weight: -0.0005150535143911839 0.0520658865571022
decider.linear3.bias: -0.014651594683527946 0.02432819828391075

Rewards:
59.0339
59.0339
59.0339
objective = 84.82231903076172
==== episode 7700/75000 ====
action = 2
probs = 0.0243 0.5011 0.2693 0.2053

action = 3
probs = 0.0500 0.2300 0.5079 0.2122

action = 2
probs = 0.0536 0.0812 0.7639 0.1013

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -3.174137236783281e-05 0.08169800043106079
encoder.encoder.weight_hh_l0: -0.0005251059774309397 0.08298534899950027
encoder.encoder.bias_ih_l0: -0.0028351128567010164 0.08555978536605835
encoder.encoder.bias_hh_l0: 0.01023687794804573 0.08378959447145462
encoder.encoder.weight_ih_l0_reverse: 0.0008618520223535597 0.0832543596625328
encoder.encoder.weight_hh_l0_reverse: 0.00048373659956268966 0.0821077823638916
encoder.encoder.bias_ih_l0_reverse: 0.007126493379473686 0.08053653687238693
encoder.encoder.bias_hh_l0_reverse: 0.007421150803565979 0.08565475791692734
decider.lstm.weight_ih_l0: -0.001505867694504559 0.1451682150363922
decider.lstm.weight_hh_l0: 0.0015371268382295966 0.1448490172624588
decider.lstm.bias_ih_l0: -0.02911340817809105 0.14302098751068115
decider.lstm.bias_hh_l0: 0.006707463413476944 0.1522587388753891
decider.linear1.weight: 0.0031298897229135036 0.11782093346118927
decider.linear1.bias: -0.0008051656186580658 0.1145576685667038
decider.linear2.weight: 0.0005354273598641157 0.05160284414887428
decider.linear2.bias: -0.0014753580326214433 0.05243535339832306
decider.linear3.weight: -0.0005545648746192455 0.052091699093580246
decider.linear3.bias: -0.01476050540804863 0.02482539229094982

Rewards:
66.0932
66.0932
66.0932
objective = 68.99185180664062
==== episode 7800/75000 ====
action = 3
probs = 0.0218 0.4836 0.2930 0.2016

action = 2
probs = 0.0448 0.2205 0.5421 0.1925

action = 3
probs = 0.0501 0.0757 0.7875 0.0867

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 4.610061660059728e-05 0.08174525201320648
encoder.encoder.weight_hh_l0: -0.0005781756481155753 0.08306201547384262
encoder.encoder.bias_ih_l0: -0.002560604363679886 0.08563145995140076
encoder.encoder.bias_hh_l0: 0.010511389002203941 0.08389818668365479
encoder.encoder.weight_ih_l0_reverse: 0.0009428244084119797 0.08331464976072311
encoder.encoder.weight_hh_l0_reverse: 0.0004844734212383628 0.08216378092765808
encoder.encoder.bias_ih_l0_reverse: 0.007326585706323385 0.08057959377765656
encoder.encoder.bias_hh_l0_reverse: 0.007621241733431816 0.0857643261551857
decider.lstm.weight_ih_l0: -0.0015005707973614335 0.145194873213768
decider.lstm.weight_hh_l0: 0.001566025777719915 0.1448630839586258
decider.lstm.bias_ih_l0: -0.028818128630518913 0.14309734106063843
decider.lstm.bias_hh_l0: 0.007002740167081356 0.1523231714963913
decider.linear1.weight: 0.0031420334707945585 0.11785437911748886
decider.linear1.bias: -0.0005975803360342979 0.11457137018442154
decider.linear2.weight: 0.0005768884439021349 0.05161889269948006
decider.linear2.bias: -0.0014055445790290833 0.052447330206632614
decider.linear3.weight: -0.0005900189280509949 0.052152205258607864
decider.linear3.bias: -0.014814946800470352 0.025098463520407677

Rewards:
66.6136
66.6136
66.6136
objective = 103.44766235351562
==== episode 7900/75000 ====
action = 2
probs = 0.0237 0.4099 0.3584 0.2080

action = 2
probs = 0.0480 0.1679 0.6028 0.1813

action = 2
probs = 0.0525 0.0631 0.8016 0.0828

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.086161349434406e-05 0.08176328986883163
encoder.encoder.weight_hh_l0: -0.0006252694875001907 0.08310134708881378
encoder.encoder.bias_ih_l0: -0.0022715777158737183 0.08570989221334457
encoder.encoder.bias_hh_l0: 0.01080041192471981 0.08399511873722076
encoder.encoder.weight_ih_l0_reverse: 0.0009388777543790638 0.08335071802139282
encoder.encoder.weight_hh_l0_reverse: 0.0004912254516966641 0.08216781914234161
encoder.encoder.bias_ih_l0_reverse: 0.007681919261813164 0.0806843489408493
encoder.encoder.bias_hh_l0_reverse: 0.007976576685905457 0.08571694046258926
decider.lstm.weight_ih_l0: -0.0015176140004768968 0.14522910118103027
decider.lstm.weight_hh_l0: 0.001553728710860014 0.14493562281131744
decider.lstm.bias_ih_l0: -0.02854875847697258 0.14329728484153748
decider.lstm.bias_hh_l0: 0.007272111251950264 0.15235233306884766
decider.linear1.weight: 0.0031337831169366837 0.11786440014839172
decider.linear1.bias: -0.0005278149619698524 0.11456549912691116
decider.linear2.weight: 0.0005873065092600882 0.051623739302158356
decider.linear2.bias: -0.0013873940333724022 0.052391473203897476
decider.linear3.weight: -0.000579147832468152 0.052157796919345856
decider.linear3.bias: -0.014767972752451897 0.024930110201239586

Rewards:
67.4559
67.4559
67.4559
objective = 39.42758560180664
==== episode 8000/75000 ====
action = 2
probs = 0.0280 0.4446 0.3305 0.1970

action = 1
probs = 0.0594 0.1582 0.6050 0.1774

action = 2
probs = 0.0557 0.0543 0.8119 0.0781

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 1.0610520803311374e-05 0.081749327480793
encoder.encoder.weight_hh_l0: -0.0005855506169609725 0.08309783041477203
encoder.encoder.bias_ih_l0: -0.0022457547020167112 0.08571897447109222
encoder.encoder.bias_hh_l0: 0.010826234705746174 0.08393903821706772
encoder.encoder.weight_ih_l0_reverse: 0.0008595169056206942 0.08330152183771133
encoder.encoder.weight_hh_l0_reverse: 0.0004927063127979636 0.08213231712579727
encoder.encoder.bias_ih_l0_reverse: 0.00755424564704299 0.08070224523544312
encoder.encoder.bias_hh_l0_reverse: 0.00784890167415142 0.08557382971048355
decider.lstm.weight_ih_l0: -0.0015158134046941996 0.14522160589694977
decider.lstm.weight_hh_l0: 0.0014742789790034294 0.14496083557605743
decider.lstm.bias_ih_l0: -0.028774399310350418 0.14328210055828094
decider.lstm.bias_hh_l0: 0.0070464638993144035 0.15234000980854034
decider.linear1.weight: 0.0031128504779189825 0.11785196512937546
decider.linear1.bias: -0.0005739219486713409 0.11449652165174484
decider.linear2.weight: 0.0005606214399449527 0.05163431540131569
decider.linear2.bias: -0.0014323574723675847 0.05232728272676468
decider.linear3.weight: -0.0005490165203809738 0.05217152461409569
decider.linear3.bias: -0.014666843228042126 0.025067925453186035

Rewards:
59.3096
59.3096
59.3096
objective = 62.460166931152344
==== episode 8100/75000 ====
action = 1
probs = 0.0340 0.5029 0.2773 0.1858

action = 3
probs = 0.0796 0.1574 0.5831 0.1798

action = 2
probs = 0.0694 0.0575 0.7881 0.0850

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -2.01503553398652e-05 0.08171064406633377
encoder.encoder.weight_hh_l0: -0.0005291598499752581 0.08302219212055206
encoder.encoder.bias_ih_l0: -0.002888341434299946 0.08553377538919449
encoder.encoder.bias_hh_l0: 0.010183646343648434 0.08377857506275177
encoder.encoder.weight_ih_l0_reverse: 0.0008311156998388469 0.08323870599269867
encoder.encoder.weight_hh_l0_reverse: 0.0004890796262770891 0.0820954442024231
encoder.encoder.bias_ih_l0_reverse: 0.006975109223276377 0.0806172639131546
encoder.encoder.bias_hh_l0_reverse: 0.00726976478472352 0.0854441225528717
decider.lstm.weight_ih_l0: -0.0015050923684611917 0.14517278969287872
decider.lstm.weight_hh_l0: 0.0014847626443952322 0.14485663175582886
decider.lstm.bias_ih_l0: -0.02946324646472931 0.1431250274181366
decider.lstm.bias_hh_l0: 0.006357602775096893 0.15226717293262482
decider.linear1.weight: 0.0031270149629563093 0.11780943721532822
decider.linear1.bias: -0.0009096884168684483 0.11441710591316223
decider.linear2.weight: 0.0004572567413561046 0.05161982774734497
decider.linear2.bias: -0.0016127647832036018 0.05225814878940582
decider.linear3.weight: -0.0004878175677731633 0.05211296305060387
decider.linear3.bias: -0.014504821039736271 0.02507355622947216

Rewards:
69.5795
69.5795
69.5795
objective = 61.25535202026367
==== episode 8200/75000 ====
action = 1
probs = 0.0306 0.4721 0.2980 0.1993

action = 2
probs = 0.0797 0.1566 0.5505 0.2132

action = 2
probs = 0.0793 0.0650 0.7452 0.1105

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -4.1735916056495626e-06 0.08170581609010696
encoder.encoder.weight_hh_l0: -0.0005153839592821896 0.08298949897289276
encoder.encoder.bias_ih_l0: -0.0032532676123082638 0.08544372022151947
encoder.encoder.bias_hh_l0: 0.009818719699978828 0.08373928815126419
encoder.encoder.weight_ih_l0_reverse: 0.0008665677742101252 0.08323860168457031
encoder.encoder.weight_hh_l0_reverse: 0.00048490255721844733 0.08209829777479172
encoder.encoder.bias_ih_l0_reverse: 0.006795918568968773 0.08061669766902924
encoder.encoder.bias_hh_l0_reverse: 0.007090570870786905 0.08544715493917465
decider.lstm.weight_ih_l0: -0.00150734290946275 0.14515185356140137
decider.lstm.weight_hh_l0: 0.0015246544498950243 0.14481592178344727
decider.lstm.bias_ih_l0: -0.029837865382432938 0.1430923342704773
decider.lstm.bias_hh_l0: 0.005982976406812668 0.15211617946624756
decider.linear1.weight: 0.0031484642531722784 0.11776923388242722
decider.linear1.bias: -0.0011007040739059448 0.114521823823452
decider.linear2.weight: 0.000443671306129545 0.051602803170681
decider.linear2.bias: -0.0016376494895666838 0.052240852266550064
decider.linear3.weight: -0.0004909581621177495 0.05207188427448273
decider.linear3.bias: -0.0145082026720047 0.02440550923347473

Rewards:
70.1874
70.1874
70.1874
objective = 38.405181884765625
==== episode 8300/75000 ====
action = 1
probs = 0.0297 0.4676 0.2847 0.2180

action = 1
probs = 0.0777 0.1742 0.5239 0.2242

action = 0
probs = 0.0793 0.0686 0.7360 0.1161

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -3.4188851714134216e-05 0.08167415112257004
encoder.encoder.weight_hh_l0: -0.0004914418677799404 0.08294657617807388
encoder.encoder.bias_ih_l0: -0.0036084267776459455 0.08535906672477722
encoder.encoder.bias_hh_l0: 0.00946356076747179 0.08368472009897232
encoder.encoder.weight_ih_l0_reverse: 0.0008577710250392556 0.08322098851203918
encoder.encoder.weight_hh_l0_reverse: 0.0004791679384652525 0.08208167552947998
encoder.encoder.bias_ih_l0_reverse: 0.006594359874725342 0.08057823032140732
encoder.encoder.bias_hh_l0_reverse: 0.006889013107866049 0.08542147278785706
decider.lstm.weight_ih_l0: -0.0015165189979597926 0.14513809978961945
decider.lstm.weight_hh_l0: 0.0015418780967593193 0.14479060471057892
decider.lstm.bias_ih_l0: -0.030138131231069565 0.1430855542421341
decider.lstm.bias_hh_l0: 0.005682716146111488 0.15201224386692047
decider.linear1.weight: 0.00317068537697196 0.11773555725812912
decider.linear1.bias: -0.0012693339958786964 0.11450061947107315
decider.linear2.weight: 0.0004109096189495176 0.05158655345439911
decider.linear2.bias: -0.0017063565319404006 0.05226856470108032
decider.linear3.weight: -0.00048154895193874836 0.052003469318151474
decider.linear3.bias: -0.014500993303954601 0.024078505113720894

Rewards:
58.9492
58.9492
58.9492
objective = 99.08528900146484
==== episode 8400/75000 ====
action = 2
probs = 0.0300 0.4932 0.2562 0.2206

action = 3
probs = 0.0872 0.1859 0.4933 0.2336

action = 1
probs = 0.0906 0.0640 0.7322 0.1132

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -2.8804390240111388e-05 0.08167226612567902
encoder.encoder.weight_hh_l0: -0.0004971067537553608 0.08295641094446182
encoder.encoder.bias_ih_l0: -0.0034918575547635555 0.08538452535867691
encoder.encoder.bias_hh_l0: 0.009580133482813835 0.08367764949798584
encoder.encoder.weight_ih_l0_reverse: 0.0008496406371705234 0.08319594711065292
encoder.encoder.weight_hh_l0_reverse: 0.0004784737539011985 0.08207113295793533
encoder.encoder.bias_ih_l0_reverse: 0.006606911774724722 0.0805920735001564
encoder.encoder.bias_hh_l0_reverse: 0.006901568733155727 0.08542513102293015
decider.lstm.weight_ih_l0: -0.001519707846455276 0.14514696598052979
decider.lstm.weight_hh_l0: 0.0015239159110933542 0.14481429755687714
decider.lstm.bias_ih_l0: -0.030146099627017975 0.14307954907417297
decider.lstm.bias_hh_l0: 0.00567475613206625 0.15204547345638275
decider.linear1.weight: 0.0031717284582555294 0.11775980144739151
decider.linear1.bias: -0.00116061232984066 0.11440812796354294
decider.linear2.weight: 0.0004147287108935416 0.051607292145490646
decider.linear2.bias: -0.0017106232699006796 0.05222273990511894
decider.linear3.weight: -0.00047364505007863045 0.0520734004676342
decider.linear3.bias: -0.014405574649572372 0.024022111669182777

Rewards:
68.5125
68.5125
68.5125
objective = 127.08101654052734
==== episode 8500/75000 ====
action = 3
probs = 0.0254 0.5379 0.2156 0.2211

action = 3
probs = 0.0771 0.2089 0.4381 0.2759

action = 2
probs = 0.0867 0.0596 0.7225 0.1311

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -3.467555870884098e-05 0.081658273935318
encoder.encoder.weight_hh_l0: -0.00047398146125487983 0.08292803913354874
encoder.encoder.bias_ih_l0: -0.0036858986131846905 0.0853390097618103
encoder.encoder.bias_hh_l0: 0.009386090561747551 0.08362936228513718
encoder.encoder.weight_ih_l0_reverse: 0.0008586525218561292 0.0831536278128624
encoder.encoder.weight_hh_l0_reverse: 0.0004705730243586004 0.08206850290298462
encoder.encoder.bias_ih_l0_reverse: 0.006493247579783201 0.08054133504629135
encoder.encoder.bias_hh_l0_reverse: 0.006787905469536781 0.08543860167264938
decider.lstm.weight_ih_l0: -0.001518324250355363 0.14512887597084045
decider.lstm.weight_hh_l0: 0.0015410585328936577 0.14477607607841492
decider.lstm.bias_ih_l0: -0.030224261805415154 0.1429174393415451
decider.lstm.bias_hh_l0: 0.0055966004729270935 0.15198782086372375
decider.linear1.weight: 0.003182502230629325 0.11777951568365097
decider.linear1.bias: -0.0010985322296619415 0.11449941992759705
decider.linear2.weight: 0.0004223760333843529 0.051616229116916656
decider.linear2.bias: -0.0016989463474601507 0.05226626247167587
decider.linear3.weight: -0.000496569846291095 0.05214812979102135
decider.linear3.bias: -0.014410357922315598 0.023349102586507797

Rewards:
67.0909
67.0909
67.0909
objective = 69.81566619873047
==== episode 8600/75000 ====
action = 1
probs = 0.0239 0.5700 0.1935 0.2125

action = 2
probs = 0.0769 0.1967 0.4652 0.2612

action = 2
probs = 0.0871 0.0596 0.7210 0.1324

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -2.5712324713822454e-05 0.08166369795799255
encoder.encoder.weight_hh_l0: -0.00048492287169210613 0.08293746411800385
encoder.encoder.bias_ih_l0: -0.003619424533098936 0.08536535501480103
encoder.encoder.bias_hh_l0: 0.009452564641833305 0.08364997059106827
encoder.encoder.weight_ih_l0_reverse: 0.0008526055607944727 0.08315257728099823
encoder.encoder.weight_hh_l0_reverse: 0.00046744546853005886 0.08206985145807266
encoder.encoder.bias_ih_l0_reverse: 0.0064879958517849445 0.08051855862140656
encoder.encoder.bias_hh_l0_reverse: 0.00678265281021595 0.08543621003627777
decider.lstm.weight_ih_l0: -0.0015147580998018384 0.14513029158115387
decider.lstm.weight_hh_l0: 0.0015283329412341118 0.14477993547916412
decider.lstm.bias_ih_l0: -0.03007775917649269 0.142933189868927
decider.lstm.bias_hh_l0: 0.005743104964494705 0.15207746624946594
decider.linear1.weight: 0.00317623233422637 0.11780551820993423
decider.linear1.bias: -0.0009579663164913654 0.11448299884796143
decider.linear2.weight: 0.00043265364365652204 0.05163484439253807
decider.linear2.bias: -0.0016872279811650515 0.052316345274448395
decider.linear3.weight: -0.0005413162871263921 0.052207574248313904
decider.linear3.bias: -0.014433772303164005 0.02347749099135399

Rewards:
70.1874
70.1874
70.1874
objective = 38.70864486694336
==== episode 8700/75000 ====
action = 1
probs = 0.0217 0.6124 0.1674 0.1985

action = 2
probs = 0.0724 0.2107 0.4622 0.2546

action = 2
probs = 0.0853 0.0621 0.7288 0.1238

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -1.0553486390563194e-05 0.08167432248592377
encoder.encoder.weight_hh_l0: -0.00048634910490363836 0.08294210582971573
encoder.encoder.bias_ih_l0: -0.0036163057666271925 0.08537580072879791
encoder.encoder.bias_hh_l0: 0.009455680847167969 0.08368201553821564
encoder.encoder.weight_ih_l0_reverse: 0.0008614450343884528 0.08314822614192963
encoder.encoder.weight_hh_l0_reverse: 0.00046321682748384774 0.08207980543375015
encoder.encoder.bias_ih_l0_reverse: 0.006431983783841133 0.0804750844836235
encoder.encoder.bias_hh_l0_reverse: 0.006726639810949564 0.08548068255186081
decider.lstm.weight_ih_l0: -0.0015112317632883787 0.14512446522712708
decider.lstm.weight_hh_l0: 0.0015340769896283746 0.14476588368415833
decider.lstm.bias_ih_l0: -0.029961854219436646 0.14287637174129486
decider.lstm.bias_hh_l0: 0.005859014578163624 0.15212790668010712
decider.linear1.weight: 0.0031786146573722363 0.11783622205257416
decider.linear1.bias: -0.0008247755467891693 0.11449811607599258
decider.linear2.weight: 0.0004382814222481102 0.051648374646902084
decider.linear2.bias: -0.0016582334646955132 0.05239087715744972
decider.linear3.weight: -0.0005616889102384448 0.05226904898881912
decider.linear3.bias: -0.014454795978963375 0.023809118196368217

Rewards:
70.1874
70.1874
70.1874
objective = 36.92945098876953
==== episode 8800/75000 ====
action = 2
probs = 0.0238 0.6369 0.1739 0.1655

action = 2
probs = 0.0753 0.2055 0.5298 0.1895

action = 2
probs = 0.0786 0.0513 0.7837 0.0864

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 6.981394835747778e-05 0.08177133649587631
encoder.encoder.weight_hh_l0: -0.000553001940716058 0.08308175951242447
encoder.encoder.bias_ih_l0: -0.002903272630646825 0.08551477640867233
encoder.encoder.bias_hh_l0: 0.010168713517487049 0.08385441452264786
encoder.encoder.weight_ih_l0_reverse: 0.0009077638387680054 0.08324245363473892
encoder.encoder.weight_hh_l0_reverse: 0.00046764983562752604 0.08213631063699722
encoder.encoder.bias_ih_l0_reverse: 0.0067199585027992725 0.08054781705141068
encoder.encoder.bias_hh_l0_reverse: 0.0070146177895367146 0.0855989009141922
decider.lstm.weight_ih_l0: -0.001494887168519199 0.14517278969287872
decider.lstm.weight_hh_l0: 0.001497632241807878 0.14480635523796082
decider.lstm.bias_ih_l0: -0.029342154040932655 0.14316268265247345
decider.lstm.bias_hh_l0: 0.006478721275925636 0.15236547589302063
decider.linear1.weight: 0.0031622792594134808 0.11790364980697632
decider.linear1.bias: -0.00043197162449359894 0.11440984904766083
decider.linear2.weight: 0.00048040435649454594 0.05169014632701874
decider.linear2.bias: -0.0015848998446017504 0.05237392708659172
decider.linear3.weight: -0.0005771734286099672 0.05235728248953819
decider.linear3.bias: -0.014460587874054909 0.02508971467614174

Rewards:
67.4559
67.4559
67.4559
objective = 59.10453414916992
==== episode 8900/75000 ====
action = 2
probs = 0.0256 0.6321 0.1732 0.1690

action = 2
probs = 0.0800 0.1883 0.5235 0.2081

action = 0
probs = 0.0762 0.0531 0.7698 0.1009

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 2.3043601686367765e-05 0.08174151927232742
encoder.encoder.weight_hh_l0: -0.0005294870352372527 0.08304629474878311
encoder.encoder.bias_ih_l0: -0.003127884818241 0.08546186238527298
encoder.encoder.bias_hh_l0: 0.009944099932909012 0.08377765119075775
encoder.encoder.weight_ih_l0_reverse: 0.0008570498321205378 0.08320958912372589
encoder.encoder.weight_hh_l0_reverse: 0.00047112000174820423 0.08210385590791702
encoder.encoder.bias_ih_l0_reverse: 0.006547530647367239 0.08055941015481949
encoder.encoder.bias_hh_l0_reverse: 0.006842189934104681 0.08543732017278671
decider.lstm.weight_ih_l0: -0.001496014534495771 0.1451575756072998
decider.lstm.weight_hh_l0: 0.0014930532779544592 0.14479006826877594
decider.lstm.bias_ih_l0: -0.02964075282216072 0.14321087300777435
decider.lstm.bias_hh_l0: 0.006180115044116974 0.15231075882911682
decider.linear1.weight: 0.003145699854940176 0.11787919700145721
decider.linear1.bias: -0.0006222054362297058 0.11440819501876831
decider.linear2.weight: 0.00041899882489815354 0.05168294161558151
decider.linear2.bias: -0.0016846803482621908 0.05233800783753395
decider.linear3.weight: -0.0005661710747517645 0.05232395976781845
decider.linear3.bias: -0.014465680345892906 0.02464437484741211

Rewards:
57.6862
57.6862
57.6862
objective = 95.65975189208984
==== episode 9000/75000 ====
action = 1
probs = 0.0256 0.6649 0.1589 0.1507

action = 0
probs = 0.0874 0.1808 0.5402 0.1916

action = 2
probs = 0.0718 0.0503 0.7892 0.0887

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 2.4689621568541043e-05 0.08176292479038239
encoder.encoder.weight_hh_l0: -0.0005304593360051513 0.08305537700653076
encoder.encoder.bias_ih_l0: -0.003066904144361615 0.08545698970556259
encoder.encoder.bias_hh_l0: 0.010005082935094833 0.08377082645893097
encoder.encoder.weight_ih_l0_reverse: 0.0008314060978591442 0.08321407437324524
encoder.encoder.weight_hh_l0_reverse: 0.00047208843170665205 0.08210426568984985
encoder.encoder.bias_ih_l0_reverse: 0.006461797747761011 0.08054596185684204
encoder.encoder.bias_hh_l0_reverse: 0.006756459828466177 0.08544513583183289
decider.lstm.weight_ih_l0: -0.001496607786975801 0.14515767991542816
decider.lstm.weight_hh_l0: 0.0014879178488627076 0.14480072259902954
decider.lstm.bias_ih_l0: -0.02963007614016533 0.14322932064533234
decider.lstm.bias_hh_l0: 0.00619079265743494 0.15231959521770477
decider.linear1.weight: 0.0031302727293223143 0.11788567155599594
decider.linear1.bias: -0.0006104880012571812 0.11436571180820465
decider.linear2.weight: 0.0004166376602370292 0.05169009417295456
decider.linear2.bias: -0.0016824956983327866 0.0523206926882267
decider.linear3.weight: -0.0005583157180808485 0.052345845848321915
decider.linear3.bias: -0.014439377933740616 0.02517896331846714

Rewards:
71.0584
71.0584
71.0584
objective = 73.01255798339844
==== episode 9100/75000 ====
action = 1
probs = 0.0234 0.6536 0.1716 0.1514

action = 3
probs = 0.0747 0.1550 0.5896 0.1806

action = 2
probs = 0.0566 0.0429 0.8158 0.0847

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.607752533862367e-05 0.08182083070278168
encoder.encoder.weight_hh_l0: -0.0005831146845594049 0.08316876739263535
encoder.encoder.bias_ih_l0: -0.002498497487977147 0.08558567613363266
encoder.encoder.bias_hh_l0: 0.010573489591479301 0.08391501009464264
encoder.encoder.weight_ih_l0_reverse: 0.0008897365187294781 0.08327193558216095
encoder.encoder.weight_hh_l0_reverse: 0.00047925152466632426 0.08214675635099411
encoder.encoder.bias_ih_l0_reverse: 0.006821594201028347 0.08058205991983414
encoder.encoder.bias_hh_l0_reverse: 0.007116258610039949 0.08555365353822708
decider.lstm.weight_ih_l0: -0.0014914461644366384 0.14519470930099487
decider.lstm.weight_hh_l0: 0.0014699985040351748 0.14485704898834229
decider.lstm.bias_ih_l0: -0.029134705662727356 0.14335907995700836
decider.lstm.bias_hh_l0: 0.006686159409582615 0.15241007506847382
decider.linear1.weight: 0.003127867355942726 0.11794191598892212
decider.linear1.bias: -0.00029220571741461754 0.11440454423427582
decider.linear2.weight: 0.00046661478700116277 0.05172380059957504
decider.linear2.bias: -0.0015811000484973192 0.05237627774477005
decider.linear3.weight: -0.0006185437086969614 0.052443213760852814
decider.linear3.bias: -0.014583969488739967 0.025102652609348297

Rewards:
69.5795
69.5795
69.5795
objective = 54.28092575073242
==== episode 9200/75000 ====
action = 1
probs = 0.0218 0.6465 0.1842 0.1474

action = 2
probs = 0.0690 0.1488 0.6066 0.1756

action = 2
probs = 0.0527 0.0402 0.8275 0.0796

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 9.461976151214913e-05 0.08183497935533524
encoder.encoder.weight_hh_l0: -0.0005934896180406213 0.08318018913269043
encoder.encoder.bias_ih_l0: -0.0023469680454581976 0.08562928438186646
encoder.encoder.bias_hh_l0: 0.010725018568336964 0.08394268900156021
encoder.encoder.weight_ih_l0_reverse: 0.0008944313158281147 0.08328840881586075
encoder.encoder.weight_hh_l0_reverse: 0.000482439121697098 0.08215566724538803
encoder.encoder.bias_ih_l0_reverse: 0.007004567421972752 0.08061607927083969
encoder.encoder.bias_hh_l0_reverse: 0.0072992341592907906 0.08561819791793823
decider.lstm.weight_ih_l0: -0.0014919840032234788 0.14520663022994995
decider.lstm.weight_hh_l0: 0.0014638137072324753 0.14488059282302856
decider.lstm.bias_ih_l0: -0.02891872078180313 0.14338083565235138
decider.lstm.bias_hh_l0: 0.006902138702571392 0.15244099497795105
decider.linear1.weight: 0.0031168684363365173 0.11796575784683228
decider.linear1.bias: -0.0001299097202718258 0.11443236470222473
decider.linear2.weight: 0.0005171785596758127 0.05173857882618904
decider.linear2.bias: -0.0014950274489820004 0.05239158123731613
decider.linear3.weight: -0.0006501655443571508 0.05249305069446564
decider.linear3.bias: -0.014647170901298523 0.025289522483944893

Rewards:
70.1874
70.1874
70.1874
objective = 26.330211639404297
==== episode 9300/75000 ====
action = 3
probs = 0.0202 0.7014 0.1513 0.1270

action = 3
probs = 0.0765 0.2002 0.5346 0.1887

action = 2
probs = 0.0660 0.0435 0.8066 0.0839

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00010599099186947569 0.08184056729078293
encoder.encoder.weight_hh_l0: -0.0005658915615640581 0.08314479142427444
encoder.encoder.bias_ih_l0: -0.0027430918999016285 0.08552513271570206
encoder.encoder.bias_hh_l0: 0.010328895412385464 0.08388000726699829
encoder.encoder.weight_ih_l0_reverse: 0.000914314528927207 0.08326547592878342
encoder.encoder.weight_hh_l0_reverse: 0.0004774424305651337 0.08215709775686264
encoder.encoder.bias_ih_l0_reverse: 0.006620357278734446 0.08053065091371536
encoder.encoder.bias_hh_l0_reverse: 0.006915021222084761 0.08563084155321121
decider.lstm.weight_ih_l0: -0.0014844979159533978 0.14517907798290253
decider.lstm.weight_hh_l0: 0.0014990752097219229 0.14480917155742645
decider.lstm.bias_ih_l0: -0.02927873283624649 0.14322510361671448
decider.lstm.bias_hh_l0: 0.006542116403579712 0.1523623913526535
decider.linear1.weight: 0.003145011840388179 0.11795809864997864
decider.linear1.bias: -0.00021285749971866608 0.11442656815052032
decider.linear2.weight: 0.0004924667300656438 0.05173654481768608
decider.linear2.bias: -0.001535639981739223 0.05235980078577995
decider.linear3.weight: -0.0006305679562501609 0.05250939354300499
decider.linear3.bias: -0.014528400264680386 0.0255420058965683

Rewards:
67.0909
67.0909
67.0909
objective = 88.2402572631836
==== episode 9400/75000 ====
action = 1
probs = 0.0178 0.6901 0.1467 0.1454

action = 3
probs = 0.0726 0.1951 0.5009 0.2314

action = 2
probs = 0.0686 0.0497 0.7665 0.1151

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 5.523942309082486e-05 0.08179643005132675
encoder.encoder.weight_hh_l0: -0.0005161815788596869 0.08307889103889465
encoder.encoder.bias_ih_l0: -0.0031573204323649406 0.0854419618844986
encoder.encoder.bias_hh_l0: 0.009914668276906013 0.08379505574703217
encoder.encoder.weight_ih_l0_reverse: 0.0008908382733352482 0.08321071416139603
encoder.encoder.weight_hh_l0_reverse: 0.00047473295126110315 0.08213046193122864
encoder.encoder.bias_ih_l0_reverse: 0.0063628097996115685 0.08046843856573105
encoder.encoder.bias_hh_l0_reverse: 0.006657475605607033 0.0855947881937027
decider.lstm.weight_ih_l0: -0.0014854876790195704 0.14514699578285217
decider.lstm.weight_hh_l0: 0.0014974119840189815 0.1447809338569641
decider.lstm.bias_ih_l0: -0.0296602975577116 0.14302857220172882
decider.lstm.bias_hh_l0: 0.006160544231534004 0.15220452845096588
decider.linear1.weight: 0.003150343429297209 0.11792463809251785
decider.linear1.bias: -0.0003823796287178993 0.1145218014717102
decider.linear2.weight: 0.0004763385222759098 0.05171983316540718
decider.linear2.bias: -0.0015796198276802897 0.052383050322532654
decider.linear3.weight: -0.0006460142321884632 0.052472569048404694
decider.linear3.bias: -0.014578079804778099 0.024557143449783325

Rewards:
69.5795
69.5795
69.5795
objective = 48.713775634765625
==== episode 9500/75000 ====
action = 2
probs = 0.0170 0.7285 0.1356 0.1189

action = 2
probs = 0.0713 0.2418 0.4794 0.2074

action = 2
probs = 0.0709 0.0553 0.7651 0.1088

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 9.046796185430139e-05 0.08184326440095901
encoder.encoder.weight_hh_l0: -0.0005334373563528061 0.08311200141906738
encoder.encoder.bias_ih_l0: -0.0029629815835505724 0.08548364788293839
encoder.encoder.bias_hh_l0: 0.010109009221196175 0.08383890986442566
encoder.encoder.weight_ih_l0_reverse: 0.000899884442333132 0.08323761820793152
encoder.encoder.weight_hh_l0_reverse: 0.00047235607053153217 0.0821484625339508
encoder.encoder.bias_ih_l0_reverse: 0.0063466355204582214 0.08046437054872513
encoder.encoder.bias_hh_l0_reverse: 0.006641301792114973 0.08568858355283737
decider.lstm.weight_ih_l0: -0.001483303145505488 0.14515629410743713
decider.lstm.weight_hh_l0: 0.001490253023803234 0.14479093253612518
decider.lstm.bias_ih_l0: -0.029451582580804825 0.14305278658866882
decider.lstm.bias_hh_l0: 0.006369259208440781 0.15228812396526337
decider.linear1.weight: 0.0031482758931815624 0.11794744431972504
decider.linear1.bias: -0.00024755438789725304 0.11451417952775955
decider.linear2.weight: 0.0005000496748834848 0.05173507705330849
decider.linear2.bias: -0.0015308319125324488 0.05240357294678688
decider.linear3.weight: -0.0006512306863442063 0.0525018535554409
decider.linear3.bias: -0.014589228667318821 0.025400253012776375

Rewards:
67.4559
67.4559
67.4559
objective = 67.48159790039062
==== episode 9600/75000 ====
action = 1
probs = 0.0140 0.7514 0.1229 0.1117

action = 2
probs = 0.0665 0.2306 0.4819 0.2210

action = 2
probs = 0.0621 0.0507 0.7719 0.1153

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00010369904339313507 0.08185308426618576
encoder.encoder.weight_hh_l0: -0.0005368089769035578 0.08310150355100632
encoder.encoder.bias_ih_l0: -0.0029229973442852497 0.08552418649196625
encoder.encoder.bias_hh_l0: 0.010148992761969566 0.08382770419120789
encoder.encoder.weight_ih_l0_reverse: 0.0008998711127787828 0.08323132991790771
encoder.encoder.weight_hh_l0_reverse: 0.00047605912550352514 0.08214600384235382
encoder.encoder.bias_ih_l0_reverse: 0.006382646504789591 0.08048432320356369
encoder.encoder.bias_hh_l0_reverse: 0.0066773067228496075 0.08573359996080399
decider.lstm.weight_ih_l0: -0.0014787662075832486 0.14515142142772675
decider.lstm.weight_hh_l0: 0.0014703039778396487 0.14480775594711304
decider.lstm.bias_ih_l0: -0.029243456199765205 0.14304696023464203
decider.lstm.bias_hh_l0: 0.006577375344932079 0.15230202674865723
decider.linear1.weight: 0.00313725508749485 0.117991141974926
decider.linear1.bias: -3.278534859418869e-05 0.11456619948148727
decider.linear2.weight: 0.0005406180862337351 0.05175827443599701
decider.linear2.bias: -0.001456918311305344 0.05245162174105644
decider.linear3.weight: -0.0006953194970265031 0.05258392170071602
decider.linear3.bias: -0.014659317210316658 0.025216195732355118

Rewards:
70.1874
70.1874
70.1874
objective = 29.823287963867188
==== episode 9700/75000 ====
action = 1
probs = 0.0123 0.7774 0.1234 0.0868

action = 2
probs = 0.0605 0.2524 0.5041 0.1830

action = 2
probs = 0.0565 0.0544 0.7837 0.1054

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00013811021926812828 0.08189605176448822
encoder.encoder.weight_hh_l0: -0.0005530190537683666 0.08312218636274338
encoder.encoder.bias_ih_l0: -0.0027987530920654535 0.08556066453456879
encoder.encoder.bias_hh_l0: 0.010273236781358719 0.08387069404125214
encoder.encoder.weight_ih_l0_reverse: 0.0009195836610160768 0.08326511830091476
encoder.encoder.weight_hh_l0_reverse: 0.0004743233439512551 0.08216847479343414
encoder.encoder.bias_ih_l0_reverse: 0.006414846517145634 0.0804729163646698
encoder.encoder.bias_hh_l0_reverse: 0.006709507666528225 0.08586091548204422
decider.lstm.weight_ih_l0: -0.0014793038135394454 0.14516732096672058
decider.lstm.weight_hh_l0: 0.0014704101486131549 0.14480528235435486
decider.lstm.bias_ih_l0: -0.02907174453139305 0.14311915636062622
decider.lstm.bias_hh_l0: 0.0067490944638848305 0.15238578617572784
decider.linear1.weight: 0.003143265377730131 0.11801118403673172
decider.linear1.bias: 0.00012753065675497055 0.11460825800895691
decider.linear2.weight: 0.0005824085092172027 0.05177435651421547
decider.linear2.bias: -0.0013774207327514887 0.05250503867864609
decider.linear3.weight: -0.0007325697224587202 0.05261349678039551
decider.linear3.bias: -0.014764435589313507 0.026194892823696136

Rewards:
70.1874
70.1874
70.1874
objective = 27.620616912841797
==== episode 9800/75000 ====
action = 2
probs = 0.0124 0.7665 0.1331 0.0880

action = 1
probs = 0.0538 0.2472 0.5243 0.1746

action = 2
probs = 0.0485 0.0465 0.8088 0.0961

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00014485664723906666 0.08192531019449234
encoder.encoder.weight_hh_l0: -0.000568268122151494 0.08317335695028305
encoder.encoder.bias_ih_l0: -0.0024952127132564783 0.08563601970672607
encoder.encoder.bias_hh_l0: 0.010576779954135418 0.08392525464296341
encoder.encoder.weight_ih_l0_reverse: 0.0009259674698114395 0.0832940861582756
encoder.encoder.weight_hh_l0_reverse: 0.0004826602234970778 0.08218284696340561
encoder.encoder.bias_ih_l0_reverse: 0.006602042820304632 0.08053581416606903
encoder.encoder.bias_hh_l0_reverse: 0.006896705366671085 0.08592149615287781
decider.lstm.weight_ih_l0: -0.0014770695706829429 0.1451890468597412
decider.lstm.weight_hh_l0: 0.0014478376833721995 0.1448441594839096
decider.lstm.bias_ih_l0: -0.028817331418395042 0.14321264624595642
decider.lstm.bias_hh_l0: 0.007003515027463436 0.15247046947479248
decider.linear1.weight: 0.0031290785409510136 0.11803974956274033
decider.linear1.bias: 0.00029566138982772827 0.114590585231781
decider.linear2.weight: 0.0006116432487033308 0.05179252475500107
decider.linear2.bias: -0.0013279090635478497 0.052527621388435364
decider.linear3.weight: -0.0007595459464937449 0.052653566002845764
decider.linear3.bias: -0.014833815395832062 0.026226889342069626

Rewards:
59.3096
59.3096
59.3096
objective = 71.68840026855469
==== episode 9900/75000 ====
action = 1
probs = 0.0170 0.7196 0.1563 0.1071

action = 2
probs = 0.0706 0.2059 0.5307 0.1927

action = 0
probs = 0.0599 0.0503 0.7763 0.1135

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 4.2565836338326335e-05 0.08184096217155457
encoder.encoder.weight_hh_l0: -0.0005085081793367863 0.08307673782110214
encoder.encoder.bias_ih_l0: -0.0032338176388293505 0.08541791886091232
encoder.encoder.bias_hh_l0: 0.009838173165917397 0.08374302089214325
encoder.encoder.weight_ih_l0_reverse: 0.0008192702662199736 0.08323174715042114
encoder.encoder.weight_hh_l0_reverse: 0.0004774756380356848 0.08211781829595566
encoder.encoder.bias_ih_l0_reverse: 0.006126374006271362 0.0805097296833992
encoder.encoder.bias_hh_l0_reverse: 0.006421036086976528 0.08558878302574158
decider.lstm.weight_ih_l0: -0.0014907465083524585 0.1451495885848999
decider.lstm.weight_hh_l0: 0.0013577567879110575 0.14483070373535156
decider.lstm.bias_ih_l0: -0.02966247871518135 0.14320392906665802
decider.lstm.bias_hh_l0: 0.006158371455967426 0.15229782462120056
decider.linear1.weight: 0.003094833344221115 0.11793659627437592
decider.linear1.bias: -0.0003068591468036175 0.11452484875917435
decider.linear2.weight: 0.0004904938396066427 0.05174162611365318
decider.linear2.bias: -0.0015574217541143298 0.05240781977772713
decider.linear3.weight: -0.0006830760976299644 0.052470363676548004
decider.linear3.bias: -0.014685310423374176 0.025542179122567177

Rewards:
73.2560
73.2560
73.2560
objective = 92.23653411865234
==== episode 10000/75000 ====
action = 2
probs = 0.0199 0.6644 0.1865 0.1292

action = 2
probs = 0.0681 0.2164 0.5324 0.1831

action = 2
probs = 0.0570 0.0488 0.7910 0.1032

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 1.4261826436268166e-05 0.0818302184343338
encoder.encoder.weight_hh_l0: -0.0004908667760901153 0.08309414237737656
encoder.encoder.bias_ih_l0: -0.003222988685593009 0.08542865514755249
encoder.encoder.bias_hh_l0: 0.009848999790847301 0.08373372256755829
encoder.encoder.weight_ih_l0_reverse: 0.0007891574059613049 0.08323061466217041
encoder.encoder.weight_hh_l0_reverse: 0.0004789278900716454 0.08211518824100494
encoder.encoder.bias_ih_l0_reverse: 0.006051521748304367 0.08052870631217957
encoder.encoder.bias_hh_l0_reverse: 0.006346185225993395 0.08556725084781647
decider.lstm.weight_ih_l0: -0.0014903342816978693 0.14515025913715363
decider.lstm.weight_hh_l0: 0.0013341587036848068 0.144852414727211
decider.lstm.bias_ih_l0: -0.02982606180012226 0.1431749314069748
decider.lstm.bias_hh_l0: 0.005994793958961964 0.15230996906757355
decider.linear1.weight: 0.0030944037716835737 0.11790443956851959
decider.linear1.bias: -0.0004046391695737839 0.11445366591215134
decider.linear2.weight: 0.0004758031282108277 0.051730867475271225
decider.linear2.bias: -0.001628380618058145 0.05238087847828865
decider.linear3.weight: -0.0006883677560836077 0.05239144340157509
decider.linear3.bias: -0.014721245504915714 0.025428922846913338

Rewards:
67.4559
67.4559
67.4559
objective = 57.2080078125
==== episode 10100/75000 ====
action = 1
probs = 0.0180 0.6811 0.1762 0.1248

action = 3
probs = 0.0674 0.2278 0.5158 0.1889

action = 0
probs = 0.0611 0.0539 0.7707 0.1142

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 5.421563855634304e-06 0.08181086927652359
encoder.encoder.weight_hh_l0: -0.00046015813131816685 0.08304373174905777
encoder.encoder.bias_ih_l0: -0.003579718992114067 0.08533664047718048
encoder.encoder.bias_hh_l0: 0.009492270648479462 0.0836760625243187
encoder.encoder.weight_ih_l0_reverse: 0.0007917466573417187 0.0832083597779274
encoder.encoder.weight_hh_l0_reverse: 0.00046908907825127244 0.08211167901754379
encoder.encoder.bias_ih_l0_reverse: 0.005864867940545082 0.08046259731054306
encoder.encoder.bias_hh_l0_reverse: 0.006159529089927673 0.08555834740400314
decider.lstm.weight_ih_l0: -0.0014896997017785907 0.1451277732849121
decider.lstm.weight_hh_l0: 0.0013753686798736453 0.14480555057525635
decider.lstm.bias_ih_l0: -0.030047478154301643 0.14306247234344482
decider.lstm.bias_hh_l0: 0.005773373879492283 0.15224623680114746
decider.linear1.weight: 0.0031159098725765944 0.11788415163755417
decider.linear1.bias: -0.00052677933126688 0.11452758312225342
decider.linear2.weight: 0.00045244712964631617 0.051718901842832565
decider.linear2.bias: -0.0016642485279589891 0.05240655690431595
decider.linear3.weight: -0.0006908510695211589 0.052361294627189636
decider.linear3.bias: -0.014710838906466961 0.025372767820954323

Rewards:
74.3478
74.3478
74.3478
objective = 120.06975555419922
==== episode 10200/75000 ====
action = 1
probs = 0.0172 0.7021 0.1659 0.1148

action = 2
probs = 0.0664 0.2352 0.5223 0.1762

action = 1
probs = 0.0592 0.0545 0.7826 0.1036

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 3.926213685190305e-05 0.08184800297021866
encoder.encoder.weight_hh_l0: -0.000477125053294003 0.08308365941047668
encoder.encoder.bias_ih_l0: -0.0033815731294453144 0.08539500832557678
encoder.encoder.bias_hh_l0: 0.009690417908132076 0.08374813944101334
encoder.encoder.weight_ih_l0_reverse: 0.000818322878330946 0.08322936296463013
encoder.encoder.weight_hh_l0_reverse: 0.00046824669698253274 0.08212923258543015
encoder.encoder.bias_ih_l0_reverse: 0.00591113418340683 0.08046264946460724
encoder.encoder.bias_hh_l0_reverse: 0.006205796264111996 0.0856461375951767
decider.lstm.weight_ih_l0: -0.0014866235433146358 0.1451401710510254
decider.lstm.weight_hh_l0: 0.0013595710042864084 0.14481167495250702
decider.lstm.bias_ih_l0: -0.02986420877277851 0.14305105805397034
decider.lstm.bias_hh_l0: 0.005956638604402542 0.15230603516101837
decider.linear1.weight: 0.0031150567810982466 0.11791005730628967
decider.linear1.bias: -0.00038405507802963257 0.11455351859331131
decider.linear2.weight: 0.0004915732424706221 0.051735248416662216
decider.linear2.bias: -0.0016014180146157742 0.052436165511608124
decider.linear3.weight: -0.0007017279276624322 0.05239980295300484
decider.linear3.bias: -0.014733654446899891 0.025861265137791634

Rewards:
58.9915
58.9915
58.9915
objective = 76.93734741210938
==== episode 10300/75000 ====
action = 1
probs = 0.0196 0.6960 0.1735 0.1109

action = 2
probs = 0.0684 0.2277 0.5338 0.1701

action = 2
probs = 0.0555 0.0511 0.7942 0.0992

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 5.772404256276786e-05 0.08187569677829742
encoder.encoder.weight_hh_l0: -0.0004829041427001357 0.08311648666858673
encoder.encoder.bias_ih_l0: -0.003284845966845751 0.08541946113109589
encoder.encoder.bias_hh_l0: 0.009787142276763916 0.08378910273313522
encoder.encoder.weight_ih_l0_reverse: 0.0008375783218070865 0.08324962109327316
encoder.encoder.weight_hh_l0_reverse: 0.0004670746566262096 0.08214608579874039
encoder.encoder.bias_ih_l0_reverse: 0.005919306073337793 0.08049875497817993
encoder.encoder.bias_hh_l0_reverse: 0.006213967222720385 0.08566880971193314
decider.lstm.weight_ih_l0: -0.001484458683989942 0.14515027403831482
decider.lstm.weight_hh_l0: 0.001364214695058763 0.14481385052204132
decider.lstm.bias_ih_l0: -0.029888546094298363 0.14306531846523285
decider.lstm.bias_hh_l0: 0.005932298488914967 0.15236376225948334
decider.linear1.weight: 0.0031335181556642056 0.11790682375431061
decider.linear1.bias: -0.00038873637095093727 0.11455756425857544
decider.linear2.weight: 0.0004924028180539608 0.05173554643988609
decider.linear2.bias: -0.0016173903131857514 0.05242437496781349
decider.linear3.weight: -0.0006861608708277345 0.05237504467368126
decider.linear3.bias: -0.014730095863342285 0.02601717971265316

Rewards:
70.1874
70.1874
70.1874
objective = 28.55531120300293
==== episode 10400/75000 ====
action = 1
probs = 0.0211 0.7031 0.1681 0.1078

action = 2
probs = 0.0801 0.2473 0.4964 0.1761

action = 3
probs = 0.0719 0.0557 0.7617 0.1107

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 6.119877070887014e-05 0.08190330117940903
encoder.encoder.weight_hh_l0: -0.0004733418463729322 0.08310995250940323
encoder.encoder.bias_ih_l0: -0.003496612887829542 0.08531959354877472
encoder.encoder.bias_hh_l0: 0.009575375355780125 0.08374053239822388
encoder.encoder.weight_ih_l0_reverse: 0.0008525646990165114 0.08328525722026825
encoder.encoder.weight_hh_l0_reverse: 0.0004564455011859536 0.08217815309762955
encoder.encoder.bias_ih_l0_reverse: 0.005791672505438328 0.08048280328512192
encoder.encoder.bias_hh_l0_reverse: 0.006086336448788643 0.08561385422945023
decider.lstm.weight_ih_l0: -0.0014878981746733189 0.1451517641544342
decider.lstm.weight_hh_l0: 0.0014324267394840717 0.14475411176681519
decider.lstm.bias_ih_l0: -0.030136149376630783 0.14294859766960144
decider.lstm.bias_hh_l0: 0.005684699863195419 0.1522616446018219
decider.linear1.weight: 0.003211729694157839 0.11787822097539902
decider.linear1.bias: -0.0006564529612660408 0.11452639847993851
decider.linear2.weight: 0.0004389513924252242 0.05171636492013931
decider.linear2.bias: -0.00172038609161973 0.05234066769480705
decider.linear3.weight: -0.0006400477141141891 0.05231456086039543
decider.linear3.bias: -0.014571644365787506 0.0259409099817276

Rewards:
68.7666
68.7666
68.7666
objective = 74.58685302734375
==== episode 10500/75000 ====
action = 2
probs = 0.0233 0.7227 0.1572 0.0967

action = 2
probs = 0.0894 0.2819 0.4552 0.1735

action = 2
probs = 0.0899 0.0636 0.7254 0.1212

Learning rate: 8.0973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 4.7114899643929675e-05 0.08193477988243103
encoder.encoder.weight_hh_l0: -0.0004695616662502289 0.0831226035952568
encoder.encoder.bias_ih_l0: -0.003495826618745923 0.08527938276529312
encoder.encoder.bias_hh_l0: 0.009576159529387951 0.08372374624013901
encoder.encoder.weight_ih_l0_reverse: 0.0008438753429800272 0.08332384377717972
encoder.encoder.weight_hh_l0_reverse: 0.00045529508497565985 0.082196444272995
encoder.encoder.bias_ih_l0_reverse: 0.005796235054731369 0.080483078956604
encoder.encoder.bias_hh_l0_reverse: 0.006090898532420397 0.08557803928852081
decider.lstm.weight_ih_l0: -0.001492638373747468 0.14516422152519226
decider.lstm.weight_hh_l0: 0.00144211167935282 0.1447194665670395
decider.lstm.bias_ih_l0: -0.030196448788046837 0.1429121047258377
decider.lstm.bias_hh_l0: 0.005624402314424515 0.15220797061920166
decider.linear1.weight: 0.0032386041712015867 0.11786782741546631
decider.linear1.bias: -0.0008203731849789619 0.11449594795703888
decider.linear2.weight: 0.00042134016985073686 0.051707468926906586
decider.linear2.bias: -0.0017348153050988913 0.0522274449467659
decider.linear3.weight: -0.000621179467998445 0.05229658633470535
decider.linear3.bias: -0.014456041157245636 0.026212871074676514

Rewards:
67.4559
67.4559
67.4559
objective = 66.50975036621094
==== episode 10600/75000 ====
action = 3
probs = 0.0223 0.7561 0.1367 0.0849

action = 2
probs = 0.0904 0.2708 0.4694 0.1694

action = 2
probs = 0.0801 0.0507 0.7623 0.1069

Learning rate: 8.0973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0001010550549835898 0.08197174966335297
encoder.encoder.weight_hh_l0: -0.0005171112716197968 0.08317237347364426
encoder.encoder.bias_ih_l0: -0.0031132446601986885 0.08538765460252762
encoder.encoder.bias_hh_l0: 0.009958741255104542 0.08379058539867401
encoder.encoder.weight_ih_l0_reverse: 0.0008607316412962973 0.08333224058151245
encoder.encoder.weight_hh_l0_reverse: 0.0004628820752259344 0.08220523595809937
encoder.encoder.bias_ih_l0_reverse: 0.0059000104665756226 0.08052331954240799
encoder.encoder.bias_hh_l0_reverse: 0.006194674409925938 0.08564728498458862
decider.lstm.weight_ih_l0: -0.001481624785810709 0.1451803594827652
decider.lstm.weight_hh_l0: 0.0014149246271699667 0.14476579427719116
decider.lstm.bias_ih_l0: -0.029872441664338112 0.14311546087265015
decider.lstm.bias_hh_l0: 0.0059484029188752174 0.15229210257530212
decider.linear1.weight: 0.0031843851320445538 0.11792472749948502
decider.linear1.bias: -0.0004819510504603386 0.1144360601902008
decider.linear2.weight: 0.0004919988568872213 0.051746491342782974
decider.linear2.bias: -0.001575580216012895 0.05222713574767113
decider.linear3.weight: -0.0006504550692625344 0.052427712827920914
decider.linear3.bias: -0.014450255781412125 0.026484569534659386

Rewards:
64.4580
64.4580
64.4580
objective = 75.0772705078125
==== episode 10700/75000 ====
action = 1
probs = 0.0253 0.7412 0.1403 0.0932

action = 2
probs = 0.0987 0.2616 0.4431 0.1966

action = 0
probs = 0.0960 0.0596 0.7110 0.1334

Learning rate: 8.0973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 1.5322417311836034e-05 0.08188237249851227
encoder.encoder.weight_hh_l0: -0.00045157058048062027 0.08304844796657562
encoder.encoder.bias_ih_l0: -0.0038852267898619175 0.08520827442407608
encoder.encoder.bias_hh_l0: 0.009186754003167152 0.08363591879606247
encoder.encoder.weight_ih_l0_reverse: 0.0007937262998893857 0.08326078206300735
encoder.encoder.weight_hh_l0_reverse: 0.0004510679573286325 0.08216555416584015
encoder.encoder.bias_ih_l0_reverse: 0.005543779581785202 0.08046036958694458
encoder.encoder.bias_hh_l0_reverse: 0.005838439799845219 0.08546774834394455
decider.lstm.weight_ih_l0: -0.001501572085544467 0.14513999223709106
decider.lstm.weight_hh_l0: 0.0014316975139081478 0.14471471309661865
decider.lstm.bias_ih_l0: -0.03048943728208542 0.1430000364780426
decider.lstm.bias_hh_l0: 0.005331411957740784 0.1521053910255432
decider.linear1.weight: 0.0032001060899347067 0.11785110086202621
decider.linear1.bias: -0.0009324406273663044 0.11447901278734207
decider.linear2.weight: 0.00039875099901109934 0.05170328915119171
decider.linear2.bias: -0.0017628810601308942 0.052198491990566254
decider.linear3.weight: -0.0005912912893109024 0.052291933447122574
decider.linear3.bias: -0.014335451647639275 0.02584119327366352

Rewards:
73.2560
73.2560
73.2560
objective = 84.40263366699219
==== episode 10800/75000 ====
action = 1
probs = 0.0232 0.7858 0.1131 0.0778

action = 3
probs = 0.0999 0.3014 0.4177 0.1811

action = 0
probs = 0.0972 0.0588 0.7244 0.1196

Learning rate: 8.0973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 5.096748282085173e-05 0.08192262053489685
encoder.encoder.weight_hh_l0: -0.00046822428703308105 0.08306686580181122
encoder.encoder.bias_ih_l0: -0.003693037200719118 0.08525963872671127
encoder.encoder.bias_hh_l0: 0.009378945454955101 0.08368717133998871
encoder.encoder.weight_ih_l0_reverse: 0.0008076634840108454 0.08326856046915054
encoder.encoder.weight_hh_l0_reverse: 0.000447985454229638 0.0821823924779892
encoder.encoder.bias_ih_l0_reverse: 0.005538540426641703 0.08043485134840012
encoder.encoder.bias_hh_l0_reverse: 0.005833201110363007 0.08557814359664917
decider.lstm.weight_ih_l0: -0.0014927631709724665 0.1451462060213089
decider.lstm.weight_hh_l0: 0.0014120249543339014 0.14471928775310516
decider.lstm.bias_ih_l0: -0.03027002140879631 0.14299926161766052
decider.lstm.bias_hh_l0: 0.005550826899707317 0.15213821828365326
decider.linear1.weight: 0.0031744521111249924 0.11788906902074814
decider.linear1.bias: -0.0007094033062458038 0.11445118486881256
decider.linear2.weight: 0.0004287479678168893 0.051730282604694366
decider.linear2.bias: -0.0016992436721920967 0.05226566642522812
decider.linear3.weight: -0.0006056616548448801 0.0523700974881649
decider.linear3.bias: -0.01430149469524622 0.026534581556916237

Rewards:
74.3478
74.3478
74.3478
objective = 106.08373260498047
==== episode 10900/75000 ====
action = 1
probs = 0.0271 0.7952 0.1002 0.0775

action = 2
probs = 0.1309 0.3262 0.3511 0.1918

action = 2
probs = 0.1315 0.0704 0.6621 0.1361

Learning rate: 8.0973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -8.834041182126384e-06 0.08184820413589478
encoder.encoder.weight_hh_l0: -0.00042703168583102524 0.08297513425350189
encoder.encoder.bias_ih_l0: -0.004181017633527517 0.08517832309007645
encoder.encoder.bias_hh_l0: 0.008890968747437 0.08353187888860703
encoder.encoder.weight_ih_l0_reverse: 0.0007289775530807674 0.08319389820098877
encoder.encoder.weight_hh_l0_reverse: 0.00043100869515910745 0.08213283121585846
encoder.encoder.bias_ih_l0_reverse: 0.005190074909478426 0.08037792146205902
encoder.encoder.bias_hh_l0_reverse: 0.005484734661877155 0.08538318425416946
decider.lstm.weight_ih_l0: -0.0015141008188948035 0.1451200693845749
decider.lstm.weight_hh_l0: 0.0014111942145973444 0.14470131695270538
decider.lstm.bias_ih_l0: -0.030753815546631813 0.14286045730113983
decider.lstm.bias_hh_l0: 0.005067028105258942 0.1520204395055771
decider.linear1.weight: 0.003175431629642844 0.11783914268016815
decider.linear1.bias: -0.001046747900545597 0.1143806204199791
decider.linear2.weight: 0.000355393101926893 0.05170698091387749
decider.linear2.bias: -0.0018320753006264567 0.05213047191500664
decider.linear3.weight: -0.0005117794498801231 0.05231383070349693
decider.linear3.bias: -0.014060277491807938 0.026498476043343544

Rewards:
70.1874
70.1874
70.1874
objective = 39.500030517578125
==== episode 11000/75000 ====
action = 1
probs = 0.0246 0.8007 0.1027 0.0720

action = 0
probs = 0.1180 0.2871 0.4117 0.1832

action = 2
probs = 0.1033 0.0548 0.7286 0.1133

Learning rate: 8.0163e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 3.089237725362182e-05 0.08187965303659439
encoder.encoder.weight_hh_l0: -0.0004653825599234551 0.0830107256770134
encoder.encoder.bias_ih_l0: -0.003946506418287754 0.08523102104663849
encoder.encoder.bias_hh_l0: 0.00912548042833805 0.08360917866230011
encoder.encoder.weight_ih_l0_reverse: 0.0007331938832066953 0.0832153931260109
encoder.encoder.weight_hh_l0_reverse: 0.0004395734576974064 0.08213497698307037
encoder.encoder.bias_ih_l0_reverse: 0.00528827216476202 0.08042170852422714
encoder.encoder.bias_hh_l0_reverse: 0.005582929588854313 0.0854552760720253
decider.lstm.weight_ih_l0: -0.0015023064333945513 0.145130917429924
decider.lstm.weight_hh_l0: 0.0013681718846783042 0.14475762844085693
decider.lstm.bias_ih_l0: -0.030506029725074768 0.14314010739326477
decider.lstm.bias_hh_l0: 0.005314812064170837 0.15210723876953125
decider.linear1.weight: 0.0031147142872214317 0.11787883937358856
decider.linear1.bias: -0.0007531801238656044 0.11438045650720596
decider.linear2.weight: 0.00042321847286075354 0.051737233996391296
decider.linear2.bias: -0.001692554447799921 0.052235763520002365
decider.linear3.weight: -0.0005996863474138081 0.05239841341972351
decider.linear3.bias: -0.01419087965041399 0.0267652440816164

Rewards:
71.0584
71.0584
71.0584
objective = 63.394378662109375
==== episode 11100/75000 ====
action = 1
probs = 0.0239 0.8035 0.1069 0.0657

action = 3
probs = 0.1090 0.2844 0.4391 0.1675

action = 2
probs = 0.1005 0.0589 0.7334 0.1071

Learning rate: 8.0163e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 6.712391768814996e-05 0.08190250396728516
encoder.encoder.weight_hh_l0: -0.00047850044211372733 0.08302733302116394
encoder.encoder.bias_ih_l0: -0.003908214624971151 0.08524173498153687
encoder.encoder.bias_hh_l0: 0.009163773618638515 0.08365313708782196
encoder.encoder.weight_ih_l0_reverse: 0.0007608144078403711 0.08324362337589264
encoder.encoder.weight_hh_l0_reverse: 0.00044002546928822994 0.08215680718421936
encoder.encoder.bias_ih_l0_reverse: 0.005342882592231035 0.08042342960834503
encoder.encoder.bias_hh_l0_reverse: 0.005637539550662041 0.08551540970802307
decider.lstm.weight_ih_l0: -0.0015003648586571217 0.1451374739408493
decider.lstm.weight_hh_l0: 0.0013885159278288484 0.1447555124759674
decider.lstm.bias_ih_l0: -0.030442895367741585 0.14318658411502838
decider.lstm.bias_hh_l0: 0.0053779371082782745 0.15215404331684113
decider.linear1.weight: 0.003130811033770442 0.11788592487573624
decider.linear1.bias: -0.0006870198994874954 0.11441327631473541
decider.linear2.weight: 0.0004475206951610744 0.05174123868346214
decider.linear2.bias: -0.0016391579993069172 0.05228213220834732
decider.linear3.weight: -0.0006403672159649432 0.05240163952112198
decider.linear3.bias: -0.014282534830272198 0.027225125581026077

Rewards:
69.5795
69.5795
69.5795
objective = 53.70835494995117
==== episode 11200/75000 ====
action = 1
probs = 0.0269 0.7916 0.1042 0.0772

action = 2
probs = 0.0984 0.2892 0.4342 0.1782

action = 2
probs = 0.0897 0.0555 0.7565 0.0983

Learning rate: 8.0163e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.904641097411513e-05 0.08189761638641357
encoder.encoder.weight_hh_l0: -0.0004699349810834974 0.08303298056125641
encoder.encoder.bias_ih_l0: -0.0039046609308570623 0.08528485149145126
encoder.encoder.bias_hh_l0: 0.009167331270873547 0.08369278162717819
encoder.encoder.weight_ih_l0_reverse: 0.0007671834318898618 0.08323972672224045
encoder.encoder.weight_hh_l0_reverse: 0.0004393835552036762 0.0821688175201416
encoder.encoder.bias_ih_l0_reverse: 0.005358741153031588 0.08042983710765839
encoder.encoder.bias_hh_l0_reverse: 0.005653400905430317 0.08556347340345383
decider.lstm.weight_ih_l0: -0.0014925559516996145 0.1451311558485031
decider.lstm.weight_hh_l0: 0.0013792829122394323 0.14475995302200317
decider.lstm.bias_ih_l0: -0.030354298651218414 0.14308424293994904
decider.lstm.bias_hh_l0: 0.005466533824801445 0.15220099687576294
decider.linear1.weight: 0.003136996878311038 0.11790011078119278
decider.linear1.bias: -0.0006439122371375561 0.1143549308180809
decider.linear2.weight: 0.00046670096344314516 0.05174301564693451
decider.linear2.bias: -0.0016111728036776185 0.05232724919915199
decider.linear3.weight: -0.0006240288494154811 0.05239405483007431
decider.linear3.bias: -0.014297271147370338 0.02697049267590046

Rewards:
70.1874
70.1874
70.1874
objective = 31.51338768005371
==== episode 11300/75000 ====
action = 1
probs = 0.0251 0.8197 0.0914 0.0638

action = 3
probs = 0.0937 0.3526 0.3933 0.1603

action = 2
probs = 0.0951 0.0692 0.7345 0.1012

Learning rate: 8.0163e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 6.065383422537707e-05 0.08187975734472275
encoder.encoder.weight_hh_l0: -0.00044477853225544095 0.08298885822296143
encoder.encoder.bias_ih_l0: -0.00407066335901618 0.08526180684566498
encoder.encoder.bias_hh_l0: 0.00900132954120636 0.08366232365369797
encoder.encoder.weight_ih_l0_reverse: 0.000740808027330786 0.0832194909453392
encoder.encoder.weight_hh_l0_reverse: 0.00043353013461455703 0.08216182142496109
encoder.encoder.bias_ih_l0_reverse: 0.005225765518844128 0.08034872263669968
encoder.encoder.bias_hh_l0_reverse: 0.005520423408597708 0.08562853932380676
decider.lstm.weight_ih_l0: -0.0014947226736694574 0.14512090384960175
decider.lstm.weight_hh_l0: 0.001367617747746408 0.14474816620349884
decider.lstm.bias_ih_l0: -0.03049197606742382 0.14304675161838531
decider.lstm.bias_hh_l0: 0.005328856408596039 0.15215981006622314
decider.linear1.weight: 0.0031177604105323553 0.11788324266672134
decider.linear1.bias: -0.0006874939426779747 0.11436247080564499
decider.linear2.weight: 0.0004702502046711743 0.05173502862453461
decider.linear2.bias: -0.0016020383918657899 0.05239197239279747
decider.linear3.weight: -0.0006192566943354905 0.05237603187561035
decider.linear3.bias: -0.014298290014266968 0.0276354793459177

Rewards:
69.5795
69.5795
69.5795
objective = 54.22092819213867
==== episode 11400/75000 ====
action = 1
probs = 0.0237 0.8424 0.0781 0.0558

action = 3
probs = 0.0947 0.3977 0.3564 0.1511

action = 0
probs = 0.0949 0.0705 0.7434 0.0912

Learning rate: 8.0163e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 9.510181553196162e-05 0.08190611004829407
encoder.encoder.weight_hh_l0: -0.000449483806733042 0.08299566805362701
encoder.encoder.bias_ih_l0: -0.0039038266986608505 0.08533585071563721
encoder.encoder.bias_hh_l0: 0.009168166667222977 0.08367057144641876
encoder.encoder.weight_ih_l0_reverse: 0.0007621804252266884 0.0832233801484108
encoder.encoder.weight_hh_l0_reverse: 0.00043237628415226936 0.08217931538820267
encoder.encoder.bias_ih_l0_reverse: 0.005268591921776533 0.08035365492105484
encoder.encoder.bias_hh_l0_reverse: 0.005563249345868826 0.08572311699390411
decider.lstm.weight_ih_l0: -0.0014868774451315403 0.14511974155902863
decider.lstm.weight_hh_l0: 0.0013799747684970498 0.14474958181381226
decider.lstm.bias_ih_l0: -0.030273789539933205 0.14291591942310333
decider.lstm.bias_hh_l0: 0.005547053180634975 0.15223167836666107
decider.linear1.weight: 0.0031266468577086926 0.11792195588350296
decider.linear1.bias: -0.0004239841364324093 0.11426915973424911
decider.linear2.weight: 0.0005219702143222094 0.05176062509417534
decider.linear2.bias: -0.0015088992659002542 0.052424170076847076
decider.linear3.weight: -0.0006286651478148997 0.05245716869831085
decider.linear3.bias: -0.014288845472037792 0.0281603392213583

Rewards:
74.3478
74.3478
74.3478
objective = 109.43077087402344
==== episode 11500/75000 ====
action = 1
probs = 0.0230 0.8363 0.0858 0.0550

action = 2
probs = 0.0951 0.3748 0.3926 0.1376

action = 2
probs = 0.0969 0.0666 0.7527 0.0838

Learning rate: 7.9361e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00012490368681028485 0.08195972442626953
encoder.encoder.weight_hh_l0: -0.0004716258845292032 0.08303529024124146
encoder.encoder.bias_ih_l0: -0.003763725282624364 0.0853252112865448
encoder.encoder.bias_hh_l0: 0.00930827111005783 0.08371450006961823
encoder.encoder.weight_ih_l0_reverse: 0.0007871149573475122 0.08328087627887726
encoder.encoder.weight_hh_l0_reverse: 0.0004317025013733655 0.08221296966075897
encoder.encoder.bias_ih_l0_reverse: 0.005317275878041983 0.08040610700845718
encoder.encoder.bias_hh_l0_reverse: 0.005611937027424574 0.08578018844127655
decider.lstm.weight_ih_l0: -0.0014884647680446506 0.14514243602752686
decider.lstm.weight_hh_l0: 0.001375937950797379 0.14475545287132263
decider.lstm.bias_ih_l0: -0.03022199310362339 0.14303547143936157
decider.lstm.bias_hh_l0: 0.005598857998847961 0.15228857100009918
decider.linear1.weight: 0.003130070399492979 0.11792802810668945
decider.linear1.bias: -0.00036438368260860443 0.11425702273845673
decider.linear2.weight: 0.0005457993829622865 0.05176720768213272
decider.linear2.bias: -0.001467859256081283 0.052422601729631424
decider.linear3.weight: -0.0006773264613002539 0.052490416914224625
decider.linear3.bias: -0.014337052591145039 0.02850232645869255

Rewards:
70.1874
70.1874
70.1874
objective = 32.70448303222656
==== episode 11600/75000 ====
action = 3
probs = 0.0230 0.8273 0.0921 0.0576

action = 1
probs = 0.0915 0.4008 0.3757 0.1320

action = 2
probs = 0.0854 0.0518 0.7937 0.0691

Learning rate: 7.9361e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.000119740107038524 0.08195937424898148
encoder.encoder.weight_hh_l0: -0.0004710998327936977 0.08305410295724869
encoder.encoder.bias_ih_l0: -0.003584190271794796 0.08540451526641846
encoder.encoder.bias_hh_l0: 0.009487803094089031 0.08372458815574646
encoder.encoder.weight_ih_l0_reverse: 0.0007729650824330747 0.08326911181211472
encoder.encoder.weight_hh_l0_reverse: 0.0004386609070934355 0.08220477402210236
encoder.encoder.bias_ih_l0_reverse: 0.005361887160688639 0.0804588571190834
encoder.encoder.bias_hh_l0_reverse: 0.005656547844409943 0.08580952882766724
decider.lstm.weight_ih_l0: -0.001476677949540317 0.1451367735862732
decider.lstm.weight_hh_l0: 0.001348418416455388 0.1447896659374237
decider.lstm.bias_ih_l0: -0.030104098841547966 0.14304114878177643
decider.lstm.bias_hh_l0: 0.005716754123568535 0.15237563848495483
decider.linear1.weight: 0.0031092732679098845 0.11795191466808319
decider.linear1.bias: -0.00021701771765947342 0.11419945955276489
decider.linear2.weight: 0.0005978208500891924 0.05178851634263992
decider.linear2.bias: -0.0013791900128126144 0.05241014063358307
decider.linear3.weight: -0.0007194095524027944 0.05256623029708862
decider.linear3.bias: -0.014367559924721718 0.02853226289153099

Rewards:
63.3518
63.3518
63.3518
objective = 84.45317840576172
==== episode 11700/75000 ====
action = 1
probs = 0.0147 0.8723 0.0667 0.0464

action = 1
probs = 0.0727 0.4464 0.3456 0.1354

action = 3
probs = 0.0758 0.0593 0.7921 0.0729

Learning rate: 7.9361e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.000164380922797136 0.08197356015443802
encoder.encoder.weight_hh_l0: -0.0004819535242859274 0.08304821699857712
encoder.encoder.bias_ih_l0: -0.00339011219330132 0.08550997078418732
encoder.encoder.bias_hh_l0: 0.009681879542768002 0.08376811444759369
encoder.encoder.weight_ih_l0_reverse: 0.0008233556873165071 0.08325928449630737
encoder.encoder.weight_hh_l0_reverse: 0.00044659507693722844 0.0822247788310051
encoder.encoder.bias_ih_l0_reverse: 0.005592716857790947 0.08042481541633606
encoder.encoder.bias_hh_l0_reverse: 0.005887377541512251 0.08598573505878448
decider.lstm.weight_ih_l0: -0.0014660529559478164 0.14513644576072693
decider.lstm.weight_hh_l0: 0.001435331767424941 0.14476630091667175
decider.lstm.bias_ih_l0: -0.02956402860581875 0.1429067850112915
decider.lstm.bias_hh_l0: 0.0062568299472332 0.15241777896881104
decider.linear1.weight: 0.0031407256610691547 0.1180259957909584
decider.linear1.bias: 0.00017252983525395393 0.11431096494197845
decider.linear2.weight: 0.0006913029355928302 0.051827240735292435
decider.linear2.bias: -0.0011950524058192968 0.05256372690200806
decider.linear3.weight: -0.0007926480611786246 0.05270763486623764
decider.linear3.bias: -0.01447729766368866 0.028659934177994728

Rewards:
59.0339
59.0339
59.0339
objective = 70.09471893310547
==== episode 11800/75000 ====
action = 1
probs = 0.0140 0.8599 0.0776 0.0485

action = 2
probs = 0.0649 0.3825 0.4238 0.1288

action = 2
probs = 0.0655 0.0489 0.8208 0.0648

Learning rate: 7.9361e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0002098436962114647 0.08204665780067444
encoder.encoder.weight_hh_l0: -0.0005274858558550477 0.08315256983041763
encoder.encoder.bias_ih_l0: -0.002882848959416151 0.08559627085924149
encoder.encoder.bias_hh_l0: 0.010189147666096687 0.08391046524047852
encoder.encoder.weight_ih_l0_reverse: 0.0008835348999127746 0.08333209156990051
encoder.encoder.weight_hh_l0_reverse: 0.000454044173238799 0.08227372169494629
encoder.encoder.bias_ih_l0_reverse: 0.005894686561077833 0.08052099496126175
encoder.encoder.bias_hh_l0_reverse: 0.006189349573105574 0.0861075296998024
decider.lstm.weight_ih_l0: -0.001463261665776372 0.1451805979013443
decider.lstm.weight_hh_l0: 0.0014894012128934264 0.14478647708892822
decider.lstm.bias_ih_l0: -0.029205119237303734 0.1430656909942627
decider.lstm.bias_hh_l0: 0.006615743041038513 0.15254636108875275
decider.linear1.weight: 0.0031572699081152678 0.118062824010849
decider.linear1.bias: 0.00036564189940690994 0.1143302246928215
decider.linear2.weight: 0.000738003640435636 0.05184980481863022
decider.linear2.bias: -0.001105910399928689 0.05262049660086632
decider.linear3.weight: -0.0008496446534991264 0.05277593061327934
decider.linear3.bias: -0.014592958614230156 0.028693081811070442

Rewards:
70.1874
70.1874
70.1874
objective = 28.235143661499023
==== episode 11900/75000 ====
action = 1
probs = 0.0135 0.8514 0.0833 0.0518

action = 2
probs = 0.0592 0.3839 0.4196 0.1373

action = 2
probs = 0.0569 0.0459 0.8310 0.0662

Learning rate: 7.9361e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018396794621367007 0.08204011619091034
encoder.encoder.weight_hh_l0: -0.0005021059769205749 0.08313695341348648
encoder.encoder.bias_ih_l0: -0.0028800060972571373 0.085610531270504
encoder.encoder.bias_hh_l0: 0.010191990062594414 0.08389059454202652
encoder.encoder.weight_ih_l0_reverse: 0.0008545739110559225 0.08331426978111267
encoder.encoder.weight_hh_l0_reverse: 0.00045942291035316885 0.08226647973060608
encoder.encoder.bias_ih_l0_reverse: 0.0058865793980658054 0.08055801689624786
encoder.encoder.bias_hh_l0_reverse: 0.00618124520406127 0.08610767126083374
decider.lstm.weight_ih_l0: -0.001451115240342915 0.14517304301261902
decider.lstm.weight_hh_l0: 0.0014902905095368624 0.14478690922260284
decider.lstm.bias_ih_l0: -0.0291171595454216 0.14300763607025146
decider.lstm.bias_hh_l0: 0.006703703664243221 0.1525813341140747
decider.linear1.weight: 0.003150075674057007 0.11806874722242355
decider.linear1.bias: 0.0004353690892457962 0.11435464769601822
decider.linear2.weight: 0.0007592226611450315 0.05185918137431145
decider.linear2.bias: -0.0010769673390313983 0.05263001099228859
decider.linear3.weight: -0.0008751964196562767 0.052794456481933594
decider.linear3.bias: -0.014654045924544334 0.028396015986800194

Rewards:
70.1874
70.1874
70.1874
objective = 28.415390014648438
==== episode 12000/75000 ====
action = 1
probs = 0.0121 0.8626 0.0708 0.0545

action = 1
probs = 0.0502 0.4612 0.3415 0.1471

action = 2
probs = 0.0454 0.0485 0.8416 0.0644

Learning rate: 7.8568e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00014160409045871347 0.08202910423278809
encoder.encoder.weight_hh_l0: -0.00046395979006774724 0.08312175422906876
encoder.encoder.bias_ih_l0: -0.0028385608457028866 0.08569229394197464
encoder.encoder.bias_hh_l0: 0.010233435779809952 0.08386988192796707
encoder.encoder.weight_ih_l0_reverse: 0.0008384980028495193 0.0832783505320549
encoder.encoder.weight_hh_l0_reverse: 0.00046504614874720573 0.08226405829191208
encoder.encoder.bias_ih_l0_reverse: 0.005855700932443142 0.08055254817008972
encoder.encoder.bias_hh_l0_reverse: 0.006150367669761181 0.08622303605079651
decider.lstm.weight_ih_l0: -0.0014411361189559102 0.14515064656734467
decider.lstm.weight_hh_l0: 0.0015207368414849043 0.1447780430316925
decider.lstm.bias_ih_l0: -0.02884679287672043 0.14274655282497406
decider.lstm.bias_hh_l0: 0.006974067538976669 0.15263132750988007
decider.linear1.weight: 0.003153265221044421 0.11809110641479492
decider.linear1.bias: 0.000559262465685606 0.11437369138002396
decider.linear2.weight: 0.0007950005237944424 0.05187699571251869
decider.linear2.bias: -0.0010099116479977965 0.05270472168922424
decider.linear3.weight: -0.0008911862969398499 0.052845075726509094
decider.linear3.bias: -0.01470572967082262 0.028198733925819397

Rewards:
74.4454
74.4454
74.4454
objective = 27.15334701538086
==== episode 12100/75000 ====
action = 1
probs = 0.0113 0.8733 0.0653 0.0501

action = 1
probs = 0.0518 0.4888 0.3207 0.1386

action = 2
probs = 0.0498 0.0466 0.8468 0.0568

Learning rate: 7.8568e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00017167773330584168 0.08206101506948471
encoder.encoder.weight_hh_l0: -0.00047241506399586797 0.08314886689186096
encoder.encoder.bias_ih_l0: -0.0027088343631476164 0.08572638034820557
encoder.encoder.bias_hh_l0: 0.01036316342651844 0.08389274775981903
encoder.encoder.weight_ih_l0_reverse: 0.0008895999053493142 0.08330614864826202
encoder.encoder.weight_hh_l0_reverse: 0.0004636017547454685 0.08229370415210724
encoder.encoder.bias_ih_l0_reverse: 0.005963205359876156 0.08055564761161804
encoder.encoder.bias_hh_l0_reverse: 0.006257872562855482 0.08627807348966599
decider.lstm.weight_ih_l0: -0.0014448871370404959 0.14516225457191467
decider.lstm.weight_hh_l0: 0.001581339631229639 0.1447722464799881
decider.lstm.bias_ih_l0: -0.02867155522108078 0.14260633289813995
decider.lstm.bias_hh_l0: 0.007149300538003445 0.15264257788658142
decider.linear1.weight: 0.0031837027054280043 0.11811895668506622
decider.linear1.bias: 0.0006635081954300404 0.11435896158218384
decider.linear2.weight: 0.0008259747992269695 0.05189668759703636
decider.linear2.bias: -0.0009596580639481544 0.052695468068122864
decider.linear3.weight: -0.0009015904506668448 0.05290667712688446
decider.linear3.bias: -0.014680188149213791 0.028565768152475357

Rewards:
74.4454
74.4454
74.4454
objective = 25.252439498901367
==== episode 12200/75000 ====
action = 1
probs = 0.0104 0.8926 0.0544 0.0426

action = 2
probs = 0.0569 0.5133 0.3043 0.1254

action = 2
probs = 0.0647 0.0553 0.8192 0.0608

Learning rate: 7.8568e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0001910937571665272 0.08208504319190979
encoder.encoder.weight_hh_l0: -0.00048725251690484583 0.0831470713019371
encoder.encoder.bias_ih_l0: -0.0027038580738008022 0.08571503311395645
encoder.encoder.bias_hh_l0: 0.010368138551712036 0.08388902992010117
encoder.encoder.weight_ih_l0_reverse: 0.0009011994116008282 0.08331955224275589
encoder.encoder.weight_hh_l0_reverse: 0.0004605152935255319 0.08229722827672958
encoder.encoder.bias_ih_l0_reverse: 0.005932446103543043 0.08051308244466782
encoder.encoder.bias_hh_l0_reverse: 0.0062271165661513805 0.08627811819314957
decider.lstm.weight_ih_l0: -0.001449947478249669 0.14517121016979218
decider.lstm.weight_hh_l0: 0.0015914541436359286 0.1447565108537674
decider.lstm.bias_ih_l0: -0.028685782104730606 0.14266261458396912
decider.lstm.bias_hh_l0: 0.007135073654353619 0.15260714292526245
decider.linear1.weight: 0.003181097097694874 0.11813107877969742
decider.linear1.bias: 0.0006820084527134895 0.11431869864463806
decider.linear2.weight: 0.0008122384315356612 0.051899611949920654
decider.linear2.bias: -0.0009678774513304234 0.05268586426973343
decider.linear3.weight: -0.0008908852469176054 0.0529177151620388
decider.linear3.bias: -0.014614898711442947 0.02900632843375206

Rewards:
70.1874
70.1874
70.1874
objective = 35.15679931640625
==== episode 12300/75000 ====
action = 1
probs = 0.0092 0.9029 0.0470 0.0409

action = 2
probs = 0.0560 0.5217 0.2850 0.1373

action = 2
probs = 0.0683 0.0539 0.8119 0.0659

Learning rate: 7.8568e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00020933084306307137 0.08209299296140671
encoder.encoder.weight_hh_l0: -0.0004995368071831763 0.08315203338861465
encoder.encoder.bias_ih_l0: -0.002663777442649007 0.08572520315647125
encoder.encoder.bias_hh_l0: 0.010408219881355762 0.08390402793884277
encoder.encoder.weight_ih_l0_reverse: 0.0009232185548171401 0.08331877738237381
encoder.encoder.weight_hh_l0_reverse: 0.00046067117364145815 0.08230195194482803
encoder.encoder.bias_ih_l0_reverse: 0.005990191362798214 0.08051258325576782
encoder.encoder.bias_hh_l0_reverse: 0.00628485856577754 0.08626861125230789
decider.lstm.weight_ih_l0: -0.0014543732395395637 0.1451711654663086
decider.lstm.weight_hh_l0: 0.001622872892767191 0.14476187527179718
decider.lstm.bias_ih_l0: -0.02856423892080784 0.14261120557785034
decider.lstm.bias_hh_l0: 0.007256617769598961 0.15259650349617004
decider.linear1.weight: 0.003187643364071846 0.1181572899222374
decider.linear1.bias: 0.0007568220607936382 0.11435112357139587
decider.linear2.weight: 0.0008247395162470639 0.051913779228925705
decider.linear2.bias: -0.0009343888377770782 0.052685875445604324
decider.linear3.weight: -0.0008961642161011696 0.052976422011852264
decider.linear3.bias: -0.014577949419617653 0.028702430427074432

Rewards:
70.1874
70.1874
70.1874
objective = 36.63541793823242
==== episode 12400/75000 ====
action = 2
probs = 0.0072 0.9244 0.0381 0.0303

action = 1
probs = 0.0395 0.6597 0.2005 0.1003

action = 2
probs = 0.0625 0.0656 0.8116 0.0603

Learning rate: 7.8568e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00027213801513426006 0.08214735984802246
encoder.encoder.weight_hh_l0: -0.0005136433755978942 0.0831940621137619
encoder.encoder.bias_ih_l0: -0.002222290961071849 0.08591583371162415
encoder.encoder.bias_hh_l0: 0.010849704034626484 0.08402001857757568
encoder.encoder.weight_ih_l0_reverse: 0.0009815357625484467 0.08334405720233917
encoder.encoder.weight_hh_l0_reverse: 0.0004730519140139222 0.08235481381416321
encoder.encoder.bias_ih_l0_reverse: 0.006322907749563456 0.08056600391864777
encoder.encoder.bias_hh_l0_reverse: 0.006617579143494368 0.08652902394533157
decider.lstm.weight_ih_l0: -0.0014568016631528735 0.14520153403282166
decider.lstm.weight_hh_l0: 0.0017879107035696507 0.14479628205299377
decider.lstm.bias_ih_l0: -0.027845244854688644 0.14244145154953003
decider.lstm.bias_hh_l0: 0.007975611835718155 0.15279521048069
decider.linear1.weight: 0.0032347149681299925 0.11822228133678436
decider.linear1.bias: 0.0011312919668853283 0.11444557458162308
decider.linear2.weight: 0.0008815861074253917 0.05195807293057442
decider.linear2.bias: -0.0008062002598308027 0.05278199911117554
decider.linear3.weight: -0.0009469479555264115 0.05308869853615761
decider.linear3.bias: -0.014684589579701424 0.02964089997112751

Rewards:
59.3096
59.3096
59.3096
objective = 76.94523620605469
==== episode 12500/75000 ====
action = 1
probs = 0.0062 0.9315 0.0342 0.0281

action = 1
probs = 0.0359 0.6751 0.1976 0.0915

action = 2
probs = 0.0492 0.0465 0.8569 0.0475

Learning rate: 7.7782e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00032585530425421894 0.08220224827528
encoder.encoder.weight_hh_l0: -0.0005297965253703296 0.08326778560876846
encoder.encoder.bias_ih_l0: -0.0017865615664049983 0.08604377508163452
encoder.encoder.bias_hh_l0: 0.011285433545708656 0.08411498367786407
encoder.encoder.weight_ih_l0_reverse: 0.001041720504872501 0.08338482677936554
encoder.encoder.weight_hh_l0_reverse: 0.00048096245154738426 0.08241003006696701
encoder.encoder.bias_ih_l0_reverse: 0.00664246641099453 0.08063824474811554
encoder.encoder.bias_hh_l0_reverse: 0.006937140598893166 0.08669954538345337
decider.lstm.weight_ih_l0: -0.0014613494277000427 0.14523188769817352
decider.lstm.weight_hh_l0: 0.001955630723387003 0.14482121169567108
decider.lstm.bias_ih_l0: -0.02728136256337166 0.14236484467983246
decider.lstm.bias_hh_l0: 0.008539495058357716 0.15297816693782806
decider.linear1.weight: 0.003272571135312319 0.11827828735113144
decider.linear1.bias: 0.0013733701780438423 0.11444098502397537
decider.linear2.weight: 0.0008794822497293353 0.05199834331870079
decider.linear2.bias: -0.0007715331157669425 0.05283894017338753
decider.linear3.weight: -0.0009880090365186334 0.05317959189414978
decider.linear3.bias: -0.014731891453266144 0.029802672564983368

Rewards:
74.4454
74.4454
74.4454
objective = 15.344401359558105
==== episode 12600/75000 ====
action = 1
probs = 0.0078 0.9204 0.0384 0.0334

action = 1
probs = 0.0469 0.6383 0.2114 0.1034

action = 3
probs = 0.0631 0.0526 0.8275 0.0567

Learning rate: 7.7782e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00025704572908580303 0.08214493095874786
encoder.encoder.weight_hh_l0: -0.00048747408436611295 0.08319924026727676
encoder.encoder.bias_ih_l0: -0.002478943206369877 0.08580511063337326
encoder.encoder.bias_hh_l0: 0.010593054816126823 0.08398047089576721
encoder.encoder.weight_ih_l0_reverse: 0.0009862345177680254 0.08337046951055527
encoder.encoder.weight_hh_l0_reverse: 0.00046133153955452144 0.08236335217952728
encoder.encoder.bias_ih_l0_reverse: 0.006125856656581163 0.08052631467580795
encoder.encoder.bias_hh_l0_reverse: 0.006420532241463661 0.08645787090063095
decider.lstm.weight_ih_l0: -0.0014550784835591912 0.1451943814754486
decider.lstm.weight_hh_l0: 0.0017471474129706621 0.14477220177650452
decider.lstm.bias_ih_l0: -0.028190091252326965 0.14244599640369415
decider.lstm.bias_hh_l0: 0.007630767300724983 0.15275809168815613
decider.linear1.weight: 0.003222428262233734 0.11819430440664291
decider.linear1.bias: 0.0009421114809811115 0.11438359320163727
decider.linear2.weight: 0.0007824337808415294 0.05195259302854538
decider.linear2.bias: -0.0009474375401623547 0.052737995982170105
decider.linear3.weight: -0.000928110268432647 0.053033553063869476
decider.linear3.bias: -0.014612477272748947 0.02944321185350418

Rewards:
59.0339
59.0339
59.0339
objective = 66.94032287597656
==== episode 12700/75000 ====
action = 1
probs = 0.0088 0.9090 0.0460 0.0361

action = 2
probs = 0.0493 0.5903 0.2550 0.1054

action = 2
probs = 0.0615 0.0457 0.8393 0.0535

Learning rate: 7.7782e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0002488519821781665 0.08215503394603729
encoder.encoder.weight_hh_l0: -0.0004918487975373864 0.08323613554239273
encoder.encoder.bias_ih_l0: -0.0023523722775280476 0.08583465218544006
encoder.encoder.bias_hh_l0: 0.010719625279307365 0.08400542289018631
encoder.encoder.weight_ih_l0_reverse: 0.0009814996737986803 0.08338805288076401
encoder.encoder.weight_hh_l0_reverse: 0.0004621510743163526 0.0823725014925003
encoder.encoder.bias_ih_l0_reverse: 0.006113610230386257 0.0805838406085968
encoder.encoder.bias_hh_l0_reverse: 0.0064082881435751915 0.0864410325884819
decider.lstm.weight_ih_l0: -0.0014472415205091238 0.14519420266151428
decider.lstm.weight_hh_l0: 0.001734005520120263 0.144788458943367
decider.lstm.bias_ih_l0: -0.02819034643471241 0.14250615239143372
decider.lstm.bias_hh_l0: 0.007630513049662113 0.15282000601291656
decider.linear1.weight: 0.003227089298889041 0.11820055544376373
decider.linear1.bias: 0.0009672283194959164 0.11430288851261139
decider.linear2.weight: 0.000787016935646534 0.051961176097393036
decider.linear2.bias: -0.0009391973726451397 0.05273903161287308
decider.linear3.weight: -0.0009452461963519454 0.05304957181215286
decider.linear3.bias: -0.014630720019340515 0.029393073171377182

Rewards:
70.1874
70.1874
70.1874
objective = 38.300987243652344
==== episode 12800/75000 ====
action = 1
probs = 0.0070 0.9240 0.0360 0.0330

action = 1
probs = 0.0402 0.6521 0.2015 0.1062

action = 2
probs = 0.0507 0.0366 0.8655 0.0472

Learning rate: 7.7782e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0003135968290735036 0.08221744000911713
encoder.encoder.weight_hh_l0: -0.0005063186399638653 0.08328154683113098
encoder.encoder.bias_ih_l0: -0.0019643253181129694 0.08599282056093216
encoder.encoder.bias_hh_l0: 0.0111076720058918 0.08410471677780151
encoder.encoder.weight_ih_l0_reverse: 0.0010489958804100752 0.08340760320425034
encoder.encoder.weight_hh_l0_reverse: 0.0004680428246501833 0.08242163807153702
encoder.encoder.bias_ih_l0_reverse: 0.006438763812184334 0.08066671341657639
encoder.encoder.bias_hh_l0_reverse: 0.006733441259711981 0.0866304412484169
decider.lstm.weight_ih_l0: -0.0014562507858499885 0.14522314071655273
decider.lstm.weight_hh_l0: 0.0018470799550414085 0.14481662213802338
decider.lstm.bias_ih_l0: -0.027593005448579788 0.14235042035579681
decider.lstm.bias_hh_l0: 0.00822785496711731 0.15293815732002258
decider.linear1.weight: 0.0032616578973829746 0.118279367685318
decider.linear1.bias: 0.0012848060578107834 0.11437822133302689
decider.linear2.weight: 0.0008629705989733338 0.052011728286743164
decider.linear2.bias: -0.0008042137487791479 0.05279800668358803
decider.linear3.weight: -0.0009878743439912796 0.053215086460113525
decider.linear3.bias: -0.014658459462225437 0.029272956773638725

Rewards:
74.4454
74.4454
74.4454
objective = 16.157238006591797
==== episode 12900/75000 ====
action = 1
probs = 0.0069 0.9313 0.0313 0.0305

action = 1
probs = 0.0408 0.7083 0.1544 0.0965

action = 1
probs = 0.0684 0.0431 0.8325 0.0559

Learning rate: 7.7782e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00030214994330890477 0.08218898624181747
encoder.encoder.weight_hh_l0: -0.0004818188026547432 0.08323761075735092
encoder.encoder.bias_ih_l0: -0.0022280870471149683 0.08594881743192673
encoder.encoder.bias_hh_l0: 0.010843908414244652 0.08405770361423492
encoder.encoder.weight_ih_l0_reverse: 0.0010413086274638772 0.0833834633231163
encoder.encoder.weight_hh_l0_reverse: 0.0004664776206482202 0.08241509646177292
encoder.encoder.bias_ih_l0_reverse: 0.006343963090330362 0.08059023320674896
encoder.encoder.bias_hh_l0_reverse: 0.0066386377438902855 0.0866326093673706
decider.lstm.weight_ih_l0: -0.0014573506778106093 0.1452118456363678
decider.lstm.weight_hh_l0: 0.001816267380490899 0.1448071151971817
decider.lstm.bias_ih_l0: -0.02770545333623886 0.14216531813144684
decider.lstm.bias_hh_l0: 0.008115398697555065 0.15289875864982605
decider.linear1.weight: 0.0032463024836033583 0.11827240139245987
decider.linear1.bias: 0.0012058443389832973 0.11442746222019196
decider.linear2.weight: 0.0008125106105580926 0.05200691521167755
decider.linear2.bias: -0.0008940960397012532 0.05273821949958801
decider.linear3.weight: -0.000963356054853648 0.05320107564330101
decider.linear3.bias: -0.014552601613104343 0.02937607653439045

Rewards:
57.3517
57.3517
57.3517
objective = 68.06867980957031
==== episode 13000/75000 ====
action = 1
probs = 0.0093 0.9205 0.0371 0.0331

action = 1
probs = 0.0536 0.6601 0.1799 0.1063

action = 2
probs = 0.0650 0.0383 0.8433 0.0534

Learning rate: 7.7004e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0002603552129585296 0.08215648680925369
encoder.encoder.weight_hh_l0: -0.00045887145097367465 0.08321867138147354
encoder.encoder.bias_ih_l0: -0.002466855337843299 0.0859086811542511
encoder.encoder.bias_hh_l0: 0.010605141520500183 0.0839894488453865
encoder.encoder.weight_ih_l0_reverse: 0.0009856990072876215 0.08334727585315704
encoder.encoder.weight_hh_l0_reverse: 0.00045752114965580404 0.08237507194280624
encoder.encoder.bias_ih_l0_reverse: 0.006040032487362623 0.08060407638549805
encoder.encoder.bias_hh_l0_reverse: 0.006334709469228983 0.08645687252283096
decider.lstm.weight_ih_l0: -0.0014504374703392386 0.1451837420463562
decider.lstm.weight_hh_l0: 0.0017191196093335748 0.14482440054416656
decider.lstm.bias_ih_l0: -0.02811487391591072 0.14221277832984924
decider.lstm.bias_hh_l0: 0.007705984637141228 0.1528722494840622
decider.linear1.weight: 0.0032329149544239044 0.11823704093694687
decider.linear1.bias: 0.0010309559293091297 0.1143231987953186
decider.linear2.weight: 0.000777191249653697 0.05199577286839485
decider.linear2.bias: -0.0009578540921211243 0.05267674848437309
decider.linear3.weight: -0.0009171993006020784 0.053147248923778534
decider.linear3.bias: -0.01450126338750124 0.02928118221461773

Rewards:
74.4454
74.4454
74.4454
objective = 16.591588973999023
==== episode 13100/75000 ====
action = 1
probs = 0.0092 0.9177 0.0406 0.0325

action = 2
probs = 0.0493 0.6110 0.2392 0.1005

action = 2
probs = 0.0447 0.0276 0.8854 0.0422

Learning rate: 7.7004e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00031817160197533667 0.08222942799329758
encoder.encoder.weight_hh_l0: -0.0005009303567931056 0.08335041999816895
encoder.encoder.bias_ih_l0: -0.0016918813344091177 0.08610346913337708
encoder.encoder.bias_hh_l0: 0.011380116455256939 0.08414525538682938
encoder.encoder.weight_ih_l0_reverse: 0.0010315016843378544 0.08341171592473984
encoder.encoder.weight_hh_l0_reverse: 0.0004680585698224604 0.0824296772480011
encoder.encoder.bias_ih_l0_reverse: 0.006430766545236111 0.08076291531324387
encoder.encoder.bias_hh_l0_reverse: 0.006725445855408907 0.08660142868757248
decider.lstm.weight_ih_l0: -0.0014405666152015328 0.14522144198417664
decider.lstm.weight_hh_l0: 0.0018486707704141736 0.14486423134803772
decider.lstm.bias_ih_l0: -0.027490653097629547 0.14233841001987457
decider.lstm.bias_hh_l0: 0.008330211043357849 0.15309028327465057
decider.linear1.weight: 0.0032704907935112715 0.11830729246139526
decider.linear1.bias: 0.0013964977115392685 0.11419260501861572
decider.linear2.weight: 0.0008540406124666333 0.05203743651509285
decider.linear2.bias: -0.0008100753766484559 0.05276857316493988
decider.linear3.weight: -0.0009814940858632326 0.053254034370183945
decider.linear3.bias: -0.014639566652476788 0.029494406655430794

Rewards:
70.1874
70.1874
70.1874
objective = 38.32040023803711
==== episode 13200/75000 ====
action = 1
probs = 0.0078 0.9278 0.0358 0.0285

action = 1
probs = 0.0432 0.6361 0.2323 0.0883

action = 2
probs = 0.0339 0.0227 0.9088 0.0346

Learning rate: 7.7004e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00034879177110269666 0.08228573948144913
encoder.encoder.weight_hh_l0: -0.0005212046671658754 0.08341999351978302
encoder.encoder.bias_ih_l0: -0.0012259009527042508 0.08623587340116501
encoder.encoder.bias_hh_l0: 0.01184609904885292 0.08423759043216705
encoder.encoder.weight_ih_l0_reverse: 0.001055757631547749 0.08344560116529465
encoder.encoder.weight_hh_l0_reverse: 0.0004727752530016005 0.08246688544750214
encoder.encoder.bias_ih_l0_reverse: 0.006689425557851791 0.08083875477313995
encoder.encoder.bias_hh_l0_reverse: 0.006984103936702013 0.08675012737512589
decider.lstm.weight_ih_l0: -0.001445123110897839 0.14525234699249268
decider.lstm.weight_hh_l0: 0.0019451003754511476 0.14489947259426117
decider.lstm.bias_ih_l0: -0.02703847736120224 0.14236266911029816
decider.lstm.bias_hh_l0: 0.008782383985817432 0.15319670736789703
decider.linear1.weight: 0.003293828573077917 0.11835961788892746
decider.linear1.bias: 0.0016412576660513878 0.1142120510339737
decider.linear2.weight: 0.0009181678760796785 0.05206793174147606
decider.linear2.bias: -0.0006956473807804286 0.052847590297460556
decider.linear3.weight: -0.001024635974317789 0.05334323272109032
decider.linear3.bias: -0.014734592288732529 0.029838090762495995

Rewards:
74.4454
74.4454
74.4454
objective = 15.456671714782715
==== episode 13300/75000 ====
action = 1
probs = 0.0070 0.9382 0.0319 0.0229

action = 1
probs = 0.0437 0.6418 0.2385 0.0760

action = 3
probs = 0.0302 0.0204 0.9222 0.0273

Learning rate: 7.7004e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0003923187032341957 0.08234355598688126
encoder.encoder.weight_hh_l0: -0.0005535508971661329 0.08350960165262222
encoder.encoder.bias_ih_l0: -0.0006705531268380582 0.08639348298311234
encoder.encoder.bias_hh_l0: 0.012401445768773556 0.08432990312576294
encoder.encoder.weight_ih_l0_reverse: 0.0010910116834565997 0.08347870409488678
encoder.encoder.weight_hh_l0_reverse: 0.0004756366543006152 0.08250382542610168
encoder.encoder.bias_ih_l0_reverse: 0.006977160926908255 0.08092254400253296
encoder.encoder.bias_hh_l0_reverse: 0.007271837443113327 0.086864173412323
decider.lstm.weight_ih_l0: -0.0014527511084452271 0.1452854573726654
decider.lstm.weight_hh_l0: 0.0020520794205367565 0.14494676887989044
decider.lstm.bias_ih_l0: -0.026640454307198524 0.14237478375434875
decider.lstm.bias_hh_l0: 0.009180400520563126 0.15330259501934052
decider.linear1.weight: 0.003326474456116557 0.11841342598199844
decider.linear1.bias: 0.001909087412059307 0.11419849097728729
decider.linear2.weight: 0.000999461393803358 0.05209839716553688
decider.linear2.bias: -0.0005607209168374538 0.052883874624967575
decider.linear3.weight: -0.0010512016015127301 0.05343696475028992
decider.linear3.bias: -0.014783536083996296 0.030493751168251038

Rewards:
59.0339
59.0339
59.0339
objective = 80.84432983398438
==== episode 13400/75000 ====
action = 1
probs = 0.0067 0.9406 0.0290 0.0236

action = 1
probs = 0.0360 0.7073 0.1832 0.0735

action = 3
probs = 0.0259 0.0222 0.9232 0.0288

Learning rate: 7.7004e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0003725573478732258 0.08237393945455551
encoder.encoder.weight_hh_l0: -0.000521174049936235 0.08354515582323074
encoder.encoder.bias_ih_l0: -0.0006084206397645175 0.08642692863941193
encoder.encoder.bias_hh_l0: 0.012463578954339027 0.08433665335178375
encoder.encoder.weight_ih_l0_reverse: 0.0010878014145419002 0.08346892893314362
encoder.encoder.weight_hh_l0_reverse: 0.00047966165584512055 0.08251357078552246
encoder.encoder.bias_ih_l0_reverse: 0.006926090456545353 0.08091675490140915
encoder.encoder.bias_hh_l0_reverse: 0.007220767438411713 0.08695570379495621
decider.lstm.weight_ih_l0: -0.0014498424716293812 0.14529509842395782
decider.lstm.weight_hh_l0: 0.0021073685493320227 0.1449742168188095
decider.lstm.bias_ih_l0: -0.0264769047498703 0.14225895702838898
decider.lstm.bias_hh_l0: 0.009343952871859074 0.1533501297235489
decider.linear1.weight: 0.00335382716730237 0.11844777315855026
decider.linear1.bias: 0.001994212158024311 0.11423064768314362
decider.linear2.weight: 0.0010242783464491367 0.05211368575692177
decider.linear2.bias: -0.0005468844319693744 0.05291653424501419
decider.linear3.weight: -0.0010661911219358444 0.053476616740226746
decider.linear3.bias: -0.014828120358288288 0.030320368707180023

Rewards:
59.0339
59.0339
59.0339
objective = 77.80802917480469
==== episode 13500/75000 ====
action = 1
probs = 0.0074 0.9428 0.0278 0.0220

action = 3
probs = 0.0425 0.7027 0.1825 0.0722

action = 2
probs = 0.0275 0.0214 0.9215 0.0297

Learning rate: 7.6234e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00037051699473522604 0.08239436149597168
encoder.encoder.weight_hh_l0: -0.0005186141352169216 0.08356382697820663
encoder.encoder.bias_ih_l0: -0.000517569191288203 0.08644970506429672
encoder.encoder.bias_hh_l0: 0.012554433196783066 0.0843389481306076
encoder.encoder.weight_ih_l0_reverse: 0.0010799737647175789 0.08347304910421371
encoder.encoder.weight_hh_l0_reverse: 0.000478186208056286 0.08252030611038208
encoder.encoder.bias_ih_l0_reverse: 0.00690156314522028 0.08096478879451752
encoder.encoder.bias_hh_l0_reverse: 0.007196239661425352 0.0869283378124237
decider.lstm.weight_ih_l0: -0.001448583323508501 0.1452977955341339
decider.lstm.weight_hh_l0: 0.002103489125147462 0.1450037956237793
decider.lstm.bias_ih_l0: -0.026461204513907433 0.14223673939704895
decider.lstm.bias_hh_l0: 0.00935964472591877 0.15333765745162964
decider.linear1.weight: 0.003357631852850318 0.11846685409545898
decider.linear1.bias: 0.0020281486213207245 0.11416730284690857
decider.linear2.weight: 0.0010441532358527184 0.052128616720438004
decider.linear2.bias: -0.0005065531004220247 0.052930351346731186
decider.linear3.weight: -0.0010881127091124654 0.05356509983539581
decider.linear3.bias: -0.014765331521630287 0.03049294278025627

Rewards:
69.5795
69.5795
69.5795
objective = 64.2133560180664
==== episode 13600/75000 ====
action = 1
probs = 0.0065 0.9457 0.0259 0.0220

action = 2
probs = 0.0358 0.7456 0.1505 0.0680

action = 0
probs = 0.0301 0.0237 0.9128 0.0333

Learning rate: 7.6234e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00037256834912113845 0.08239630609750748
encoder.encoder.weight_hh_l0: -0.0005078659160062671 0.08353877067565918
encoder.encoder.bias_ih_l0: -0.0006456267437897623 0.08642284572124481
encoder.encoder.bias_hh_l0: 0.012426376342773438 0.0843261182308197
encoder.encoder.weight_ih_l0_reverse: 0.0010843782220035791 0.08347612619400024
encoder.encoder.weight_hh_l0_reverse: 0.00047782377805560827 0.08252795785665512
encoder.encoder.bias_ih_l0_reverse: 0.0069162314757704735 0.08094131201505661
encoder.encoder.bias_hh_l0_reverse: 0.007210906129330397 0.08699312806129456
decider.lstm.weight_ih_l0: -0.001450511277653277 0.14530323445796967
decider.lstm.weight_hh_l0: 0.0021162708289921284 0.14499139785766602
decider.lstm.bias_ih_l0: -0.026409829035401344 0.14219994843006134
decider.lstm.bias_hh_l0: 0.009411022067070007 0.15334169566631317
decider.linear1.weight: 0.0033521861769258976 0.11846835166215897
decider.linear1.bias: 0.0019998541101813316 0.114239901304245
decider.linear2.weight: 0.0010198121890425682 0.05213266611099243
decider.linear2.bias: -0.0005272331181913614 0.05295668914914131
decider.linear3.weight: -0.0011296637821942568 0.05359548702836037
decider.linear3.bias: -0.01478936243802309 0.03042050264775753

Rewards:
73.2560
73.2560
73.2560
objective = 133.1283416748047
==== episode 13700/75000 ====
action = 1
probs = 0.0082 0.9359 0.0313 0.0246

action = 1
probs = 0.0466 0.6676 0.2084 0.0774

action = 2
probs = 0.0238 0.0155 0.9346 0.0260

Learning rate: 7.6234e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0003924403281416744 0.0824187770485878
encoder.encoder.weight_hh_l0: -0.0005293440772220492 0.0835936889052391
encoder.encoder.bias_ih_l0: -0.0004649388720281422 0.0864608883857727
encoder.encoder.bias_hh_l0: 0.012607064098119736 0.08436660468578339
encoder.encoder.weight_ih_l0_reverse: 0.001116370433010161 0.08350782096385956
encoder.encoder.weight_hh_l0_reverse: 0.0004750073712784797 0.08253833651542664
encoder.encoder.bias_ih_l0_reverse: 0.006882097572088242 0.08099310100078583
encoder.encoder.bias_hh_l0_reverse: 0.007176773156970739 0.08693108707666397
decider.lstm.weight_ih_l0: -0.0014516743831336498 0.1453026831150055
decider.lstm.weight_hh_l0: 0.0020907819271087646 0.1450134813785553
decider.lstm.bias_ih_l0: -0.026464879512786865 0.14221011102199554
decider.lstm.bias_hh_l0: 0.009355969727039337 0.15335646271705627
decider.linear1.weight: 0.003356024157255888 0.1184721440076828
decider.linear1.bias: 0.0019824206829071045 0.11409077793359756
decider.linear2.weight: 0.001037130132317543 0.052131231874227524
decider.linear2.bias: -0.0005271307891234756 0.05292965844273567
decider.linear3.weight: -0.0011163853341713548 0.053584933280944824
decider.linear3.bias: -0.014745830558240414 0.03034420683979988

Rewards:
74.4454
74.4454
74.4454
objective = 13.348037719726562
==== episode 13800/75000 ====
action = 1
probs = 0.0070 0.9387 0.0290 0.0254

action = 3
probs = 0.0388 0.6996 0.1864 0.0751

action = 2
probs = 0.0268 0.0194 0.9246 0.0292

Learning rate: 7.6234e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00038463028613477945 0.08241402357816696
encoder.encoder.weight_hh_l0: -0.0005218761507421732 0.08358120173215866
encoder.encoder.bias_ih_l0: -0.0005103692528791726 0.08644194155931473
encoder.encoder.bias_hh_l0: 0.012561636045575142 0.0843682587146759
encoder.encoder.weight_ih_l0_reverse: 0.001110671553760767 0.08350491523742676
encoder.encoder.weight_hh_l0_reverse: 0.00047588685993105173 0.0825408324599266
encoder.encoder.bias_ih_l0_reverse: 0.00690621230751276 0.08096622675657272
encoder.encoder.bias_hh_l0_reverse: 0.007200888358056545 0.08697810024023056
decider.lstm.weight_ih_l0: -0.0014501434052363038 0.14530274271965027
decider.lstm.weight_hh_l0: 0.0021072730887681246 0.14499393105506897
decider.lstm.bias_ih_l0: -0.026396017521619797 0.14220745861530304
decider.lstm.bias_hh_l0: 0.009424830786883831 0.15336158871650696
decider.linear1.weight: 0.0033515056129544973 0.11847548931837082
decider.linear1.bias: 0.001986103132367134 0.11413070559501648
decider.linear2.weight: 0.0010276657994836569 0.052134640514850616
decider.linear2.bias: -0.0005237361183390021 0.05296795070171356
decider.linear3.weight: -0.001143434550613165 0.053594935685396194
decider.linear3.bias: -0.014795329421758652 0.03022872842848301

Rewards:
69.5795
69.5795
69.5795
objective = 63.33110046386719
==== episode 13900/75000 ====
action = 3
probs = 0.0068 0.9307 0.0333 0.0292

action = 2
probs = 0.0333 0.6808 0.2022 0.0838

action = 2
probs = 0.0184 0.0129 0.9428 0.0260

Learning rate: 7.6234e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00043027958599850535 0.08245430141687393
encoder.encoder.weight_hh_l0: -0.0005603036261163652 0.0836949497461319
encoder.encoder.bias_ih_l0: 8.490442996844649e-05 0.08657757192850113
encoder.encoder.bias_hh_l0: 0.013156905770301819 0.08450490981340408
encoder.encoder.weight_ih_l0_reverse: 0.0011541121639311314 0.08356025815010071
encoder.encoder.weight_hh_l0_reverse: 0.0004754484980367124 0.08258792012929916
encoder.encoder.bias_ih_l0_reverse: 0.0072849951684474945 0.08109372109174728
encoder.encoder.bias_hh_l0_reverse: 0.0075796726159751415 0.08701757341623306
decider.lstm.weight_ih_l0: -0.0014550186460837722 0.14533625543117523
decider.lstm.weight_hh_l0: 0.002244262956082821 0.145041361451149
decider.lstm.bias_ih_l0: -0.02593230828642845 0.14225254952907562
decider.lstm.bias_hh_l0: 0.009888539090752602 0.15344615280628204
decider.linear1.weight: 0.003382953815162182 0.11854030936956406
decider.linear1.bias: 0.002172369509935379 0.11404863744974136
decider.linear2.weight: 0.0011028230655938387 0.05216250196099281
decider.linear2.bias: -0.000432642234954983 0.053019728511571884
decider.linear3.weight: -0.0011906858999282122 0.05366722494363785
decider.linear3.bias: -0.01487556379288435 0.029685407876968384

Rewards:
64.4580
64.4580
64.4580
objective = 111.508056640625
==== episode 14000/75000 ====
action = 1
probs = 0.0059 0.9353 0.0304 0.0284

action = 1
probs = 0.0336 0.5912 0.2783 0.0968

action = 2
probs = 0.0112 0.0078 0.9613 0.0197

Learning rate: 7.5472e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00047731390804983675 0.08251308649778366
encoder.encoder.weight_hh_l0: -0.0005995098035782576 0.08381214737892151
encoder.encoder.bias_ih_l0: 0.000737450085580349 0.08675722032785416
encoder.encoder.bias_hh_l0: 0.013809449039399624 0.0846380889415741
encoder.encoder.weight_ih_l0_reverse: 0.0012004104210063815 0.08361102640628815
encoder.encoder.weight_hh_l0_reverse: 0.00047348899533972144 0.08264348655939102
encoder.encoder.bias_ih_l0_reverse: 0.007731597404927015 0.08119075745344162
encoder.encoder.bias_hh_l0_reverse: 0.008026273921132088 0.08714525401592255
decider.lstm.weight_ih_l0: -0.0014674434205517173 0.14538273215293884
decider.lstm.weight_hh_l0: 0.0024376041255891323 0.14508263766765594
decider.lstm.bias_ih_l0: -0.025332316756248474 0.14223548769950867
decider.lstm.bias_hh_l0: 0.010488532483577728 0.15357860922813416
decider.linear1.weight: 0.003436645958572626 0.11863837391138077
decider.linear1.bias: 0.002493389882147312 0.11399146169424057
decider.linear2.weight: 0.001240108860656619 0.05222752317786217
decider.linear2.bias: -0.00028805097099393606 0.05308684706687927
decider.linear3.weight: -0.001238813973031938 0.05380631238222122
decider.linear3.bias: -0.01494094729423523 0.029513666406273842

Rewards:
74.4454
74.4454
74.4454
objective = 15.68292236328125
==== episode 14100/75000 ====
action = 1
probs = 0.0062 0.9278 0.0363 0.0297

action = 3
probs = 0.0334 0.4769 0.3864 0.1032

action = 2
probs = 0.0093 0.0059 0.9662 0.0185

Learning rate: 7.5472e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005385475233197212 0.08255783468484879
encoder.encoder.weight_hh_l0: -0.0006520464667119086 0.08394179493188858
encoder.encoder.bias_ih_l0: 0.001390711055137217 0.08691233396530151
encoder.encoder.bias_hh_l0: 0.014462709426879883 0.08476881682872772
encoder.encoder.weight_ih_l0_reverse: 0.0012437929399311543 0.0836760550737381
encoder.encoder.weight_hh_l0_reverse: 0.00046689590089954436 0.0827019214630127
encoder.encoder.bias_ih_l0_reverse: 0.008129590190947056 0.08126036077737808
encoder.encoder.bias_hh_l0_reverse: 0.008424265310168266 0.08720266819000244
decider.lstm.weight_ih_l0: -0.0014769472181797028 0.1454320251941681
decider.lstm.weight_hh_l0: 0.0025430121459066868 0.14510567486286163
decider.lstm.bias_ih_l0: -0.02499309740960598 0.1423252671957016
decider.lstm.bias_hh_l0: 0.010827748104929924 0.1536584049463272
decider.linear1.weight: 0.0034451037645339966 0.11866167187690735
decider.linear1.bias: 0.002565317787230015 0.11391047388315201
decider.linear2.weight: 0.0013060792116448283 0.052244678139686584
decider.linear2.bias: -0.00018649105913937092 0.05309616029262543
decider.linear3.weight: -0.0012882587034255266 0.053897932171821594
decider.linear3.bias: -0.01496434397995472 0.029427586123347282

Rewards:
69.5795
69.5795
69.5795
objective = 55.20615768432617
==== episode 14200/75000 ====
action = 1
probs = 0.0080 0.8909 0.0573 0.0438

action = 1
probs = 0.0348 0.3493 0.5064 0.1096

action = 2
probs = 0.0076 0.0038 0.9737 0.0149

Learning rate: 7.5472e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005323393270373344 0.08254515379667282
encoder.encoder.weight_hh_l0: -0.0006573873106390238 0.0839788168668747
encoder.encoder.bias_ih_l0: 0.0015214785235002637 0.08688861131668091
encoder.encoder.bias_hh_l0: 0.014593475498259068 0.0848093032836914
encoder.encoder.weight_ih_l0_reverse: 0.0012356790248304605 0.08370885252952576
encoder.encoder.weight_hh_l0_reverse: 0.000467516016215086 0.08271539211273193
encoder.encoder.bias_ih_l0_reverse: 0.008228685706853867 0.08130080252885818
encoder.encoder.bias_hh_l0_reverse: 0.008523359894752502 0.08711854368448257
decider.lstm.weight_ih_l0: -0.0014615836553275585 0.14543785154819489
decider.lstm.weight_hh_l0: 0.0025320323184132576 0.1451028287410736
decider.lstm.bias_ih_l0: -0.025039199739694595 0.14237016439437866
decider.lstm.bias_hh_l0: 0.010781645774841309 0.15363922715187073
decider.linear1.weight: 0.0034061342012137175 0.11862960457801819
decider.linear1.bias: 0.002370142377912998 0.11382397264242172
decider.linear2.weight: 0.001287118997424841 0.052231959998607635
decider.linear2.bias: -0.00024795025819912553 0.05302361771464348
decider.linear3.weight: -0.0012913739774376154 0.05384961515665054
decider.linear3.bias: -0.014914128929376602 0.028977705165743828

Rewards:
74.4454
74.4454
74.4454
objective = 29.63019371032715
==== episode 14300/75000 ====
action = 1
probs = 0.0081 0.8910 0.0542 0.0467

action = 2
probs = 0.0332 0.3464 0.5023 0.1181

action = 2
probs = 0.0077 0.0045 0.9718 0.0160

Learning rate: 7.5472e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.000512428698129952 0.0825437679886818
encoder.encoder.weight_hh_l0: -0.0006499252049252391 0.0839933380484581
encoder.encoder.bias_ih_l0: 0.0015640252968296409 0.0868908017873764
encoder.encoder.bias_hh_l0: 0.014636019244790077 0.08481329679489136
encoder.encoder.weight_ih_l0_reverse: 0.0012223932426422834 0.08369889110326767
encoder.encoder.weight_hh_l0_reverse: 0.00047432995052076876 0.08271680027246475
encoder.encoder.bias_ih_l0_reverse: 0.00820448063313961 0.08129403740167618
encoder.encoder.bias_hh_l0_reverse: 0.008499153889715672 0.08711112290620804
decider.lstm.weight_ih_l0: -0.0014543934958055615 0.14543692767620087
decider.lstm.weight_hh_l0: 0.002535564359277487 0.14510641992092133
decider.lstm.bias_ih_l0: -0.025023747235536575 0.14235518872737885
decider.lstm.bias_hh_l0: 0.010797097347676754 0.1536664217710495
decider.linear1.weight: 0.0034047551453113556 0.1186356320977211
decider.linear1.bias: 0.0023731645196676254 0.1137971431016922
decider.linear2.weight: 0.0013008539099246264 0.05223199352622032
decider.linear2.bias: -0.00022021454060450196 0.05303953215479851
decider.linear3.weight: -0.0012896095868200064 0.05385270714759827
decider.linear3.bias: -0.014922558329999447 0.02874946966767311

Rewards:
70.1874
70.1874
70.1874
objective = 19.47695541381836
==== episode 14400/75000 ====
action = 1
probs = 0.0066 0.9004 0.0487 0.0442

action = 2
probs = 0.0277 0.3905 0.4703 0.1115

action = 2
probs = 0.0066 0.0048 0.9741 0.0145

Learning rate: 7.5472e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005262401537038386 0.08256277441978455
encoder.encoder.weight_hh_l0: -0.0006527010700665414 0.08401176333427429
encoder.encoder.bias_ih_l0: 0.0016368587967008352 0.08693765103816986
encoder.encoder.bias_hh_l0: 0.01470885518938303 0.08483441919088364
encoder.encoder.weight_ih_l0_reverse: 0.0012402262073010206 0.08371401578187943
encoder.encoder.weight_hh_l0_reverse: 0.0004741725279018283 0.08273167908191681
encoder.encoder.bias_ih_l0_reverse: 0.008297804743051529 0.08131782710552216
encoder.encoder.bias_hh_l0_reverse: 0.00859247986227274 0.08719643950462341
decider.lstm.weight_ih_l0: -0.001460963860154152 0.14544646441936493
decider.lstm.weight_hh_l0: 0.0025937058962881565 0.1451229602098465
decider.lstm.bias_ih_l0: -0.02482447400689125 0.14235009253025055
decider.lstm.bias_hh_l0: 0.010996367782354355 0.1537223756313324
decider.linear1.weight: 0.0034314505755901337 0.11866652965545654
decider.linear1.bias: 0.002515495754778385 0.11383714526891708
decider.linear2.weight: 0.001351100392639637 0.05224933847784996
decider.linear2.bias: -0.00014821672812104225 0.05310729891061783
decider.linear3.weight: -0.0013450259575620294 0.0539114773273468
decider.linear3.bias: -0.015053218230605125 0.02892046608030796

Rewards:
70.1874
70.1874
70.1874
objective = 20.71833038330078
==== episode 14500/75000 ====
action = 1
probs = 0.0064 0.9084 0.0417 0.0435

action = 1
probs = 0.0303 0.4542 0.3904 0.1251

action = 2
probs = 0.0067 0.0047 0.9735 0.0151

Learning rate: 7.4717e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00048247608356177807 0.08254417032003403
encoder.encoder.weight_hh_l0: -0.0006203851662576199 0.08394438773393631
encoder.encoder.bias_ih_l0: 0.001222450751811266 0.08682059496641159
encoder.encoder.bias_hh_l0: 0.014294450171291828 0.08474492281675339
encoder.encoder.weight_ih_l0_reverse: 0.0012101955944672227 0.08366481214761734
encoder.encoder.weight_hh_l0_reverse: 0.000482414907310158 0.08268862962722778
encoder.encoder.bias_ih_l0_reverse: 0.007945967838168144 0.08126261830329895
encoder.encoder.bias_hh_l0_reverse: 0.008240642957389355 0.0871349573135376
decider.lstm.weight_ih_l0: -0.0014530911576002836 0.14540304243564606
decider.lstm.weight_hh_l0: 0.0025101753417402506 0.14511685073375702
decider.lstm.bias_ih_l0: -0.025113191455602646 0.14226843416690826
decider.lstm.bias_hh_l0: 0.010707656852900982 0.15365265309810638
decider.linear1.weight: 0.003432038240134716 0.1186644583940506
decider.linear1.bias: 0.0024808631278574467 0.11386124789714813
decider.linear2.weight: 0.0013612501788884401 0.05226066708564758
decider.linear2.bias: -0.00017108593601733446 0.05307266488671303
decider.linear3.weight: -0.0013306050095707178 0.05392573028802872
decider.linear3.bias: -0.01500050351023674 0.028707295656204224

Rewards:
74.4454
74.4454
74.4454
objective = 22.636028289794922
==== episode 14600/75000 ====
action = 1
probs = 0.0066 0.9114 0.0373 0.0446

action = 1
probs = 0.0339 0.4361 0.3911 0.1388

action = 2
probs = 0.0062 0.0039 0.9754 0.0145

Learning rate: 7.4717e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00048434262862429023 0.08256801217794418
encoder.encoder.weight_hh_l0: -0.000624444626737386 0.08398240059614182
encoder.encoder.bias_ih_l0: 0.0013833352131769061 0.08688107132911682
encoder.encoder.bias_hh_l0: 0.014455333352088928 0.08477796614170074
encoder.encoder.weight_ih_l0_reverse: 0.0012138746678829193 0.08367185294628143
encoder.encoder.weight_hh_l0_reverse: 0.0004845351504627615 0.08270061761140823
encoder.encoder.bias_ih_l0_reverse: 0.007994839921593666 0.08129895478487015
encoder.encoder.bias_hh_l0_reverse: 0.008289511315524578 0.08713220804929733
decider.lstm.weight_ih_l0: -0.001455076620914042 0.14541175961494446
decider.lstm.weight_hh_l0: 0.002548825927078724 0.14514265954494476
decider.lstm.bias_ih_l0: -0.024970099329948425 0.14223742485046387
decider.lstm.bias_hh_l0: 0.010850748978555202 0.15365900099277496
decider.linear1.weight: 0.003442739136517048 0.11869727820158005
decider.linear1.bias: 0.0025523798540234566 0.11380213499069214
decider.linear2.weight: 0.0013959887437522411 0.052285369485616684
decider.linear2.bias: -0.0001418638275936246 0.053040292114019394
decider.linear3.weight: -0.0013115064939484 0.05398484691977501
decider.linear3.bias: -0.014912750571966171 0.028348464518785477

Rewards:
74.4454
74.4454
74.4454
objective = 23.510969161987305
==== episode 14700/75000 ====
action = 1
probs = 0.0066 0.9192 0.0361 0.0380

action = 2
probs = 0.0345 0.4338 0.4083 0.1233

action = 2
probs = 0.0065 0.0041 0.9763 0.0131

Learning rate: 7.4717e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005147382616996765 0.08259890973567963
encoder.encoder.weight_hh_l0: -0.0006420233403332531 0.08402584493160248
encoder.encoder.bias_ih_l0: 0.0015643661608919501 0.08696013689041138
encoder.encoder.bias_hh_l0: 0.01463636476546526 0.08482213318347931
encoder.encoder.weight_ih_l0_reverse: 0.0012388393515720963 0.08370472490787506
encoder.encoder.weight_hh_l0_reverse: 0.0004918482736684382 0.08273102343082428
encoder.encoder.bias_ih_l0_reverse: 0.00810453575104475 0.08133590966463089
encoder.encoder.bias_hh_l0_reverse: 0.008399204351007938 0.08719370514154434
decider.lstm.weight_ih_l0: -0.0014579951530322433 0.14542952179908752
decider.lstm.weight_hh_l0: 0.0025789844803512096 0.14516490697860718
decider.lstm.bias_ih_l0: -0.02484496682882309 0.14226965606212616
decider.lstm.bias_hh_l0: 0.010975874960422516 0.1537303775548935
decider.linear1.weight: 0.003459483850747347 0.11871840059757233
decider.linear1.bias: 0.002632917370647192 0.1138027161359787
decider.linear2.weight: 0.0014322742354124784 0.052300143986940384
decider.linear2.bias: -9.57767479121685e-05 0.053058166056871414
decider.linear3.weight: -0.0013177287764847279 0.05400853231549263
decider.linear3.bias: -0.014923964627087116 0.02888990193605423

Rewards:
70.1874
70.1874
70.1874
objective = 23.486164093017578
==== episode 14800/75000 ====
action = 1
probs = 0.0050 0.9415 0.0242 0.0293

action = 1
probs = 0.0301 0.5807 0.2790 0.1102

action = 2
probs = 0.0069 0.0049 0.9751 0.0130

Learning rate: 7.4717e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005146379116922617 0.08260013908147812
encoder.encoder.weight_hh_l0: -0.000625491316895932 0.08397512137889862
encoder.encoder.bias_ih_l0: 0.001292161294259131 0.08688931167125702
encoder.encoder.bias_hh_l0: 0.014364157803356647 0.08475713431835175
encoder.encoder.weight_ih_l0_reverse: 0.0012362034758552909 0.0836799368262291
encoder.encoder.weight_hh_l0_reverse: 0.00048614147817716 0.08270900696516037
encoder.encoder.bias_ih_l0_reverse: 0.007988577708601952 0.08129860460758209
encoder.encoder.bias_hh_l0_reverse: 0.00828324630856514 0.08723832666873932
decider.lstm.weight_ih_l0: -0.0014664947520941496 0.14542162418365479
decider.lstm.weight_hh_l0: 0.002603430300951004 0.14517833292484283
decider.lstm.bias_ih_l0: -0.02475445531308651 0.14215418696403503
decider.lstm.bias_hh_l0: 0.011066386476159096 0.15370628237724304
decider.linear1.weight: 0.0035032075829803944 0.11874174326658249
decider.linear1.bias: 0.0028082788921892643 0.11388903856277466
decider.linear2.weight: 0.001466309535317123 0.05231943354010582
decider.linear2.bias: -4.194490611553192e-05 0.0531216636300087
decider.linear3.weight: -0.0013442195486277342 0.054065264761447906
decider.linear3.bias: -0.014981064014136791 0.02931668981909752

Rewards:
74.4454
74.4454
74.4454
objective = 15.607161521911621
==== episode 14900/75000 ====
action = 1
probs = 0.0040 0.9544 0.0176 0.0240

action = 1
probs = 0.0259 0.6690 0.2045 0.1006

action = 2
probs = 0.0067 0.0061 0.9742 0.0130

Learning rate: 7.4717e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005308619001880288 0.08261745423078537
encoder.encoder.weight_hh_l0: -0.0006255482439883053 0.08396384865045547
encoder.encoder.bias_ih_l0: 0.001267206622287631 0.08691006898880005
encoder.encoder.bias_hh_l0: 0.014339202083647251 0.08474738895893097
encoder.encoder.weight_ih_l0_reverse: 0.0012514990521594882 0.0836813896894455
encoder.encoder.weight_hh_l0_reverse: 0.0004818097804673016 0.08271212875843048
encoder.encoder.bias_ih_l0_reverse: 0.008073067292571068 0.08131946623325348
encoder.encoder.bias_hh_l0_reverse: 0.00836773868650198 0.08731787651777267
decider.lstm.weight_ih_l0: -0.0014745757216587663 0.14543530344963074
decider.lstm.weight_hh_l0: 0.0026826816610991955 0.14520837366580963
decider.lstm.bias_ih_l0: -0.024475613608956337 0.14205573499202728
decider.lstm.bias_hh_l0: 0.01134522445499897 0.15371885895729065
decider.linear1.weight: 0.0035520712845027447 0.11878151446580887
decider.linear1.bias: 0.0030831671319901943 0.11387678980827332
decider.linear2.weight: 0.001535502728074789 0.05235477164387703
decider.linear2.bias: 4.498852649703622e-05 0.05316523462533951
decider.linear3.weight: -0.00136396917514503 0.05413853004574776
decider.linear3.bias: -0.015027831308543682 0.0295723807066679

Rewards:
74.4454
74.4454
74.4454
objective = 11.779078483581543
==== episode 15000/75000 ====
action = 1
probs = 0.0039 0.9556 0.0175 0.0230

action = 1
probs = 0.0279 0.6084 0.2628 0.1009

action = 2
probs = 0.0051 0.0042 0.9810 0.0098

Learning rate: 7.3970e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005864435224793851 0.08267823606729507
encoder.encoder.weight_hh_l0: -0.0006625934620387852 0.08407070487737656
encoder.encoder.bias_ih_l0: 0.001795830437913537 0.08710737526416779
encoder.encoder.bias_hh_l0: 0.014867827296257019 0.08485492318868637
encoder.encoder.weight_ih_l0_reverse: 0.001292672473937273 0.08374767750501633
encoder.encoder.weight_hh_l0_reverse: 0.0004852132115047425 0.08276957273483276
encoder.encoder.bias_ih_l0_reverse: 0.008385056629776955 0.08143287897109985
encoder.encoder.bias_hh_l0_reverse: 0.008679728023707867 0.08739608526229858
decider.lstm.weight_ih_l0: -0.0014816615730524063 0.1454772651195526
decider.lstm.weight_hh_l0: 0.0027765368577092886 0.14525018632411957
decider.lstm.bias_ih_l0: -0.02415432035923004 0.1421375572681427
decider.lstm.bias_hh_l0: 0.011666519567370415 0.15382225811481476
decider.linear1.weight: 0.0035769068636000156 0.11883057653903961
decider.linear1.bias: 0.0032637445256114006 0.11376262456178665
decider.linear2.weight: 0.0016042165225371718 0.052386846393346786
decider.linear2.bias: 0.0001344345510005951 0.05317874625325203
decider.linear3.weight: -0.0013807985233142972 0.05421127751469612
decider.linear3.bias: -0.015031915158033371 0.029686400666832924

Rewards:
74.4454
74.4454
74.4454
objective = 13.93105697631836
==== episode 15100/75000 ====
action = 1
probs = 0.0044 0.9530 0.0179 0.0247

action = 0
probs = 0.0297 0.5654 0.2965 0.1085

action = 2
probs = 0.0037 0.0030 0.9846 0.0087

Learning rate: 7.3970e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005901692784391344 0.08268957585096359
encoder.encoder.weight_hh_l0: -0.0006688525900244713 0.0841001644730568
encoder.encoder.bias_ih_l0: 0.001938557019457221 0.08715813606977463
encoder.encoder.bias_hh_l0: 0.015010553412139416 0.0848948210477829
encoder.encoder.weight_ih_l0_reverse: 0.0012940258020535111 0.08375728130340576
encoder.encoder.weight_hh_l0_reverse: 0.0004877922765444964 0.08278322964906693
encoder.encoder.bias_ih_l0_reverse: 0.008442721329629421 0.08146483451128006
encoder.encoder.bias_hh_l0_reverse: 0.008737395517528057 0.08738293498754501
decider.lstm.weight_ih_l0: -0.0014798840275034308 0.14548401534557343
decider.lstm.weight_hh_l0: 0.002791996579617262 0.14525407552719116
decider.lstm.bias_ih_l0: -0.024108849465847015 0.14217232167720795
decider.lstm.bias_hh_l0: 0.011711988598108292 0.15382635593414307
decider.linear1.weight: 0.0035737589932978153 0.11883748322725296
decider.linear1.bias: 0.003270711749792099 0.11370266228914261
decider.linear2.weight: 0.0016457688761875033 0.05239778012037277
decider.linear2.bias: 0.0001948361750692129 0.05319281294941902
decider.linear3.weight: -0.0015025180764496326 0.05429163575172424
decider.linear3.bias: -0.014984337612986565 0.029447786509990692

Rewards:
71.0584
71.0584
71.0584
objective = 84.77684020996094
==== episode 15200/75000 ====
action = 0
probs = 0.0043 0.9543 0.0167 0.0247

action = 2
probs = 0.0335 0.2687 0.5965 0.1013

action = 2
probs = 0.0047 0.0046 0.9800 0.0106

Learning rate: 7.3970e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005547890905290842 0.08265774697065353
encoder.encoder.weight_hh_l0: -0.0006424523307941854 0.08402884006500244
encoder.encoder.bias_ih_l0: 0.0015662842197343707 0.08703578263521194
encoder.encoder.bias_hh_l0: 0.014638281427323818 0.08479736745357513
encoder.encoder.weight_ih_l0_reverse: 0.001257251133210957 0.08372589200735092
encoder.encoder.weight_hh_l0_reverse: 0.00048315819003619254 0.08274482935667038
encoder.encoder.bias_ih_l0_reverse: 0.008227420039474964 0.08142964541912079
encoder.encoder.bias_hh_l0_reverse: 0.008522093296051025 0.08733967691659927
decider.lstm.weight_ih_l0: -0.0014752704882994294 0.1454581320285797
decider.lstm.weight_hh_l0: 0.002725037280470133 0.1452452540397644
decider.lstm.bias_ih_l0: -0.02430706098675728 0.14211705327033997
decider.lstm.bias_hh_l0: 0.011513791978359222 0.15373936295509338
decider.linear1.weight: 0.0035601572599262 0.11881285160779953
decider.linear1.bias: 0.00317379180341959 0.1137712150812149
decider.linear2.weight: 0.0016275898087769747 0.05238600820302963
decider.linear2.bias: 0.00015760562382638454 0.05319158360362053
decider.linear3.weight: -0.001548841828480363 0.054298724979162216
decider.linear3.bias: -0.014997142367064953 0.02953074872493744

Rewards:
59.5434
59.5434
59.5434
objective = 118.89724731445312
==== episode 15300/75000 ====
action = 1
probs = 0.0034 0.9623 0.0127 0.0216

action = 1
probs = 0.0210 0.7500 0.1436 0.0854

action = 2
probs = 0.0045 0.0061 0.9783 0.0112

Learning rate: 7.3970e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005431436584331095 0.08267458528280258
encoder.encoder.weight_hh_l0: -0.0006264925468713045 0.08402281254529953
encoder.encoder.bias_ih_l0: 0.0014748036628589034 0.08700712770223618
encoder.encoder.bias_hh_l0: 0.014546801336109638 0.08477333188056946
encoder.encoder.weight_ih_l0_reverse: 0.0012551608961075544 0.08370957523584366
encoder.encoder.weight_hh_l0_reverse: 0.00048087237519212067 0.08273916691541672
encoder.encoder.bias_ih_l0_reverse: 0.008207316510379314 0.08141026645898819
encoder.encoder.bias_hh_l0_reverse: 0.008501989766955376 0.08742690086364746
decider.lstm.weight_ih_l0: -0.0014798286138102412 0.14547671377658844
decider.lstm.weight_hh_l0: 0.002834351034834981 0.14528949558734894
decider.lstm.bias_ih_l0: -0.02398642525076866 0.14193713665008545
decider.lstm.bias_hh_l0: 0.011834420263767242 0.15374435484409332
decider.linear1.weight: 0.0036033163778483868 0.11884774267673492
decider.linear1.bias: 0.003336501307785511 0.11389508098363876
decider.linear2.weight: 0.001656646141782403 0.05241992324590683
decider.linear2.bias: 0.00020968273747712374 0.053262852132320404
decider.linear3.weight: -0.001624262542463839 0.05441954359412193
decider.linear3.bias: -0.015111008659005165 0.029770709574222565

Rewards:
74.4454
74.4454
74.4454
objective = 8.636470794677734
==== episode 15400/75000 ====
action = 1
probs = 0.0020 0.9761 0.0077 0.0142

action = 1
probs = 0.0120 0.8603 0.0733 0.0544

action = 2
probs = 0.0035 0.0071 0.9799 0.0094

Learning rate: 7.3970e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0006062457105144858 0.08278714865446091
encoder.encoder.weight_hh_l0: -0.0006555565632879734 0.08415068686008453
encoder.encoder.bias_ih_l0: 0.0020721585024148226 0.08723011612892151
encoder.encoder.bias_hh_l0: 0.015144158154726028 0.08487239480018616
encoder.encoder.weight_ih_l0_reverse: 0.0013120947405695915 0.08376561850309372
encoder.encoder.weight_hh_l0_reverse: 0.00048554677050560713 0.08280999958515167
encoder.encoder.bias_ih_l0_reverse: 0.008764424361288548 0.08150341361761093
encoder.encoder.bias_hh_l0_reverse: 0.009059098549187183 0.08771795779466629
decider.lstm.weight_ih_l0: -0.0015024946769699454 0.14559276401996613
decider.lstm.weight_hh_l0: 0.003237410681322217 0.14540569484233856
decider.lstm.bias_ih_l0: -0.022937972098588943 0.14179164171218872
decider.lstm.bias_hh_l0: 0.012882871553301811 0.15382565557956696
decider.linear1.weight: 0.0037187698762863874 0.11896482110023499
decider.linear1.bias: 0.0038411300629377365 0.11406102031469345
decider.linear2.weight: 0.0017458070069551468 0.052519649267196655
decider.linear2.bias: 0.0003807110188063234 0.053376294672489166
decider.linear3.weight: -0.0017504824791103601 0.054693371057510376
decider.linear3.bias: -0.015311924740672112 0.030566278845071793

Rewards:
74.4454
74.4454
74.4454
objective = 4.836976051330566
==== episode 15500/75000 ====
action = 1
probs = 0.0019 0.9745 0.0074 0.0162

action = 3
probs = 0.0114 0.8593 0.0661 0.0633

action = 2
probs = 0.0047 0.0094 0.9721 0.0138

Learning rate: 7.3230e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0006002245936542749 0.08275557309389114
encoder.encoder.weight_hh_l0: -0.0006444356986321509 0.08409435302019119
encoder.encoder.bias_ih_l0: 0.0018194925505667925 0.0871376171708107
encoder.encoder.bias_hh_l0: 0.014891494996845722 0.08484331518411636
encoder.encoder.weight_ih_l0_reverse: 0.0013179158559069037 0.08374962955713272
encoder.encoder.weight_hh_l0_reverse: 0.00048594645340926945 0.08279280364513397
encoder.encoder.bias_ih_l0_reverse: 0.008677450008690357 0.08145543187856674
encoder.encoder.bias_hh_l0_reverse: 0.008972123265266418 0.0876874104142189
decider.lstm.weight_ih_l0: -0.0015010770875960588 0.14556843042373657
decider.lstm.weight_hh_l0: 0.003144162241369486 0.1453697681427002
decider.lstm.bias_ih_l0: -0.023131754249334335 0.14180169999599457
decider.lstm.bias_hh_l0: 0.012689088471233845 0.1537959724664688
decider.linear1.weight: 0.0037068561650812626 0.11895749717950821
decider.linear1.bias: 0.0037667322903871536 0.11409012973308563
decider.linear2.weight: 0.0017001776723191142 0.05252423509955406
decider.linear2.bias: 0.0003408615302760154 0.05337001755833626
decider.linear3.weight: -0.0017570257186889648 0.05470343679189682
decider.linear3.bias: -0.015295893885195255 0.029993746429681778

Rewards:
69.5795
69.5795
69.5795
objective = 65.27696228027344
==== episode 15600/75000 ====
action = 1
probs = 0.0015 0.9802 0.0063 0.0120

action = 1
probs = 0.0093 0.8838 0.0588 0.0481

action = 2
probs = 0.0037 0.0085 0.9772 0.0106

Learning rate: 7.3230e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0006457628333009779 0.08280482888221741
encoder.encoder.weight_hh_l0: -0.000671560293994844 0.0841498151421547
encoder.encoder.bias_ih_l0: 0.0021379943937063217 0.08727394044399261
encoder.encoder.bias_hh_l0: 0.015210000798106194 0.08490342646837234
encoder.encoder.weight_ih_l0_reverse: 0.001355863525532186 0.08379090577363968
encoder.encoder.weight_hh_l0_reverse: 0.0004882849752902985 0.0828344076871872
encoder.encoder.bias_ih_l0_reverse: 0.009005632251501083 0.08152777701616287
encoder.encoder.bias_hh_l0_reverse: 0.009300310164690018 0.08782559633255005
decider.lstm.weight_ih_l0: -0.001512965769506991 0.1456253081560135
decider.lstm.weight_hh_l0: 0.0033016023226082325 0.14540639519691467
decider.lstm.bias_ih_l0: -0.0226920023560524 0.14180539548397064
decider.lstm.bias_hh_l0: 0.013128841295838356 0.15383043885231018
decider.linear1.weight: 0.0037453086115419865 0.1189950630068779
decider.linear1.bias: 0.003973979968577623 0.11412984877824783
decider.linear2.weight: 0.0017547083552926779 0.05254191532731056
decider.linear2.bias: 0.00043016343261115253 0.05342506244778633
decider.linear3.weight: -0.0018000395502895117 0.0547490268945694
decider.linear3.bias: -0.015410141088068485 0.030722951516509056

Rewards:
74.4454
74.4454
74.4454
objective = 4.131597518920898
==== episode 15700/75000 ====
action = 1
probs = 0.0012 0.9843 0.0052 0.0093

action = 1
probs = 0.0076 0.9067 0.0475 0.0382

action = 2
probs = 0.0033 0.0088 0.9782 0.0096

Learning rate: 7.3230e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0006880505243316293 0.0828593522310257
encoder.encoder.weight_hh_l0: -0.0006976395379751921 0.08422013372182846
encoder.encoder.bias_ih_l0: 0.002479779999703169 0.08740939944982529
encoder.encoder.bias_hh_l0: 0.015551785007119179 0.08496297895908356
encoder.encoder.weight_ih_l0_reverse: 0.0013888090616092086 0.08382940292358398
encoder.encoder.weight_hh_l0_reverse: 0.000490495003759861 0.08287511765956879
encoder.encoder.bias_ih_l0_reverse: 0.009310392662882805 0.08158040791749954
encoder.encoder.bias_hh_l0_reverse: 0.009605071507394314 0.08795817941427231
decider.lstm.weight_ih_l0: -0.0015251009026542306 0.14568664133548737
decider.lstm.weight_hh_l0: 0.003475447650998831 0.1454462707042694
decider.lstm.bias_ih_l0: -0.022229645401239395 0.14177662134170532
decider.lstm.bias_hh_l0: 0.013591192662715912 0.15386256575584412
decider.linear1.weight: 0.0037864958867430687 0.11904913932085037
decider.linear1.bias: 0.00417980644851923 0.11417567729949951
decider.linear2.weight: 0.0017981764394789934 0.05257635936141014
decider.linear2.bias: 0.0005036861402913928 0.053462620824575424
decider.linear3.weight: -0.0018370368052273989 0.05483367294073105
decider.linear3.bias: -0.015482611954212189 0.03116350993514061

Rewards:
74.4454
74.4454
74.4454
objective = 3.3699653148651123
==== episode 15800/75000 ====
action = 1
probs = 0.0012 0.9834 0.0053 0.0101

action = 1
probs = 0.0078 0.8925 0.0546 0.0451

action = 2
probs = 0.0030 0.0081 0.9784 0.0105

Learning rate: 7.3230e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0006866487674415112 0.08284119516611099
encoder.encoder.weight_hh_l0: -0.0006988234235905111 0.08419575542211533
encoder.encoder.bias_ih_l0: 0.002406839281320572 0.0873899832367897
encoder.encoder.bias_hh_l0: 0.015478839166462421 0.08496157824993134
encoder.encoder.weight_ih_l0_reverse: 0.0013904636725783348 0.08382996916770935
encoder.encoder.weight_hh_l0_reverse: 0.0004900266649201512 0.08287167549133301
encoder.encoder.bias_ih_l0_reverse: 0.009290238842368126 0.08159064501523972
encoder.encoder.bias_hh_l0_reverse: 0.009584917686879635 0.08793666958808899
decider.lstm.weight_ih_l0: -0.0015234873862937093 0.1456678956747055
decider.lstm.weight_hh_l0: 0.0034277383238077164 0.1454329937696457
decider.lstm.bias_ih_l0: -0.02234950102865696 0.14181239902973175
decider.lstm.bias_hh_l0: 0.013471344485878944 0.1539059728384018
decider.linear1.weight: 0.0037754522636532784 0.11904357373714447
decider.linear1.bias: 0.004145435057580471 0.11414843052625656
decider.linear2.weight: 0.0018003281438723207 0.05257640779018402
decider.linear2.bias: 0.0005076125962659717 0.05346094071865082
decider.linear3.weight: -0.0018546601058915257 0.0548376739025116
decider.linear3.bias: -0.015507693402469158 0.030811244621872902

Rewards:
74.4454
74.4454
74.4454
objective = 3.7798495292663574
==== episode 15900/75000 ====
action = 1
probs = 0.0010 0.9836 0.0051 0.0103

action = 1
probs = 0.0071 0.8866 0.0579 0.0483

action = 2
probs = 0.0023 0.0060 0.9827 0.0090

Learning rate: 7.3230e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007164785638451576 0.08288385719060898
encoder.encoder.weight_hh_l0: -0.0007226389134302735 0.08426664024591446
encoder.encoder.bias_ih_l0: 0.002712598303332925 0.08750581741333008
encoder.encoder.bias_hh_l0: 0.015784602612257004 0.08503371477127075
encoder.encoder.weight_ih_l0_reverse: 0.001419398351572454 0.0838649719953537
encoder.encoder.weight_hh_l0_reverse: 0.0004915745812468231 0.08290830999612808
encoder.encoder.bias_ih_l0_reverse: 0.009510030969977379 0.08164706826210022
encoder.encoder.bias_hh_l0_reverse: 0.009804708883166313 0.08800272643566132
decider.lstm.weight_ih_l0: -0.001531142508611083 0.14570456743240356
decider.lstm.weight_hh_l0: 0.0035549732856452465 0.14546817541122437
decider.lstm.bias_ih_l0: -0.022016245871782303 0.1417999565601349
decider.lstm.bias_hh_l0: 0.013804605230689049 0.15397793054580688
decider.linear1.weight: 0.0038028291892260313 0.11909183859825134
decider.linear1.bias: 0.004280988126993179 0.11410319060087204
decider.linear2.weight: 0.0018461928702890873 0.052611254155635834
decider.linear2.bias: 0.0005786345573142171 0.05348573997616768
decider.linear3.weight: -0.0018953251419588923 0.054931968450546265
decider.linear3.bias: -0.015555932186543941 0.030639564618468285

Rewards:
74.4454
74.4454
74.4454
objective = 3.831524610519409
==== episode 16000/75000 ====
action = 1
probs = 0.0008 0.9873 0.0041 0.0079

action = 1
probs = 0.0051 0.9163 0.0432 0.0354

action = 2
probs = 0.0021 0.0067 0.9823 0.0089

Learning rate: 7.2498e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007558256038464606 0.08294488489627838
encoder.encoder.weight_hh_l0: -0.0007443713839165866 0.08434346318244934
encoder.encoder.bias_ih_l0: 0.0030610114336013794 0.08764012902975082
encoder.encoder.bias_hh_l0: 0.01613301783800125 0.08509469032287598
encoder.encoder.weight_ih_l0_reverse: 0.0014458729419857264 0.08390048891305923
encoder.encoder.weight_hh_l0_reverse: 0.0004894064040854573 0.0829513743519783
encoder.encoder.bias_ih_l0_reverse: 0.009842459112405777 0.08170036971569061
encoder.encoder.bias_hh_l0_reverse: 0.010137136094272137 0.08814718574285507
decider.lstm.weight_ih_l0: -0.0015435321256518364 0.1457754522562027
decider.lstm.weight_hh_l0: 0.0037258833181113005 0.1455146223306656
decider.lstm.bias_ih_l0: -0.021534325554966927 0.14174960553646088
decider.lstm.bias_hh_l0: 0.014286517165601254 0.15398381650447845
decider.linear1.weight: 0.003840602934360504 0.11913856863975525
decider.linear1.bias: 0.004450349137187004 0.11420131474733353
decider.linear2.weight: 0.0018878401024267077 0.05264103412628174
decider.linear2.bias: 0.0006472733221016824 0.053544167429208755
decider.linear3.weight: -0.0019524048548191786 0.05502615123987198
decider.linear3.bias: -0.01567528396844864 0.031155819073319435

Rewards:
74.4454
74.4454
74.4454
objective = 2.9300475120544434
==== episode 16100/75000 ====
action = 1
probs = 0.0006 0.9891 0.0036 0.0066

action = 1
probs = 0.0044 0.9205 0.0435 0.0317

action = 2
probs = 0.0017 0.0059 0.9851 0.0072

Learning rate: 7.2498e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008031032048165798 0.08299868553876877
encoder.encoder.weight_hh_l0: -0.00077958800829947 0.08442939817905426
encoder.encoder.bias_ih_l0: 0.003446787130087614 0.08780089765787125
encoder.encoder.bias_hh_l0: 0.016518795862793922 0.08517098426818848
encoder.encoder.weight_ih_l0_reverse: 0.0014837965136393905 0.08394405245780945
encoder.encoder.weight_hh_l0_reverse: 0.0004845349758397788 0.0830000787973404
encoder.encoder.bias_ih_l0_reverse: 0.010169810615479946 0.08177215605974197
encoder.encoder.bias_hh_l0_reverse: 0.010464491322636604 0.08825138956308365
decider.lstm.weight_ih_l0: -0.0015605189837515354 0.14583367109298706
decider.lstm.weight_hh_l0: 0.0038903607055544853 0.1455601006746292
decider.lstm.bias_ih_l0: -0.02110469341278076 0.1417321264743805
decider.lstm.bias_hh_l0: 0.014716139063239098 0.15403108298778534
decider.linear1.weight: 0.0038776728324592113 0.11918748170137405
decider.linear1.bias: 0.004623902030289173 0.11419195681810379
decider.linear2.weight: 0.0019495710730552673 0.05267186462879181
decider.linear2.bias: 0.0007420614128932357 0.053585704416036606
decider.linear3.weight: -0.0019950238056480885 0.055107150226831436
decider.linear3.bias: -0.015752872452139854 0.031427230685949326

Rewards:
74.4454
74.4454
74.4454
objective = 2.698137044906616
==== episode 16200/75000 ====
action = 1
probs = 0.0007 0.9874 0.0041 0.0078

action = 1
probs = 0.0052 0.9025 0.0554 0.0370

action = 2
probs = 0.0014 0.0043 0.9886 0.0058

Learning rate: 7.2498e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007892349967733026 0.08299587666988373
encoder.encoder.weight_hh_l0: -0.0007730289362370968 0.08443756401538849
encoder.encoder.bias_ih_l0: 0.00343456887640059 0.08778820186853409
encoder.encoder.bias_hh_l0: 0.01650657318532467 0.08517969399690628
encoder.encoder.weight_ih_l0_reverse: 0.0014783308142796159 0.08394259214401245
encoder.encoder.weight_hh_l0_reverse: 0.00048696468002162874 0.08299964666366577
encoder.encoder.bias_ih_l0_reverse: 0.010081257671117783 0.08178632706403732
encoder.encoder.bias_hh_l0_reverse: 0.010375939309597015 0.08820191025733948
decider.lstm.weight_ih_l0: -0.0015542748151347041 0.14581716060638428
decider.lstm.weight_hh_l0: 0.003862581681460142 0.14556391537189484
decider.lstm.bias_ih_l0: -0.0211961530148983 0.141751229763031
decider.lstm.bias_hh_l0: 0.014624683186411858 0.15406391024589539
decider.linear1.weight: 0.0038739386945962906 0.11919108033180237
decider.linear1.bias: 0.004590881988406181 0.11412744224071503
decider.linear2.weight: 0.0019662193953990936 0.0526883564889431
decider.linear2.bias: 0.0007508168346248567 0.053571917116642
decider.linear3.weight: -0.001995732542127371 0.05513398349285126
decider.linear3.bias: -0.015723716467618942 0.03126052767038345

Rewards:
74.4454
74.4454
74.4454
objective = 3.1466856002807617
==== episode 16300/75000 ====
action = 1
probs = 0.0007 0.9881 0.0039 0.0073

action = 1
probs = 0.0048 0.9185 0.0445 0.0323

action = 2
probs = 0.0014 0.0050 0.9879 0.0056

Learning rate: 7.2498e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007886983221396804 0.08300203084945679
encoder.encoder.weight_hh_l0: -0.0007631314219906926 0.0844339057803154
encoder.encoder.bias_ih_l0: 0.0033694040030241013 0.08774974942207336
encoder.encoder.bias_hh_l0: 0.016441406682133675 0.08515435457229614
encoder.encoder.weight_ih_l0_reverse: 0.0014718819875270128 0.08393840491771698
encoder.encoder.weight_hh_l0_reverse: 0.0004880185006186366 0.08299148082733154
encoder.encoder.bias_ih_l0_reverse: 0.010047802701592445 0.08176960051059723
encoder.encoder.bias_hh_l0_reverse: 0.010342488996684551 0.08819794654846191
decider.lstm.weight_ih_l0: -0.001552301342599094 0.14582139253616333
decider.lstm.weight_hh_l0: 0.0038425540551543236 0.14557959139347076
decider.lstm.bias_ih_l0: -0.021222863346338272 0.14173492789268494
decider.lstm.bias_hh_l0: 0.014597967267036438 0.15404725074768066
decider.linear1.weight: 0.0038772437255829573 0.11919131875038147
decider.linear1.bias: 0.0045910365879535675 0.11418593674898148
decider.linear2.weight: 0.0019730678759515285 0.0526968389749527
decider.linear2.bias: 0.0007462988724000752 0.05357249826192856
decider.linear3.weight: -0.0020006634294986725 0.05515047907829285
decider.linear3.bias: -0.015733443200588226 0.03147318959236145

Rewards:
74.4454
74.4454
74.4454
objective = 2.709775924682617
==== episode 16400/75000 ====
action = 1
probs = 0.0006 0.9900 0.0031 0.0064

action = 1
probs = 0.0042 0.9318 0.0343 0.0298

action = 2
probs = 0.0016 0.0051 0.9875 0.0057

Learning rate: 7.2498e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008110200287774205 0.08302193135023117
encoder.encoder.weight_hh_l0: -0.0007743965252302587 0.08444993197917938
encoder.encoder.bias_ih_l0: 0.003469333052635193 0.08779255300760269
encoder.encoder.bias_hh_l0: 0.016541335731744766 0.08516848087310791
encoder.encoder.weight_ih_l0_reverse: 0.001484873122535646 0.08395659923553467
encoder.encoder.weight_hh_l0_reverse: 0.00048715018783695996 0.08300774544477463
encoder.encoder.bias_ih_l0_reverse: 0.010169778019189835 0.08178167045116425
encoder.encoder.bias_hh_l0_reverse: 0.010464460588991642 0.0882587805390358
decider.lstm.weight_ih_l0: -0.0015572932315990329 0.14583967626094818
decider.lstm.weight_hh_l0: 0.003862365847453475 0.14558793604373932
decider.lstm.bias_ih_l0: -0.021134117618203163 0.14171841740608215
decider.lstm.bias_hh_l0: 0.014686712995171547 0.15410077571868896
decider.linear1.weight: 0.003891304600983858 0.11922133713960648
decider.linear1.bias: 0.00468548946082592 0.11423177272081375
decider.linear2.weight: 0.001983771799132228 0.052723582834005356
decider.linear2.bias: 0.0007772543467581272 0.0535762682557106
decider.linear3.weight: -0.0020099100656807423 0.05521576479077339
decider.linear3.bias: -0.015734197571873665 0.031509410589933395

Rewards:
74.4454
74.4454
74.4454
objective = 2.3141019344329834
==== episode 16500/75000 ====
action = 1
probs = 0.0006 0.9898 0.0033 0.0062

action = 2
probs = 0.0042 0.9270 0.0396 0.0291

action = 2
probs = 0.0017 0.0058 0.9859 0.0066

Learning rate: 7.1773e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008094803197309375 0.0830274224281311
encoder.encoder.weight_hh_l0: -0.0007776652346365154 0.08446034789085388
encoder.encoder.bias_ih_l0: 0.00350761110894382 0.08781079202890396
encoder.encoder.bias_hh_l0: 0.01657961495220661 0.08517526835203171
encoder.encoder.weight_ih_l0_reverse: 0.001485365559346974 0.08396493643522263
encoder.encoder.weight_hh_l0_reverse: 0.00048754687304608524 0.08301616460084915
encoder.encoder.bias_ih_l0_reverse: 0.010177266784012318 0.08179605007171631
encoder.encoder.bias_hh_l0_reverse: 0.010471949353814125 0.08826496452093124
decider.lstm.weight_ih_l0: -0.0015570020768791437 0.1458462029695511
decider.lstm.weight_hh_l0: 0.003881700336933136 0.14558656513690948
decider.lstm.bias_ih_l0: -0.021091608330607414 0.14170299470424652
decider.lstm.bias_hh_l0: 0.014729215763509274 0.1541159749031067
decider.linear1.weight: 0.0038901183288544416 0.11921921372413635
decider.linear1.bias: 0.004669262561947107 0.11419825255870819
decider.linear2.weight: 0.0019649388268589973 0.05272158980369568
decider.linear2.bias: 0.0007633601780980825 0.05357883870601654
decider.linear3.weight: -0.002015701262280345 0.055202916264534
decider.linear3.bias: -0.015750497579574585 0.03160615637898445

Rewards:
70.1874
70.1874
70.1874
objective = 76.11194610595703
==== episode 16600/75000 ====
action = 1
probs = 0.0005 0.9913 0.0029 0.0052

action = 1
probs = 0.0035 0.9392 0.0334 0.0240

action = 2
probs = 0.0012 0.0042 0.9898 0.0048

Learning rate: 7.1773e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008370392024517059 0.0830853059887886
encoder.encoder.weight_hh_l0: -0.0007947902195155621 0.08455049246549606
encoder.encoder.bias_ih_l0: 0.003841096069663763 0.08792685717344284
encoder.encoder.bias_hh_l0: 0.016913099214434624 0.08524670451879501
encoder.encoder.weight_ih_l0_reverse: 0.001504035433754325 0.08399105817079544
encoder.encoder.weight_hh_l0_reverse: 0.0004835717554669827 0.08304892480373383
encoder.encoder.bias_ih_l0_reverse: 0.010405848734080791 0.08182766288518906
encoder.encoder.bias_hh_l0_reverse: 0.010700528509914875 0.08833926916122437
decider.lstm.weight_ih_l0: -0.0015664581442251801 0.14589715003967285
decider.lstm.weight_hh_l0: 0.004007040988653898 0.14563320577144623
decider.lstm.bias_ih_l0: -0.020726986229419708 0.14168129861354828
decider.lstm.bias_hh_l0: 0.015093835070729256 0.15412503480911255
decider.linear1.weight: 0.003923858515918255 0.11926664412021637
decider.linear1.bias: 0.0048327394761145115 0.11422599852085114
decider.linear2.weight: 0.002007461618632078 0.052759505808353424
decider.linear2.bias: 0.0008310973644256592 0.053610485047101974
decider.linear3.weight: -0.002049828413873911 0.055296096950769424
decider.linear3.bias: -0.015814272686839104 0.03194904699921608

Rewards:
74.4454
74.4454
74.4454
objective = 2.029439687728882
==== episode 16700/75000 ====
action = 1
probs = 0.0005 0.9910 0.0029 0.0056

action = 1
probs = 0.0034 0.9373 0.0334 0.0260

action = 2
probs = 0.0010 0.0034 0.9914 0.0042

Learning rate: 7.1773e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008389733266085386 0.08309810608625412
encoder.encoder.weight_hh_l0: -0.0007972061284817755 0.08458021283149719
encoder.encoder.bias_ih_l0: 0.003930616192519665 0.08795550465583801
encoder.encoder.bias_hh_l0: 0.017002619802951813 0.08526520431041718
encoder.encoder.weight_ih_l0_reverse: 0.0015069687506183982 0.08399675041437149
encoder.encoder.weight_hh_l0_reverse: 0.00048418884398415685 0.08305853605270386
encoder.encoder.bias_ih_l0_reverse: 0.010442836210131645 0.08184170722961426
encoder.encoder.bias_hh_l0_reverse: 0.010737517848610878 0.08833548426628113
decider.lstm.weight_ih_l0: -0.0015664278762415051 0.14590312540531158
decider.lstm.weight_hh_l0: 0.004035465884953737 0.14565014839172363
decider.lstm.bias_ih_l0: -0.020664338022470474 0.14165587723255157
decider.lstm.bias_hh_l0: 0.015156479552388191 0.15416158735752106
decider.linear1.weight: 0.0039393845945596695 0.11929628998041153
decider.linear1.bias: 0.004919538274407387 0.11423373967409134
decider.linear2.weight: 0.002053645672276616 0.05279172211885452
decider.linear2.bias: 0.0008636416750960052 0.05361010506749153
decider.linear3.weight: -0.0020772572606801987 0.05537261441349983
decider.linear3.bias: -0.01583801582455635 0.03175918385386467

Rewards:
74.4454
74.4454
74.4454
objective = 2.044163465499878
==== episode 16800/75000 ====
action = 1
probs = 0.0004 0.9916 0.0026 0.0053

action = 1
probs = 0.0030 0.9437 0.0280 0.0253

action = 2
probs = 0.0011 0.0039 0.9895 0.0054

Learning rate: 7.1773e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00083719048416242 0.08309205621480942
encoder.encoder.weight_hh_l0: -0.0007930683204904199 0.0845525786280632
encoder.encoder.bias_ih_l0: 0.003850530367344618 0.0879264771938324
encoder.encoder.bias_hh_l0: 0.01692253351211548 0.08525276184082031
encoder.encoder.weight_ih_l0_reverse: 0.0015019446145743132 0.08399023860692978
encoder.encoder.weight_hh_l0_reverse: 0.00048538873670622706 0.08305161446332932
encoder.encoder.bias_ih_l0_reverse: 0.010450738482177258 0.08182279765605927
encoder.encoder.bias_hh_l0_reverse: 0.010745422914624214 0.08835674822330475
decider.lstm.weight_ih_l0: -0.0015646902611479163 0.1458994746208191
decider.lstm.weight_hh_l0: 0.004011564422398806 0.14563563466072083
decider.lstm.bias_ih_l0: -0.02070743963122368 0.14167536795139313
decider.lstm.bias_hh_l0: 0.015113386325538158 0.15413983166217804
decider.linear1.weight: 0.003933210391551256 0.11929543316364288
decider.linear1.bias: 0.004918075166642666 0.1142924502491951
decider.linear2.weight: 0.0020272918045520782 0.052793238312006
decider.linear2.bias: 0.0008433166076429188 0.05361748859286308
decider.linear3.weight: -0.0020989039912819862 0.05538440868258476
decider.linear3.bias: -0.015879254788160324 0.031645748764276505

Rewards:
74.4454
74.4454
74.4454
objective = 1.9069993495941162
==== episode 16900/75000 ====
action = 1
probs = 0.0006 0.9904 0.0027 0.0063

action = 1
probs = 0.0048 0.9346 0.0286 0.0320

action = 2
probs = 0.0015 0.0036 0.9886 0.0063

Learning rate: 7.1773e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007880490738898516 0.08301908522844315
encoder.encoder.weight_hh_l0: -0.000758988840971142 0.08442718535661697
encoder.encoder.bias_ih_l0: 0.0033220236655324697 0.08773332834243774
encoder.encoder.bias_hh_l0: 0.016394028440117836 0.0851227343082428
encoder.encoder.weight_ih_l0_reverse: 0.0014593005180358887 0.08393868803977966
encoder.encoder.weight_hh_l0_reverse: 0.0004954219912178814 0.08299589157104492
encoder.encoder.bias_ih_l0_reverse: 0.009991641156375408 0.0817745104432106
encoder.encoder.bias_hh_l0_reverse: 0.01028632465749979 0.08819577097892761
decider.lstm.weight_ih_l0: -0.001546176034025848 0.14581741392612457
decider.lstm.weight_hh_l0: 0.003794438438490033 0.1455797702074051
decider.lstm.bias_ih_l0: -0.021356822922825813 0.14172415435314178
decider.lstm.bias_hh_l0: 0.014464008621871471 0.15410633385181427
decider.linear1.weight: 0.003891071304678917 0.11925195157527924
decider.linear1.bias: 0.0046941787004470825 0.11424998939037323
decider.linear2.weight: 0.0019629085436463356 0.05278845131397247
decider.linear2.bias: 0.0007195278885774314 0.0535358190536499
decider.linear3.weight: -0.002011758740991354 0.05532782897353172
decider.linear3.bias: -0.015630610287189484 0.031159762293100357

Rewards:
74.4454
74.4454
74.4454
objective = 2.2013745307922363
==== episode 17000/75000 ====
action = 1
probs = 0.0007 0.9891 0.0029 0.0073

action = 1
probs = 0.0058 0.9187 0.0343 0.0412

action = 2
probs = 0.0013 0.0029 0.9899 0.0058

Learning rate: 7.1055e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007746805786155164 0.08299392461776733
encoder.encoder.weight_hh_l0: -0.0007519864593632519 0.08440127968788147
encoder.encoder.bias_ih_l0: 0.003198719583451748 0.08768779039382935
encoder.encoder.bias_hh_l0: 0.016270725056529045 0.08509000390768051
encoder.encoder.weight_ih_l0_reverse: 0.0014518696116283536 0.08392997831106186
encoder.encoder.weight_hh_l0_reverse: 0.0004973943578079343 0.08298397064208984
encoder.encoder.bias_ih_l0_reverse: 0.009842179715633392 0.08177278935909271
encoder.encoder.bias_hh_l0_reverse: 0.010136861354112625 0.08812431991100311
decider.lstm.weight_ih_l0: -0.0015418888069689274 0.14578814804553986
decider.lstm.weight_hh_l0: 0.003735729493200779 0.14556418359279633
decider.lstm.bias_ih_l0: -0.021554168313741684 0.1417277604341507
decider.lstm.bias_hh_l0: 0.014266673475503922 0.1541370004415512
decider.linear1.weight: 0.0038862021174281836 0.11925157159566879
decider.linear1.bias: 0.004667080473154783 0.11419510096311569
decider.linear2.weight: 0.0019613313488662243 0.05280308052897453
decider.linear2.bias: 0.0006945609929971397 0.05349329113960266
decider.linear3.weight: -0.0020013495814055204 0.05533934384584427
decider.linear3.bias: -0.015566778369247913 0.030715739354491234

Rewards:
74.4454
74.4454
74.4454
objective = 2.6255886554718018
==== episode 17100/75000 ====
action = 1
probs = 0.0009 0.9869 0.0034 0.0088

action = 1
probs = 0.0062 0.9139 0.0337 0.0462

action = 2
probs = 0.0016 0.0038 0.9867 0.0080

Learning rate: 7.1055e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007297272677533329 0.08293617516756058
encoder.encoder.weight_hh_l0: -0.0007233757642097771 0.08431974053382874
encoder.encoder.bias_ih_l0: 0.0028044593054801226 0.08752170205116272
encoder.encoder.bias_hh_l0: 0.015876464545726776 0.08499770611524582
encoder.encoder.weight_ih_l0_reverse: 0.001407795469276607 0.08387546241283417
encoder.encoder.weight_hh_l0_reverse: 0.0004962071543559432 0.0829344391822815
encoder.encoder.bias_ih_l0_reverse: 0.00952122826129198 0.08168435096740723
encoder.encoder.bias_hh_l0_reverse: 0.009815911762416363 0.08800448477268219
decider.lstm.weight_ih_l0: -0.001532545080408454 0.14573796093463898
decider.lstm.weight_hh_l0: 0.003624564968049526 0.14551545679569244
decider.lstm.bias_ih_l0: -0.021932514384388924 0.14171366393566132
decider.lstm.bias_hh_l0: 0.013888324610888958 0.1540345847606659
decider.linear1.weight: 0.0038560577668249607 0.11919417232275009
decider.linear1.bias: 0.004446461796760559 0.11423362046480179
decider.linear2.weight: 0.0018987443763762712 0.052769728004932404
decider.linear2.bias: 0.0006025091279298067 0.0534585602581501
decider.linear3.weight: -0.0019858619198203087 0.0552554577589035
decider.linear3.bias: -0.015546208247542381 0.030359594151377678

Rewards:
74.4454
74.4454
74.4454
objective = 2.8945024013519287
==== episode 17200/75000 ====
action = 1
probs = 0.0013 0.9835 0.0042 0.0110

action = 1
probs = 0.0087 0.8990 0.0383 0.0541

action = 2
probs = 0.0018 0.0035 0.9858 0.0088

Learning rate: 7.1055e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0006722331745550036 0.08288440853357315
encoder.encoder.weight_hh_l0: -0.0006922069587744772 0.08424460887908936
encoder.encoder.bias_ih_l0: 0.0024164931382983923 0.08736514300107956
encoder.encoder.bias_hh_l0: 0.015488497912883759 0.08489444106817245
encoder.encoder.weight_ih_l0_reverse: 0.001354995067231357 0.08382095396518707
encoder.encoder.weight_hh_l0_reverse: 0.0004946491681039333 0.08289030939340591
encoder.encoder.bias_ih_l0_reverse: 0.009118194691836834 0.0816434994339943
encoder.encoder.bias_hh_l0_reverse: 0.009412878192961216 0.08782579749822617
decider.lstm.weight_ih_l0: -0.0015209394041448832 0.14567875862121582
decider.lstm.weight_hh_l0: 0.0034901031758636236 0.14547176659107208
decider.lstm.bias_ih_l0: -0.022416256368160248 0.14170724153518677
decider.lstm.bias_hh_l0: 0.013404578901827335 0.1539580076932907
decider.linear1.weight: 0.003821952734142542 0.11914156377315521
decider.linear1.bias: 0.00418277969583869 0.11416799575090408
decider.linear2.weight: 0.0018279607174918056 0.052750758826732635
decider.linear2.bias: 0.0004736463015433401 0.053381722420454025
decider.linear3.weight: -0.001934639411047101 0.05518244951963425
decider.linear3.bias: -0.015365168452262878 0.02996901236474514

Rewards:
74.4454
74.4454
74.4454
objective = 3.4109532833099365
==== episode 17300/75000 ====
action = 1
probs = 0.0010 0.9856 0.0033 0.0101

action = 1
probs = 0.0073 0.9058 0.0313 0.0556

action = 2
probs = 0.0020 0.0043 0.9831 0.0106

Learning rate: 7.1055e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0006939676241017878 0.08289118111133575
encoder.encoder.weight_hh_l0: -0.0007029228145256639 0.08422841876745224
encoder.encoder.bias_ih_l0: 0.002421802841126919 0.08739053457975388
encoder.encoder.bias_hh_l0: 0.015493806451559067 0.08492559939622879
encoder.encoder.weight_ih_l0_reverse: 0.0013838985469192266 0.08383536338806152
encoder.encoder.weight_hh_l0_reverse: 0.000497666944283992 0.08290214091539383
encoder.encoder.bias_ih_l0_reverse: 0.009310261346399784 0.08166192471981049
encoder.encoder.bias_hh_l0_reverse: 0.009604944847524166 0.08791937679052353
decider.lstm.weight_ih_l0: -0.0015270697185769677 0.14569687843322754
decider.lstm.weight_hh_l0: 0.003520009573549032 0.14548183977603912
decider.lstm.bias_ih_l0: -0.022255660966038704 0.14171157777309418
decider.lstm.bias_hh_l0: 0.01356517244130373 0.1539442241191864
decider.linear1.weight: 0.003824954852461815 0.11916608363389969
decider.linear1.bias: 0.004283531568944454 0.11424726992845535
decider.linear2.weight: 0.001843837322667241 0.052765853703022
decider.linear2.bias: 0.0005220721941441298 0.053418129682540894
decider.linear3.weight: -0.0019616978242993355 0.05521967262029648
decider.linear3.bias: -0.015447692945599556 0.029754549264907837

Rewards:
74.4454
74.4454
74.4454
objective = 3.2387759685516357
==== episode 17400/75000 ====
action = 1
probs = 0.0009 0.9863 0.0028 0.0100

action = 1
probs = 0.0072 0.9104 0.0263 0.0561

action = 2
probs = 0.0027 0.0047 0.9808 0.0118

Learning rate: 7.1055e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00070954579859972 0.08288466930389404
encoder.encoder.weight_hh_l0: -0.0007096528424881399 0.084195576608181
encoder.encoder.bias_ih_l0: 0.002310739131644368 0.08735629916191101
encoder.encoder.bias_hh_l0: 0.015382739715278149 0.08491887152194977
encoder.encoder.weight_ih_l0_reverse: 0.001406045281328261 0.08384421467781067
encoder.encoder.weight_hh_l0_reverse: 0.0004992404719814658 0.08290264010429382
encoder.encoder.bias_ih_l0_reverse: 0.009310217574238777 0.08163924515247345
encoder.encoder.bias_hh_l0_reverse: 0.009604902006685734 0.08793274313211441
decider.lstm.weight_ih_l0: -0.0015340873505920172 0.14569155871868134
decider.lstm.weight_hh_l0: 0.0034968594554811716 0.1454690843820572
decider.lstm.bias_ih_l0: -0.022291429340839386 0.14169833064079285
decider.lstm.bias_hh_l0: 0.013529409654438496 0.15391024947166443
decider.linear1.weight: 0.0038207839243113995 0.11917126923799515
decider.linear1.bias: 0.004291928373277187 0.1142655685544014
decider.linear2.weight: 0.0018168515525758266 0.052770745009183884
decider.linear2.bias: 0.0005098868859931827 0.05340418219566345
decider.linear3.weight: -0.0019341374281793833 0.055223654955625534
decider.linear3.bias: -0.015376288443803787 0.029553808271884918

Rewards:
74.4454
74.4454
74.4454
objective = 3.153240919113159
==== episode 17500/75000 ====
action = 3
probs = 0.0009 0.9877 0.0025 0.0089

action = 1
probs = 0.0070 0.9252 0.0206 0.0471

action = 2
probs = 0.0028 0.0044 0.9807 0.0121

Learning rate: 7.0345e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007209787145256996 0.08289923518896103
encoder.encoder.weight_hh_l0: -0.0007168336887843907 0.08420545607805252
encoder.encoder.bias_ih_l0: 0.0023660354781895876 0.08738438785076141
encoder.encoder.bias_hh_l0: 0.015438036993145943 0.08492890745401382
encoder.encoder.weight_ih_l0_reverse: 0.001419495907612145 0.08385828137397766
encoder.encoder.weight_hh_l0_reverse: 0.0005005169077776372 0.08291328698396683
encoder.encoder.bias_ih_l0_reverse: 0.009353552013635635 0.08168113976716995
encoder.encoder.bias_hh_l0_reverse: 0.009648237377405167 0.08793096989393234
decider.lstm.weight_ih_l0: -0.0015366312582045794 0.14569920301437378
decider.lstm.weight_hh_l0: 0.0035034522879868746 0.14548367261886597
decider.lstm.bias_ih_l0: -0.022251799702644348 0.14171259105205536
decider.lstm.bias_hh_l0: 0.013569040223956108 0.1539253294467926
decider.linear1.weight: 0.0038255106192082167 0.11918904632329941
decider.linear1.bias: 0.004336309153586626 0.11422639340162277
decider.linear2.weight: 0.001821521669626236 0.05278882011771202
decider.linear2.bias: 0.0005029015010222793 0.053384315222501755
decider.linear3.weight: -0.0019208311568945646 0.05525489151477814
decider.linear3.bias: -0.015279905870556831 0.029584698379039764

Rewards:
63.3518
63.3518
63.3518
objective = 101.79985046386719
==== episode 17600/75000 ====
action = 1
probs = 0.0011 0.9847 0.0027 0.0115

action = 1
probs = 0.0095 0.8901 0.0295 0.0709

action = 2
probs = 0.0022 0.0031 0.9839 0.0107

Learning rate: 7.0345e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007025168160907924 0.08288295567035675
encoder.encoder.weight_hh_l0: -0.0007093791500665247 0.08419804275035858
encoder.encoder.bias_ih_l0: 0.0023036939091980457 0.0873633399605751
encoder.encoder.bias_hh_l0: 0.01537569984793663 0.08490912616252899
encoder.encoder.weight_ih_l0_reverse: 0.0014127125032246113 0.08385080099105835
encoder.encoder.weight_hh_l0_reverse: 0.0004991716123186052 0.0829077884554863
encoder.encoder.bias_ih_l0_reverse: 0.0092496108263731 0.08170000463724136
encoder.encoder.bias_hh_l0_reverse: 0.009544296190142632 0.0878516435623169
decider.lstm.weight_ih_l0: -0.0015329933958128095 0.14568452537059784
decider.lstm.weight_hh_l0: 0.003478601574897766 0.14548218250274658
decider.lstm.bias_ih_l0: -0.022338202223181725 0.14167481660842896
decider.lstm.bias_hh_l0: 0.013482637703418732 0.1539614200592041
decider.linear1.weight: 0.0038243557792156935 0.11918964236974716
decider.linear1.bias: 0.004296782426536083 0.11415775865316391
decider.linear2.weight: 0.0018280420918017626 0.05280200392007828
decider.linear2.bias: 0.0004984542028978467 0.05335840582847595
decider.linear3.weight: -0.0019324077293276787 0.05529189854860306
decider.linear3.bias: -0.015242058783769608 0.028890660032629967

Rewards:
74.4454
74.4454
74.4454
objective = 3.6755924224853516
==== episode 17700/75000 ====
action = 1
probs = 0.0007 0.9896 0.0018 0.0079

action = 1
probs = 0.0067 0.9217 0.0200 0.0516

action = 2
probs = 0.0020 0.0034 0.9844 0.0101

Learning rate: 7.0345e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007681910647079349 0.08298511803150177
encoder.encoder.weight_hh_l0: -0.0007417263113893569 0.08430947363376617
encoder.encoder.bias_ih_l0: 0.0028208468575030565 0.08755703270435333
encoder.encoder.bias_hh_l0: 0.01589285396039486 0.0850590243935585
encoder.encoder.weight_ih_l0_reverse: 0.0014750760747119784 0.08392171561717987
encoder.encoder.weight_hh_l0_reverse: 0.0005056470981799066 0.0829688310623169
encoder.encoder.bias_ih_l0_reverse: 0.009733985178172588 0.0817626565694809
encoder.encoder.bias_hh_l0_reverse: 0.010028674267232418 0.08808692544698715
decider.lstm.weight_ih_l0: -0.0015395060181617737 0.14576633274555206
decider.lstm.weight_hh_l0: 0.0036472950596362352 0.1455552875995636
decider.lstm.bias_ih_l0: -0.02169523760676384 0.14167818427085876
decider.lstm.bias_hh_l0: 0.01412560511380434 0.15402495861053467
decider.linear1.weight: 0.0038674480747431517 0.11926884949207306
decider.linear1.bias: 0.004649279173463583 0.11424154788255692
decider.linear2.weight: 0.0019146804697811604 0.05285193771123886
decider.linear2.bias: 0.0006405048770830035 0.05344885215163231
decider.linear3.weight: -0.0019906042143702507 0.05541640892624855
decider.linear3.bias: -0.015373136848211288 0.0295086856931448

Rewards:
74.4454
74.4454
74.4454
objective = 2.672499418258667
==== episode 17800/75000 ====
action = 1
probs = 0.0006 0.9899 0.0015 0.0080

action = 1
probs = 0.0053 0.9331 0.0158 0.0458

action = 2
probs = 0.0016 0.0032 0.9871 0.0082

Learning rate: 7.0345e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007848077802918851 0.08304266631603241
encoder.encoder.weight_hh_l0: -0.0007513619493693113 0.08439522981643677
encoder.encoder.bias_ih_l0: 0.0031396185513585806 0.08766405284404755
encoder.encoder.bias_hh_l0: 0.01621161960065365 0.08514146506786346
encoder.encoder.weight_ih_l0_reverse: 0.001491755829192698 0.08394937962293625
encoder.encoder.weight_hh_l0_reverse: 0.0005067019374109805 0.0829988420009613
encoder.encoder.bias_ih_l0_reverse: 0.009938728995621204 0.08179030567407608
encoder.encoder.bias_hh_l0_reverse: 0.01023341715335846 0.08816754817962646
decider.lstm.weight_ih_l0: -0.001540481112897396 0.1458100527524948
decider.lstm.weight_hh_l0: 0.0037631606683135033 0.14560344815254211
decider.lstm.bias_ih_l0: -0.021328061819076538 0.1416267305612564
decider.lstm.bias_hh_l0: 0.014492776244878769 0.15407836437225342
decider.linear1.weight: 0.003898660419508815 0.11931026726961136
decider.linear1.bias: 0.004800969734787941 0.11424864083528519
decider.linear2.weight: 0.0019814432598650455 0.05289044976234436
decider.linear2.bias: 0.000749544647987932 0.05350716412067413
decider.linear3.weight: -0.002046465640887618 0.05552113428711891
decider.linear3.bias: -0.015473499894142151 0.02962028793990612

Rewards:
74.4454
74.4454
74.4454
objective = 2.294335126876831
==== episode 17900/75000 ====
action = 1
probs = 0.0012 0.9835 0.0026 0.0126

action = 1
probs = 0.0094 0.8963 0.0242 0.0700

action = 2
probs = 0.0025 0.0043 0.9794 0.0138

Learning rate: 7.0345e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.000673206930514425 0.08286834508180618
encoder.encoder.weight_hh_l0: -0.0006840556743554771 0.08416223526000977
encoder.encoder.bias_ih_l0: 0.0020548508036881685 0.08725219964981079
encoder.encoder.bias_hh_l0: 0.015126855112612247 0.08486920595169067
encoder.encoder.weight_ih_l0_reverse: 0.0013784952461719513 0.08381277322769165
encoder.encoder.weight_hh_l0_reverse: 0.0005089465412311256 0.08288231492042542
encoder.encoder.bias_ih_l0_reverse: 0.009050079621374607 0.08164311200380325
encoder.encoder.bias_hh_l0_reverse: 0.009344767779111862 0.08781557530164719
decider.lstm.weight_ih_l0: -0.0015169947873800993 0.14566202461719513
decider.lstm.weight_hh_l0: 0.0034094369038939476 0.14547067880630493
decider.lstm.bias_ih_l0: -0.022550273686647415 0.1416393369436264
decider.lstm.bias_hh_l0: 0.013270560652017593 0.15388594567775726
decider.linear1.weight: 0.003813402494415641 0.1191636398434639
decider.linear1.bias: 0.004216560162603855 0.1142229437828064
decider.linear2.weight: 0.0018037079134956002 0.05281046777963638
decider.linear2.bias: 0.0004373764677438885 0.05333714559674263
decider.linear3.weight: -0.001961785601451993 0.055279940366744995
decider.linear3.bias: -0.015276215970516205 0.028729453682899475

Rewards:
74.4454
74.4454
74.4454
objective = 3.644259452819824
==== episode 18000/75000 ====
action = 1
probs = 0.0015 0.9808 0.0031 0.0147

action = 1
probs = 0.0110 0.8898 0.0252 0.0740

action = 2
probs = 0.0049 0.0090 0.9637 0.0224

Learning rate: 6.9641e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005972863873466849 0.08275080472230911
encoder.encoder.weight_hh_l0: -0.0006390709313564003 0.08400117605924606
encoder.encoder.bias_ih_l0: 0.0012975033605471253 0.0869574323296547
encoder.encoder.bias_hh_l0: 0.014369511045515537 0.08470549434423447
encoder.encoder.weight_ih_l0_reverse: 0.0012966805370524526 0.08370383083820343
encoder.encoder.weight_hh_l0_reverse: 0.0004981919191777706 0.08280084282159805
encoder.encoder.bias_ih_l0_reverse: 0.008546890690922737 0.08150628209114075
encoder.encoder.bias_hh_l0_reverse: 0.008841579779982567 0.08766061812639236
decider.lstm.weight_ih_l0: -0.0015137704322114587 0.14557580649852753
decider.lstm.weight_hh_l0: 0.0032012849114835262 0.1453772485256195
decider.lstm.bias_ih_l0: -0.023327380418777466 0.1416088342666626
decider.lstm.bias_hh_l0: 0.012493463233113289 0.15366703271865845
decider.linear1.weight: 0.0037490809336304665 0.11905890703201294
decider.linear1.bias: 0.0038087251596152782 0.11433318257331848
decider.linear2.weight: 0.0016911709681153297 0.05272337794303894
decider.linear2.bias: 0.0002375880430918187 0.053263984620571136
decider.linear3.weight: -0.0018765827408060431 0.055046334862709045
decider.linear3.bias: -0.015201996080577374 0.02861311472952366

Rewards:
74.4454
74.4454
74.4454
objective = 4.2967000007629395
==== episode 18100/75000 ====
action = 1
probs = 0.0015 0.9820 0.0027 0.0138

action = 1
probs = 0.0111 0.9001 0.0211 0.0677

action = 2
probs = 0.0091 0.0155 0.9433 0.0321

Learning rate: 6.9641e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005742619978263974 0.08269400149583817
encoder.encoder.weight_hh_l0: -0.0006216501351445913 0.08390723913908005
encoder.encoder.bias_ih_l0: 0.000885410001501441 0.08680818974971771
encoder.encoder.bias_hh_l0: 0.01395741943269968 0.08464574068784714
encoder.encoder.weight_ih_l0_reverse: 0.0012641476932913065 0.08365186303853989
encoder.encoder.weight_hh_l0_reverse: 0.0004956072079949081 0.08276594430208206
encoder.encoder.bias_ih_l0_reverse: 0.008394483476877213 0.08142826706171036
encoder.encoder.bias_hh_l0_reverse: 0.008689170703291893 0.0876435860991478
decider.lstm.weight_ih_l0: -0.0015165576478466392 0.1455436497926712
decider.lstm.weight_hh_l0: 0.003108517499640584 0.1453326791524887
decider.lstm.bias_ih_l0: -0.02366311103105545 0.1415794938802719
decider.lstm.bias_hh_l0: 0.012157722376286983 0.15351620316505432
decider.linear1.weight: 0.0037158369086682796 0.11901675164699554
decider.linear1.bias: 0.0036548450589179993 0.11446092277765274
decider.linear2.weight: 0.0016278893454000354 0.05268189311027527
decider.linear2.bias: 0.0001438950130250305 0.05323528125882149
decider.linear3.weight: -0.0018188258400186896 0.05493602156639099
decider.linear3.bias: -0.015142949298024178 0.028766928240656853

Rewards:
74.4454
74.4454
74.4454
objective = 4.510437965393066
==== episode 18200/75000 ====
action = 1
probs = 0.0017 0.9806 0.0032 0.0146

action = 1
probs = 0.0128 0.8896 0.0243 0.0733

action = 2
probs = 0.0136 0.0178 0.9311 0.0376

Learning rate: 6.9641e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00051812210585922 0.0826207622885704
encoder.encoder.weight_hh_l0: -0.0005912578199058771 0.08382837474346161
encoder.encoder.bias_ih_l0: 0.000462857773527503 0.08662236481904984
encoder.encoder.bias_hh_l0: 0.013534865342080593 0.0845404863357544
encoder.encoder.weight_ih_l0_reverse: 0.0012009214842692018 0.08358082175254822
encoder.encoder.weight_hh_l0_reverse: 0.0004803282208740711 0.08271703869104385
encoder.encoder.bias_ih_l0_reverse: 0.008065246976912022 0.08133886754512787
encoder.encoder.bias_hh_l0_reverse: 0.008359931409358978 0.08749589323997498
decider.lstm.weight_ih_l0: -0.0015151455299928784 0.14548684656620026
decider.lstm.weight_hh_l0: 0.0029829470440745354 0.14527544379234314
decider.lstm.bias_ih_l0: -0.02418169379234314 0.1415911316871643
decider.lstm.bias_hh_l0: 0.011639146134257317 0.15339134633541107
decider.linear1.weight: 0.003677967470139265 0.11896387487649918
decider.linear1.bias: 0.003396631684154272 0.11448407918214798
decider.linear2.weight: 0.001541788107715547 0.052644725888967514
decider.linear2.bias: 1.2595031876116991e-05 0.05316642299294472
decider.linear3.weight: -0.0017562366556376219 0.05482678860425949
decider.linear3.bias: -0.015023293904960155 0.02864566445350647

Rewards:
74.4454
74.4454
74.4454
objective = 5.16171407699585
==== episode 18300/75000 ====
action = 1
probs = 0.0025 0.9707 0.0049 0.0219

action = 1
probs = 0.0164 0.8439 0.0344 0.1054

action = 2
probs = 0.0144 0.0175 0.9175 0.0506

Learning rate: 6.9641e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0004415803705342114 0.08250287175178528
encoder.encoder.weight_hh_l0: -0.0005482804263010621 0.08372046053409576
encoder.encoder.bias_ih_l0: -0.0002030596078839153 0.08636603504419327
encoder.encoder.bias_hh_l0: 0.012868947349488735 0.08438388258218765
encoder.encoder.weight_ih_l0_reverse: 0.001126842456869781 0.08348773419857025
encoder.encoder.weight_hh_l0_reverse: 0.000462077499832958 0.08265578746795654
encoder.encoder.bias_ih_l0_reverse: 0.007608060725033283 0.08125299960374832
encoder.encoder.bias_hh_l0_reverse: 0.00790274515748024 0.08722115308046341
decider.lstm.weight_ih_l0: -0.0015171123668551445 0.1454114317893982
decider.lstm.weight_hh_l0: 0.00282309390604496 0.14520834386348724
decider.lstm.bias_ih_l0: -0.0249386765062809 0.1415521651506424
decider.lstm.bias_hh_l0: 0.010882165282964706 0.1532324105501175
decider.linear1.weight: 0.0036500822752714157 0.11888378113508224
decider.linear1.bias: 0.0030128881335258484 0.11446249485015869
decider.linear2.weight: 0.0014499370008707047 0.05260093882679939
decider.linear2.bias: -0.0001639437978155911 0.05309612303972244
decider.linear3.weight: -0.0017365763196721673 0.05470743775367737
decider.linear3.bias: -0.015009624883532524 0.027474919334053993

Rewards:
74.4454
74.4454
74.4454
objective = 7.085258483886719
==== episode 18400/75000 ====
action = 1
probs = 0.0020 0.9769 0.0038 0.0173

action = 1
probs = 0.0141 0.8696 0.0274 0.0889

action = 2
probs = 0.0202 0.0289 0.8835 0.0674

Learning rate: 6.9641e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0004585891147144139 0.08249706774950027
encoder.encoder.weight_hh_l0: -0.0005502820131368935 0.08368246257305145
encoder.encoder.bias_ih_l0: -0.00034081697231158614 0.08630251884460449
encoder.encoder.bias_hh_l0: 0.012731190770864487 0.08441635966300964
encoder.encoder.weight_ih_l0_reverse: 0.0011565855238586664 0.08349545300006866
encoder.encoder.weight_hh_l0_reverse: 0.00047582347178831697 0.08266577124595642
encoder.encoder.bias_ih_l0_reverse: 0.007687191013246775 0.081150121986866
encoder.encoder.bias_hh_l0_reverse: 0.007981876842677593 0.0873851329088211
decider.lstm.weight_ih_l0: -0.001522289589047432 0.1454131007194519
decider.lstm.weight_hh_l0: 0.0028038742020726204 0.1451857089996338
decider.lstm.bias_ih_l0: -0.02497199922800064 0.1415328085422516
decider.lstm.bias_hh_l0: 0.01084884162992239 0.15309570729732513
decider.linear1.weight: 0.003638161811977625 0.11888372153043747
decider.linear1.bias: 0.0030455291271209717 0.11463627964258194
decider.linear2.weight: 0.0014397954801097512 0.05258603394031525
decider.linear2.bias: -0.00018586544319987297 0.05313783511519432
decider.linear3.weight: -0.0017246169736608863 0.05466374382376671
decider.linear3.bias: -0.015056510455906391 0.027956491336226463

Rewards:
74.4454
74.4454
74.4454
objective = 7.121861934661865
==== episode 18500/75000 ====
action = 1
probs = 0.0017 0.9812 0.0034 0.0137

action = 1
probs = 0.0123 0.8935 0.0245 0.0697

action = 2
probs = 0.0147 0.0206 0.9164 0.0484

Learning rate: 6.8945e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005286718951538205 0.0826120674610138
encoder.encoder.weight_hh_l0: -0.0005849599256180227 0.08378565311431885
encoder.encoder.bias_ih_l0: 0.0002029675233643502 0.08652283251285553
encoder.encoder.bias_hh_l0: 0.01327497698366642 0.0845215916633606
encoder.encoder.weight_ih_l0_reverse: 0.0012224154779687524 0.08360854536294937
encoder.encoder.weight_hh_l0_reverse: 0.0004801388713531196 0.08272788673639297
encoder.encoder.bias_ih_l0_reverse: 0.007912559434771538 0.08124731481075287
encoder.encoder.bias_hh_l0_reverse: 0.008207247592508793 0.08754914253950119
decider.lstm.weight_ih_l0: -0.001521592610515654 0.14546222984790802
decider.lstm.weight_hh_l0: 0.0029156357049942017 0.14523500204086304
decider.lstm.bias_ih_l0: -0.02446598932147026 0.14160454273223877
decider.lstm.bias_hh_l0: 0.011354858987033367 0.1532737910747528
decider.linear1.weight: 0.0036679264158010483 0.1189386248588562
decider.linear1.bias: 0.0032872632145881653 0.11456838250160217
decider.linear2.weight: 0.0015038931742310524 0.05262858793139458
decider.linear2.bias: -5.010963650420308e-05 0.05317728966474533
decider.linear3.weight: -0.001761899096891284 0.0547829195857048
decider.linear3.bias: -0.015072337351739407 0.028702402487397194

Rewards:
74.4454
74.4454
74.4454
objective = 5.433571815490723
==== episode 18600/75000 ====
action = 1
probs = 0.0020 0.9792 0.0042 0.0146

action = 1
probs = 0.0136 0.8911 0.0268 0.0684

action = 2
probs = 0.0148 0.0208 0.9227 0.0416

Learning rate: 6.8945e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.000492180697619915 0.08260057121515274
encoder.encoder.weight_hh_l0: -0.0005648453370667994 0.08377338200807571
encoder.encoder.bias_ih_l0: 7.449298573192209e-05 0.0864613726735115
encoder.encoder.bias_hh_l0: 0.013146504759788513 0.08448205888271332
encoder.encoder.weight_ih_l0_reverse: 0.0011822793167084455 0.08358196914196014
encoder.encoder.weight_hh_l0_reverse: 0.0004703549202531576 0.08271095901727676
encoder.encoder.bias_ih_l0_reverse: 0.007703024428337812 0.08123240619897842
encoder.encoder.bias_hh_l0_reverse: 0.007997710257768631 0.08746761083602905
decider.lstm.weight_ih_l0: -0.001514927833341062 0.14544014632701874
decider.lstm.weight_hh_l0: 0.002859305590391159 0.14522355794906616
decider.lstm.bias_ih_l0: -0.024692777544260025 0.14161232113838196
decider.lstm.bias_hh_l0: 0.011128071695566177 0.15324461460113525
decider.linear1.weight: 0.003657336812466383 0.11890741437673569
decider.linear1.bias: 0.003149095457047224 0.11452098190784454
decider.linear2.weight: 0.0014677781146019697 0.05261698737740517
decider.linear2.bias: -0.00011137122055515647 0.05314304307103157
decider.linear3.weight: -0.0017306036315858364 0.05472679063677788
decider.linear3.bias: -0.015012686140835285 0.028971930965781212

Rewards:
74.4454
74.4454
74.4454
objective = 5.377303600311279
==== episode 18700/75000 ====
action = 1
probs = 0.0028 0.9673 0.0057 0.0241

action = 1
probs = 0.0186 0.8352 0.0387 0.1076

action = 2
probs = 0.0112 0.0125 0.9434 0.0329

Learning rate: 6.8945e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0004437273892108351 0.08256258815526962
encoder.encoder.weight_hh_l0: -0.000547810283023864 0.08375568687915802
encoder.encoder.bias_ih_l0: -0.00010202080011367798 0.08639827370643616
encoder.encoder.bias_hh_l0: 0.012969993986189365 0.08439266681671143
encoder.encoder.weight_ih_l0_reverse: 0.0011403411626815796 0.08355660736560822
encoder.encoder.weight_hh_l0_reverse: 0.0004546958953142166 0.08268295228481293
encoder.encoder.bias_ih_l0_reverse: 0.007412964012473822 0.08129264414310455
encoder.encoder.bias_hh_l0_reverse: 0.007707652170211077 0.08719950914382935
decider.lstm.weight_ih_l0: -0.0015103014884516597 0.1454043835401535
decider.lstm.weight_hh_l0: 0.0027952147647738457 0.14521650969982147
decider.lstm.bias_ih_l0: -0.02497737668454647 0.1416313797235489
decider.lstm.bias_hh_l0: 0.010843473486602306 0.15325254201889038
decider.linear1.weight: 0.0036510152276605368 0.11888350546360016
decider.linear1.bias: 0.0029723024927079678 0.11430619657039642
decider.linear2.weight: 0.0014672789257019758 0.05262038856744766
decider.linear2.bias: -0.0001399655593559146 0.05308694764971733
decider.linear3.weight: -0.0017478915397077799 0.054732952266931534
decider.linear3.bias: -0.01497261505573988 0.027658754959702492

Rewards:
74.4454
74.4454
74.4454
objective = 6.739126205444336
==== episode 18800/75000 ====
action = 1
probs = 0.0028 0.9707 0.0068 0.0197

action = 1
probs = 0.0201 0.8339 0.0497 0.0963

action = 2
probs = 0.0105 0.0099 0.9515 0.0281

Learning rate: 6.8945e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0004567316791508347 0.08258911222219467
encoder.encoder.weight_hh_l0: -0.0005527660250663757 0.0837649405002594
encoder.encoder.bias_ih_l0: -5.3190586186246946e-05 0.08637768030166626
encoder.encoder.bias_hh_l0: 0.013018820434808731 0.08438324183225632
encoder.encoder.weight_ih_l0_reverse: 0.0011495681246742606 0.08359302580356598
encoder.encoder.weight_hh_l0_reverse: 0.00045059536932967603 0.08268685638904572
encoder.encoder.bias_ih_l0_reverse: 0.0074005648493766785 0.0813072919845581
encoder.encoder.bias_hh_l0_reverse: 0.007695251144468784 0.08718481659889221
decider.lstm.weight_ih_l0: -0.0015099815791472793 0.14540258049964905
decider.lstm.weight_hh_l0: 0.0027759610675275326 0.14520730078220367
decider.lstm.bias_ih_l0: -0.025053933262825012 0.14176969230175018
decider.lstm.bias_hh_l0: 0.010766918770968914 0.15323443710803986
decider.linear1.weight: 0.0036438768729567528 0.11888184398412704
decider.linear1.bias: 0.002940984908491373 0.11426864564418793
decider.linear2.weight: 0.0014421312371268868 0.052618902176618576
decider.linear2.bias: -0.00018431793432682753 0.05304492264986038
decider.linear3.weight: -0.0017307421658188105 0.05471799522638321
decider.linear3.bias: -0.014911782927811146 0.02839249186217785

Rewards:
74.4454
74.4454
74.4454
objective = 6.479964256286621
==== episode 18900/75000 ====
action = 1
probs = 0.0019 0.9779 0.0047 0.0155

action = 1
probs = 0.0148 0.8666 0.0374 0.0812

action = 2
probs = 0.0079 0.0088 0.9583 0.0249

Learning rate: 6.8945e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005330222775228322 0.08267013728618622
encoder.encoder.weight_hh_l0: -0.0005925591103732586 0.0838584452867508
encoder.encoder.bias_ih_l0: 0.0004735806433018297 0.08659897744655609
encoder.encoder.bias_hh_l0: 0.013545586727559566 0.08452588319778442
encoder.encoder.weight_ih_l0_reverse: 0.0012201365316286683 0.0836668536067009
encoder.encoder.weight_hh_l0_reverse: 0.0004615288635250181 0.08275213092565536
encoder.encoder.bias_ih_l0_reverse: 0.007816999219357967 0.08138648420572281
encoder.encoder.bias_hh_l0_reverse: 0.008111681789159775 0.08741476386785507
decider.lstm.weight_ih_l0: -0.001512426882982254 0.1454644501209259
decider.lstm.weight_hh_l0: 0.002925994573161006 0.14527137577533722
decider.lstm.bias_ih_l0: -0.024384602904319763 0.1417870819568634
decider.lstm.bias_hh_l0: 0.011436227709054947 0.15337559580802917
decider.linear1.weight: 0.003688457887619734 0.11896438151597977
decider.linear1.bias: 0.0033512096852064133 0.11430113017559052
decider.linear2.weight: 0.0015533756231889129 0.05267292633652687
decider.linear2.bias: 3.097840817645192e-05 0.05315906181931496
decider.linear3.weight: -0.0018090411322191358 0.054877087473869324
decider.linear3.bias: -0.015069055370986462 0.028701039031147957

Rewards:
74.4454
74.4454
74.4454
objective = 5.167000770568848
==== episode 19000/75000 ====
action = 1
probs = 0.0015 0.9808 0.0039 0.0138

action = 1
probs = 0.0127 0.8783 0.0322 0.0768

action = 2
probs = 0.0110 0.0124 0.9424 0.0341

Learning rate: 6.8255e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005251726252026856 0.08264485001564026
encoder.encoder.weight_hh_l0: -0.0005836538621224463 0.08381180465221405
encoder.encoder.bias_ih_l0: 0.0002892938209697604 0.08652639389038086
encoder.encoder.bias_hh_l0: 0.013361298479139805 0.08452121913433075
encoder.encoder.weight_ih_l0_reverse: 0.001214086078107357 0.08364588767290115
encoder.encoder.weight_hh_l0_reverse: 0.0004641567065846175 0.08274144679307938
encoder.encoder.bias_ih_l0_reverse: 0.007800261955708265 0.08133724331855774
encoder.encoder.bias_hh_l0_reverse: 0.008094947785139084 0.0874747559428215
decider.lstm.weight_ih_l0: -0.0015119034796953201 0.1454557478427887
decider.lstm.weight_hh_l0: 0.002893318422138691 0.1452447474002838
decider.lstm.bias_ih_l0: -0.024498924612998962 0.1417931467294693
decider.lstm.bias_hh_l0: 0.011321909725666046 0.1533144861459732
decider.linear1.weight: 0.003668298479169607 0.11895983666181564
decider.linear1.bias: 0.003342865966260433 0.11443327367305756
decider.linear2.weight: 0.001536211813800037 0.05265974625945091
decider.linear2.bias: 1.1221447493880987e-05 0.05318326875567436
decider.linear3.weight: -0.0018150117248296738 0.05485331639647484
decider.linear3.bias: -0.015130081214010715 0.028666164726018906

Rewards:
74.4454
74.4454
74.4454
objective = 5.172094821929932
==== episode 19100/75000 ====
action = 1
probs = 0.0019 0.9789 0.0046 0.0146

action = 2
probs = 0.0158 0.8625 0.0384 0.0832

action = 2
probs = 0.0124 0.0137 0.9338 0.0400

Learning rate: 6.8255e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.000499606248922646 0.08263253420591354
encoder.encoder.weight_hh_l0: -0.0005714100552722812 0.0837918296456337
encoder.encoder.bias_ih_l0: 0.00015560179599560797 0.08647480607032776
encoder.encoder.bias_hh_l0: 0.013227608054876328 0.08447147160768509
encoder.encoder.weight_ih_l0_reverse: 0.0011906852014362812 0.08363153785467148
encoder.encoder.weight_hh_l0_reverse: 0.00045658572344109416 0.08272519707679749
encoder.encoder.bias_ih_l0_reverse: 0.007635949645191431 0.0813622698187828
encoder.encoder.bias_hh_l0_reverse: 0.0079306336119771 0.08737336099147797
decider.lstm.weight_ih_l0: -0.0015086630592122674 0.1454373449087143
decider.lstm.weight_hh_l0: 0.002833508187904954 0.1452343463897705
decider.lstm.bias_ih_l0: -0.024732202291488647 0.1418379694223404
decider.lstm.bias_hh_l0: 0.01108863577246666 0.15328502655029297
decider.linear1.weight: 0.003652942832559347 0.11893510073423386
decider.linear1.bias: 0.003200720064342022 0.11436726152896881
decider.linear2.weight: 0.0015028112102299929 0.05265066772699356
decider.linear2.bias: -6.057752761989832e-05 0.053128913044929504
decider.linear3.weight: -0.0017863510875031352 0.05481613054871559
decider.linear3.bias: -0.015030807815492153 0.028536608442664146

Rewards:
70.1874
70.1874
70.1874
objective = 78.35474395751953
==== episode 19200/75000 ====
action = 1
probs = 0.0016 0.9823 0.0040 0.0120

action = 1
probs = 0.0133 0.8896 0.0320 0.0651

action = 2
probs = 0.0142 0.0167 0.9292 0.0399

Learning rate: 6.8255e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005005293060094118 0.08262689411640167
encoder.encoder.weight_hh_l0: -0.0005652488325722516 0.08375811576843262
encoder.encoder.bias_ih_l0: 2.2508502297569066e-05 0.08643102645874023
encoder.encoder.bias_hh_l0: 0.013094511814415455 0.08448012173175812
encoder.encoder.weight_ih_l0_reverse: 0.0011768388794735074 0.08362340182065964
encoder.encoder.weight_hh_l0_reverse: 0.0004582432156894356 0.08272404968738556
encoder.encoder.bias_ih_l0_reverse: 0.007634979207068682 0.08131548017263412
encoder.encoder.bias_hh_l0_reverse: 0.0079296650364995 0.087474025785923
decider.lstm.weight_ih_l0: -0.0015089773805812001 0.14543738961219788
decider.lstm.weight_hh_l0: 0.0028133161831647158 0.14521752297878265
decider.lstm.bias_ih_l0: -0.024812910705804825 0.1418267786502838
decider.lstm.bias_hh_l0: 0.011007927358150482 0.15325376391410828
decider.linear1.weight: 0.0036337159108370543 0.11891992390155792
decider.linear1.bias: 0.003155067563056946 0.11450828611850739
decider.linear2.weight: 0.0014758131001144648 0.0526285395026207
decider.linear2.bias: -0.00010009604739025235 0.05314650386571884
decider.linear3.weight: -0.0017640006262809038 0.05475680157542229
decider.linear3.bias: -0.015049615874886513 0.029291251674294472

Rewards:
74.4454
74.4454
74.4454
objective = 5.169140815734863
==== episode 19300/75000 ====
action = 1
probs = 0.0016 0.9821 0.0035 0.0127

action = 1
probs = 0.0141 0.8837 0.0301 0.0721

action = 2
probs = 0.0145 0.0148 0.9312 0.0396

Learning rate: 6.8255e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005054781213402748 0.08262980729341507
encoder.encoder.weight_hh_l0: -0.0005705665680579841 0.08376359194517136
encoder.encoder.bias_ih_l0: 6.333828059723601e-05 0.08645609021186829
encoder.encoder.bias_hh_l0: 0.013135340064764023 0.08447804301977158
encoder.encoder.weight_ih_l0_reverse: 0.0011852516327053308 0.0836268737912178
encoder.encoder.weight_hh_l0_reverse: 0.0004587724688462913 0.08272747695446014
encoder.encoder.bias_ih_l0_reverse: 0.007642572745680809 0.08134578168392181
encoder.encoder.bias_hh_l0_reverse: 0.00793725810945034 0.08745040744543076
decider.lstm.weight_ih_l0: -0.0015088625950738788 0.14543958008289337
decider.lstm.weight_hh_l0: 0.0028232126496732235 0.1452264040708542
decider.lstm.bias_ih_l0: -0.024757273495197296 0.14181281626224518
decider.lstm.bias_hh_l0: 0.011063570156693459 0.15327775478363037
decider.linear1.weight: 0.0036369413137435913 0.11893799901008606
decider.linear1.bias: 0.003213775809854269 0.1144544929265976
decider.linear2.weight: 0.0014970905613154173 0.05264502763748169
decider.linear2.bias: -6.44508982077241e-05 0.05314760282635689
decider.linear3.weight: -0.0017785216914489865 0.054805733263492584
decider.linear3.bias: -0.01500999927520752 0.028871245682239532

Rewards:
74.4454
74.4454
74.4454
objective = 5.2850470542907715
==== episode 19400/75000 ====
action = 1
probs = 0.0015 0.9836 0.0036 0.0113

action = 1
probs = 0.0141 0.8827 0.0340 0.0692

action = 2
probs = 0.0113 0.0095 0.9511 0.0281

Learning rate: 6.8255e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005371276056393981 0.08266788721084595
encoder.encoder.weight_hh_l0: -0.0005901518743485212 0.0838087871670723
encoder.encoder.bias_ih_l0: 0.00031004188349470496 0.08654944598674774
encoder.encoder.bias_hh_l0: 0.013382043689489365 0.08451144397258759
encoder.encoder.weight_ih_l0_reverse: 0.0012092640390619636 0.08367397636175156
encoder.encoder.weight_hh_l0_reverse: 0.0004577290383167565 0.0827515497803688
encoder.encoder.bias_ih_l0_reverse: 0.007765871938318014 0.08140802383422852
encoder.encoder.bias_hh_l0_reverse: 0.008060557767748833 0.0874604880809784
decider.lstm.weight_ih_l0: -0.0015090296510607004 0.14545774459838867
decider.lstm.weight_hh_l0: 0.0028834030963480473 0.14524781703948975
decider.lstm.bias_ih_l0: -0.0245130006223917 0.1419118493795395
decider.lstm.bias_hh_l0: 0.011307853274047375 0.15334822237491608
decider.linear1.weight: 0.0036562939640134573 0.11897633224725723
decider.linear1.bias: 0.0033781128004193306 0.11433858424425125
decider.linear2.weight: 0.0015421649441123009 0.05267072096467018
decider.linear2.bias: 3.313872730359435e-05 0.053142160177230835
decider.linear3.weight: -0.0017950338078662753 0.05488141253590584
decider.linear3.bias: -0.014989500865340233 0.029213786125183105

Rewards:
74.4454
74.4454
74.4454
objective = 4.751530170440674
==== episode 19500/75000 ====
action = 1
probs = 0.0008 0.9907 0.0021 0.0064

action = 3
probs = 0.0081 0.9280 0.0214 0.0426

action = 2
probs = 0.0097 0.0114 0.9509 0.0280

Learning rate: 6.7573e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0006601214408874512 0.08279865980148315
encoder.encoder.weight_hh_l0: -0.0006621441571041942 0.08396399766206741
encoder.encoder.bias_ih_l0: 0.0011806467082351446 0.0868806317448616
encoder.encoder.bias_hh_l0: 0.01425264123827219 0.08472046256065369
encoder.encoder.weight_ih_l0_reverse: 0.0013147451682016253 0.0837884321808815
encoder.encoder.weight_hh_l0_reverse: 0.000476907443953678 0.08284521102905273
encoder.encoder.bias_ih_l0_reverse: 0.00850797537714243 0.08150959014892578
encoder.encoder.bias_hh_l0_reverse: 0.008802661672234535 0.08779842406511307
decider.lstm.weight_ih_l0: -0.0015243676025420427 0.14556320011615753
decider.lstm.weight_hh_l0: 0.0031826095655560493 0.14534294605255127
decider.lstm.bias_ih_l0: -0.02343876101076603 0.14191868901252747
decider.lstm.bias_hh_l0: 0.01238209381699562 0.15348702669143677
decider.linear1.weight: 0.0037394757382571697 0.11910512298345566
decider.linear1.bias: 0.003960235510021448 0.11442827433347702
decider.linear2.weight: 0.0016804373590275645 0.052744459360837936
decider.linear2.bias: 0.00030939289717935026 0.0532865971326828
decider.linear3.weight: -0.0018874519737437367 0.05510149896144867
decider.linear3.bias: -0.015162678435444832 0.03021261841058731

Rewards:
69.5795
69.5795
69.5795
objective = 74.56184387207031
==== episode 19600/75000 ====
action = 2
probs = 0.0008 0.9900 0.0020 0.0072

action = 1
probs = 0.0076 0.9301 0.0181 0.0443

action = 2
probs = 0.0134 0.0197 0.9234 0.0435

Learning rate: 6.7573e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0006267004064284265 0.08276568353176117
encoder.encoder.weight_hh_l0: -0.0006389567861333489 0.08391093462705612
encoder.encoder.bias_ih_l0: 0.00090716005070135 0.08678315579891205
encoder.encoder.bias_hh_l0: 0.013979155570268631 0.08468231558799744
encoder.encoder.weight_ih_l0_reverse: 0.0012875047978013754 0.08375120908021927
encoder.encoder.weight_hh_l0_reverse: 0.00047726373304612935 0.08282195776700974
encoder.encoder.bias_ih_l0_reverse: 0.008321961387991905 0.08145619183778763
encoder.encoder.bias_hh_l0_reverse: 0.008616646751761436 0.08776719123125076
decider.lstm.weight_ih_l0: -0.0015168559039011598 0.1455381065607071
decider.lstm.weight_hh_l0: 0.003094569779932499 0.1453140676021576
decider.lstm.bias_ih_l0: -0.023703645914793015 0.14189250767230988
decider.lstm.bias_hh_l0: 0.012117205187678337 0.15343745052814484
decider.linear1.weight: 0.003712957724928856 0.11907444894313812
decider.linear1.bias: 0.0038479501381516457 0.1144903227686882
decider.linear2.weight: 0.0016583959804847836 0.05272471532225609
decider.linear2.bias: 0.0002581461740192026 0.05328786373138428
decider.linear3.weight: -0.0018861464923247695 0.05504792556166649
decider.linear3.bias: -0.015196606516838074 0.02979174070060253

Rewards:
59.3096
59.3096
59.3096
objective = 125.8982162475586
==== episode 19700/75000 ====
action = 1
probs = 0.0007 0.9920 0.0016 0.0056

action = 1
probs = 0.0067 0.9396 0.0163 0.0374

action = 2
probs = 0.0080 0.0096 0.9588 0.0236

Learning rate: 6.7573e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0006795815424993634 0.08283887058496475
encoder.encoder.weight_hh_l0: -0.0006774849025532603 0.08401115983724594
encoder.encoder.bias_ih_l0: 0.0014090240001678467 0.08697366714477539
encoder.encoder.bias_hh_l0: 0.014481019228696823 0.08477441221475601
encoder.encoder.weight_ih_l0_reverse: 0.0013348042266443372 0.08380548655986786
encoder.encoder.weight_hh_l0_reverse: 0.0004834798164665699 0.08286584913730621
encoder.encoder.bias_ih_l0_reverse: 0.008681133389472961 0.08152119070291519
encoder.encoder.bias_hh_l0_reverse: 0.008975820615887642 0.08789190649986267
decider.lstm.weight_ih_l0: -0.0015294334152713418 0.14559386670589447
decider.lstm.weight_hh_l0: 0.003263898193836212 0.14537081122398376
decider.lstm.bias_ih_l0: -0.023149345070123672 0.1418696641921997
decider.lstm.bias_hh_l0: 0.012671513482928276 0.15352857112884521
decider.linear1.weight: 0.0037588567938655615 0.1191406399011612
decider.linear1.bias: 0.004118256736546755 0.11446131020784378
decider.linear2.weight: 0.0017241706373170018 0.0527678020298481
decider.linear2.bias: 0.0003938826557714492 0.053342752158641815
decider.linear3.weight: -0.001913731568492949 0.055161572992801666
decider.linear3.bias: -0.015207841992378235 0.030373631045222282

Rewards:
74.4454
74.4454
74.4454
objective = 2.7905850410461426
==== episode 19800/75000 ====
action = 1
probs = 0.0006 0.9926 0.0015 0.0053

action = 1
probs = 0.0062 0.9400 0.0165 0.0373

action = 2
probs = 0.0070 0.0083 0.9641 0.0206

Learning rate: 6.7573e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007082042866386473 0.08285936713218689
encoder.encoder.weight_hh_l0: -0.000696901697665453 0.08404188603162766
encoder.encoder.bias_ih_l0: 0.001588457147590816 0.08704782277345657
encoder.encoder.bias_hh_l0: 0.014660453423857689 0.0848127007484436
encoder.encoder.weight_ih_l0_reverse: 0.00136065564583987 0.0838342159986496
encoder.encoder.weight_hh_l0_reverse: 0.0004867735842708498 0.08288490027189255
encoder.encoder.bias_ih_l0_reverse: 0.008851195685565472 0.0815616250038147
encoder.encoder.bias_hh_l0_reverse: 0.009145882911980152 0.08793305605649948
decider.lstm.weight_ih_l0: -0.0015346325235441327 0.14561425149440765
decider.lstm.weight_hh_l0: 0.0033241126220673323 0.14539000391960144
decider.lstm.bias_ih_l0: -0.022937551140785217 0.14188243448734283
decider.lstm.bias_hh_l0: 0.012883307412266731 0.15358129143714905
decider.linear1.weight: 0.0037768185138702393 0.1191747859120369
decider.linear1.bias: 0.0042510624043643475 0.11443371325731277
decider.linear2.weight: 0.001758618513122201 0.0527898408472538
decider.linear2.bias: 0.0004553537874016911 0.05336233973503113
decider.linear3.weight: -0.0019407409708946943 0.05521620064973831
decider.linear3.bias: -0.015251202508807182 0.03043370507657528

Rewards:
74.4454
74.4454
74.4454
objective = 2.6273086071014404
==== episode 19900/75000 ====
action = 1
probs = 0.0005 0.9941 0.0013 0.0042

action = 1
probs = 0.0054 0.9492 0.0144 0.0310

action = 2
probs = 0.0053 0.0068 0.9722 0.0157

Learning rate: 6.7573e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007594486232846975 0.082927405834198
encoder.encoder.weight_hh_l0: -0.0007345690974034369 0.08414386212825775
encoder.encoder.bias_ih_l0: 0.0020623866003006697 0.0872209221124649
encoder.encoder.bias_hh_l0: 0.015134385786950588 0.08490651100873947
encoder.encoder.weight_ih_l0_reverse: 0.0014064040733501315 0.08388600498437881
encoder.encoder.weight_hh_l0_reverse: 0.000488554360345006 0.0829283818602562
encoder.encoder.bias_ih_l0_reverse: 0.00921723060309887 0.08162861317396164
encoder.encoder.bias_hh_l0_reverse: 0.0095119159668684 0.08803901821374893
decider.lstm.weight_ih_l0: -0.0015510352095589042 0.14566932618618011
decider.lstm.weight_hh_l0: 0.0034921595361083746 0.1454545259475708
decider.lstm.bias_ih_l0: -0.022412125021219254 0.1418704390525818
decider.lstm.bias_hh_l0: 0.013408735394477844 0.15364325046539307
decider.linear1.weight: 0.0038260016590356827 0.11924175173044205
decider.linear1.bias: 0.004511583596467972 0.11440861225128174
decider.linear2.weight: 0.0018250012071803212 0.05283292755484581
decider.linear2.bias: 0.0005744578083977103 0.05340775102376938
decider.linear3.weight: -0.001969617325812578 0.05532166734337807
decider.linear3.bias: -0.015275774523615837 0.030891990289092064

Rewards:
74.4454
74.4454
74.4454
objective = 2.139169692993164
==== episode 20000/75000 ====
action = 1
probs = 0.0005 0.9950 0.0011 0.0034

action = 1
probs = 0.0053 0.9559 0.0127 0.0261

action = 2
probs = 0.0054 0.0079 0.9708 0.0158

Learning rate: 6.6897e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.000772010360378772 0.08295250684022903
encoder.encoder.weight_hh_l0: -0.0007427048403769732 0.08416350930929184
encoder.encoder.bias_ih_l0: 0.0021416014060378075 0.08725268393754959
encoder.encoder.bias_hh_l0: 0.015213598497211933 0.08492442220449448
encoder.encoder.weight_ih_l0_reverse: 0.0014155643293634057 0.08389781415462494
encoder.encoder.weight_hh_l0_reverse: 0.0004889042465947568 0.08293953537940979
encoder.encoder.bias_ih_l0_reverse: 0.009300319477915764 0.08164836466312408
encoder.encoder.bias_hh_l0_reverse: 0.009595008566975594 0.08809113502502441
decider.lstm.weight_ih_l0: -0.0015546256909146905 0.14568664133548737
decider.lstm.weight_hh_l0: 0.0035216547548770905 0.14548172056674957
decider.lstm.bias_ih_l0: -0.022312114015221596 0.14187288284301758
decider.lstm.bias_hh_l0: 0.01350875198841095 0.15363192558288574
decider.linear1.weight: 0.00383521500043571 0.11925383657217026
decider.linear1.bias: 0.004570000804960728 0.11444281041622162
decider.linear2.weight: 0.001834054128266871 0.052838653326034546
decider.linear2.bias: 0.0005790120922029018 0.053412698209285736
decider.linear3.weight: -0.001951463520526886 0.055321577936410904
decider.linear3.bias: -0.01523960754275322 0.03130647912621498

Rewards:
74.4454
74.4454
74.4454
objective = 1.9791371822357178
==== episode 20100/75000 ====
action = 1
probs = 0.0004 0.9956 0.0009 0.0030

action = 2
probs = 0.0046 0.9623 0.0103 0.0228

action = 2
probs = 0.0091 0.0187 0.9462 0.0261

Learning rate: 6.6897e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.000769356032833457 0.08293669670820236
encoder.encoder.weight_hh_l0: -0.000732357962988317 0.0841103121638298
encoder.encoder.bias_ih_l0: 0.0019301854772493243 0.08718287199735641
encoder.encoder.bias_hh_l0: 0.01500218641012907 0.08490032702684402
encoder.encoder.weight_ih_l0_reverse: 0.0014073034981265664 0.08388561010360718
encoder.encoder.weight_hh_l0_reverse: 0.0004889114061370492 0.082924984395504
encoder.encoder.bias_ih_l0_reverse: 0.009238934144377708 0.0816042348742485
encoder.encoder.bias_hh_l0_reverse: 0.00953361950814724 0.08813703805208206
decider.lstm.weight_ih_l0: -0.0015507843345403671 0.14568038284778595
decider.lstm.weight_hh_l0: 0.0034728539176285267 0.14545877277851105
decider.lstm.bias_ih_l0: -0.022433914244174957 0.14186237752437592
decider.lstm.bias_hh_l0: 0.013386951759457588 0.1535731703042984
decider.linear1.weight: 0.0038179676048457623 0.11923841387033463
decider.linear1.bias: 0.004530101083219051 0.11456715315580368
decider.linear2.weight: 0.0018191298004239798 0.0528167299926281
decider.linear2.bias: 0.0005364100215956569 0.05342400074005127
decider.linear3.weight: -0.0019329553470015526 0.05525723844766617
decider.linear3.bias: -0.01527052279561758 0.03146567568182945

Rewards:
70.1874
70.1874
70.1874
objective = 108.443359375
==== episode 20200/75000 ====
action = 1
probs = 0.0004 0.9959 0.0009 0.0028

action = 1
probs = 0.0050 0.9626 0.0104 0.0220

action = 2
probs = 0.0066 0.0111 0.9610 0.0213

Learning rate: 6.6897e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007863024366088212 0.08296144753694534
encoder.encoder.weight_hh_l0: -0.0007448028190992773 0.0841389000415802
encoder.encoder.bias_ih_l0: 0.0020591651555150747 0.08723684400320053
encoder.encoder.bias_hh_l0: 0.015131165273487568 0.08492224663496017
encoder.encoder.weight_ih_l0_reverse: 0.0014263218035921454 0.08390749990940094
encoder.encoder.weight_hh_l0_reverse: 0.000491431332193315 0.08294390887022018
encoder.encoder.bias_ih_l0_reverse: 0.0093390429392457 0.0816507562994957
encoder.encoder.bias_hh_l0_reverse: 0.009633728303015232 0.088156558573246
decider.lstm.weight_ih_l0: -0.0015529304509982467 0.14569613337516785
decider.lstm.weight_hh_l0: 0.0035090362653136253 0.14548172056674957
decider.lstm.bias_ih_l0: -0.022311754524707794 0.1418823003768921
decider.lstm.bias_hh_l0: 0.013509107753634453 0.15360061824321747
decider.linear1.weight: 0.0038308005314320326 0.11926213651895523
decider.linear1.bias: 0.004601023159921169 0.11453182250261307
decider.linear2.weight: 0.0018252437002956867 0.052840087562799454
decider.linear2.bias: 0.0005599731812253594 0.0534185990691185
decider.linear3.weight: -0.0019486286910250783 0.05531226471066475
decider.linear3.bias: -0.01524006761610508 0.03148329630494118

Rewards:
74.4454
74.4454
74.4454
objective = 2.033344030380249
==== episode 20300/75000 ====
action = 1
probs = 0.0005 0.9941 0.0012 0.0042

action = 1
probs = 0.0067 0.9401 0.0166 0.0366

action = 2
probs = 0.0050 0.0067 0.9691 0.0192

Learning rate: 6.6897e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007471726858057082 0.08289894461631775
encoder.encoder.weight_hh_l0: -0.0007269945926964283 0.08408254384994507
encoder.encoder.bias_ih_l0: 0.001787909190170467 0.08714648336172104
encoder.encoder.bias_hh_l0: 0.014859911985695362 0.08485578745603561
encoder.encoder.weight_ih_l0_reverse: 0.001405001967214048 0.08388177305459976
encoder.encoder.weight_hh_l0_reverse: 0.00048802007222548127 0.0829198881983757
encoder.encoder.bias_ih_l0_reverse: 0.00907491147518158 0.08166579157114029
encoder.encoder.bias_hh_l0_reverse: 0.00936959683895111 0.08799063414335251
decider.lstm.weight_ih_l0: -0.0015445464523509145 0.14564406871795654
decider.lstm.weight_hh_l0: 0.0034088294487446547 0.1454477608203888
decider.lstm.bias_ih_l0: -0.022644568234682083 0.1419021636247635
decider.lstm.bias_hh_l0: 0.013176299631595612 0.15364067256450653
decider.linear1.weight: 0.003814126132056117 0.1192396804690361
decider.linear1.bias: 0.004460930824279785 0.11436497420072556
decider.linear2.weight: 0.001815995667129755 0.05284113064408302
decider.linear2.bias: 0.0005273473216220737 0.05337192863225937
decider.linear3.weight: -0.001978718675673008 0.055304259061813354
decider.linear3.bias: -0.015270906500518322 0.030455999076366425

Rewards:
74.4454
74.4454
74.4454
objective = 2.4573814868927
==== episode 20400/75000 ====
action = 1
probs = 0.0005 0.9948 0.0011 0.0037

action = 1
probs = 0.0056 0.9508 0.0127 0.0310

action = 2
probs = 0.0074 0.0111 0.9551 0.0263

Learning rate: 6.6897e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0007359417504630983 0.08288123458623886
encoder.encoder.weight_hh_l0: -0.000717233750037849 0.08402848988771439
encoder.encoder.bias_ih_l0: 0.0015585231594741344 0.08707332611083984
encoder.encoder.bias_hh_l0: 0.014630522578954697 0.08483651280403137
encoder.encoder.weight_ih_l0_reverse: 0.0013863140484318137 0.08385802805423737
encoder.encoder.weight_hh_l0_reverse: 0.000488830788526684 0.08290575444698334
encoder.encoder.bias_ih_l0_reverse: 0.009002376347780228 0.08160959929227829
encoder.encoder.bias_hh_l0_reverse: 0.009297061711549759 0.08804237842559814
decider.lstm.weight_ih_l0: -0.0015427994076162577 0.14563381671905518
decider.lstm.weight_hh_l0: 0.003364392789080739 0.1454237550497055
decider.lstm.bias_ih_l0: -0.022802580147981644 0.14188745617866516
decider.lstm.bias_hh_l0: 0.013018285855650902 0.15356700122356415
decider.linear1.weight: 0.003795851022005081 0.11921743303537369
decider.linear1.bias: 0.004408641718327999 0.11451348662376404
decider.linear2.weight: 0.0017824930837377906 0.052821431308984756
decider.linear2.bias: 0.00048446308937855065 0.05338968709111214
decider.linear3.weight: -0.0019593662582337856 0.055254071950912476
decider.linear3.bias: -0.01528922189027071 0.0306746456772089

Rewards:
74.4454
74.4454
74.4454
objective = 2.52078914642334
==== episode 20500/75000 ====
action = 1
probs = 0.0003 0.9967 0.0007 0.0023

action = 1
probs = 0.0034 0.9685 0.0081 0.0200

action = 2
probs = 0.0060 0.0124 0.9585 0.0231

Learning rate: 6.6228e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008237276924774051 0.08298882842063904
encoder.encoder.weight_hh_l0: -0.0007724562310613692 0.0841619148850441
encoder.encoder.bias_ih_l0: 0.002224880736321211 0.08733434230089188
encoder.encoder.bias_hh_l0: 0.015296884812414646 0.08499449491500854
encoder.encoder.weight_ih_l0_reverse: 0.0014616172993555665 0.08394183218479156
encoder.encoder.weight_hh_l0_reverse: 0.0005023241974413395 0.08296862244606018
encoder.encoder.bias_ih_l0_reverse: 0.009620081633329391 0.08167346566915512
encoder.encoder.bias_hh_l0_reverse: 0.009914766997098923 0.08828074485063553
decider.lstm.weight_ih_l0: -0.0015642294893041253 0.14573267102241516
decider.lstm.weight_hh_l0: 0.0036176317371428013 0.14550341665744781
decider.lstm.bias_ih_l0: -0.02196856215596199 0.14184638857841492
decider.lstm.bias_hh_l0: 0.013852309435606003 0.15363727509975433
decider.linear1.weight: 0.0038612072821706533 0.11931591480970383
decider.linear1.bias: 0.0048244409263134 0.11461316049098969
decider.linear2.weight: 0.0018855059752240777 0.05287044867873192
decider.linear2.bias: 0.0006697032367810607 0.05350324511528015
decider.linear3.weight: -0.002016525249928236 0.05539770796895027
decider.linear3.bias: -0.01540329772979021 0.03143153339624405

Rewards:
74.4454
74.4454
74.4454
objective = 1.9271106719970703
==== episode 20600/75000 ====
action = 1
probs = 0.0002 0.9977 0.0005 0.0016

action = 1
probs = 0.0024 0.9780 0.0054 0.0142

action = 2
probs = 0.0068 0.0182 0.9468 0.0283

Learning rate: 6.6228e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008757495670579374 0.08303909003734589
encoder.encoder.weight_hh_l0: -0.0008082202984951437 0.08421807736158371
encoder.encoder.bias_ih_l0: 0.0025230413302779198 0.08746562898159027
encoder.encoder.bias_hh_l0: 0.015595044009387493 0.08506827056407928
encoder.encoder.weight_ih_l0_reverse: 0.0015022980514913797 0.08398140221834183
encoder.encoder.weight_hh_l0_reverse: 0.0005097996327094734 0.08299621939659119
encoder.encoder.bias_ih_l0_reverse: 0.009978526271879673 0.08168230205774307
encoder.encoder.bias_hh_l0_reverse: 0.010273214429616928 0.08843330293893814
decider.lstm.weight_ih_l0: -0.0015820842236280441 0.14579357206821442
decider.lstm.weight_hh_l0: 0.0037617390044033527 0.14553388953208923
decider.lstm.bias_ih_l0: -0.021541975438594818 0.14180335402488708
decider.lstm.bias_hh_l0: 0.014278904534876347 0.15363900363445282
decider.linear1.weight: 0.0038942056708037853 0.11936968564987183
decider.linear1.bias: 0.005031021311879158 0.11476293951272964
decider.linear2.weight: 0.001923283445648849 0.05288855358958244
decider.linear2.bias: 0.0007437558379024267 0.053573720157146454
decider.linear3.weight: -0.0020367936231195927 0.05545525625348091
decider.linear3.bias: -0.015447299927473068 0.03182432800531387

Rewards:
74.4454
74.4454
74.4454
objective = 1.9659416675567627
==== episode 20700/75000 ====
action = 1
probs = 0.0002 0.9981 0.0004 0.0013

action = 1
probs = 0.0021 0.9814 0.0047 0.0118

action = 2
probs = 0.0066 0.0154 0.9572 0.0208

Learning rate: 6.6228e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009125579963438213 0.08308181911706924
encoder.encoder.weight_hh_l0: -0.0008375794277526438 0.08427585661411285
encoder.encoder.bias_ih_l0: 0.002791937440633774 0.08757530152797699
encoder.encoder.bias_hh_l0: 0.01586393639445305 0.08511984348297119
encoder.encoder.weight_ih_l0_reverse: 0.001531733782030642 0.08401692658662796
encoder.encoder.weight_hh_l0_reverse: 0.0005119018605910242 0.08302544802427292
encoder.encoder.bias_ih_l0_reverse: 0.01019326876848936 0.08173009753227234
encoder.encoder.bias_hh_l0_reverse: 0.010487956926226616 0.08848301321268082
decider.lstm.weight_ih_l0: -0.0015942242462188005 0.14582747220993042
decider.lstm.weight_hh_l0: 0.003855109680444002 0.14556853473186493
decider.lstm.bias_ih_l0: -0.021271510049700737 0.1418009102344513
decider.lstm.bias_hh_l0: 0.014549369923770428 0.15367895364761353
decider.linear1.weight: 0.003928913734853268 0.11941612511873245
decider.linear1.bias: 0.00521119637414813 0.11476680636405945
decider.linear2.weight: 0.001964760012924671 0.05291656032204628
decider.linear2.bias: 0.0008141842554323375 0.05359673127532005
decider.linear3.weight: -0.002036925172433257 0.055522091686725616
decider.linear3.bias: -0.015399356372654438 0.03228122368454933

Rewards:
74.4454
74.4454
74.4454
objective = 1.5979657173156738
==== episode 20800/75000 ====
action = 1
probs = 0.0002 0.9979 0.0004 0.0015

action = 1
probs = 0.0027 0.9788 0.0051 0.0134

action = 2
probs = 0.0084 0.0151 0.9534 0.0230

Learning rate: 6.6228e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008824232500046492 0.08303813636302948
encoder.encoder.weight_hh_l0: -0.0008152109803631902 0.08419840782880783
encoder.encoder.bias_ih_l0: 0.002441809047013521 0.08744478970766068
encoder.encoder.bias_hh_l0: 0.015513808466494083 0.08504240214824677
encoder.encoder.weight_ih_l0_reverse: 0.0015058348653838038 0.08398472517728806
encoder.encoder.weight_hh_l0_reverse: 0.0005106890457682312 0.08300062268972397
encoder.encoder.bias_ih_l0_reverse: 0.009898464195430279 0.08171147853136063
encoder.encoder.bias_hh_l0_reverse: 0.010193152353167534 0.08839652687311172
decider.lstm.weight_ih_l0: -0.001581963850185275 0.1457783430814743
decider.lstm.weight_hh_l0: 0.003719871863722801 0.14552883803844452
decider.lstm.bias_ih_l0: -0.02168188989162445 0.14183560013771057
decider.lstm.bias_hh_l0: 0.01413900125771761 0.15364696085453033
decider.linear1.weight: 0.00389610487036407 0.1193772703409195
decider.linear1.bias: 0.005044482182711363 0.11472316086292267
decider.linear2.weight: 0.0019071933347731829 0.05290196090936661
decider.linear2.bias: 0.0007179077947512269 0.053528279066085815
decider.linear3.weight: -0.002001253655180335 0.05547181889414787
decider.linear3.bias: -0.015291359275579453 0.03205093368887901

Rewards:
74.4454
74.4454
74.4454
objective = 1.7667243480682373
==== episode 20900/75000 ====
action = 1
probs = 0.0001 0.9985 0.0003 0.0011

action = 1
probs = 0.0021 0.9847 0.0035 0.0097

action = 2
probs = 0.0114 0.0260 0.9345 0.0281

Learning rate: 6.6228e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.000915583863388747 0.08306542783975601
encoder.encoder.weight_hh_l0: -0.0008354508900083601 0.08421892672777176
encoder.encoder.bias_ih_l0: 0.002570983488112688 0.08750922232866287
encoder.encoder.bias_hh_l0: 0.015642983838915825 0.08508499711751938
encoder.encoder.weight_ih_l0_reverse: 0.0015298144426196814 0.08400707691907883
encoder.encoder.weight_hh_l0_reverse: 0.0005168038769625127 0.08301503211259842
encoder.encoder.bias_ih_l0_reverse: 0.010127188637852669 0.08170202374458313
encoder.encoder.bias_hh_l0_reverse: 0.010421877726912498 0.08851656317710876
decider.lstm.weight_ih_l0: -0.0015908022178336978 0.1458199918270111
decider.lstm.weight_hh_l0: 0.0037967823445796967 0.1455443799495697
decider.lstm.bias_ih_l0: -0.02144060842692852 0.14179348945617676
decider.lstm.bias_hh_l0: 0.014380283653736115 0.1536242514848709
decider.linear1.weight: 0.003911010455340147 0.11940690875053406
decider.linear1.bias: 0.0051731145940721035 0.11488977819681168
decider.linear2.weight: 0.0019256884697824717 0.05290598049759865
decider.linear2.bias: 0.0007496265461668372 0.053575944155454636
decider.linear3.weight: -0.001991510158404708 0.05547867715358734
decider.linear3.bias: -0.015279477462172508 0.03253345564007759

Rewards:
74.4454
74.4454
74.4454
objective = 2.100497007369995
==== episode 21000/75000 ====
action = 1
probs = 0.0001 0.9989 0.0002 0.0008

action = 1
probs = 0.0015 0.9886 0.0028 0.0072

action = 2
probs = 0.0085 0.0264 0.9425 0.0225

Learning rate: 6.5566e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009752900223247707 0.08314996212720871
encoder.encoder.weight_hh_l0: -0.0008850223384797573 0.0843445286154747
encoder.encoder.bias_ih_l0: 0.0031167040579020977 0.08773826062679291
encoder.encoder.bias_hh_l0: 0.01618869975209236 0.08521351963281631
encoder.encoder.weight_ih_l0_reverse: 0.0015833080979064107 0.08407264202833176
encoder.encoder.weight_hh_l0_reverse: 0.0005262135528028011 0.08306893706321716
encoder.encoder.bias_ih_l0_reverse: 0.010620157234370708 0.08176993578672409
encoder.encoder.bias_hh_l0_reverse: 0.010914847254753113 0.08866169303655624
decider.lstm.weight_ih_l0: -0.0016126172849908471 0.1459038406610489
decider.lstm.weight_hh_l0: 0.004014637786895037 0.1456257551908493
decider.lstm.bias_ih_l0: -0.020794371142983437 0.14173103868961334
decider.lstm.bias_hh_l0: 0.015026514418423176 0.15370002388954163
decider.linear1.weight: 0.003967431373894215 0.11948150396347046
decider.linear1.bias: 0.005476546473801136 0.11494139581918716
decider.linear2.weight: 0.0020142863504588604 0.05294298753142357
decider.linear2.bias: 0.0008875762578099966 0.053676847368478775
decider.linear3.weight: -0.002035469515249133 0.055577583611011505
decider.linear3.bias: -0.015377099625766277 0.03305510804057121

Rewards:
74.4454
74.4454
74.4454
objective = 1.7812503576278687
==== episode 21100/75000 ====
action = 1
probs = 0.0001 0.9990 0.0002 0.0007

action = 1
probs = 0.0012 0.9900 0.0024 0.0063

action = 2
probs = 0.0069 0.0281 0.9455 0.0194

Learning rate: 6.5566e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0010024458169937134 0.08319614827632904
encoder.encoder.weight_hh_l0: -0.0009079280425794423 0.08441872149705887
encoder.encoder.bias_ih_l0: 0.0034145298413932323 0.08785700798034668
encoder.encoder.bias_hh_l0: 0.016486525535583496 0.08528360724449158
encoder.encoder.weight_ih_l0_reverse: 0.0016101524233818054 0.08410530537366867
encoder.encoder.weight_hh_l0_reverse: 0.0005275933654047549 0.08309728652238846
encoder.encoder.bias_ih_l0_reverse: 0.010887601412832737 0.08180336654186249
encoder.encoder.bias_hh_l0_reverse: 0.011182291433215141 0.08873409032821655
decider.lstm.weight_ih_l0: -0.001624789205379784 0.14595307409763336
decider.lstm.weight_hh_l0: 0.004134789574891329 0.14567866921424866
decider.lstm.bias_ih_l0: -0.02044154703617096 0.14168141782283783
decider.lstm.bias_hh_l0: 0.015379346907138824 0.15373334288597107
decider.linear1.weight: 0.004003327339887619 0.11952130496501923
decider.linear1.bias: 0.005641605705022812 0.11497445404529572
decider.linear2.weight: 0.002074394840747118 0.05296063795685768
decider.linear2.bias: 0.000973409682046622 0.05373602733016014
decider.linear3.weight: -0.0020686949137598276 0.055625852197408676
decider.linear3.bias: -0.015453357249498367 0.0333278626203537

Rewards:
74.4454
74.4454
74.4454
objective = 1.6625938415527344
==== episode 21200/75000 ====
action = 1
probs = 0.0001 0.9988 0.0002 0.0009

action = 1
probs = 0.0015 0.9874 0.0030 0.0082

action = 2
probs = 0.0082 0.0265 0.9377 0.0277

Learning rate: 6.5566e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009662389638833702 0.08312810212373734
encoder.encoder.weight_hh_l0: -0.0008764407830312848 0.08430570363998413
encoder.encoder.bias_ih_l0: 0.0029524692799896 0.0876847356557846
encoder.encoder.bias_hh_l0: 0.01602446287870407 0.08517853170633316
encoder.encoder.weight_ih_l0_reverse: 0.0015793746570125222 0.08406306803226471
encoder.encoder.weight_hh_l0_reverse: 0.000523917842656374 0.08305743336677551
encoder.encoder.bias_ih_l0_reverse: 0.01052766852080822 0.08175968378782272
encoder.encoder.bias_hh_l0_reverse: 0.010822359472513199 0.0886482298374176
decider.lstm.weight_ih_l0: -0.0016109150601550937 0.14588682353496552
decider.lstm.weight_hh_l0: 0.003970901947468519 0.14560315012931824
decider.lstm.bias_ih_l0: -0.020931966602802277 0.1417418122291565
decider.lstm.bias_hh_l0: 0.014888932928442955 0.15368908643722534
decider.linear1.weight: 0.003955434076488018 0.11947310715913773
decider.linear1.bias: 0.00540984608232975 0.1149556040763855
decider.linear2.weight: 0.001993170939385891 0.05293945595622063
decider.linear2.bias: 0.0008499390678480268 0.05366866663098335
decider.linear3.weight: -0.0020577572286128998 0.05555880442261696
decider.linear3.bias: -0.015442335046827793 0.03264215588569641

Rewards:
74.4454
74.4454
74.4454
objective = 1.9413609504699707
==== episode 21300/75000 ====
action = 1
probs = 0.0001 0.9988 0.0002 0.0008

action = 1
probs = 0.0013 0.9876 0.0028 0.0083

action = 2
probs = 0.0071 0.0248 0.9384 0.0298

Learning rate: 6.5566e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009827229660004377 0.08314723521471024
encoder.encoder.weight_hh_l0: -0.0008894241182133555 0.08433092385530472
encoder.encoder.bias_ih_l0: 0.0030606314539909363 0.08773769438266754
encoder.encoder.bias_hh_l0: 0.016132622957229614 0.08520793169736862
encoder.encoder.weight_ih_l0_reverse: 0.0015956813003867865 0.0840827226638794
encoder.encoder.weight_hh_l0_reverse: 0.0005280837067402899 0.083073191344738
encoder.encoder.bias_ih_l0_reverse: 0.010640420950949192 0.0817803144454956
encoder.encoder.bias_hh_l0_reverse: 0.010935110040009022 0.08868562430143356
decider.lstm.weight_ih_l0: -0.0016143503598868847 0.1459035873413086
decider.lstm.weight_hh_l0: 0.004016089253127575 0.1456177681684494
decider.lstm.bias_ih_l0: -0.020789187401533127 0.14173027873039246
decider.lstm.bias_hh_l0: 0.015031713992357254 0.15372276306152344
decider.linear1.weight: 0.003966633230447769 0.11949490010738373
decider.linear1.bias: 0.00547901913523674 0.11496337503194809
decider.linear2.weight: 0.0020162600558251143 0.05295385792851448
decider.linear2.bias: 0.0008896833169274032 0.05369072034955025
decider.linear3.weight: -0.0020966418087482452 0.05560438707470894
decider.linear3.bias: -0.015521043911576271 0.03244330734014511

Rewards:
74.4454
74.4454
74.4454
objective = 1.9172948598861694
==== episode 21400/75000 ====
action = 1
probs = 0.0002 0.9984 0.0003 0.0011

action = 1
probs = 0.0023 0.9814 0.0045 0.0117

action = 2
probs = 0.0051 0.0119 0.9632 0.0198

Learning rate: 6.5566e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009526807116344571 0.0831213891506195
encoder.encoder.weight_hh_l0: -0.0008706996450200677 0.08431574702262878
encoder.encoder.bias_ih_l0: 0.002942668739706278 0.08769181370735168
encoder.encoder.bias_hh_l0: 0.01601465791463852 0.08515787869691849
encoder.encoder.weight_ih_l0_reverse: 0.0015762215480208397 0.08406541496515274
encoder.encoder.weight_hh_l0_reverse: 0.0005237996228970587 0.0830603763461113
encoder.encoder.bias_ih_l0_reverse: 0.010368666611611843 0.08182785660028458
encoder.encoder.bias_hh_l0_reverse: 0.010663357563316822 0.08853702247142792
decider.lstm.weight_ih_l0: -0.0016075175954028964 0.14586187899112701
decider.lstm.weight_hh_l0: 0.003940586466342211 0.14561475813388824
decider.lstm.bias_ih_l0: -0.02102850005030632 0.14177627861499786
decider.lstm.bias_hh_l0: 0.014792395755648613 0.15378233790397644
decider.linear1.weight: 0.0039576138369739056 0.11947136372327805
decider.linear1.bias: 0.005374419502913952 0.1147170439362526
decider.linear2.weight: 0.0019955856259912252 0.05295969918370247
decider.linear2.bias: 0.000842154782731086 0.053611818701028824
decider.linear3.weight: -0.002080668928101659 0.05560297146439552
decider.linear3.bias: -0.015433967113494873 0.03218113258481026

Rewards:
74.4454
74.4454
74.4454
objective = 1.433905005455017
==== episode 21500/75000 ====
action = 1
probs = 0.0001 0.9986 0.0003 0.0010

action = 1
probs = 0.0021 0.9827 0.0041 0.0111

action = 2
probs = 0.0050 0.0101 0.9654 0.0195

Learning rate: 6.4910e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009753431659191847 0.08314207941293716
encoder.encoder.weight_hh_l0: -0.0008858718792907894 0.08434049040079117
encoder.encoder.bias_ih_l0: 0.0030659979674965143 0.08774229139089584
encoder.encoder.bias_hh_l0: 0.0161379873752594 0.08518771827220917
encoder.encoder.weight_ih_l0_reverse: 0.0015933174872770905 0.08408719301223755
encoder.encoder.weight_hh_l0_reverse: 0.000526649528183043 0.08307893574237823
encoder.encoder.bias_ih_l0_reverse: 0.010482897982001305 0.08184503018856049
encoder.encoder.bias_hh_l0_reverse: 0.010777588933706284 0.08856794983148575
decider.lstm.weight_ih_l0: -0.0016115143662318587 0.14587746560573578
decider.lstm.weight_hh_l0: 0.003980092238634825 0.14562520384788513
decider.lstm.bias_ih_l0: -0.020894184708595276 0.14178627729415894
decider.lstm.bias_hh_l0: 0.014926708303391933 0.15380199253559113
decider.linear1.weight: 0.003965796437114477 0.11949998140335083
decider.linear1.bias: 0.0054502240382134914 0.11470840126276016
decider.linear2.weight: 0.0020094874780625105 0.05297931656241417
decider.linear2.bias: 0.0008721681078895926 0.05361771956086159
decider.linear3.weight: -0.00209710281342268 0.05566207692027092
decider.linear3.bias: -0.015427077189087868 0.03213126212358475

Rewards:
74.4454
74.4454
74.4454
objective = 1.3407057523727417
==== episode 21600/75000 ====
action = 1
probs = 0.0002 0.9978 0.0003 0.0016

action = 1
probs = 0.0031 0.9765 0.0046 0.0158

action = 2
probs = 0.0079 0.0172 0.9338 0.0411

Learning rate: 6.4910e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008716160082258284 0.08301464468240738
encoder.encoder.weight_hh_l0: -0.0008189437794499099 0.08416112512350082
encoder.encoder.bias_ih_l0: 0.0022235107608139515 0.08742618560791016
encoder.encoder.bias_hh_l0: 0.015295497141778469 0.08498561382293701
encoder.encoder.weight_ih_l0_reverse: 0.0015089667867869139 0.08397135883569717
encoder.encoder.weight_hh_l0_reverse: 0.000508899858687073 0.08298861980438232
encoder.encoder.bias_ih_l0_reverse: 0.009789876639842987 0.08171670883893967
encoder.encoder.bias_hh_l0_reverse: 0.010084569454193115 0.08839797973632812
decider.lstm.weight_ih_l0: -0.0015930593945086002 0.1457729935646057
decider.lstm.weight_hh_l0: 0.0037362580187618732 0.14552047848701477
decider.lstm.bias_ih_l0: -0.021754352375864983 0.1417607069015503
decider.lstm.bias_hh_l0: 0.014066551811993122 0.15362796187400818
decider.linear1.weight: 0.0039031251799315214 0.11937867850065231
decider.linear1.bias: 0.004994822666049004 0.11479655653238297
decider.linear2.weight: 0.001864207093603909 0.05291242524981499
decider.linear2.bias: 0.0006344156572595239 0.0535234734416008
decider.linear3.weight: -0.00205825362354517 0.055489301681518555
decider.linear3.bias: -0.015351023524999619 0.031075187027454376

Rewards:
74.4454
74.4454
74.4454
objective = 2.3463075160980225
==== episode 21700/75000 ====
action = 1
probs = 0.0003 0.9977 0.0004 0.0016

action = 1
probs = 0.0035 0.9739 0.0056 0.0170

action = 2
probs = 0.0080 0.0137 0.9412 0.0371

Learning rate: 6.4910e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008665996720083058 0.08299528062343597
encoder.encoder.weight_hh_l0: -0.0008165997569449246 0.08413476496934891
encoder.encoder.bias_ih_l0: 0.002103714505210519 0.08738504350185394
encoder.encoder.bias_hh_l0: 0.01517570111900568 0.08494778722524643
encoder.encoder.weight_ih_l0_reverse: 0.0015147979138419032 0.08396714925765991
encoder.encoder.weight_hh_l0_reverse: 0.0005055256769992411 0.08298084139823914
encoder.encoder.bias_ih_l0_reverse: 0.00964949931949377 0.08170898258686066
encoder.encoder.bias_hh_l0_reverse: 0.009944193065166473 0.08835438638925552
decider.lstm.weight_ih_l0: -0.0015925629995763302 0.145744189620018
decider.lstm.weight_hh_l0: 0.003683733521029353 0.14549563825130463
decider.lstm.bias_ih_l0: -0.021952543407678604 0.14181075990200043
decider.lstm.bias_hh_l0: 0.013868364505469799 0.153625950217247
decider.linear1.weight: 0.0038911141455173492 0.11936929821968079
decider.linear1.bias: 0.0049260463565588 0.11472781747579575
decider.linear2.weight: 0.0018423516303300858 0.052908651530742645
decider.linear2.bias: 0.0005978416884317994 0.0534856803715229
decider.linear3.weight: -0.002035056706517935 0.05546312406659126
decider.linear3.bias: -0.015315765514969826 0.031068719923496246

Rewards:
74.4454
74.4454
74.4454
objective = 2.218954086303711
==== episode 21800/75000 ====
action = 1
probs = 0.0003 0.9977 0.0004 0.0017

action = 1
probs = 0.0036 0.9734 0.0055 0.0174

action = 1
probs = 0.0074 0.0138 0.9408 0.0380

Learning rate: 6.4910e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008696970180608332 0.08300747722387314
encoder.encoder.weight_hh_l0: -0.0008193075191229582 0.08414530009031296
encoder.encoder.bias_ih_l0: 0.0021388542372733355 0.08740001916885376
encoder.encoder.bias_hh_l0: 0.015210838057100773 0.08496002852916718
encoder.encoder.weight_ih_l0_reverse: 0.0015226560644805431 0.08397553861141205
encoder.encoder.weight_hh_l0_reverse: 0.0005075075896456838 0.08298572152853012
encoder.encoder.bias_ih_l0_reverse: 0.009670427069067955 0.08171766996383667
encoder.encoder.bias_hh_l0_reverse: 0.009965120814740658 0.08837436139583588
decider.lstm.weight_ih_l0: -0.0015927569475024939 0.14574997127056122
decider.lstm.weight_hh_l0: 0.003694883780553937 0.1455068588256836
decider.lstm.bias_ih_l0: -0.021898984909057617 0.1418047994375229
decider.lstm.bias_hh_l0: 0.013921919278800488 0.1536330133676529
decider.linear1.weight: 0.0038962364196777344 0.11937554180622101
decider.linear1.bias: 0.004957611672580242 0.11473076790571213
decider.linear2.weight: 0.0018500181613489985 0.05291534587740898
decider.linear2.bias: 0.0006013037636876106 0.05348672717809677
decider.linear3.weight: -0.0020528100430965424 0.05547749996185303
decider.linear3.bias: -0.015342243015766144 0.030997259542346

Rewards:
57.3517
57.3517
57.3517
objective = 82.4915542602539
==== episode 21900/75000 ====
action = 1
probs = 0.0002 0.9985 0.0003 0.0011

action = 1
probs = 0.0025 0.9819 0.0040 0.0116

action = 2
probs = 0.0055 0.0135 0.9534 0.0276

Learning rate: 6.4910e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009399124537594616 0.08312155306339264
encoder.encoder.weight_hh_l0: -0.0008632338140159845 0.08428902179002762
encoder.encoder.bias_ih_l0: 0.0027762746904045343 0.08764433860778809
encoder.encoder.bias_hh_l0: 0.01584826037287712 0.08512601256370544
encoder.encoder.weight_ih_l0_reverse: 0.0015812368365004659 0.08406319469213486
encoder.encoder.weight_hh_l0_reverse: 0.000521952984854579 0.08305343240499496
encoder.encoder.bias_ih_l0_reverse: 0.010190347209572792 0.08179716020822525
encoder.encoder.bias_hh_l0_reverse: 0.010485040955245495 0.08856695145368576
decider.lstm.weight_ih_l0: -0.001602411037310958 0.14584119617938995
decider.lstm.weight_hh_l0: 0.0038864719681441784 0.1455973982810974
decider.lstm.bias_ih_l0: -0.021179981529712677 0.14180132746696472
decider.lstm.bias_hh_l0: 0.014640925452113152 0.15374821424484253
decider.linear1.weight: 0.00394593458622694 0.11945857852697372
decider.linear1.bias: 0.005311725661158562 0.11477096378803253
decider.linear2.weight: 0.0019506847020238638 0.05296291410923004
decider.linear2.bias: 0.0007788565708324313 0.05358220264315605
decider.linear3.weight: -0.002097195014357567 0.055606745183467865
decider.linear3.bias: -0.015411557629704475 0.03192323446273804

Rewards:
74.4454
74.4454
74.4454
objective = 1.6775811910629272
==== episode 22000/75000 ====
action = 1
probs = 0.0002 0.9981 0.0003 0.0014

action = 1
probs = 0.0030 0.9763 0.0050 0.0156

action = 2
probs = 0.0055 0.0110 0.9582 0.0252

Learning rate: 6.4261e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009139504982158542 0.08307968825101852
encoder.encoder.weight_hh_l0: -0.0008494050707668066 0.08423976600170135
encoder.encoder.bias_ih_l0: 0.002560530323535204 0.08756736665964127
encoder.encoder.bias_hh_l0: 0.01563251204788685 0.08506056666374207
encoder.encoder.weight_ih_l0_reverse: 0.0015621855854988098 0.0840347558259964
encoder.encoder.weight_hh_l0_reverse: 0.0005223483312875032 0.08303043991327286
encoder.encoder.bias_ih_l0_reverse: 0.009958929382264614 0.08178882300853729
encoder.encoder.bias_hh_l0_reverse: 0.010253624990582466 0.08846396207809448
decider.lstm.weight_ih_l0: -0.0015986801590770483 0.14580200612545013
decider.lstm.weight_hh_l0: 0.0038169180043041706 0.1455652415752411
decider.lstm.bias_ih_l0: -0.021452173590660095 0.14180269837379456
decider.lstm.bias_hh_l0: 0.014368727803230286 0.15375962853431702
decider.linear1.weight: 0.0039313361048698425 0.11943656206130981
decider.linear1.bias: 0.005202998407185078 0.11467395722866058
decider.linear2.weight: 0.0019335747929289937 0.05295416712760925
decider.linear2.bias: 0.0007304088212549686 0.05353405699133873
decider.linear3.weight: -0.0020935419015586376 0.05557899922132492
decider.linear3.bias: -0.01539239939302206 0.03151729330420494

Rewards:
74.4454
74.4454
74.4454
objective = 1.701168417930603
==== episode 22100/75000 ====
action = 1
probs = 0.0002 0.9978 0.0003 0.0016

action = 1
probs = 0.0037 0.9720 0.0058 0.0186

action = 2
probs = 0.0050 0.0081 0.9643 0.0226

Learning rate: 6.4261e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009107595542445779 0.08307147026062012
encoder.encoder.weight_hh_l0: -0.0008485755533911288 0.08423614501953125
encoder.encoder.bias_ih_l0: 0.0025437951553612947 0.0875626653432846
encoder.encoder.bias_hh_l0: 0.015615778975188732 0.08504464477300644
encoder.encoder.weight_ih_l0_reverse: 0.0015631071291863918 0.08403542637825012
encoder.encoder.weight_hh_l0_reverse: 0.0005226170178502798 0.08303123712539673
encoder.encoder.bias_ih_l0_reverse: 0.009898745454847813 0.08181466162204742
encoder.encoder.bias_hh_l0_reverse: 0.010193439200520515 0.08840232342481613
decider.lstm.weight_ih_l0: -0.0015975183341652155 0.14579150080680847
decider.lstm.weight_hh_l0: 0.0037992314901202917 0.14556434750556946
decider.lstm.bias_ih_l0: -0.02150837332010269 0.14181378483772278
decider.lstm.bias_hh_l0: 0.014312518760561943 0.1537865549325943
decider.linear1.weight: 0.003928447142243385 0.11943889409303665
decider.linear1.bias: 0.005176809150725603 0.11457398533821106
decider.linear2.weight: 0.0019314299570396543 0.05296415090560913
decider.linear2.bias: 0.0007149364100769162 0.05350180342793465
decider.linear3.weight: -0.0021031429059803486 0.05560522526502609
decider.linear3.bias: -0.015352564863860607 0.031198155134916306

Rewards:
74.4454
74.4454
74.4454
objective = 1.6605424880981445
==== episode 22200/75000 ====
action = 1
probs = 0.0002 0.9984 0.0002 0.0012

action = 1
probs = 0.0029 0.9801 0.0035 0.0134

action = 2
probs = 0.0085 0.0212 0.9268 0.0435

Learning rate: 6.4261e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008993340888991952 0.08306358009576797
encoder.encoder.weight_hh_l0: -0.0008419715450145304 0.08417979627847672
encoder.encoder.bias_ih_l0: 0.002279333770275116 0.08747950196266174
encoder.encoder.bias_hh_l0: 0.015351316891610622 0.08502281457185745
encoder.encoder.weight_ih_l0_reverse: 0.0015563152264803648 0.08401176333427429
encoder.encoder.weight_hh_l0_reverse: 0.0005252195405773818 0.08301063627004623
encoder.encoder.bias_ih_l0_reverse: 0.009885907173156738 0.08173712342977524
encoder.encoder.bias_hh_l0_reverse: 0.010180601850152016 0.08852147310972214
decider.lstm.weight_ih_l0: -0.0015980760799720883 0.14579302072525024
decider.lstm.weight_hh_l0: 0.0037712957710027695 0.14554542303085327
decider.lstm.bias_ih_l0: -0.021623095497488976 0.1417909413576126
decider.lstm.bias_hh_l0: 0.014197803102433681 0.15363940596580505
decider.linear1.weight: 0.003919030074030161 0.1194237768650055
decider.linear1.bias: 0.005160758271813393 0.11485622823238373
decider.linear2.weight: 0.0018969015218317509 0.052943889051675797
decider.linear2.bias: 0.0006548496894538403 0.053542137145996094
decider.linear3.weight: -0.0020902962423861027 0.05555209890007973
decider.linear3.bias: -0.015312209725379944 0.031416188925504684

Rewards:
74.4454
74.4454
74.4454
objective = 2.425381660461426
==== episode 22300/75000 ====
action = 1
probs = 0.0002 0.9983 0.0002 0.0013

action = 1
probs = 0.0031 0.9781 0.0038 0.0150

action = 2
probs = 0.0083 0.0182 0.9343 0.0392

Learning rate: 6.4261e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008994963718578219 0.08305497467517853
encoder.encoder.weight_hh_l0: -0.0008431233000010252 0.0841703787446022
encoder.encoder.bias_ih_l0: 0.0022408997174352407 0.08746826648712158
encoder.encoder.bias_hh_l0: 0.015312881208956242 0.0850042998790741
encoder.encoder.weight_ih_l0_reverse: 0.0015558574814349413 0.08401135355234146
encoder.encoder.weight_hh_l0_reverse: 0.0005237367586232722 0.08300894498825073
encoder.encoder.bias_ih_l0_reverse: 0.00982996542006731 0.0817498117685318
encoder.encoder.bias_hh_l0_reverse: 0.010124662891030312 0.08848688751459122
decider.lstm.weight_ih_l0: -0.00159864267334342 0.14578258991241455
decider.lstm.weight_hh_l0: 0.003755626268684864 0.1455400586128235
decider.lstm.bias_ih_l0: -0.021682392805814743 0.1417984664440155
decider.lstm.bias_hh_l0: 0.014138501137495041 0.15365946292877197
decider.linear1.weight: 0.003916557878255844 0.11942722648382187
decider.linear1.bias: 0.005152781959623098 0.11479686200618744
decider.linear2.weight: 0.0019059941405430436 0.05294804275035858
decider.linear2.bias: 0.0006557808956131339 0.05352112278342247
decider.linear3.weight: -0.00209858943708241 0.05556212365627289
decider.linear3.bias: -0.015314923599362373 0.031293321400880814

Rewards:
74.4454
74.4454
74.4454
objective = 2.280198335647583
==== episode 22400/75000 ====
action = 1
probs = 0.0002 0.9982 0.0002 0.0014

action = 1
probs = 0.0031 0.9774 0.0039 0.0157

action = 2
probs = 0.0099 0.0246 0.9170 0.0485

Learning rate: 6.4261e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008738265605643392 0.08301929384469986
encoder.encoder.weight_hh_l0: -0.0008254094864241779 0.08411769568920135
encoder.encoder.bias_ih_l0: 0.0019950843416154385 0.08736550062894821
encoder.encoder.bias_hh_l0: 0.015067062340676785 0.08495558798313141
encoder.encoder.weight_ih_l0_reverse: 0.0015354574425145984 0.08397955447435379
encoder.encoder.weight_hh_l0_reverse: 0.0005175120895728469 0.08298356831073761
encoder.encoder.bias_ih_l0_reverse: 0.00967879593372345 0.08170082420110703
encoder.encoder.bias_hh_l0_reverse: 0.009973494336009026 0.08846046030521393
decider.lstm.weight_ih_l0: -0.0015960321761667728 0.1457575410604477
decider.lstm.weight_hh_l0: 0.0036915610544383526 0.14550964534282684
decider.lstm.bias_ih_l0: -0.021914327517151833 0.14179514348506927
decider.lstm.bias_hh_l0: 0.01390657015144825 0.15357136726379395
decider.linear1.weight: 0.0039015719667077065 0.11940449476242065
decider.linear1.bias: 0.005054370500147343 0.11486110836267471
decider.linear2.weight: 0.0018721437081694603 0.05292857438325882
decider.linear2.bias: 0.0005888133309781551 0.05350472778081894
decider.linear3.weight: -0.002082871738821268 0.05549241229891777
decider.linear3.bias: -0.015328886918723583 0.031179489567875862

Rewards:
74.4454
74.4454
74.4454
objective = 2.762455463409424
==== episode 22500/75000 ====
action = 1
probs = 0.0002 0.9979 0.0002 0.0016

action = 1
probs = 0.0032 0.9739 0.0040 0.0190

action = 2
probs = 0.0110 0.0311 0.8963 0.0616

Learning rate: 6.3619e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008458499214611948 0.0829882100224495
encoder.encoder.weight_hh_l0: -0.0008066513109952211 0.08407726883888245
encoder.encoder.bias_ih_l0: 0.0017913182964548469 0.0872831866145134
encoder.encoder.bias_hh_l0: 0.014863296411931515 0.08492226153612137
encoder.encoder.weight_ih_l0_reverse: 0.0015201759524643421 0.0839511901140213
encoder.encoder.weight_hh_l0_reverse: 0.0005131261423230171 0.08296292275190353
encoder.encoder.bias_ih_l0_reverse: 0.009554494172334671 0.08166052401065826
encoder.encoder.bias_hh_l0_reverse: 0.009849192574620247 0.08844218403100967
decider.lstm.weight_ih_l0: -0.0015927845379337668 0.14573822915554047
decider.lstm.weight_hh_l0: 0.003643870120868087 0.1454906165599823
decider.lstm.bias_ih_l0: -0.022074613720178604 0.14176809787750244
decider.lstm.bias_hh_l0: 0.013746283017098904 0.15349958837032318
decider.linear1.weight: 0.0038933453615754843 0.11938993632793427
decider.linear1.bias: 0.0049947393126785755 0.11491554230451584
decider.linear2.weight: 0.0018586020451039076 0.05291903764009476
decider.linear2.bias: 0.0005484954454004765 0.05349908024072647
decider.linear3.weight: -0.0021039473358541727 0.05546270310878754
decider.linear3.bias: -0.015390204265713692 0.030787624418735504

Rewards:
74.4454
74.4454
74.4454
objective = 3.425389051437378
==== episode 22600/75000 ====
action = 1
probs = 0.0002 0.9980 0.0002 0.0016

action = 1
probs = 0.0036 0.9724 0.0045 0.0195

action = 2
probs = 0.0083 0.0194 0.9299 0.0425

Learning rate: 6.3619e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008668298833072186 0.08301965147256851
encoder.encoder.weight_hh_l0: -0.000821113761048764 0.08412081748247147
encoder.encoder.bias_ih_l0: 0.001977246953174472 0.08736462891101837
encoder.encoder.bias_hh_l0: 0.015049228444695473 0.08494309335947037
encoder.encoder.weight_ih_l0_reverse: 0.0015405698213726282 0.08398482948541641
encoder.encoder.weight_hh_l0_reverse: 0.0005151950172148645 0.08298703283071518
encoder.encoder.bias_ih_l0_reverse: 0.009605091996490955 0.0817401185631752
encoder.encoder.bias_hh_l0_reverse: 0.009899786673486233 0.08841761201620102
decider.lstm.weight_ih_l0: -0.0015938295982778072 0.1457490622997284
decider.lstm.weight_hh_l0: 0.0036768754944205284 0.14551663398742676
decider.lstm.bias_ih_l0: -0.021946504712104797 0.14181651175022125
decider.lstm.bias_hh_l0: 0.013874396681785583 0.1536002904176712
decider.linear1.weight: 0.003906276077032089 0.11941666156053543
decider.linear1.bias: 0.005079003982245922 0.1147608533501625
decider.linear2.weight: 0.0019000128377228975 0.05294368043541908
decider.linear2.bias: 0.0006048245122656226 0.05348917096853256
decider.linear3.weight: -0.002116337651386857 0.055522214621305466
decider.linear3.bias: -0.015375819057226181 0.030924765393137932

Rewards:
74.4454
74.4454
74.4454
objective = 2.5488696098327637
==== episode 22700/75000 ====
action = 1
probs = 0.0002 0.9986 0.0002 0.0011

action = 1
probs = 0.0028 0.9794 0.0033 0.0145

action = 2
probs = 0.0092 0.0200 0.9257 0.0451

Learning rate: 6.3619e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009107510559260845 0.08306184411048889
encoder.encoder.weight_hh_l0: -0.0008488456369377673 0.08415613323450089
encoder.encoder.bias_ih_l0: 0.0021817805245518684 0.08745619654655457
encoder.encoder.bias_hh_l0: 0.015253767371177673 0.08500255644321442
encoder.encoder.weight_ih_l0_reverse: 0.0015748323639854789 0.0840277373790741
encoder.encoder.weight_hh_l0_reverse: 0.0005283126374706626 0.08301638811826706
encoder.encoder.bias_ih_l0_reverse: 0.009865363128483295 0.08175923675298691
encoder.encoder.bias_hh_l0_reverse: 0.010160054080188274 0.08853417634963989
decider.lstm.weight_ih_l0: -0.001599655020982027 0.14578506350517273
decider.lstm.weight_hh_l0: 0.003749023424461484 0.1455347239971161
decider.lstm.bias_ih_l0: -0.021685387939214706 0.1418270617723465
decider.lstm.bias_hh_l0: 0.01413552276790142 0.15364046394824982
decider.linear1.weight: 0.0039192140102386475 0.11946417391300201
decider.linear1.bias: 0.005245458334684372 0.11482831090688705
decider.linear2.weight: 0.001938546309247613 0.052970245480537415
decider.linear2.bias: 0.000681324047036469 0.05353929102420807
decider.linear3.weight: -0.002129212487488985 0.055606771260499954
decider.linear3.bias: -0.01533130370080471 0.031172119081020355

Rewards:
74.4454
74.4454
74.4454
objective = 2.467679738998413
==== episode 22800/75000 ====
action = 1
probs = 0.0001 0.9990 0.0001 0.0007

action = 1
probs = 0.0027 0.9815 0.0034 0.0124

action = 2
probs = 0.0053 0.0095 0.9607 0.0245

Learning rate: 6.3619e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009724636329337955 0.08315642178058624
encoder.encoder.weight_hh_l0: -0.0008869356825016439 0.08428962528705597
encoder.encoder.bias_ih_l0: 0.0027842065319418907 0.08768613636493683
encoder.encoder.bias_hh_l0: 0.015856193378567696 0.08513377606868744
encoder.encoder.weight_ih_l0_reverse: 0.001624128082767129 0.08411328494548798
encoder.encoder.weight_hh_l0_reverse: 0.0005458066007122397 0.08308243006467819
encoder.encoder.bias_ih_l0_reverse: 0.010251111350953579 0.08187440782785416
encoder.encoder.bias_hh_l0_reverse: 0.010545804165303707 0.08860031515359879
decider.lstm.weight_ih_l0: -0.0016037728637456894 0.14584754407405853
decider.lstm.weight_hh_l0: 0.003899906761944294 0.14561058580875397
decider.lstm.bias_ih_l0: -0.021115247160196304 0.14186623692512512
decider.lstm.bias_hh_l0: 0.0147056570276618 0.15380887687206268
decider.linear1.weight: 0.003959243651479483 0.11954048275947571
decider.linear1.bias: 0.005514154210686684 0.11466348171234131
decider.linear2.weight: 0.002071262802928686 0.05302644520998001
decider.linear2.bias: 0.0009351249318569899 0.05346507951617241
decider.linear3.weight: -0.0022196415811777115 0.0558050163090229
decider.linear3.bias: -0.015356387943029404 0.03165781870484352

Rewards:
74.4454
74.4454
74.4454
objective = 1.4827938079833984
==== episode 22900/75000 ====
action = 1
probs = 0.0001 0.9995 0.0001 0.0004

action = 1
probs = 0.0016 0.9888 0.0022 0.0074

action = 2
probs = 0.0059 0.0139 0.9525 0.0278

Learning rate: 6.3619e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009918601717799902 0.08318620920181274
encoder.encoder.weight_hh_l0: -0.0008982990984804928 0.08430903404951096
encoder.encoder.bias_ih_l0: 0.0028704258147627115 0.08772220462560654
encoder.encoder.bias_hh_l0: 0.015942411497235298 0.08517113327980042
encoder.encoder.weight_ih_l0_reverse: 0.001641597249545157 0.08413337916135788
encoder.encoder.weight_hh_l0_reverse: 0.0005479885148815811 0.08309704810380936
encoder.encoder.bias_ih_l0_reverse: 0.010411487892270088 0.08187232911586761
encoder.encoder.bias_hh_l0_reverse: 0.010706178843975067 0.0886940136551857
decider.lstm.weight_ih_l0: -0.0016060820780694485 0.14587582647800446
decider.lstm.weight_hh_l0: 0.003942238166928291 0.1456282138824463
decider.lstm.bias_ih_l0: -0.020955165848135948 0.14185728132724762
decider.lstm.bias_hh_l0: 0.014865735545754433 0.15377870202064514
decider.linear1.weight: 0.003968083765357733 0.11956597864627838
decider.linear1.bias: 0.005616632290184498 0.1147821694612503
decider.linear2.weight: 0.002176448702812195 0.0530591681599617
decider.linear2.bias: 0.0010789504740387201 0.05341615155339241
decider.linear3.weight: -0.0023047160357236862 0.05598539486527443
decider.linear3.bias: -0.01533668115735054 0.03194607421755791

Rewards:
74.4454
74.4454
74.4454
objective = 1.5019423961639404
==== episode 23000/75000 ====
action = 1
probs = 0.0000 0.9996 0.0001 0.0003

action = 1
probs = 0.0013 0.9909 0.0018 0.0060

action = 2
probs = 0.0055 0.0136 0.9503 0.0305

Learning rate: 6.2982e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0010172523325309157 0.08321785181760788
encoder.encoder.weight_hh_l0: -0.0009156253654509783 0.08434378355741501
encoder.encoder.bias_ih_l0: 0.003038850612938404 0.08778810501098633
encoder.encoder.bias_hh_l0: 0.01611083559691906 0.08522028475999832
encoder.encoder.weight_ih_l0_reverse: 0.0016650478355586529 0.08416327834129333
encoder.encoder.weight_hh_l0_reverse: 0.0005536312237381935 0.08311983197927475
encoder.encoder.bias_ih_l0_reverse: 0.010595968924462795 0.08188433945178986
encoder.encoder.bias_hh_l0_reverse: 0.010890662670135498 0.0887640118598938
decider.lstm.weight_ih_l0: -0.0016095559112727642 0.14590437710285187
decider.lstm.weight_hh_l0: 0.004010071512311697 0.1456468105316162
decider.lstm.bias_ih_l0: -0.020723551511764526 0.1418544352054596
decider.lstm.bias_hh_l0: 0.015097357332706451 0.15378761291503906
decider.linear1.weight: 0.003981917165219784 0.1196010485291481
decider.linear1.bias: 0.005729916505515575 0.11482000350952148
decider.linear2.weight: 0.002223468851298094 0.05309923738241196
decider.linear2.bias: 0.001137008424848318 0.05344890058040619
decider.linear3.weight: -0.002339757978916168 0.05608104169368744
decider.linear3.bias: -0.015383618883788586 0.03187048062682152

Rewards:
74.4454
74.4454
74.4454
objective = 1.4997508525848389
==== episode 23100/75000 ====
action = 1
probs = 0.0000 0.9997 0.0001 0.0002

action = 1
probs = 0.0011 0.9924 0.0016 0.0049

action = 2
probs = 0.0050 0.0098 0.9612 0.0239

Learning rate: 6.2982e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0010452161077409983 0.08324853330850601
encoder.encoder.weight_hh_l0: -0.0009351951302960515 0.08438438922166824
encoder.encoder.bias_ih_l0: 0.003236306831240654 0.08785788714885712
encoder.encoder.bias_hh_l0: 0.016308290883898735 0.08526329696178436
encoder.encoder.weight_ih_l0_reverse: 0.0016820337623357773 0.08419236540794373
encoder.encoder.weight_hh_l0_reverse: 0.0005586406332440674 0.0831446424126625
encoder.encoder.bias_ih_l0_reverse: 0.010716503486037254 0.08191289752721786
encoder.encoder.bias_hh_l0_reverse: 0.011011197231709957 0.08877594023942947
decider.lstm.weight_ih_l0: -0.0016137768980115652 0.14592164754867554
decider.lstm.weight_hh_l0: 0.004062889143824577 0.14566539227962494
decider.lstm.bias_ih_l0: -0.020549986511468887 0.14187689125537872
decider.lstm.bias_hh_l0: 0.015270926989614964 0.15382573008537292
decider.linear1.weight: 0.003999126143753529 0.11964019387960434
decider.linear1.bias: 0.005848507862538099 0.11474896967411041
decider.linear2.weight: 0.0022616013884544373 0.05313979089260101
decider.linear2.bias: 0.0011902907863259315 0.053449299186468124
decider.linear3.weight: -0.002339576371014118 0.05617498606443405
decider.linear3.bias: -0.015339473262429237 0.03205987066030502

Rewards:
74.4454
74.4454
74.4454
objective = 1.1768333911895752
==== episode 23200/75000 ====
action = 1
probs = 0.0000 0.9998 0.0000 0.0002

action = 1
probs = 0.0008 0.9943 0.0011 0.0037

action = 3
probs = 0.0060 0.0155 0.9468 0.0317

Learning rate: 6.2982e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0010515350149944425 0.08326301723718643
encoder.encoder.weight_hh_l0: -0.0009399356786161661 0.08438528329133987
encoder.encoder.bias_ih_l0: 0.0032292066607624292 0.08785904943943024
encoder.encoder.bias_hh_l0: 0.016301188617944717 0.08527816087007523
encoder.encoder.weight_ih_l0_reverse: 0.0016906586242839694 0.08419875800609589
encoder.encoder.weight_hh_l0_reverse: 0.0005600500735454261 0.08314879238605499
encoder.encoder.bias_ih_l0_reverse: 0.010814378969371319 0.08189741522073746
encoder.encoder.bias_hh_l0_reverse: 0.011109073646366596 0.08885057270526886
decider.lstm.weight_ih_l0: -0.0016145267290994525 0.14594131708145142
decider.lstm.weight_hh_l0: 0.004090993665158749 0.14567403495311737
decider.lstm.bias_ih_l0: -0.020462173968553543 0.14185571670532227
decider.lstm.bias_hh_l0: 0.015358738601207733 0.1537686437368393
decider.linear1.weight: 0.0040099723264575005 0.11965560168027878
decider.linear1.bias: 0.005918612703680992 0.11488572508096695
decider.linear2.weight: 0.0022784946486353874 0.05315655097365379
decider.linear2.bias: 0.0012056221021339297 0.05348842963576317
decider.linear3.weight: -0.0023432851303368807 0.05620144307613373
decider.linear3.bias: -0.015342149883508682 0.03211655840277672

Rewards:
59.0339
59.0339
59.0339
objective = 68.03417205810547
==== episode 23300/75000 ====
action = 1
probs = 0.0000 0.9998 0.0000 0.0002

action = 1
probs = 0.0008 0.9942 0.0012 0.0038

action = 2
probs = 0.0065 0.0207 0.9319 0.0408

Learning rate: 6.2982e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0010351804085075855 0.08324383199214935
encoder.encoder.weight_hh_l0: -0.0009265895350836217 0.08435272425413132
encoder.encoder.bias_ih_l0: 0.0030723868403583765 0.08780383318662643
encoder.encoder.bias_hh_l0: 0.016144370660185814 0.08525031059980392
encoder.encoder.weight_ih_l0_reverse: 0.0016814392292872071 0.08418278396129608
encoder.encoder.weight_hh_l0_reverse: 0.0005581313162110746 0.08313419669866562
encoder.encoder.bias_ih_l0_reverse: 0.010754668153822422 0.0818738341331482
encoder.encoder.bias_hh_l0_reverse: 0.011049366556107998 0.08886196464300156
decider.lstm.weight_ih_l0: -0.001610834151506424 0.1459321826696396
decider.lstm.weight_hh_l0: 0.004050719551742077 0.145655557513237
decider.lstm.bias_ih_l0: -0.02058941312134266 0.14185062050819397
decider.lstm.bias_hh_l0: 0.015231495723128319 0.15372665226459503
decider.linear1.weight: 0.004001735243946314 0.11963625997304916
decider.linear1.bias: 0.005854559130966663 0.1149616613984108
decider.linear2.weight: 0.002248907694593072 0.0531456358730793
decider.linear2.bias: 0.0011644441401585937 0.05349746346473694
decider.linear3.weight: -0.002343039959669113 0.056145500391721725
decider.linear3.bias: -0.015397582203149796 0.03199143335223198

Rewards:
74.4454
74.4454
74.4454
objective = 1.9004333019256592
==== episode 23400/75000 ====
action = 1
probs = 0.0000 0.9998 0.0000 0.0001

action = 1
probs = 0.0008 0.9945 0.0012 0.0036

action = 2
probs = 0.0061 0.0161 0.9412 0.0366

Learning rate: 6.2982e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0010508898412808776 0.08325576782226562
encoder.encoder.weight_hh_l0: -0.0009392119245603681 0.08436643332242966
encoder.encoder.bias_ih_l0: 0.0031431231182068586 0.08783439546823502
encoder.encoder.bias_hh_l0: 0.01621510647237301 0.08526026457548141
encoder.encoder.weight_ih_l0_reverse: 0.0016890414990484715 0.08419667184352875
encoder.encoder.weight_hh_l0_reverse: 0.000561250897590071 0.08314533531665802
encoder.encoder.bias_ih_l0_reverse: 0.010771846398711205 0.08188454806804657
encoder.encoder.bias_hh_l0_reverse: 0.011066540144383907 0.08886013180017471
decider.lstm.weight_ih_l0: -0.0016131217125803232 0.1459326297044754
decider.lstm.weight_hh_l0: 0.004068661946803331 0.14565660059452057
decider.lstm.bias_ih_l0: -0.020541399717330933 0.1418820023536682
decider.lstm.bias_hh_l0: 0.015279507264494896 0.1537499576807022
decider.linear1.weight: 0.004003783687949181 0.11965584009885788
decider.linear1.bias: 0.005896297283470631 0.11490128189325333
decider.linear2.weight: 0.002264244481921196 0.05316817760467529
decider.linear2.bias: 0.001182858133688569 0.053483590483665466
decider.linear3.weight: -0.0023516668006777763 0.05619743466377258
decider.linear3.bias: -0.0153824957087636 0.031986553221940994

Rewards:
74.4454
74.4454
74.4454
objective = 1.6460685729980469
==== episode 23500/75000 ====
action = 1
probs = 0.0000 0.9998 0.0000 0.0001

action = 1
probs = 0.0007 0.9950 0.0012 0.0030

action = 2
probs = 0.0049 0.0097 0.9632 0.0223

Learning rate: 6.2353e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0010875898879021406 0.08330707997083664
encoder.encoder.weight_hh_l0: -0.0009628063999116421 0.08444156497716904
encoder.encoder.bias_ih_l0: 0.003478585509583354 0.08795332908630371
encoder.encoder.bias_hh_l0: 0.016550570726394653 0.08533117175102234
encoder.encoder.weight_ih_l0_reverse: 0.0017073198687285185 0.08423911035060883
encoder.encoder.weight_hh_l0_reverse: 0.0005655965651385486 0.08318278938531876
encoder.encoder.bias_ih_l0_reverse: 0.010929320007562637 0.08193863183259964
encoder.encoder.bias_hh_l0_reverse: 0.011224014684557915 0.0888657495379448
decider.lstm.weight_ih_l0: -0.0016183897387236357 0.14596164226531982
decider.lstm.weight_hh_l0: 0.004144122824072838 0.1456989347934723
decider.lstm.bias_ih_l0: -0.020270437002182007 0.14191047847270966
decider.lstm.bias_hh_l0: 0.015550464391708374 0.15383519232273102
decider.linear1.weight: 0.004022593609988689 0.11969947814941406
decider.linear1.bias: 0.0060374541208148 0.11478382349014282
decider.linear2.weight: 0.0023206956684589386 0.053205233067274094
decider.linear2.bias: 0.0012678279308602214 0.05347064882516861
decider.linear3.weight: -0.0023554880172014236 0.056285224854946136
decider.linear3.bias: -0.015357261523604393 0.03244436904788017

Rewards:
74.4454
74.4454
74.4454
objective = 1.0585100650787354
==== episode 23600/75000 ====
action = 1
probs = 0.0000 0.9999 0.0000 0.0001

action = 1
probs = 0.0006 0.9961 0.0010 0.0023

action = 2
probs = 0.0041 0.0104 0.9665 0.0190

Learning rate: 6.2353e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011203995672985911 0.08337873965501785
encoder.encoder.weight_hh_l0: -0.0009822978172451258 0.08453623950481415
encoder.encoder.bias_ih_l0: 0.003861628705635667 0.08806704729795456
encoder.encoder.bias_hh_l0: 0.016933610662817955 0.0854249894618988
encoder.encoder.weight_ih_l0_reverse: 0.0017261563334614038 0.08428226411342621
encoder.encoder.weight_hh_l0_reverse: 0.0005645557539537549 0.08321983367204666
encoder.encoder.bias_ih_l0_reverse: 0.011198469437658787 0.08197586983442307
encoder.encoder.bias_hh_l0_reverse: 0.011493165977299213 0.0889398604631424
decider.lstm.weight_ih_l0: -0.0016260120319202542 0.14602050185203552
decider.lstm.weight_hh_l0: 0.004256553016602993 0.14576248824596405
decider.lstm.bias_ih_l0: -0.01987456902861595 0.1418958306312561
decider.lstm.bias_hh_l0: 0.01594632677733898 0.15385130047798157
decider.linear1.weight: 0.004052986390888691 0.11974400281906128
decider.linear1.bias: 0.0062178270891308784 0.1148168221116066
decider.linear2.weight: 0.0023756446316838264 0.05323418602347374
decider.linear2.bias: 0.0013592580799013376 0.053504928946495056
decider.linear3.weight: -0.002375165931880474 0.056351300328969955
decider.linear3.bias: -0.015390582382678986 0.03285377845168114

Rewards:
74.4454
74.4454
74.4454
objective = 0.94598788022995
==== episode 23700/75000 ====
action = 1
probs = 0.0000 0.9999 0.0000 0.0001

action = 1
probs = 0.0005 0.9967 0.0009 0.0019

action = 2
probs = 0.0029 0.0078 0.9760 0.0133

Learning rate: 6.2353e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011571054346859455 0.08344104886054993
encoder.encoder.weight_hh_l0: -0.0010092350421473384 0.08464036881923676
encoder.encoder.bias_ih_l0: 0.004295187070965767 0.08819657564163208
encoder.encoder.bias_hh_l0: 0.01736716739833355 0.08553285896778107
encoder.encoder.weight_ih_l0_reverse: 0.001753235817886889 0.0843275710940361
encoder.encoder.weight_hh_l0_reverse: 0.0005591533845290542 0.08326519280672073
encoder.encoder.bias_ih_l0_reverse: 0.01148468442261219 0.08202400803565979
encoder.encoder.bias_hh_l0_reverse: 0.011779381893575191 0.0889805480837822
decider.lstm.weight_ih_l0: -0.0016394986305385828 0.14607343077659607
decider.lstm.weight_hh_l0: 0.004381257575005293 0.14582490921020508
decider.lstm.bias_ih_l0: -0.019462045282125473 0.14186735451221466
decider.lstm.bias_hh_l0: 0.01635885052382946 0.15392646193504333
decider.linear1.weight: 0.004088076297193766 0.11979798227548599
decider.linear1.bias: 0.006411269772797823 0.11477961391210556
decider.linear2.weight: 0.002462850185111165 0.05327508971095085
decider.linear2.bias: 0.0014896078500896692 0.05350671708583832
decider.linear3.weight: -0.002451388631016016 0.05649974197149277
decider.linear3.bias: -0.015448764897882938 0.03320235759019852

Rewards:
74.4454
74.4454
74.4454
objective = 0.6862984895706177
==== episode 23800/75000 ====
action = 1
probs = 0.0000 0.9999 0.0000 0.0000

action = 1
probs = 0.0003 0.9976 0.0007 0.0013

action = 2
probs = 0.0023 0.0060 0.9808 0.0108

Learning rate: 6.2353e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011796014150604606 0.08347321301698685
encoder.encoder.weight_hh_l0: -0.0010267860488966107 0.08469920605421066
encoder.encoder.bias_ih_l0: 0.004541936330497265 0.08826788514852524
encoder.encoder.bias_hh_l0: 0.017613915726542473 0.08559734374284744
encoder.encoder.weight_ih_l0_reverse: 0.001773323048837483 0.0843546912074089
encoder.encoder.weight_hh_l0_reverse: 0.0005526199238374829 0.0832948237657547
encoder.encoder.bias_ih_l0_reverse: 0.011659026145935059 0.08205323666334152
encoder.encoder.bias_hh_l0_reverse: 0.011953726410865784 0.0889987051486969
decider.lstm.weight_ih_l0: -0.0016492578433826566 0.1461019068956375
decider.lstm.weight_hh_l0: 0.004454007372260094 0.1458558291196823
decider.lstm.bias_ih_l0: -0.019228145480155945 0.14183899760246277
decider.lstm.bias_hh_l0: 0.016592761501669884 0.15398286283016205
decider.linear1.weight: 0.004109853412955999 0.11983466893434525
decider.linear1.bias: 0.0065329959616065025 0.11474984139204025
decider.linear2.weight: 0.0025545586831867695 0.05333308130502701
decider.linear2.bias: 0.0016306859906762838 0.053435180336236954
decider.linear3.weight: -0.002620342653244734 0.05683686584234238
decider.linear3.bias: -0.015498051419854164 0.03328589349985123

Rewards:
74.4454
74.4454
74.4454
objective = 0.5406473875045776
==== episode 23900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9982 0.0006 0.0010

action = 2
probs = 0.0017 0.0040 0.9866 0.0077

Learning rate: 6.2353e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012071635574102402 0.08351589739322662
encoder.encoder.weight_hh_l0: -0.0010475559392943978 0.08478987216949463
encoder.encoder.bias_ih_l0: 0.004899823106825352 0.08835281431674957
encoder.encoder.bias_hh_l0: 0.01797179877758026 0.08568467199802399
encoder.encoder.weight_ih_l0_reverse: 0.0017970441840589046 0.08438705652952194
encoder.encoder.weight_hh_l0_reverse: 0.0005397312343120575 0.08333228528499603
encoder.encoder.bias_ih_l0_reverse: 0.011880828998982906 0.08208095282316208
encoder.encoder.bias_hh_l0_reverse: 0.01217553112655878 0.08900875598192215
decider.lstm.weight_ih_l0: -0.001664256094954908 0.14614123106002808
decider.lstm.weight_hh_l0: 0.004551151301711798 0.14589999616146088
decider.lstm.bias_ih_l0: -0.0189102403819561 0.1417955905199051
decider.lstm.bias_hh_l0: 0.01691065914928913 0.1540556401014328
decider.linear1.weight: 0.004138225689530373 0.11988130956888199
decider.linear1.bias: 0.0066840252839028835 0.11469665914773941
decider.linear2.weight: 0.0026200246065855026 0.053408313542604446
decider.linear2.bias: 0.0017572520300745964 0.05340291187167168
decider.linear3.weight: -0.0027352042961865664 0.05716821923851967
decider.linear3.bias: -0.01555030606687069 0.0334366038441658

Rewards:
74.4454
74.4454
74.4454
objective = 0.380241334438324
==== episode 24000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9987 0.0004 0.0007

action = 2
probs = 0.0020 0.0056 0.9820 0.0105

Learning rate: 6.1729e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00119776651263237 0.08350241184234619
encoder.encoder.weight_hh_l0: -0.0010396252619102597 0.08474305272102356
encoder.encoder.bias_ih_l0: 0.004716077353805304 0.08831514418125153
encoder.encoder.bias_hh_l0: 0.017788050696253777 0.08564407378435135
encoder.encoder.weight_ih_l0_reverse: 0.001788603374734521 0.08437703549861908
encoder.encoder.weight_hh_l0_reverse: 0.0005438409862108529 0.08331774175167084
encoder.encoder.bias_ih_l0_reverse: 0.01180376298725605 0.08207834511995316
encoder.encoder.bias_hh_l0_reverse: 0.012098459526896477 0.08902893215417862
decider.lstm.weight_ih_l0: -0.0016567830462008715 0.146127387881279
decider.lstm.weight_hh_l0: 0.004510147962719202 0.14587785303592682
decider.lstm.bias_ih_l0: -0.01905268058180809 0.14181609451770782
decider.lstm.bias_hh_l0: 0.01676821894943714 0.15401242673397064
decider.linear1.weight: 0.0041271294467151165 0.1198681890964508
decider.linear1.bias: 0.0066350121051073074 0.11476745456457138
decider.linear2.weight: 0.00261030625551939 0.053437769412994385
decider.linear2.bias: 0.0017467528814449906 0.053388889878988266
decider.linear3.weight: -0.0027952820528298616 0.05734478309750557
decider.linear3.bias: -0.015548798255622387 0.03329017385840416

Rewards:
74.4454
74.4454
74.4454
objective = 0.4846303462982178
==== episode 24100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9989 0.0003 0.0006

action = 2
probs = 0.0017 0.0043 0.9848 0.0092

Learning rate: 6.1729e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012098796432837844 0.08351605385541916
encoder.encoder.weight_hh_l0: -0.0010505393147468567 0.08477521687746048
encoder.encoder.bias_ih_l0: 0.004847495350986719 0.0883566215634346
encoder.encoder.bias_hh_l0: 0.017919467762112617 0.08568132668733597
encoder.encoder.weight_ih_l0_reverse: 0.001801908714696765 0.08439263701438904
encoder.encoder.weight_hh_l0_reverse: 0.0005408047582022846 0.0833367332816124
encoder.encoder.bias_ih_l0_reverse: 0.011897568590939045 0.08209370076656342
encoder.encoder.bias_hh_l0_reverse: 0.01219227071851492 0.089030921459198
decider.lstm.weight_ih_l0: -0.001662351656705141 0.1461406648159027
decider.lstm.weight_hh_l0: 0.00454992800951004 0.1458939164876938
decider.lstm.bias_ih_l0: -0.018920840695500374 0.14179129898548126
decider.lstm.bias_hh_l0: 0.016900070011615753 0.15405407547950745
decider.linear1.weight: 0.0041392212733626366 0.11989125609397888
decider.linear1.bias: 0.006705101579427719 0.11473613232374191
decider.linear2.weight: 0.002652122639119625 0.053487420082092285
decider.linear2.bias: 0.0018126326613128185 0.053376454859972
decider.linear3.weight: -0.0028644083067774773 0.05757112801074982
decider.linear3.bias: -0.01559290662407875 0.03324480727314949

Rewards:
74.4454
74.4454
74.4454
objective = 0.40808600187301636
==== episode 24200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9985 0.0004 0.0008

action = 2
probs = 0.0018 0.0036 0.9847 0.0099

Learning rate: 6.1729e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011607264168560505 0.08344003558158875
encoder.encoder.weight_hh_l0: -0.0010160076199099422 0.08466211706399918
encoder.encoder.bias_ih_l0: 0.0043876683339476585 0.08824080973863602
encoder.encoder.bias_hh_l0: 0.01745964027941227 0.08557359874248505
encoder.encoder.weight_ih_l0_reverse: 0.001768551766872406 0.08434195071458817
encoder.encoder.weight_hh_l0_reverse: 0.0005566413165070117 0.08328601717948914
encoder.encoder.bias_ih_l0_reverse: 0.011523401364684105 0.08205792307853699
encoder.encoder.bias_hh_l0_reverse: 0.011818106286227703 0.08893997967243195
decider.lstm.weight_ih_l0: -0.0016420820029452443 0.1460695117712021
decider.lstm.weight_hh_l0: 0.004410964902490377 0.14583101868629456
decider.lstm.bias_ih_l0: -0.019390026107430458 0.14183196425437927
decider.lstm.bias_hh_l0: 0.01643087901175022 0.15404054522514343
decider.linear1.weight: 0.004105515778064728 0.11982773244380951
decider.linear1.bias: 0.006460798438638449 0.11463035643100739
decider.linear2.weight: 0.0025681019760668278 0.05347948521375656
decider.linear2.bias: 0.0016929481644183397 0.05332273989915848
decider.linear3.weight: -0.0028910664841532707 0.05761953815817833
decider.linear3.bias: -0.015538277104496956 0.032891012728214264

Rewards:
74.4454
74.4454
74.4454
objective = 0.4209021329879761
==== episode 24300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9986 0.0004 0.0007

action = 2
probs = 0.0013 0.0026 0.9888 0.0073

Learning rate: 6.1729e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011853041360154748 0.08348660916090012
encoder.encoder.weight_hh_l0: -0.001033012056723237 0.08475092053413391
encoder.encoder.bias_ih_l0: 0.004735314287245274 0.08833849430084229
encoder.encoder.bias_hh_l0: 0.017807288095355034 0.08565638214349747
encoder.encoder.weight_ih_l0_reverse: 0.0017898035002872348 0.08437807112932205
encoder.encoder.weight_hh_l0_reverse: 0.0005511214258149266 0.08332393318414688
encoder.encoder.bias_ih_l0_reverse: 0.011733212508261204 0.08208783715963364
encoder.encoder.bias_hh_l0_reverse: 0.012027915567159653 0.08896244317293167
decider.lstm.weight_ih_l0: -0.0016523468075320125 0.1461130827665329
decider.lstm.weight_hh_l0: 0.004499324597418308 0.1458822786808014
decider.lstm.bias_ih_l0: -0.019057655707001686 0.14180880784988403
decider.lstm.bias_hh_l0: 0.016763249412178993 0.15409767627716064
decider.linear1.weight: 0.004130220040678978 0.11987075954675674
decider.linear1.bias: 0.0066065238788723946 0.11459330469369888
decider.linear2.weight: 0.0026031406596302986 0.05352090299129486
decider.linear2.bias: 0.001775915501639247 0.05333220586180687
decider.linear3.weight: -0.002961348043754697 0.057815082371234894
decider.linear3.bias: -0.015581751242280006 0.03305814415216446

Rewards:
74.4454
74.4454
74.4454
objective = 0.3167083263397217
==== episode 24400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9987 0.0004 0.0007

action = 2
probs = 0.0011 0.0021 0.9911 0.0058

Learning rate: 6.1729e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001203698106110096 0.08352073282003403
encoder.encoder.weight_hh_l0: -0.0010457831667736173 0.08481983095407486
encoder.encoder.bias_ih_l0: 0.004998084623366594 0.08840582519769669
encoder.encoder.bias_hh_l0: 0.01807006075978279 0.08571912348270416
encoder.encoder.weight_ih_l0_reverse: 0.001807543565519154 0.08440462499856949
encoder.encoder.weight_hh_l0_reverse: 0.0005427864962257445 0.08335335552692413
encoder.encoder.bias_ih_l0_reverse: 0.011899754405021667 0.0821077898144722
encoder.encoder.bias_hh_l0_reverse: 0.012194455601274967 0.08897978812456131
decider.lstm.weight_ih_l0: -0.0016626347787678242 0.14614711701869965
decider.lstm.weight_hh_l0: 0.0045671891421079636 0.14592048525810242
decider.lstm.bias_ih_l0: -0.018805228173732758 0.14178358018398285
decider.lstm.bias_hh_l0: 0.017015676945447922 0.15413735806941986
decider.linear1.weight: 0.004149397369474173 0.1199057474732399
decider.linear1.bias: 0.006719666067510843 0.11457706242799759
decider.linear2.weight: 0.0026206050533801317 0.053562846034765244
decider.linear2.bias: 0.0018384138820692897 0.053342390805482864
decider.linear3.weight: -0.003020716831088066 0.057985708117485046
decider.linear3.bias: -0.015614394098520279 0.03317009285092354

Rewards:
74.4454
74.4454
74.4454
objective = 0.25524720549583435
==== episode 24500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0004 0.9982 0.0005 0.0009

action = 2
probs = 0.0017 0.0032 0.9856 0.0094

Learning rate: 6.1112e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011369010899215937 0.08341450989246368
encoder.encoder.weight_hh_l0: -0.0010013931896537542 0.08462969958782196
encoder.encoder.bias_ih_l0: 0.004223593510687351 0.08818527311086655
encoder.encoder.bias_hh_l0: 0.01729556731879711 0.0855272114276886
encoder.encoder.weight_ih_l0_reverse: 0.0017484567360952497 0.08431953191757202
encoder.encoder.weight_hh_l0_reverse: 0.0005664320779033005 0.08326421678066254
encoder.encoder.bias_ih_l0_reverse: 0.011354113928973675 0.08204197138547897
encoder.encoder.bias_hh_l0_reverse: 0.011648817919194698 0.08888472616672516
decider.lstm.weight_ih_l0: -0.0016328635392710567 0.1460411548614502
decider.lstm.weight_hh_l0: 0.004356752149760723 0.14581555128097534
decider.lstm.bias_ih_l0: -0.019585536792874336 0.1418321430683136
decider.lstm.bias_hh_l0: 0.016235359013080597 0.15403883159160614
decider.linear1.weight: 0.004094691481441259 0.11980204284191132
decider.linear1.bias: 0.006344504654407501 0.11456853896379471
decider.linear2.weight: 0.0024888068437576294 0.05351702496409416
decider.linear2.bias: 0.0016240105032920837 0.053294502198696136
decider.linear3.weight: -0.003026883117854595 0.05793369561433792
decider.linear3.bias: -0.01551153976470232 0.032808538526296616

Rewards:
74.4454
74.4454
74.4454
objective = 0.4044262170791626
==== episode 24600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0004 0.9984 0.0005 0.0008

action = 2
probs = 0.0015 0.0028 0.9871 0.0086

Learning rate: 6.1112e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011508835013955832 0.08343993872404099
encoder.encoder.weight_hh_l0: -0.0010109771974384785 0.0846705511212349
encoder.encoder.bias_ih_l0: 0.004392064642161131 0.0882422998547554
encoder.encoder.bias_hh_l0: 0.017464039847254753 0.08557167649269104
encoder.encoder.weight_ih_l0_reverse: 0.001762333675287664 0.08434166759252548
encoder.encoder.weight_hh_l0_reverse: 0.0005656154244206846 0.08328632265329361
encoder.encoder.bias_ih_l0_reverse: 0.011472787708044052 0.08206281065940857
encoder.encoder.bias_hh_l0_reverse: 0.011767493560910225 0.08890790492296219
decider.lstm.weight_ih_l0: -0.0016366601921617985 0.14606481790542603
decider.lstm.weight_hh_l0: 0.0044039152562618256 0.14584100246429443
decider.lstm.bias_ih_l0: -0.01940428465604782 0.14182579517364502
decider.lstm.bias_hh_l0: 0.016416609287261963 0.15406852960586548
decider.linear1.weight: 0.004106898792088032 0.11982671916484833
decider.linear1.bias: 0.006428403779864311 0.1145600751042366
decider.linear2.weight: 0.0025205493438988924 0.053540829569101334
decider.linear2.bias: 0.001675211708061397 0.05330636352300644
decider.linear3.weight: -0.003086935030296445 0.05809786915779114
decider.linear3.bias: -0.0155460424721241 0.0328037366271019

Rewards:
74.4454
74.4454
74.4454
objective = 0.36212849617004395
==== episode 24700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9986 0.0004 0.0007

action = 2
probs = 0.0015 0.0034 0.9859 0.0091

Learning rate: 6.1112e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001154668047092855 0.08345510810613632
encoder.encoder.weight_hh_l0: -0.0010124630061909556 0.0846790298819542
encoder.encoder.bias_ih_l0: 0.004415333271026611 0.0882495567202568
encoder.encoder.bias_hh_l0: 0.017487306147813797 0.08557814359664917
encoder.encoder.weight_ih_l0_reverse: 0.0017638837452977896 0.08434753119945526
encoder.encoder.weight_hh_l0_reverse: 0.0005651359679177403 0.08328887820243835
encoder.encoder.bias_ih_l0_reverse: 0.011510920710861683 0.08207151293754578
encoder.encoder.bias_hh_l0_reverse: 0.011805624701082706 0.08893617242574692
decider.lstm.weight_ih_l0: -0.0016364929033443332 0.14607393741607666
decider.lstm.weight_hh_l0: 0.004413148853927851 0.1458500176668167
decider.lstm.bias_ih_l0: -0.019369803369045258 0.14182434976100922
decider.lstm.bias_hh_l0: 0.01645108312368393 0.15405966341495514
decider.linear1.weight: 0.004110798239707947 0.11983071267604828
decider.linear1.bias: 0.006461570039391518 0.1146167516708374
decider.linear2.weight: 0.0025319401174783707 0.053548384457826614
decider.linear2.bias: 0.0016903881914913654 0.05332186818122864
decider.linear3.weight: -0.003122088499367237 0.05820505693554878
decider.linear3.bias: -0.015544574707746506 0.03297063708305359

Rewards:
74.4454
74.4454
74.4454
objective = 0.38677605986595154
==== episode 24800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9987 0.0004 0.0006

action = 2
probs = 0.0011 0.0025 0.9897 0.0067

Learning rate: 6.1112e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001179137616418302 0.0835023745894432
encoder.encoder.weight_hh_l0: -0.0010305825853720307 0.08476680517196655
encoder.encoder.bias_ih_l0: 0.004761914722621441 0.08835943043231964
encoder.encoder.bias_hh_l0: 0.017833886668086052 0.08566344529390335
encoder.encoder.weight_ih_l0_reverse: 0.0017872777534648776 0.08438615500926971
encoder.encoder.weight_hh_l0_reverse: 0.0005617153947241604 0.08332961797714233
encoder.encoder.bias_ih_l0_reverse: 0.01172074768692255 0.0821058601140976
encoder.encoder.bias_hh_l0_reverse: 0.012015450745821 0.08896475285291672
decider.lstm.weight_ih_l0: -0.0016462031053379178 0.1461196392774582
decider.lstm.weight_hh_l0: 0.00450578797608614 0.145902618765831
decider.lstm.bias_ih_l0: -0.019026566296815872 0.14181120693683624
decider.lstm.bias_hh_l0: 0.016794327646493912 0.15411777794361115
decider.linear1.weight: 0.0041375188156962395 0.11987489461898804
decider.linear1.bias: 0.006618564948439598 0.11458061635494232
decider.linear2.weight: 0.002587971743196249 0.053581222891807556
decider.linear2.bias: 0.0017842703964561224 0.05333654209971428
decider.linear3.weight: -0.003174893092364073 0.05837272107601166
decider.linear3.bias: -0.015590987168252468 0.033148378133773804

Rewards:
74.4454
74.4454
74.4454
objective = 0.2889024615287781
==== episode 24900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9988 0.0004 0.0005

action = 2
probs = 0.0009 0.0019 0.9921 0.0052

Learning rate: 6.1112e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011996030807495117 0.08354120701551437
encoder.encoder.weight_hh_l0: -0.0010458993492648005 0.08484462648630142
encoder.encoder.bias_ih_l0: 0.005059188697487116 0.08844581991434097
encoder.encoder.bias_hh_l0: 0.018131157383322716 0.0857357606291771
encoder.encoder.weight_ih_l0_reverse: 0.0018078585853800178 0.08441758900880814
encoder.encoder.weight_hh_l0_reverse: 0.0005549259949475527 0.08336400240659714
encoder.encoder.bias_ih_l0_reverse: 0.011903168633580208 0.08213036507368088
encoder.encoder.bias_hh_l0_reverse: 0.012197870761156082 0.08898752182722092
decider.lstm.weight_ih_l0: -0.0016571636078879237 0.1461593508720398
decider.lstm.weight_hh_l0: 0.0045855408534407616 0.14594681560993195
decider.lstm.bias_ih_l0: -0.018735714256763458 0.1417897343635559
decider.lstm.bias_hh_l0: 0.017085177823901176 0.15416669845581055
decider.linear1.weight: 0.004161351826041937 0.11991464346647263
decider.linear1.bias: 0.00675567053258419 0.11455810815095901
decider.linear2.weight: 0.0026303837075829506 0.05361354351043701
decider.linear2.bias: 0.0018622641218826175 0.05334978923201561
decider.linear3.weight: -0.003222729079425335 0.05852974206209183
decider.linear3.bias: -0.01562771201133728 0.03330050781369209

Rewards:
74.4454
74.4454
74.4454
objective = 0.22709837555885315
==== episode 25000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9990 0.0003 0.0005

action = 2
probs = 0.0012 0.0030 0.9883 0.0076

Learning rate: 6.0501e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011881091631948948 0.08352786302566528
encoder.encoder.weight_hh_l0: -0.001033966545946896 0.08478438854217529
encoder.encoder.bias_ih_l0: 0.004825532902032137 0.08837290108203888
encoder.encoder.bias_hh_l0: 0.017897499725222588 0.08567588031291962
encoder.encoder.weight_ih_l0_reverse: 0.001789830275811255 0.08439594507217407
encoder.encoder.weight_hh_l0_reverse: 0.0005588342319242656 0.08333756029605865
encoder.encoder.bias_ih_l0_reverse: 0.011801834218204021 0.08212172985076904
encoder.encoder.bias_hh_l0_reverse: 0.01209653913974762 0.08899497240781784
decider.lstm.weight_ih_l0: -0.0016480261692777276 0.14613565802574158
decider.lstm.weight_hh_l0: 0.004525654949247837 0.14591674506664276
decider.lstm.bias_ih_l0: -0.018957063555717468 0.1418256312608719
decider.lstm.bias_hh_l0: 0.016863830387592316 0.15408819913864136
decider.linear1.weight: 0.004141577985137701 0.11988455057144165
decider.linear1.bias: 0.006659427657723427 0.11464101821184158
decider.linear2.weight: 0.0025929268449544907 0.05360525846481323
decider.linear2.bias: 0.0018032644875347614 0.05335661768913269
decider.linear3.weight: -0.0032431932631880045 0.05857006832957268
decider.linear3.bias: -0.01560567319393158 0.033208899199962616

Rewards:
74.4454
74.4454
74.4454
objective = 0.3179902732372284
==== episode 25100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9993 0.0002 0.0003

action = 2
probs = 0.0013 0.0051 0.9857 0.0079

Learning rate: 6.0501e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011991900391876698 0.08357152342796326
encoder.encoder.weight_hh_l0: -0.001039452850818634 0.08483105152845383
encoder.encoder.bias_ih_l0: 0.004986284766346216 0.08840100467205048
encoder.encoder.bias_hh_l0: 0.018058251589536667 0.0856950432062149
encoder.encoder.weight_ih_l0_reverse: 0.0017889230512082577 0.08440705388784409
encoder.encoder.weight_hh_l0_reverse: 0.0005544713931158185 0.08334281295537949
encoder.encoder.bias_ih_l0_reverse: 0.011919030919671059 0.08213138580322266
encoder.encoder.bias_hh_l0_reverse: 0.012213732115924358 0.0890394076704979
decider.lstm.weight_ih_l0: -0.0016531702131032944 0.1461668461561203
decider.lstm.weight_hh_l0: 0.004564705770462751 0.145945742726326
decider.lstm.bias_ih_l0: -0.018823491409420967 0.1418381631374359
decider.lstm.bias_hh_l0: 0.016997408121824265 0.15404540300369263
decider.linear1.weight: 0.004155067726969719 0.11989161372184753
decider.linear1.bias: 0.0067288074642419815 0.11473983526229858
decider.linear2.weight: 0.0026025627739727497 0.053608253598213196
decider.linear2.bias: 0.0018223500810563564 0.05337909609079361
decider.linear3.weight: -0.00325651653110981 0.058630477637052536
decider.linear3.bias: -0.015583801083266735 0.033727556467056274

Rewards:
74.4454
74.4454
74.4454
objective = 0.37555059790611267
==== episode 25200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9993 0.0002 0.0003

action = 2
probs = 0.0009 0.0034 0.9900 0.0057

Learning rate: 6.0501e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012172673596069217 0.08360191434621811
encoder.encoder.weight_hh_l0: -0.0010576285421848297 0.08490043878555298
encoder.encoder.bias_ih_l0: 0.005243837833404541 0.08848775923252106
encoder.encoder.bias_hh_l0: 0.01831580512225628 0.08576320856809616
encoder.encoder.weight_ih_l0_reverse: 0.0018086933996528387 0.08443676680326462
encoder.encoder.weight_hh_l0_reverse: 0.0005524566513486207 0.08337636291980743
encoder.encoder.bias_ih_l0_reverse: 0.01205386407673359 0.08215509355068207
encoder.encoder.bias_hh_l0_reverse: 0.012348562479019165 0.08905456960201263
decider.lstm.weight_ih_l0: -0.0016618948429822922 0.14619730412960052
decider.lstm.weight_hh_l0: 0.00463622622191906 0.14598365128040314
decider.lstm.bias_ih_l0: -0.01858566515147686 0.14181090891361237
decider.lstm.bias_hh_l0: 0.01723523437976837 0.15412728488445282
decider.linear1.weight: 0.004179692827165127 0.11992871761322021
decider.linear1.bias: 0.006861028261482716 0.1146836131811142
decider.linear2.weight: 0.002653361763805151 0.053637370467185974
decider.linear2.bias: 0.0019031083211302757 0.053395308554172516
decider.linear3.weight: -0.0032977641094475985 0.05875961482524872
decider.linear3.bias: -0.015641115605831146 0.03386329114437103

Rewards:
74.4454
74.4454
74.4454
objective = 0.26791054010391235
==== episode 25300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0004 0.9987 0.0004 0.0005

action = 2
probs = 0.0010 0.0026 0.9907 0.0057

Learning rate: 6.0501e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011679428862407804 0.08352342247962952
encoder.encoder.weight_hh_l0: -0.0010244279401376843 0.08479399979114532
encoder.encoder.bias_ih_l0: 0.0048057157546281815 0.0883701741695404
encoder.encoder.bias_hh_l0: 0.01787768304347992 0.08565190434455872
encoder.encoder.weight_ih_l0_reverse: 0.001772560877725482 0.08438435941934586
encoder.encoder.weight_hh_l0_reverse: 0.0005678277811966836 0.08332677185535431
encoder.encoder.bias_ih_l0_reverse: 0.011671972461044788 0.08210919052362442
encoder.encoder.bias_hh_l0_reverse: 0.011966672725975513 0.08895359188318253
decider.lstm.weight_ih_l0: -0.0016424068016931415 0.14612479507923126
decider.lstm.weight_hh_l0: 0.004505998454988003 0.1459258794784546
decider.lstm.bias_ih_l0: -0.01902809739112854 0.14182686805725098
decider.lstm.bias_hh_l0: 0.01679280214011669 0.15411320328712463
decider.linear1.weight: 0.004147361032664776 0.11986595392227173
decider.linear1.bias: 0.0066085150465369225 0.11455374956130981
decider.linear2.weight: 0.0025814599357545376 0.05361103266477585
decider.linear2.bias: 0.001773577881976962 0.053326770663261414
decider.linear3.weight: -0.003317791037261486 0.05875846743583679
decider.linear3.bias: -0.01556263118982315 0.03353756666183472

Rewards:
74.4454
74.4454
74.4454
objective = 0.26264798641204834
==== episode 25400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9988 0.0004 0.0005

action = 2
probs = 0.0008 0.0020 0.9929 0.0044

Learning rate: 6.0501e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011856795754283667 0.08355916291475296
encoder.encoder.weight_hh_l0: -0.0010389868402853608 0.0848647803068161
encoder.encoder.bias_ih_l0: 0.005074193235486746 0.08845631033182144
encoder.encoder.bias_hh_l0: 0.01814616098999977 0.08572132885456085
encoder.encoder.weight_ih_l0_reverse: 0.0017928824527189136 0.08441568166017532
encoder.encoder.weight_hh_l0_reverse: 0.0005631637177430093 0.08335956186056137
encoder.encoder.bias_ih_l0_reverse: 0.011834056116640568 0.08213386684656143
encoder.encoder.bias_hh_l0_reverse: 0.012128754518926144 0.08898089826107025
decider.lstm.weight_ih_l0: -0.001651084516197443 0.14616188406944275
decider.lstm.weight_hh_l0: 0.004578564316034317 0.1459670066833496
decider.lstm.bias_ih_l0: -0.018762249499559402 0.1418091058731079
decider.lstm.bias_hh_l0: 0.01705864816904068 0.15417681634426117
decider.linear1.weight: 0.004170989617705345 0.11990436911582947
decider.linear1.bias: 0.006746737286448479 0.1145331859588623
decider.linear2.weight: 0.0026275210548192263 0.053643111139535904
decider.linear2.bias: 0.0018535038689151406 0.05334173142910004
decider.linear3.weight: -0.003366866149008274 0.05892382562160492
decider.linear3.bias: -0.015601444989442825 0.033683277666568756

Rewards:
74.4454
74.4454
74.4454
objective = 0.2070765197277069
==== episode 25500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9989 0.0004 0.0004

action = 2
probs = 0.0006 0.0016 0.9943 0.0035

Learning rate: 5.9896e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012015564134344459 0.0835902988910675
encoder.encoder.weight_hh_l0: -0.0010513020679354668 0.08492861688137054
encoder.encoder.bias_ih_l0: 0.005310858599841595 0.0885266661643982
encoder.encoder.bias_hh_l0: 0.018382828682661057 0.08578182011842728
encoder.encoder.weight_ih_l0_reverse: 0.0018112632678821683 0.08444231748580933
encoder.encoder.weight_hh_l0_reverse: 0.0005564640741795301 0.08338826894760132
encoder.encoder.bias_ih_l0_reverse: 0.011984817683696747 0.08215424418449402
encoder.encoder.bias_hh_l0_reverse: 0.012279519811272621 0.08900266140699387
decider.lstm.weight_ih_l0: -0.0016604126431047916 0.14619538187980652
decider.lstm.weight_hh_l0: 0.004642116837203503 0.14600344002246857
decider.lstm.bias_ih_l0: -0.018529536202549934 0.1417926549911499
decider.lstm.bias_hh_l0: 0.0172913558781147 0.15422575175762177
decider.linear1.weight: 0.004192426800727844 0.11993933469057083
decider.linear1.bias: 0.006871744524687529 0.11452190577983856
decider.linear2.weight: 0.002660248428583145 0.053678568452596664
decider.linear2.bias: 0.0019233889179304242 0.05335446447134018
decider.linear3.weight: -0.003412277903407812 0.05908079817891121
decider.linear3.bias: -0.01563344895839691 0.033813126385211945

Rewards:
74.4454
74.4454
74.4454
objective = 0.1699138581752777
==== episode 25600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9990 0.0004 0.0004

action = 2
probs = 0.0005 0.0013 0.9952 0.0029

Learning rate: 5.9896e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001216141157783568 0.08361797779798508
encoder.encoder.weight_hh_l0: -0.0010621180990710855 0.08498688787221909
encoder.encoder.bias_ih_l0: 0.00552239129319787 0.0885847955942154
encoder.encoder.bias_hh_l0: 0.01859435811638832 0.08583579957485199
encoder.encoder.weight_ih_l0_reverse: 0.0018279330106452107 0.08446546643972397
encoder.encoder.weight_hh_l0_reverse: 0.0005483442218974233 0.08341354876756668
encoder.encoder.bias_ih_l0_reverse: 0.012126919813454151 0.08217029273509979
encoder.encoder.bias_hh_l0_reverse: 0.0124216228723526 0.08902298659086227
decider.lstm.weight_ih_l0: -0.0016700518317520618 0.14622585475444794
decider.lstm.weight_hh_l0: 0.004699356853961945 0.14603541791439056
decider.lstm.bias_ih_l0: -0.018320690840482712 0.14177727699279785
decider.lstm.bias_hh_l0: 0.017500197514891624 0.15426397323608398
decider.linear1.weight: 0.0042096273973584175 0.11996695399284363
decider.linear1.bias: 0.006971077062189579 0.11452145874500275
decider.linear2.weight: 0.002686156891286373 0.05371592938899994
decider.linear2.bias: 0.0019873199053108692 0.05336993932723999
decider.linear3.weight: -0.0034542158246040344 0.05922878533601761
decider.linear3.bias: -0.015660585835576057 0.03392967954277992

Rewards:
74.4454
74.4454
74.4454
objective = 0.14371012151241302
==== episode 25700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9991 0.0003 0.0004

action = 2
probs = 0.0005 0.0014 0.9947 0.0034

Learning rate: 5.9896e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012117165606468916 0.08361255377531052
encoder.encoder.weight_hh_l0: -0.0010599115630611777 0.08496677130460739
encoder.encoder.bias_ih_l0: 0.0054487562738358974 0.08856719732284546
encoder.encoder.bias_hh_l0: 0.018520725890994072 0.08581948280334473
encoder.encoder.weight_ih_l0_reverse: 0.0018249725690111518 0.08446065336465836
encoder.encoder.weight_hh_l0_reverse: 0.0005493902135640383 0.08340663462877274
encoder.encoder.bias_ih_l0_reverse: 0.012097789905965328 0.08216827362775803
encoder.encoder.bias_hh_l0_reverse: 0.012392492964863777 0.08902619034051895
decider.lstm.weight_ih_l0: -0.0016676922095939517 0.1462186574935913
decider.lstm.weight_hh_l0: 0.004685599356889725 0.1460266262292862
decider.lstm.bias_ih_l0: -0.01837156154215336 0.14177265763282776
decider.lstm.bias_hh_l0: 0.017449328675866127 0.1542569100856781
decider.linear1.weight: 0.0042016590014100075 0.11996342241764069
decider.linear1.bias: 0.006941549479961395 0.11453628540039062
decider.linear2.weight: 0.0026684203185141087 0.05373122915625572
decider.linear2.bias: 0.001972783822566271 0.053372614085674286
decider.linear3.weight: -0.0034869404044002295 0.05932210385799408
decider.linear3.bias: -0.015665553510189056 0.03378388285636902

Rewards:
74.4454
74.4454
74.4454
objective = 0.1550038456916809
==== episode 25800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9991 0.0003 0.0003

action = 2
probs = 0.0004 0.0012 0.9955 0.0029

Learning rate: 5.9896e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012268527643755078 0.08363718539476395
encoder.encoder.weight_hh_l0: -0.0010701228165999055 0.0850188136100769
encoder.encoder.bias_ih_l0: 0.0056383959017694 0.08862107992172241
encoder.encoder.bias_hh_l0: 0.018710361793637276 0.08587025105953217
encoder.encoder.weight_ih_l0_reverse: 0.0018397349631413817 0.08448194712400436
encoder.encoder.weight_hh_l0_reverse: 0.0005424259579740465 0.0834304615855217
encoder.encoder.bias_ih_l0_reverse: 0.012226135469973087 0.08218435198068619
encoder.encoder.bias_hh_l0_reverse: 0.012520839460194111 0.08904355764389038
decider.lstm.weight_ih_l0: -0.0016760858707129955 0.1462453305721283
decider.lstm.weight_hh_l0: 0.004735753405839205 0.14605385065078735
decider.lstm.bias_ih_l0: -0.01818818226456642 0.14176344871520996
decider.lstm.bias_hh_l0: 0.01763271354138851 0.15428757667541504
decider.linear1.weight: 0.0042197201400995255 0.11999239772558212
decider.linear1.bias: 0.007047863677144051 0.11453498899936676
decider.linear2.weight: 0.0027024438604712486 0.05375693365931511
decider.linear2.bias: 0.0020338473841547966 0.053386390209198
decider.linear3.weight: -0.0035252568777650595 0.05945725366473198
decider.linear3.bias: -0.015690887346863747 0.033881187438964844

Rewards:
74.4454
74.4454
74.4454
objective = 0.13326942920684814
==== episode 25900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9992 0.0003 0.0003

action = 2
probs = 0.0004 0.0010 0.9962 0.0024

Learning rate: 5.9896e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012417121324688196 0.08366218954324722
encoder.encoder.weight_hh_l0: -0.0010804112534970045 0.0850737988948822
encoder.encoder.bias_ih_l0: 0.005833085160702467 0.08867260068655014
encoder.encoder.bias_hh_l0: 0.018905051052570343 0.08592025935649872
encoder.encoder.weight_ih_l0_reverse: 0.0018545635975897312 0.08450276404619217
encoder.encoder.weight_hh_l0_reverse: 0.0005341895739547908 0.08345428109169006
encoder.encoder.bias_ih_l0_reverse: 0.012358446605503559 0.08219857513904572
encoder.encoder.bias_hh_l0_reverse: 0.012653151527047157 0.08906036615371704
decider.lstm.weight_ih_l0: -0.0016856231959536672 0.1462729424238205
decider.lstm.weight_hh_l0: 0.00478732492774725 0.14608177542686462
decider.lstm.bias_ih_l0: -0.018001383170485497 0.14175130426883698
decider.lstm.bias_hh_l0: 0.017819521948695183 0.15431664884090424
decider.linear1.weight: 0.00423815380781889 0.12002194672822952
decider.linear1.bias: 0.007154626771807671 0.11453472077846527
decider.linear2.weight: 0.002826339565217495 0.05379359796643257
decider.linear2.bias: 0.0022561727091670036 0.05319773778319359
decider.linear3.weight: -0.003656239714473486 0.05962454155087471
decider.linear3.bias: -0.01571451872587204 0.033989280462265015

Rewards:
74.4454
74.4454
74.4454
objective = 0.1126503050327301
==== episode 26000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9987 0.0005 0.0004

action = 2
probs = 0.0002 0.0008 0.9972 0.0018

Learning rate: 5.9297e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001199140097014606 0.08358881622552872
encoder.encoder.weight_hh_l0: -0.0010532211745157838 0.08497882634401321
encoder.encoder.bias_ih_l0: 0.005455334205180407 0.08857189118862152
encoder.encoder.bias_hh_l0: 0.018527302891016006 0.08582083135843277
encoder.encoder.weight_ih_l0_reverse: 0.0018206670647487044 0.08445623517036438
encoder.encoder.weight_hh_l0_reverse: 0.0005533986259251833 0.08341078460216522
encoder.encoder.bias_ih_l0_reverse: 0.012012839317321777 0.0821562185883522
encoder.encoder.bias_hh_l0_reverse: 0.012307546101510525 0.08895905315876007
decider.lstm.weight_ih_l0: -0.0016659676330164075 0.14620672166347504
decider.lstm.weight_hh_l0: 0.004672032780945301 0.14603164792060852
decider.lstm.bias_ih_l0: -0.01841602474451065 0.14176271855831146
decider.lstm.bias_hh_l0: 0.017404887825250626 0.15430496633052826
decider.linear1.weight: 0.004216307308524847 0.11996541917324066
decider.linear1.bias: 0.006934302859008312 0.11438792198896408
decider.linear2.weight: 0.0028725937008857727 0.05382070317864418
decider.linear2.bias: 0.0023196376860141754 0.05296113342046738
decider.linear3.weight: -0.00371388322673738 0.059784695506095886
decider.linear3.bias: -0.0156491007655859 0.03379743918776512

Rewards:
74.4454
74.4454
74.4454
objective = 0.10130895674228668
==== episode 26100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0003 0.9990 0.0004 0.0003

action = 2
probs = 0.0003 0.0011 0.9966 0.0019

Learning rate: 5.9297e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001190106151625514 0.0835782065987587
encoder.encoder.weight_hh_l0: -0.0010454721050336957 0.08493734896183014
encoder.encoder.bias_ih_l0: 0.005296255461871624 0.0885239914059639
encoder.encoder.bias_hh_l0: 0.01836821809411049 0.08577881753444672
encoder.encoder.weight_ih_l0_reverse: 0.0018083035247400403 0.08444035053253174
encoder.encoder.weight_hh_l0_reverse: 0.0005572948721237481 0.08338924497365952
encoder.encoder.bias_ih_l0_reverse: 0.011929205618798733 0.08215797692537308
encoder.encoder.bias_hh_l0_reverse: 0.01222391240298748 0.08895435184240341
decider.lstm.weight_ih_l0: -0.0016597635112702847 0.1461888700723648
decider.lstm.weight_hh_l0: 0.004630345851182938 0.14601455628871918
decider.lstm.bias_ih_l0: -0.01857137680053711 0.14178292453289032
decider.lstm.bias_hh_l0: 0.017249539494514465 0.15426281094551086
decider.linear1.weight: 0.004200589843094349 0.11994059383869171
decider.linear1.bias: 0.00685786921530962 0.11445485055446625
decider.linear2.weight: 0.002859576838091016 0.053823281079530716
decider.linear2.bias: 0.002279372652992606 0.0529651865363121
decider.linear3.weight: -0.0037550530396401882 0.05991160869598389
decider.linear3.bias: -0.01562712900340557 0.03407427296042442

Rewards:
74.4454
74.4454
74.4454
objective = 0.1084628701210022
==== episode 26200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9994 0.0002 0.0002

action = 2
probs = 0.0006 0.0035 0.9930 0.0029

Learning rate: 5.9297e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001170371426269412 0.08355341106653214
encoder.encoder.weight_hh_l0: -0.0010255506495013833 0.08484329283237457
encoder.encoder.bias_ih_l0: 0.004919666331261396 0.08839485794305801
encoder.encoder.bias_hh_l0: 0.017991632223129272 0.08567742258310318
encoder.encoder.weight_ih_l0_reverse: 0.0017874634359031916 0.08440175652503967
encoder.encoder.weight_hh_l0_reverse: 0.0005570909706875682 0.08333880454301834
encoder.encoder.bias_ih_l0_reverse: 0.011796791106462479 0.08215514570474625
encoder.encoder.bias_hh_l0_reverse: 0.012091499753296375 0.08894947916269302
decider.lstm.weight_ih_l0: -0.001651792787015438 0.1461523324251175
decider.lstm.weight_hh_l0: 0.004541788250207901 0.14597544074058533
decider.lstm.bias_ih_l0: -0.018892662599682808 0.14181698858737946
decider.lstm.bias_hh_l0: 0.01692824810743332 0.15412962436676025
decider.linear1.weight: 0.0041703032329678535 0.1198844164609909
decider.linear1.bias: 0.006705913692712784 0.11466426402330399
decider.linear2.weight: 0.002822260372340679 0.05379670858383179
decider.linear2.bias: 0.002197097986936569 0.05296720936894417
decider.linear3.weight: -0.0038004249799996614 0.059921231120824814
decider.linear3.bias: -0.015590820461511612 0.034665387123823166

Rewards:
74.4454
74.4454
74.4454
objective = 0.18977779150009155
==== episode 26300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9996 0.0001 0.0001

action = 2
probs = 0.0012 0.0151 0.9788 0.0048

Learning rate: 5.9297e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011549514019861817 0.0835542157292366
encoder.encoder.weight_hh_l0: -0.0010090837022289634 0.0847942903637886
encoder.encoder.bias_ih_l0: 0.004682193510234356 0.0882936343550682
encoder.encoder.bias_hh_l0: 0.01775415800511837 0.08562467247247696
encoder.encoder.weight_ih_l0_reverse: 0.0017892169998958707 0.08437665551900864
encoder.encoder.weight_hh_l0_reverse: 0.0005545472959056497 0.08330274373292923
encoder.encoder.bias_ih_l0_reverse: 0.011895994655787945 0.08216571807861328
encoder.encoder.bias_hh_l0_reverse: 0.012190701439976692 0.08897505700588226
decider.lstm.weight_ih_l0: -0.0016498458571732044 0.14614729583263397
decider.lstm.weight_hh_l0: 0.00450708856806159 0.145964577794075
decider.lstm.bias_ih_l0: -0.019013475626707077 0.14183937013149261
decider.lstm.bias_hh_l0: 0.016807444393634796 0.15396013855934143
decider.linear1.weight: 0.004161598160862923 0.11984952539205551
decider.linear1.bias: 0.0066580865532159805 0.1149645447731018
decider.linear2.weight: 0.0028051906265318394 0.053785450756549835
decider.linear2.bias: 0.002169966232031584 0.05300357565283775
decider.linear3.weight: -0.0038701482117176056 0.059934377670288086
decider.linear3.bias: -0.015581376850605011 0.03547586873173714

Rewards:
74.4454
74.4454
74.4454
objective = 0.540965735912323
==== episode 26400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9995 0.0001 0.0002

action = 2
probs = 0.0018 0.0106 0.9833 0.0043

Learning rate: 5.9297e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011388134444132447 0.08348619192838669
encoder.encoder.weight_hh_l0: -0.0009879320859909058 0.08470053970813751
encoder.encoder.bias_ih_l0: 0.004326388705521822 0.0881793349981308
encoder.encoder.bias_hh_l0: 0.017398357391357422 0.08551701158285141
encoder.encoder.weight_ih_l0_reverse: 0.0017559562111273408 0.08433780819177628
encoder.encoder.weight_hh_l0_reverse: 0.000538449443411082 0.08326766639947891
encoder.encoder.bias_ih_l0_reverse: 0.01150608528405428 0.08210727572441101
encoder.encoder.bias_hh_l0_reverse: 0.011800791136920452 0.08888557553291321
decider.lstm.weight_ih_l0: -0.00165088742505759 0.14607667922973633
decider.lstm.weight_hh_l0: 0.004367482382804155 0.14589586853981018
decider.lstm.bias_ih_l0: -0.01946518011391163 0.14183005690574646
decider.lstm.bias_hh_l0: 0.016355741769075394 0.15394529700279236
decider.linear1.weight: 0.004120520781725645 0.11981675028800964
decider.linear1.bias: 0.006470132153481245 0.11485409736633301
decider.linear2.weight: 0.0027385468129068613 0.05377592518925667
decider.linear2.bias: 0.002043567830696702 0.05292459577322006
decider.linear3.weight: -0.0038390515837818384 0.05994568020105362
decider.linear3.bias: -0.015451963059604168 0.035399071872234344

Rewards:
74.4454
74.4454
74.4454
objective = 0.42980703711509705
==== episode 26500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9995 0.0002 0.0001

action = 2
probs = 0.0011 0.0060 0.9900 0.0029

Learning rate: 5.8704e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011612208327278495 0.08352811634540558
encoder.encoder.weight_hh_l0: -0.001007678685709834 0.08477599918842316
encoder.encoder.bias_ih_l0: 0.004640392959117889 0.08830545097589493
encoder.encoder.bias_hh_l0: 0.017712360247969627 0.08559572696685791
encoder.encoder.weight_ih_l0_reverse: 0.0017707558581605554 0.08437975496053696
encoder.encoder.weight_hh_l0_reverse: 0.0005431866738945246 0.0833103135228157
encoder.encoder.bias_ih_l0_reverse: 0.011623491533100605 0.08213967829942703
encoder.encoder.bias_hh_l0_reverse: 0.011918201111257076 0.08892545104026794
decider.lstm.weight_ih_l0: -0.001653023879043758 0.14611847698688507
decider.lstm.weight_hh_l0: 0.004450174048542976 0.14594204723834991
decider.lstm.bias_ih_l0: -0.019172050058841705 0.14183251559734344
decider.lstm.bias_hh_l0: 0.016648879274725914 0.15406310558319092
decider.linear1.weight: 0.004144949372857809 0.11985579878091812
decider.linear1.bias: 0.006610269658267498 0.11474689841270447
decider.linear2.weight: 0.0027899187989532948 0.053810637444257736
decider.linear2.bias: 0.002127829473465681 0.05293414741754532
decider.linear3.weight: -0.0038943695835769176 0.060088153928518295
decider.linear3.bias: -0.01553550735116005 0.035386282950639725

Rewards:
74.4454
74.4454
74.4454
objective = 0.26187190413475037
==== episode 26600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9995 0.0002 0.0001

action = 2
probs = 0.0008 0.0041 0.9930 0.0021

Learning rate: 5.8704e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011790671851485968 0.08356232941150665
encoder.encoder.weight_hh_l0: -0.0010227971943095326 0.08483904600143433
encoder.encoder.bias_ih_l0: 0.004895789083093405 0.08839904516935349
encoder.encoder.bias_hh_l0: 0.01796775311231613 0.08566569536924362
encoder.encoder.weight_ih_l0_reverse: 0.0017861011438071728 0.08441122621297836
encoder.encoder.weight_hh_l0_reverse: 0.0005445022252388299 0.08334317803382874
encoder.encoder.bias_ih_l0_reverse: 0.011756174266338348 0.08216295391321182
encoder.encoder.bias_hh_l0_reverse: 0.01205088198184967 0.08895785361528397
decider.lstm.weight_ih_l0: -0.0016571794403716922 0.1461547315120697
decider.lstm.weight_hh_l0: 0.004520499147474766 0.14598043262958527
decider.lstm.bias_ih_l0: -0.01891913078725338 0.1418304443359375
decider.lstm.bias_hh_l0: 0.016901792958378792 0.15413740277290344
decider.linear1.weight: 0.004166482016444206 0.11988923698663712
decider.linear1.bias: 0.006734463386237621 0.11468491703271866
decider.linear2.weight: 0.0028342814184725285 0.05384054034948349
decider.linear2.bias: 0.002200546208769083 0.05295476317405701
decider.linear3.weight: -0.003941246308386326 0.06021938472986221
decider.linear3.bias: -0.015594953671097755 0.03540600463747978

Rewards:
74.4454
74.4454
74.4454
objective = 0.1885712742805481
==== episode 26700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9995 0.0002 0.0001

action = 2
probs = 0.0006 0.0031 0.9946 0.0017

Learning rate: 5.8704e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0011948650935664773 0.08359142392873764
encoder.encoder.weight_hh_l0: -0.0010353683028370142 0.08489441126585007
encoder.encoder.bias_ih_l0: 0.005114168860018253 0.08847487717866898
encoder.encoder.bias_hh_l0: 0.018186135217547417 0.08572708815336227
encoder.encoder.weight_ih_l0_reverse: 0.001800153753720224 0.08443696051836014
encoder.encoder.weight_hh_l0_reverse: 0.0005436297506093979 0.08337069302797318
encoder.encoder.bias_ih_l0_reverse: 0.011879775673151016 0.08218038082122803
encoder.encoder.bias_hh_l0_reverse: 0.012174484319984913 0.08898485451936722
decider.lstm.weight_ih_l0: -0.0016621961258351803 0.1461857706308365
decider.lstm.weight_hh_l0: 0.004580166190862656 0.14601245522499084
decider.lstm.bias_ih_l0: -0.018703140318393707 0.14182619750499725
decider.lstm.bias_hh_l0: 0.017117781564593315 0.1541932374238968
decider.linear1.weight: 0.0041856952011585236 0.11991890519857407
decider.linear1.bias: 0.006846422329545021 0.11464626342058182
decider.linear2.weight: 0.0028732926584780216 0.05386780574917793
decider.linear2.bias: 0.0022642468102276325 0.05297353118658066
decider.linear3.weight: -0.003983452450484037 0.06034458428621292
decider.linear3.bias: -0.015642032027244568 0.03543583303689957

Rewards:
74.4454
74.4454
74.4454
objective = 0.14662060141563416
==== episode 26800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9995 0.0002 0.0001

action = 2
probs = 0.0005 0.0024 0.9957 0.0014

Learning rate: 5.8704e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012088404037058353 0.08361561596393585
encoder.encoder.weight_hh_l0: -0.0010460057528689504 0.0849422886967659
encoder.encoder.bias_ih_l0: 0.005299854092299938 0.08853738754987717
encoder.encoder.bias_hh_l0: 0.018371816724538803 0.08578144013881683
encoder.encoder.weight_ih_l0_reverse: 0.0018135859863832593 0.08445919305086136
encoder.encoder.weight_hh_l0_reverse: 0.0005413453909568489 0.08339463174343109
encoder.encoder.bias_ih_l0_reverse: 0.011993397027254105 0.0821952223777771
encoder.encoder.bias_hh_l0_reverse: 0.01228810753673315 0.08900826424360275
decider.lstm.weight_ih_l0: -0.001667517120949924 0.1462125927209854
decider.lstm.weight_hh_l0: 0.004631679505109787 0.14603930711746216
decider.lstm.bias_ih_l0: -0.018515825271606445 0.1418202966451645
decider.lstm.bias_hh_l0: 0.017305094748735428 0.1542392373085022
decider.linear1.weight: 0.004202430602163076 0.11994579434394836
decider.linear1.bias: 0.006945220287889242 0.11461970210075378
decider.linear2.weight: 0.002907722955569625 0.053893089294433594
decider.linear2.bias: 0.0023199047427624464 0.05299050733447075
decider.linear3.weight: -0.004022692795842886 0.06046612188220024
decider.linear3.bias: -0.015681393444538116 0.03546975553035736

Rewards:
74.4454
74.4454
74.4454
objective = 0.11906194686889648
==== episode 26900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9995 0.0002 0.0001

action = 2
probs = 0.0004 0.0020 0.9965 0.0011

Learning rate: 5.8704e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012218407355248928 0.08363772928714752
encoder.encoder.weight_hh_l0: -0.0010554922046139836 0.08498669415712357
encoder.encoder.bias_ih_l0: 0.00546902185305953 0.08859188109636307
encoder.encoder.bias_hh_l0: 0.01854098215699196 0.08583065122365952
encoder.encoder.weight_ih_l0_reverse: 0.0018261433579027653 0.08447904884815216
encoder.encoder.weight_hh_l0_reverse: 0.0005381769733503461 0.0834161788225174
encoder.encoder.bias_ih_l0_reverse: 0.012100297957658768 0.08220779895782471
encoder.encoder.bias_hh_l0_reverse: 0.012395011261105537 0.08902911841869354
decider.lstm.weight_ih_l0: -0.0016730879433453083 0.1462370902299881
decider.lstm.weight_hh_l0: 0.004678274970501661 0.1460631936788559
decider.lstm.bias_ih_l0: -0.018345670774579048 0.14181405305862427
decider.lstm.bias_hh_l0: 0.017475251108407974 0.1542768031358719
decider.linear1.weight: 0.00421757809817791 0.11997083574533463
decider.linear1.bias: 0.007035606540739536 0.11460012197494507
decider.linear2.weight: 0.002938767895102501 0.05391693115234375
decider.linear2.bias: 0.0023697558790445328 0.05300597846508026
decider.linear3.weight: -0.004059822764247656 0.060585085302591324
decider.linear3.bias: -0.01571541279554367 0.03550536930561066

Rewards:
74.4454
74.4454
74.4454
objective = 0.09956963360309601
==== episode 27000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9995 0.0002 0.0001

action = 2
probs = 0.0003 0.0016 0.9970 0.0010

Learning rate: 5.8117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012340076500549912 0.08365778625011444
encoder.encoder.weight_hh_l0: -0.0010640221880748868 0.08502783626317978
encoder.encoder.bias_ih_l0: 0.005623467266559601 0.08863998204469681
encoder.encoder.bias_hh_l0: 0.018695427104830742 0.08587536215782166
encoder.encoder.weight_ih_l0_reverse: 0.0018379983957856894 0.08449719101190567
encoder.encoder.weight_hh_l0_reverse: 0.0005344306700862944 0.08343581110239029
encoder.encoder.bias_ih_l0_reverse: 0.012202081270515919 0.08221945911645889
encoder.encoder.bias_hh_l0_reverse: 0.012496796436607838 0.08904749900102615
decider.lstm.weight_ih_l0: -0.0016787819331511855 0.1462598294019699
decider.lstm.weight_hh_l0: 0.004720793571323156 0.1460849791765213
decider.lstm.bias_ih_l0: -0.018190018832683563 0.14180722832679749
decider.lstm.bias_hh_l0: 0.017630910500884056 0.15430867671966553
decider.linear1.weight: 0.004231777507811785 0.11999449133872986
decider.linear1.bias: 0.007121244445443153 0.11458630859851837
decider.linear2.weight: 0.0029679681174457073 0.05393974855542183
decider.linear2.bias: 0.002416814910247922 0.0530194416642189
decider.linear3.weight: -0.004095347132533789 0.060702066868543625
decider.linear3.bias: -0.015745529904961586 0.035541556775569916

Rewards:
74.4454
74.4454
74.4454
objective = 0.08525562286376953
==== episode 27100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9995 0.0002 0.0001

action = 2
probs = 0.0003 0.0014 0.9975 0.0008

Learning rate: 5.8117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012453441740944982 0.0836763009428978
encoder.encoder.weight_hh_l0: -0.0010717808036133647 0.08506639301776886
encoder.encoder.bias_ih_l0: 0.0057656955905258656 0.08868280798196793
encoder.encoder.bias_hh_l0: 0.01883765682578087 0.08591590821743011
encoder.encoder.weight_ih_l0_reverse: 0.0018489020876586437 0.08451370149850845
encoder.encoder.weight_hh_l0_reverse: 0.0005303578218445182 0.08345367014408112
encoder.encoder.bias_ih_l0_reverse: 0.01229699607938528 0.08222953975200653
encoder.encoder.bias_hh_l0_reverse: 0.012591712176799774 0.0890640839934349
decider.lstm.weight_ih_l0: -0.001684448216110468 0.14628076553344727
decider.lstm.weight_hh_l0: 0.004759589210152626 0.14610466361045837
decider.lstm.bias_ih_l0: -0.01804773509502411 0.14179962873458862
decider.lstm.bias_hh_l0: 0.017773201689124107 0.15433625876903534
decider.linear1.weight: 0.004245051182806492 0.12001678347587585
decider.linear1.bias: 0.0072013260796666145 0.11457659304141998
decider.linear2.weight: 0.002994467504322529 0.0539616160094738
decider.linear2.bias: 0.0024601309560239315 0.05303207412362099
decider.linear3.weight: -0.004129298962652683 0.060816437005996704
decider.linear3.bias: -0.015772448852658272 0.03557741269469261

Rewards:
74.4454
74.4454
74.4454
objective = 0.07428857684135437
==== episode 27200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9996 0.0002 0.0001

action = 2
probs = 0.0003 0.0012 0.9978 0.0007

Learning rate: 5.8117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001256000017747283 0.08369369804859161
encoder.encoder.weight_hh_l0: -0.0010789800435304642 0.0851031020283699
encoder.encoder.bias_ih_l0: 0.0058988784439861774 0.08872159570455551
encoder.encoder.bias_hh_l0: 0.01897083781659603 0.08595334738492966
encoder.encoder.weight_ih_l0_reverse: 0.0018592620035633445 0.0845291018486023
encoder.encoder.weight_hh_l0_reverse: 0.0005259924801066518 0.08347032964229584
encoder.encoder.bias_ih_l0_reverse: 0.012387187220156193 0.08223888278007507
encoder.encoder.bias_hh_l0_reverse: 0.012681903317570686 0.08907925337553024
decider.lstm.weight_ih_l0: -0.0016901317285373807 0.14630047976970673
decider.lstm.weight_hh_l0: 0.004795699845999479 0.1461229771375656
decider.lstm.bias_ih_l0: -0.017915071919560432 0.14179125428199768
decider.lstm.bias_hh_l0: 0.017905857414007187 0.15436077117919922
decider.linear1.weight: 0.004257574677467346 0.12003818899393082
decider.linear1.bias: 0.007277105003595352 0.11456958204507828
decider.linear2.weight: 0.0030194749124348164 0.05398283153772354
decider.linear2.bias: 0.002501316601410508 0.0530441552400589
decider.linear3.weight: -0.0041622593998909 0.06092965602874756
decider.linear3.bias: -0.015797091647982597 0.03561301529407501

Rewards:
74.4454
74.4454
74.4454
objective = 0.06555986404418945
==== episode 27300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9996 0.0002 0.0001

action = 2
probs = 0.0002 0.0011 0.9981 0.0006

Learning rate: 5.8117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012660687789320946 0.08371010422706604
encoder.encoder.weight_hh_l0: -0.0010858334135264158 0.08513858914375305
encoder.encoder.bias_ih_l0: 0.00602491432800889 0.0887574777007103
encoder.encoder.bias_hh_l0: 0.019096875563263893 0.08598822355270386
encoder.encoder.weight_ih_l0_reverse: 0.0018694829195737839 0.08454367518424988
encoder.encoder.weight_hh_l0_reverse: 0.0005213486729189754 0.0834861621260643
encoder.encoder.bias_ih_l0_reverse: 0.012475235387682915 0.08224771171808243
encoder.encoder.bias_hh_l0_reverse: 0.012769951485097408 0.08909311890602112
decider.lstm.weight_ih_l0: -0.001695951446890831 0.14631950855255127
decider.lstm.weight_hh_l0: 0.004830272868275642 0.14614082872867584
decider.lstm.bias_ih_l0: -0.01778796873986721 0.14178122580051422
decider.lstm.bias_hh_l0: 0.01803295686841011 0.15438304841518402
decider.linear1.weight: 0.004269785713404417 0.12005911767482758
decider.linear1.bias: 0.0073509979993104935 0.11456631869077682
decider.linear2.weight: 0.003044877201318741 0.05400343984365463
decider.linear2.bias: 0.002543908078223467 0.05305313691496849
decider.linear3.weight: -0.004194353707134724 0.0610417015850544
decider.linear3.bias: -0.01581992767751217 0.0356481559574604

Rewards:
74.4454
74.4454
74.4454
objective = 0.05853522941470146
==== episode 27400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9996 0.0002 0.0001

action = 2
probs = 0.0002 0.0010 0.9983 0.0006

Learning rate: 5.8117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012757962103933096 0.08372578024864197
encoder.encoder.weight_hh_l0: -0.0010924107627943158 0.08517304807901382
encoder.encoder.bias_ih_l0: 0.00614556297659874 0.08879078924655914
encoder.encoder.bias_hh_l0: 0.01921752095222473 0.08602114766836166
encoder.encoder.weight_ih_l0_reverse: 0.0018792940536513925 0.08455745130777359
encoder.encoder.weight_hh_l0_reverse: 0.0005165169714018703 0.08350144326686859
encoder.encoder.bias_ih_l0_reverse: 0.012561014853417873 0.08225611597299576
encoder.encoder.bias_hh_l0_reverse: 0.012855730950832367 0.08910577744245529
decider.lstm.weight_ih_l0: -0.001701852073892951 0.14633774757385254
decider.lstm.weight_hh_l0: 0.004863278940320015 0.14615797996520996
decider.lstm.bias_ih_l0: -0.017666615545749664 0.14177145063877106
decider.lstm.bias_hh_l0: 0.018154311925172806 0.15440236032009125
decider.linear1.weight: 0.004280992783606052 0.12007910758256912
decider.linear1.bias: 0.007420400623232126 0.11456368863582611
decider.linear2.weight: 0.0030690976418554783 0.05402350798249245
decider.linear2.bias: 0.0025844452902674675 0.053062062710523605
decider.linear3.weight: -0.004225618205964565 0.061152342706918716
decider.linear3.bias: -0.0158412866294384 0.03568267822265625

Rewards:
74.4454
74.4454
74.4454
objective = 0.052593909204006195
==== episode 27500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9996 0.0002 0.0001

action = 2
probs = 0.0002 0.0008 0.9985 0.0005

Learning rate: 5.7535e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012849927879869938 0.08374061435461044
encoder.encoder.weight_hh_l0: -0.0010986959096044302 0.08520641177892685
encoder.encoder.bias_ih_l0: 0.006260157562792301 0.08882158994674683
encoder.encoder.bias_hh_l0: 0.019332120195031166 0.0860518366098404
encoder.encoder.weight_ih_l0_reverse: 0.0018886110046878457 0.08457040786743164
encoder.encoder.weight_hh_l0_reverse: 0.0005116275860927999 0.08351605385541916
encoder.encoder.bias_ih_l0_reverse: 0.012643690221011639 0.08226386457681656
encoder.encoder.bias_hh_l0_reverse: 0.012938408181071281 0.0891171470284462
decider.lstm.weight_ih_l0: -0.0017077750526368618 0.14635519683361053
decider.lstm.weight_hh_l0: 0.004894633777439594 0.14617443084716797
decider.lstm.bias_ih_l0: -0.017551438882946968 0.14176125824451447
decider.lstm.bias_hh_l0: 0.018269488587975502 0.1544196456670761
decider.linear1.weight: 0.0042916773818433285 0.12009859085083008
decider.linear1.bias: 0.007486692164093256 0.11456238478422165
decider.linear2.weight: 0.0030902819707989693 0.05404486507177353
decider.linear2.bias: 0.0026229543145745993 0.05307065695524216
decider.linear3.weight: -0.004256117157638073 0.061261605471372604
decider.linear3.bias: -0.015861378982663155 0.03571652993559837

Rewards:
74.4454
74.4454
74.4454
objective = 0.04753073304891586
==== episode 27600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9996 0.0002 0.0001

action = 2
probs = 0.0002 0.0008 0.9986 0.0005

Learning rate: 5.7535e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012938930885866284 0.083754763007164
encoder.encoder.weight_hh_l0: -0.001104754745028913 0.08523876965045929
encoder.encoder.bias_ih_l0: 0.006369950249791145 0.08885037899017334
encoder.encoder.bias_hh_l0: 0.019441913813352585 0.08608075231313705
encoder.encoder.weight_ih_l0_reverse: 0.001897500129416585 0.08458270877599716
encoder.encoder.weight_hh_l0_reverse: 0.0005066592711955309 0.08353007584810257
encoder.encoder.bias_ih_l0_reverse: 0.012723305262625217 0.08227100223302841
encoder.encoder.bias_hh_l0_reverse: 0.01301802508533001 0.08912789076566696
decider.lstm.weight_ih_l0: -0.0017136820824816823 0.14637187123298645
decider.lstm.weight_hh_l0: 0.004924451000988483 0.14618994295597076
decider.lstm.bias_ih_l0: -0.017442036420106888 0.14175096154212952
decider.lstm.bias_hh_l0: 0.018378883600234985 0.15443526208400726
decider.linear1.weight: 0.004301928915083408 0.12011751532554626
decider.linear1.bias: 0.007550242822617292 0.11456220597028732
decider.linear2.weight: 0.003109856741502881 0.0540660098195076
decider.linear2.bias: 0.0026594791561365128 0.05307913199067116
decider.linear3.weight: -0.004285604227334261 0.06136835739016533
decider.linear3.bias: -0.015880193561315536 0.03574934974312782

Rewards:
74.4454
74.4454
74.4454
objective = 0.043186746537685394
==== episode 27700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9997 0.0002 0.0001

action = 2
probs = 0.0001 0.0007 0.9988 0.0004

Learning rate: 5.7535e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013026251690462232 0.08376841247081757
encoder.encoder.weight_hh_l0: -0.0011106794700026512 0.08527054637670517
encoder.encoder.bias_ih_l0: 0.006476553622633219 0.08887768536806107
encoder.encoder.bias_hh_l0: 0.01954852044582367 0.08610838651657104
encoder.encoder.weight_ih_l0_reverse: 0.001906087389215827 0.08459455519914627
encoder.encoder.weight_hh_l0_reverse: 0.0005015735514461994 0.08354374021291733
encoder.encoder.bias_ih_l0_reverse: 0.012800962664186954 0.08227773755788803
encoder.encoder.bias_hh_l0_reverse: 0.013095682486891747 0.08913819491863251
decider.lstm.weight_ih_l0: -0.0017196341650560498 0.14638809859752655
decider.lstm.weight_hh_l0: 0.0049531664699316025 0.1462046504020691
decider.lstm.bias_ih_l0: -0.017336755990982056 0.1417405754327774
decider.lstm.bias_hh_l0: 0.01848416030406952 0.15444961190223694
decider.linear1.weight: 0.004311797209084034 0.12013603001832962
decider.linear1.bias: 0.007611703593283892 0.11456279456615448
decider.linear2.weight: 0.0031286152079701424 0.054086778312921524
decider.linear2.bias: 0.00269452016800642 0.053087688982486725
decider.linear3.weight: -0.004314426798373461 0.06147371605038643
decider.linear3.bias: -0.015898076817393303 0.03578149154782295

Rewards:
74.4454
74.4454
74.4454
objective = 0.03937500715255737
==== episode 27800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9997 0.0002 0.0001

action = 2
probs = 0.0001 0.0006 0.9989 0.0004

Learning rate: 5.7535e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013112183660268784 0.0837816521525383
encoder.encoder.weight_hh_l0: -0.0011165111791342497 0.0853019431233406
encoder.encoder.bias_ih_l0: 0.0065806168131530285 0.0889037624001503
encoder.encoder.bias_hh_l0: 0.019652580842375755 0.0861348956823349
encoder.encoder.weight_ih_l0_reverse: 0.0019144054967910051 0.08460599929094315
encoder.encoder.weight_hh_l0_reverse: 0.0004963789833709598 0.0835571363568306
encoder.encoder.bias_ih_l0_reverse: 0.012877032160758972 0.0822841078042984
encoder.encoder.bias_hh_l0_reverse: 0.013171754777431488 0.08914808928966522
decider.lstm.weight_ih_l0: -0.0017256508581340313 0.14640387892723083
decider.lstm.weight_hh_l0: 0.004980938509106636 0.14621876180171967
decider.lstm.bias_ih_l0: -0.01723499596118927 0.14172999560832977
decider.lstm.bias_hh_l0: 0.018585912883281708 0.15446284413337708
decider.linear1.weight: 0.00432138005271554 0.12015421688556671
decider.linear1.bias: 0.0076715052127838135 0.11456403881311417
decider.linear2.weight: 0.003146825823932886 0.054107099771499634
decider.linear2.bias: 0.002728376304730773 0.05309614539146423
decider.linear3.weight: -0.0043426090851426125 0.06157761439681053
decider.linear3.bias: -0.01591513492166996 0.03581294044852257

Rewards:
74.4454
74.4454
74.4454
objective = 0.03600054979324341
==== episode 27900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9997 0.0001 0.0001

action = 2
probs = 0.0001 0.0006 0.9990 0.0003

Learning rate: 5.7535e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001319695496931672 0.08379452675580978
encoder.encoder.weight_hh_l0: -0.001122274436056614 0.08533305674791336
encoder.encoder.bias_ih_l0: 0.0066825030371546745 0.08892873674631119
encoder.encoder.bias_hh_l0: 0.01975446566939354 0.08616034686565399
encoder.encoder.weight_ih_l0_reverse: 0.0019224191782996058 0.08461705595254898
encoder.encoder.weight_hh_l0_reverse: 0.00049110985128209 0.08357029408216476
encoder.encoder.bias_ih_l0_reverse: 0.012951225973665714 0.08228997141122818
encoder.encoder.bias_hh_l0_reverse: 0.01324595045298338 0.08915762603282928
decider.lstm.weight_ih_l0: -0.001731725293211639 0.14641930162906647
decider.lstm.weight_hh_l0: 0.005007806234061718 0.1462322473526001
decider.lstm.bias_ih_l0: -0.017136583104729652 0.141719251871109
decider.lstm.bias_hh_l0: 0.018684327602386475 0.1544751077890396
decider.linear1.weight: 0.004330674186348915 0.12017213553190231
decider.linear1.bias: 0.0077296290546655655 0.11456555873155594
decider.linear2.weight: 0.00316431000828743 0.0541270487010479
decider.linear2.bias: 0.0027608750388026237 0.05310402810573578
decider.linear3.weight: -0.004370174836367369 0.06168004125356674
decider.linear3.bias: -0.015931453555822372 0.03584368899464607

Rewards:
74.4454
74.4454
74.4454
objective = 0.03300249204039574
==== episode 28000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9997 0.0001 0.0001

action = 2
probs = 0.0002 0.0008 0.9984 0.0006

Learning rate: 5.6960e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012831934727728367 0.08373284339904785
encoder.encoder.weight_hh_l0: -0.0010975183686241508 0.08518655598163605
encoder.encoder.bias_ih_l0: 0.006184310652315617 0.08879142254590988
encoder.encoder.bias_hh_l0: 0.01925627700984478 0.08604072034358978
encoder.encoder.weight_ih_l0_reverse: 0.0018859395058825612 0.08457127213478088
encoder.encoder.weight_hh_l0_reverse: 0.0005045807920396328 0.08351357281208038
encoder.encoder.bias_ih_l0_reverse: 0.012602347880601883 0.082255519926548
encoder.encoder.bias_hh_l0_reverse: 0.012897075153887272 0.08910349011421204
decider.lstm.weight_ih_l0: -0.001708434778265655 0.14634405076503754
decider.lstm.weight_hh_l0: 0.004876935854554176 0.1461629569530487
decider.lstm.bias_ih_l0: -0.01762324944138527 0.14173711836338043
decider.lstm.bias_hh_l0: 0.018197663128376007 0.15443342924118042
decider.linear1.weight: 0.004280054476112127 0.1201053261756897
decider.linear1.bias: 0.007458727806806564 0.1145980954170227
decider.linear2.weight: 0.003076661843806505 0.054105062037706375
decider.linear2.bias: 0.002606874331831932 0.0530850775539875
decider.linear3.weight: -0.0043684495612978935 0.06166911870241165
decider.linear3.bias: -0.015863658860325813 0.035292770713567734

Rewards:
74.4454
74.4454
74.4454
objective = 0.04699420928955078
==== episode 28100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9997 0.0001 0.0001

action = 2
probs = 0.0002 0.0007 0.9985 0.0006

Learning rate: 5.6960e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001290015410631895 0.08374544978141785
encoder.encoder.weight_hh_l0: -0.0011021464597433805 0.08520998805761337
encoder.encoder.bias_ih_l0: 0.0062662046402692795 0.08881890773773193
encoder.encoder.bias_hh_l0: 0.01933816447854042 0.08606496453285217
encoder.encoder.weight_ih_l0_reverse: 0.0018920933362096548 0.08458149433135986
encoder.encoder.weight_hh_l0_reverse: 0.0005027843290008605 0.0835254043340683
encoder.encoder.bias_ih_l0_reverse: 0.012658867985010147 0.08226232975721359
encoder.encoder.bias_hh_l0_reverse: 0.01295359618961811 0.08911408483982086
decider.lstm.weight_ih_l0: -0.0017117684474214911 0.14635740220546722
decider.lstm.weight_hh_l0: 0.00489996001124382 0.14617611467838287
decider.lstm.bias_ih_l0: -0.01753612980246544 0.14173519611358643
decider.lstm.bias_hh_l0: 0.018284786492586136 0.1544455736875534
decider.linear1.weight: 0.004287067800760269 0.12011988461017609
decider.linear1.bias: 0.007507100235670805 0.1145944818854332
decider.linear2.weight: 0.0030946440529078245 0.054121751338243484
decider.linear2.bias: 0.0026362768840044737 0.05309242010116577
decider.linear3.weight: -0.00439092330634594 0.061755042523145676
decider.linear3.bias: -0.015880325809121132 0.035285286605358124

Rewards:
74.4454
74.4454
74.4454
objective = 0.04364075884222984
==== episode 28200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9997 0.0001 0.0001

action = 2
probs = 0.0001 0.0006 0.9987 0.0005

Learning rate: 5.6960e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001299759023822844 0.08376248925924301
encoder.encoder.weight_hh_l0: -0.0011086766608059406 0.08524460345506668
encoder.encoder.bias_ih_l0: 0.006385854445397854 0.08885564655065536
encoder.encoder.bias_hh_l0: 0.019457809627056122 0.08609768003225327
encoder.encoder.weight_ih_l0_reverse: 0.0019010920077562332 0.08459487557411194
encoder.encoder.weight_hh_l0_reverse: 0.0004995368653908372 0.08354128897190094
encoder.encoder.bias_ih_l0_reverse: 0.01274297945201397 0.0822712779045105
encoder.encoder.bias_hh_l0_reverse: 0.013037709519267082 0.08912847191095352
decider.lstm.weight_ih_l0: -0.0017171594081446528 0.14637629687786102
decider.lstm.weight_hh_l0: 0.004932730458676815 0.14619404077529907
decider.lstm.bias_ih_l0: -0.017413172870874405 0.14173072576522827
decider.lstm.bias_hh_l0: 0.018407754600048065 0.1544600874185562
decider.linear1.weight: 0.004298022016882896 0.12013988941907883
decider.linear1.bias: 0.0075766704976558685 0.11458985507488251
decider.linear2.weight: 0.0031191238667815924 0.054140906780958176
decider.linear2.bias: 0.002677224576473236 0.05310145020484924
decider.linear3.weight: -0.004414998460561037 0.06184811517596245
decider.linear3.bias: -0.015901681035757065 0.035318274050951004

Rewards:
74.4454
74.4454
74.4454
objective = 0.039276137948036194
==== episode 28300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9997 0.0001 0.0001

action = 2
probs = 0.0001 0.0006 0.9988 0.0005

Learning rate: 5.6960e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001309249666519463 0.08377861976623535
encoder.encoder.weight_hh_l0: -0.0011148923076689243 0.08527765423059464
encoder.encoder.bias_ih_l0: 0.006499086041003466 0.0888899490237236
encoder.encoder.bias_hh_l0: 0.01957104355096817 0.08612866699695587
encoder.encoder.weight_ih_l0_reverse: 0.001909778919070959 0.08460764586925507
encoder.encoder.weight_hh_l0_reverse: 0.0004961094819009304 0.08355648070573807
encoder.encoder.bias_ih_l0_reverse: 0.012824303470551968 0.08228009194135666
encoder.encoder.bias_hh_l0_reverse: 0.01311903540045023 0.08914230018854141
decider.lstm.weight_ih_l0: -0.0017225011251866817 0.14639420807361603
decider.lstm.weight_hh_l0: 0.004963751416653395 0.14621049165725708
decider.lstm.bias_ih_l0: -0.01729712076485157 0.14172637462615967
decider.lstm.bias_hh_l0: 0.01852380856871605 0.15447339415550232
decider.linear1.weight: 0.004308435134589672 0.12015936523675919
decider.linear1.bias: 0.007642950862646103 0.11458631604909897
decider.linear2.weight: 0.0031414590775966644 0.05416041240096092
decider.linear2.bias: 0.0027160639874637127 0.05311049893498421
decider.linear3.weight: -0.004438681527972221 0.06194063648581505
decider.linear3.bias: -0.01592175103724003 0.035351213067770004

Rewards:
74.4454
74.4454
74.4454
objective = 0.035548917949199677
==== episode 28400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9998 0.0001 0.0000

action = 2
probs = 0.0001 0.0005 0.9989 0.0004

Learning rate: 5.6960e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013187149306759238 0.08379484713077545
encoder.encoder.weight_hh_l0: -0.0011210073716938496 0.08531082421541214
encoder.encoder.bias_ih_l0: 0.006611056160181761 0.08892294764518738
encoder.encoder.bias_hh_l0: 0.01968301460146904 0.08615818619728088
encoder.encoder.weight_ih_l0_reverse: 0.001918273395858705 0.08462003618478775
encoder.encoder.weight_hh_l0_reverse: 0.0004924646345898509 0.08357125520706177
encoder.encoder.bias_ih_l0_reverse: 0.012904869392514229 0.08228813111782074
encoder.encoder.bias_hh_l0_reverse: 0.013199599459767342 0.08915652334690094
decider.lstm.weight_ih_l0: -0.0017279835883527994 0.14641200006008148
decider.lstm.weight_hh_l0: 0.004994386341422796 0.1462266892194748
decider.lstm.bias_ih_l0: -0.017182674258947372 0.14172068238258362
decider.lstm.bias_hh_l0: 0.018638258799910545 0.15448500216007233
decider.linear1.weight: 0.004318930208683014 0.12017875164747238
decider.linear1.bias: 0.007709387689828873 0.1145857721567154
decider.linear2.weight: 0.003162816632539034 0.054179735481739044
decider.linear2.bias: 0.002753780223429203 0.053119074553251266
decider.linear3.weight: -0.004462000913918018 0.06203257292509079
decider.linear3.bias: -0.01594073697924614 0.035383980721235275

Rewards:
74.4454
74.4454
74.4454
objective = 0.03235816955566406
==== episode 28500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9998 0.0001 0.0000

action = 2
probs = 0.0001 0.0005 0.9990 0.0004

Learning rate: 5.6391e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013276648242026567 0.08380982279777527
encoder.encoder.weight_hh_l0: -0.0011268176604062319 0.08534203469753265
encoder.encoder.bias_ih_l0: 0.00671510910615325 0.08895326405763626
encoder.encoder.bias_hh_l0: 0.01978706754744053 0.0861857682466507
encoder.encoder.weight_ih_l0_reverse: 0.001926494063809514 0.0846317857503891
encoder.encoder.weight_hh_l0_reverse: 0.0004887992981821299 0.08358516544103622
encoder.encoder.bias_ih_l0_reverse: 0.012980914674699306 0.08229552209377289
encoder.encoder.bias_hh_l0_reverse: 0.01327564474195242 0.08916979283094406
decider.lstm.weight_ih_l0: -0.001733323442749679 0.14642861485481262
decider.lstm.weight_hh_l0: 0.0050230249762535095 0.14624164998531342
decider.lstm.bias_ih_l0: -0.017075857147574425 0.14171351492404938
decider.lstm.bias_hh_l0: 0.01874508708715439 0.15449652075767517
decider.linear1.weight: 0.004328982904553413 0.12019768357276917
decider.linear1.bias: 0.007773001678287983 0.11458641290664673
decider.linear2.weight: 0.003182816319167614 0.05419912189245224
decider.linear2.bias: 0.0027898969128727913 0.05312752723693848
decider.linear3.weight: -0.004484975710511208 0.0621238574385643
decider.linear3.bias: -0.01595878414809704 0.035416435450315475

Rewards:
74.4454
74.4454
74.4454
objective = 0.029576372355222702
==== episode 28600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9998 0.0001 0.0000

action = 2
probs = 0.0001 0.0004 0.9991 0.0004

Learning rate: 5.6391e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013360982993617654 0.08382371813058853
encoder.encoder.weight_hh_l0: -0.001132301869802177 0.08537133783102036
encoder.encoder.bias_ih_l0: 0.006811110768467188 0.08898098766803741
encoder.encoder.bias_hh_l0: 0.01988307014107704 0.08621101826429367
encoder.encoder.weight_ih_l0_reverse: 0.0019342511659488082 0.084642693400383
encoder.encoder.weight_hh_l0_reverse: 0.00048525247257202864 0.08359794318675995
encoder.encoder.bias_ih_l0_reverse: 0.013051364570856094 0.08230198174715042
encoder.encoder.bias_hh_l0_reverse: 0.013346095569431782 0.08918213099241257
decider.lstm.weight_ih_l0: -0.0017383990343660116 0.1464439034461975
decider.lstm.weight_hh_l0: 0.005049144383519888 0.14625544846057892
decider.lstm.bias_ih_l0: -0.016978442668914795 0.1417047679424286
decider.lstm.bias_hh_l0: 0.01884249970316887 0.15450811386108398
decider.linear1.weight: 0.004338432103395462 0.12021610885858536
decider.linear1.bias: 0.007832501083612442 0.11458621919155121
decider.linear2.weight: 0.003201273735612631 0.05421866849064827
decider.linear2.bias: 0.0028243977576494217 0.05313568189740181
decider.linear3.weight: -0.004507423844188452 0.0622137077152729
decider.linear3.bias: -0.015975849702954292 0.03544829040765762

Rewards:
74.4454
74.4454
74.4454
objective = 0.0271441787481308
==== episode 28700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9998 0.0001 0.0000

action = 2
probs = 0.0001 0.0004 0.9992 0.0003

Learning rate: 5.6391e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013443443458527327 0.08383722603321075
encoder.encoder.weight_hh_l0: -0.0011376554612070322 0.08540007472038269
encoder.encoder.bias_ih_l0: 0.006904402747750282 0.08900750428438187
encoder.encoder.bias_hh_l0: 0.019976360723376274 0.08623521029949188
encoder.encoder.weight_ih_l0_reverse: 0.0019417771836742759 0.08465322852134705
encoder.encoder.weight_hh_l0_reverse: 0.0004816573054995388 0.08361037075519562
encoder.encoder.bias_ih_l0_reverse: 0.013120312243700027 0.08230817317962646
encoder.encoder.bias_hh_l0_reverse: 0.01341504417359829 0.08919404447078705
decider.lstm.weight_ih_l0: -0.001743470667861402 0.14645877480506897
decider.lstm.weight_hh_l0: 0.005074364133179188 0.14626868069171906
decider.lstm.bias_ih_l0: -0.01688430830836296 0.1416958123445511
decider.lstm.bias_hh_l0: 0.018936628475785255 0.15451879799365997
decider.linear1.weight: 0.004347538575530052 0.12023419886827469
decider.linear1.bias: 0.007890358567237854 0.11458642035722733
decider.linear2.weight: 0.003218383062630892 0.054238785058259964
decider.linear2.bias: 0.002857800805941224 0.05314371734857559
decider.linear3.weight: -0.004529597703367472 0.062303029000759125
decider.linear3.bias: -0.015992209315299988 0.035479847341775894

Rewards:
74.4454
74.4454
74.4454
objective = 0.02497417852282524
==== episode 28800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9998 0.0001 0.0000

action = 2
probs = 0.0001 0.0004 0.9993 0.0003

Learning rate: 5.6391e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013524284586310387 0.08385037630796432
encoder.encoder.weight_hh_l0: -0.001142902416177094 0.08542831987142563
encoder.encoder.bias_ih_l0: 0.00699531240388751 0.08903300017118454
encoder.encoder.bias_hh_l0: 0.02006727084517479 0.08625847101211548
encoder.encoder.weight_ih_l0_reverse: 0.0019491028506308794 0.08466344326734543
encoder.encoder.weight_hh_l0_reverse: 0.00047801464097574353 0.08362248539924622
encoder.encoder.bias_ih_l0_reverse: 0.01318791601806879 0.08231411874294281
encoder.encoder.bias_hh_l0_reverse: 0.013482648879289627 0.08920557051897049
decider.lstm.weight_ih_l0: -0.0017485481221228838 0.14647327363491058
decider.lstm.weight_hh_l0: 0.005098779685795307 0.1462813764810562
decider.lstm.bias_ih_l0: -0.016793057322502136 0.14168661832809448
decider.lstm.bias_hh_l0: 0.019027888774871826 0.15452873706817627
decider.linear1.weight: 0.004356397315859795 0.12025204300880432
decider.linear1.bias: 0.007946912199258804 0.1145869791507721
decider.linear2.weight: 0.003234714502468705 0.054258909076452255
decider.linear2.bias: 0.0028901875484734774 0.0531516894698143
decider.linear3.weight: -0.0045514884404838085 0.06239171326160431
decider.linear3.bias: -0.016007941216230392 0.0355110839009285

Rewards:
74.4454
74.4454
74.4454
objective = 0.0230204276740551
==== episode 28900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9998 0.0001 0.0000

action = 2
probs = 0.0001 0.0003 0.9993 0.0003

Learning rate: 5.6391e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013602647231891751 0.08386312425136566
encoder.encoder.weight_hh_l0: -0.0011480478569865227 0.08545609563589096
encoder.encoder.bias_ih_l0: 0.007083748932927847 0.0890575423836708
encoder.encoder.bias_hh_l0: 0.020155705511569977 0.0862807035446167
encoder.encoder.weight_ih_l0_reverse: 0.0019562365487217903 0.08467332273721695
encoder.encoder.weight_hh_l0_reverse: 0.0004743784375023097 0.08363416790962219
encoder.encoder.bias_ih_l0_reverse: 0.013253502547740936 0.08231940120458603
encoder.encoder.bias_hh_l0_reverse: 0.013548238202929497 0.08921679854393005
decider.lstm.weight_ih_l0: -0.0017536147497594357 0.14648744463920593
decider.lstm.weight_hh_l0: 0.0051223766058683395 0.14629343152046204
decider.lstm.bias_ih_l0: -0.016704674810171127 0.14167657494544983
decider.lstm.bias_hh_l0: 0.01911625638604164 0.15453843772411346
decider.linear1.weight: 0.004365109372884035 0.12026971578598022
decider.linear1.bias: 0.008002685382962227 0.11458800733089447
decider.linear2.weight: 0.00325021892786026 0.054279036819934845
decider.linear2.bias: 0.0029215384274721146 0.053159598261117935
decider.linear3.weight: -0.004573095124214888 0.06247973069548607
decider.linear3.bias: -0.016023097559809685 0.03554198518395424

Rewards:
74.4454
74.4454
74.4454
objective = 0.02126067504286766
==== episode 29000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9998 0.0001 0.0000

action = 2
probs = 0.0001 0.0003 0.9994 0.0003

Learning rate: 5.5827e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001367968856357038 0.08387554436922073
encoder.encoder.weight_hh_l0: -0.0011531065683811903 0.08548342436552048
encoder.encoder.bias_ih_l0: 0.0071700154803693295 0.08908121287822723
encoder.encoder.bias_hh_l0: 0.020241975784301758 0.08630211651325226
encoder.encoder.weight_ih_l0_reverse: 0.0019631681498140097 0.08468291163444519
encoder.encoder.weight_hh_l0_reverse: 0.0004707210755441338 0.08364555984735489
encoder.encoder.bias_ih_l0_reverse: 0.013317706063389778 0.08232443034648895
encoder.encoder.bias_hh_l0_reverse: 0.013612442649900913 0.08922766149044037
decider.lstm.weight_ih_l0: -0.0017586747417226434 0.14650124311447144
decider.lstm.weight_hh_l0: 0.0051451739855110645 0.14630497992038727
decider.lstm.bias_ih_l0: -0.016619013622403145 0.14166633784770966
decider.lstm.bias_hh_l0: 0.019201917573809624 0.1545475274324417
decider.linear1.weight: 0.0043718027882277966 0.12028427422046661
decider.linear1.bias: 0.008047238923609257 0.11459174752235413
decider.linear2.weight: 0.0032649110071361065 0.05429922044277191
decider.linear2.bias: 0.0029519149102270603 0.05316741764545441
decider.linear3.weight: -0.004594421945512295 0.06256703287363052
decider.linear3.bias: -0.016037732362747192 0.03557253256440163

Rewards:
74.4454
74.4454
74.4454
objective = 0.019665297120809555
==== episode 29100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9998 0.0001 0.0000

action = 2
probs = 0.0001 0.0003 0.9994 0.0002

Learning rate: 5.5827e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013755836989730597 0.0838877409696579
encoder.encoder.weight_hh_l0: -0.0011580940335988998 0.08551046252250671
encoder.encoder.bias_ih_l0: 0.007254656404256821 0.08910432457923889
encoder.encoder.bias_hh_l0: 0.02032661624252796 0.08632278442382812
encoder.encoder.weight_ih_l0_reverse: 0.0019698068499565125 0.08469205349683762
encoder.encoder.weight_hh_l0_reverse: 0.000467081117676571 0.08365650475025177
encoder.encoder.bias_ih_l0_reverse: 0.013379678130149841 0.08232897520065308
encoder.encoder.bias_hh_l0_reverse: 0.013674422167241573 0.08923833817243576
decider.lstm.weight_ih_l0: -0.0017637073760852218 0.1465146690607071
decider.lstm.weight_hh_l0: 0.0051671103574335575 0.1463157832622528
decider.lstm.bias_ih_l0: -0.016536254435777664 0.14165595173835754
decider.lstm.bias_hh_l0: 0.019284676760435104 0.15455612540245056
decider.linear1.weight: 0.00438007153570652 0.12030143290758133
decider.linear1.bias: 0.008100811392068863 0.11459343880414963
decider.linear2.weight: 0.003279132302850485 0.054319024085998535
decider.linear2.bias: 0.002981398720294237 0.05317575857043266
decider.linear3.weight: -0.004615267738699913 0.06265272200107574
decider.linear3.bias: -0.0160517618060112 0.03560242801904678

Rewards:
74.4454
74.4454
74.4454
objective = 0.018240178003907204
==== episode 29200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9998 0.0001 0.0000

action = 2
probs = 0.0001 0.0003 0.9995 0.0002

Learning rate: 5.5827e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013830398675054312 0.0838996022939682
encoder.encoder.weight_hh_l0: -0.001163005013950169 0.08553705364465714
encoder.encoder.bias_ih_l0: 0.007337209302932024 0.0891265943646431
encoder.encoder.bias_hh_l0: 0.020409168675541878 0.08634275197982788
encoder.encoder.weight_ih_l0_reverse: 0.0019762993324548006 0.08470098674297333
encoder.encoder.weight_hh_l0_reverse: 0.00046342663699761033 0.0836673155426979
encoder.encoder.bias_ih_l0_reverse: 0.013440758921205997 0.08233343809843063
encoder.encoder.bias_hh_l0_reverse: 0.01373550109565258 0.08924853801727295
decider.lstm.weight_ih_l0: -0.001768732676282525 0.14652778208255768
decider.lstm.weight_hh_l0: 0.005188316106796265 0.1463261991739273
decider.lstm.bias_ih_l0: -0.01645585335791111 0.14164531230926514
decider.lstm.bias_hh_l0: 0.019365064799785614 0.15456417202949524
decider.linear1.weight: 0.004388258792459965 0.1203187108039856
decider.linear1.bias: 0.008153241127729416 0.11459407210350037
decider.linear2.weight: 0.0032931948080658913 0.05433855205774307
decider.linear2.bias: 0.0030102382879704237 0.05318404361605644
decider.linear3.weight: -0.0046358490362763405 0.06273768842220306
decider.linear3.bias: -0.01606537215411663 0.03563196212053299

Rewards:
74.4454
74.4454
74.4454
objective = 0.016933508217334747
==== episode 29300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0001 0.0000

action = 2
probs = 0.0001 0.0002 0.9995 0.0002

Learning rate: 5.5827e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001390382763929665 0.08391123265028
encoder.encoder.weight_hh_l0: -0.001167857670225203 0.08556339889764786
encoder.encoder.bias_ih_l0: 0.007418324705213308 0.08914814889431
encoder.encoder.bias_hh_l0: 0.020490288734436035 0.0863620787858963
encoder.encoder.weight_ih_l0_reverse: 0.0019826479256153107 0.08470971882343292
encoder.encoder.weight_hh_l0_reverse: 0.0004597545485012233 0.0836779996752739
encoder.encoder.bias_ih_l0_reverse: 0.01350089069455862 0.08233776688575745
encoder.encoder.bias_hh_l0_reverse: 0.013795632869005203 0.08925829082727432
decider.lstm.weight_ih_l0: -0.001773777767084539 0.14654071629047394
decider.lstm.weight_hh_l0: 0.005208957940340042 0.1463363766670227
decider.lstm.bias_ih_l0: -0.016377167776226997 0.1416345089673996
decider.lstm.bias_hh_l0: 0.019443737342953682 0.15457169711589813
decider.linear1.weight: 0.004396119154989719 0.12033580988645554
decider.linear1.bias: 0.008204166777431965 0.11459454894065857
decider.linear2.weight: 0.003306552767753601 0.05435796454548836
decider.linear2.bias: 0.0030380580574274063 0.053191881626844406
decider.linear3.weight: -0.00465617747977376 0.06282191723585129
decider.linear3.bias: -0.01607860065996647 0.03566114604473114

Rewards:
74.4454
74.4454
74.4454
objective = 0.015740826725959778
==== episode 29400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9999 0.0001 0.0000

action = 2
probs = 0.0000 0.0002 0.9995 0.0002

Learning rate: 5.5827e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013976477785035968 0.08392264693975449
encoder.encoder.weight_hh_l0: -0.0011726657394319773 0.08558955043554306
encoder.encoder.bias_ih_l0: 0.007498171180486679 0.0891689658164978
encoder.encoder.bias_hh_l0: 0.02057012915611267 0.08638086915016174
encoder.encoder.weight_ih_l0_reverse: 0.001988834934309125 0.0847182422876358
encoder.encoder.weight_hh_l0_reverse: 0.00045607073116116226 0.08368857204914093
encoder.encoder.bias_ih_l0_reverse: 0.013559943996369839 0.08234195411205292
encoder.encoder.bias_hh_l0_reverse: 0.013854684308171272 0.0892675444483757
decider.lstm.weight_ih_l0: -0.0017788426484912634 0.14655347168445587
decider.lstm.weight_hh_l0: 0.0052290428429841995 0.14634636044502258
decider.lstm.bias_ih_l0: -0.016300233080983162 0.14162364602088928
decider.lstm.bias_hh_l0: 0.019520670175552368 0.15457862615585327
decider.linear1.weight: 0.004403926897794008 0.12035279721021652
decider.linear1.bias: 0.00825474876910448 0.11459581553936005
decider.linear2.weight: 0.003319593844935298 0.054377179592847824
decider.linear2.bias: 0.003065193071961403 0.053199488669633865
decider.linear3.weight: -0.004676262382417917 0.0629054382443428
decider.linear3.bias: -0.016091464087367058 0.03568996861577034

Rewards:
74.4454
74.4454
74.4454
objective = 0.014647322706878185
==== episode 29500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9999 0.0001 0.0000

action = 2
probs = 0.0000 0.0002 0.9996 0.0002

Learning rate: 5.5268e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014048455050215125 0.0839337632060051
encoder.encoder.weight_hh_l0: -0.0011774224694818258 0.08561538904905319
encoder.encoder.bias_ih_l0: 0.007576498668640852 0.08918912708759308
encoder.encoder.bias_hh_l0: 0.020648455247282982 0.0863991379737854
encoder.encoder.weight_ih_l0_reverse: 0.0019948696717619896 0.08472659438848495
encoder.encoder.weight_hh_l0_reverse: 0.0004523840907495469 0.08369903266429901
encoder.encoder.bias_ih_l0_reverse: 0.013617734424769878 0.08234602957963943
encoder.encoder.bias_hh_l0_reverse: 0.013912474736571312 0.08927642554044724
decider.lstm.weight_ih_l0: -0.0017839079955592752 0.1465660184621811
decider.lstm.weight_hh_l0: 0.0052485037595033646 0.1463560163974762
decider.lstm.bias_ih_l0: -0.016225330531597137 0.14161278307437897
decider.lstm.bias_hh_l0: 0.019595574587583542 0.15458519756793976
decider.linear1.weight: 0.004411496687680483 0.12036959081888199
decider.linear1.bias: 0.008304283954203129 0.11459727585315704
decider.linear2.weight: 0.003332318738102913 0.05439620465040207
decider.linear2.bias: 0.003091671736910939 0.053206898272037506
decider.linear3.weight: -0.004696115851402283 0.06298825889825821
decider.linear3.bias: -0.016103995963931084 0.035718467086553574

Rewards:
74.4454
74.4454
74.4454
objective = 0.013641156256198883
==== episode 29600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9999 0.0001 0.0000

action = 2
probs = 0.0000 0.0002 0.9996 0.0002

Learning rate: 5.5268e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014118906110525131 0.08394457399845123
encoder.encoder.weight_hh_l0: -0.001182110863737762 0.08564077317714691
encoder.encoder.bias_ih_l0: 0.007652898784726858 0.08920859545469284
encoder.encoder.bias_hh_l0: 0.020724857226014137 0.08641673624515533
encoder.encoder.weight_ih_l0_reverse: 0.002000737702473998 0.0847347155213356
encoder.encoder.weight_hh_l0_reverse: 0.0004486996622290462 0.08370928466320038
encoder.encoder.bias_ih_l0_reverse: 0.013674323447048664 0.08234996348619461
encoder.encoder.bias_hh_l0_reverse: 0.013969069346785545 0.08928503841161728
decider.lstm.weight_ih_l0: -0.0017889607697725296 0.14657828211784363
decider.lstm.weight_hh_l0: 0.005267317406833172 0.14636529982089996
decider.lstm.bias_ih_l0: -0.016152571886777878 0.14160187542438507
decider.lstm.bias_hh_l0: 0.019668331369757652 0.15459132194519043
decider.linear1.weight: 0.004418813623487949 0.12038611620664597
decider.linear1.bias: 0.008352559059858322 0.11459879577159882
decider.linear2.weight: 0.0033447020687162876 0.05441487580537796
decider.linear2.bias: 0.003117383224889636 0.05321412533521652
decider.linear3.weight: -0.00471554696559906 0.06306955963373184
decider.linear3.bias: -0.016116103157401085 0.035746362060308456

Rewards:
74.4454
74.4454
74.4454
objective = 0.012720836326479912
==== episode 29700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9995 0.0004 0.0001

action = 2
probs = 0.0000 0.0001 0.9998 0.0001

Learning rate: 5.5268e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013720110291615129 0.08383986353874207
encoder.encoder.weight_hh_l0: -0.0011563872685655951 0.08553355187177658
encoder.encoder.bias_ih_l0: 0.007266685366630554 0.08915308862924576
encoder.encoder.bias_hh_l0: 0.020338645204901695 0.08632376044988632
encoder.encoder.weight_ih_l0_reverse: 0.001988341799005866 0.08471498638391495
encoder.encoder.weight_hh_l0_reverse: 0.0004542520036920905 0.08368264138698578
encoder.encoder.bias_ih_l0_reverse: 0.013372077606618404 0.08225993067026138
encoder.encoder.bias_hh_l0_reverse: 0.013666825369000435 0.0892266184091568
decider.lstm.weight_ih_l0: -0.001782684586942196 0.14651796221733093
decider.lstm.weight_hh_l0: 0.005210565868765116 0.14632739126682281
decider.lstm.bias_ih_l0: -0.016363022848963737 0.14163722097873688
decider.lstm.bias_hh_l0: 0.019457899034023285 0.15462614595890045
decider.linear1.weight: 0.004411799367517233 0.1203504428267479
decider.linear1.bias: 0.008249807171523571 0.11432940512895584
decider.linear2.weight: 0.0033071935176849365 0.05438189208507538
decider.linear2.bias: 0.003070700680837035 0.053152408450841904
decider.linear3.weight: -0.004740111995488405 0.06298553198575974
decider.linear3.bias: -0.016157707199454308 0.035422299057245255

Rewards:
74.4454
74.4454
74.4454
objective = 0.019450092688202858
==== episode 29800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9994 0.0004 0.0001

action = 2
probs = 0.0000 0.0001 0.9998 0.0001

Learning rate: 5.5268e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013707122998312116 0.08383823931217194
encoder.encoder.weight_hh_l0: -0.0011547158937901258 0.08553650975227356
encoder.encoder.bias_ih_l0: 0.007266789674758911 0.08915762603282928
encoder.encoder.bias_hh_l0: 0.020338742062449455 0.08632722496986389
encoder.encoder.weight_ih_l0_reverse: 0.001989268232136965 0.08471809327602386
encoder.encoder.weight_hh_l0_reverse: 0.00045316247269511223 0.08368632197380066
encoder.encoder.bias_ih_l0_reverse: 0.013368820771574974 0.08225767314434052
encoder.encoder.bias_hh_l0_reverse: 0.013663573190569878 0.08922731876373291
decider.lstm.weight_ih_l0: -0.001782985171303153 0.14651824533939362
decider.lstm.weight_hh_l0: 0.005212138406932354 0.14632979035377502
decider.lstm.bias_ih_l0: -0.016351941972970963 0.1416417360305786
decider.lstm.bias_hh_l0: 0.019468968734145164 0.1546333283185959
decider.linear1.weight: 0.004412428475916386 0.12035132944583893
decider.linear1.bias: 0.008252942934632301 0.11431097984313965
decider.linear2.weight: 0.0033073769882321358 0.05440124124288559
decider.linear2.bias: 0.003079173155128956 0.05315180867910385
decider.linear3.weight: -0.00476484838873148 0.0630364716053009
decider.linear3.bias: -0.016184572130441666 0.03543390333652496

Rewards:
74.4454
74.4454
74.4454
objective = 0.020879890769720078
==== episode 29900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9994 0.0004 0.0001

action = 2
probs = 0.0000 0.0001 0.9998 0.0001

Learning rate: 5.5268e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001376285101287067 0.08385199308395386
encoder.encoder.weight_hh_l0: -0.0011573784286156297 0.0855574756860733
encoder.encoder.bias_ih_l0: 0.007333594840019941 0.08917222917079926
encoder.encoder.bias_hh_l0: 0.020405542105436325 0.0863460823893547
encoder.encoder.weight_ih_l0_reverse: 0.0019928868860006332 0.08472410589456558
encoder.encoder.weight_hh_l0_reverse: 0.00045074892113916576 0.08369413763284683
encoder.encoder.bias_ih_l0_reverse: 0.013416473753750324 0.08226720243692398
encoder.encoder.bias_hh_l0_reverse: 0.013711223378777504 0.08923695981502533
decider.lstm.weight_ih_l0: -0.0017848393181338906 0.14652812480926514
decider.lstm.weight_hh_l0: 0.005224383901804686 0.14633803069591522
decider.lstm.bias_ih_l0: -0.01630076952278614 0.14163905382156372
decider.lstm.bias_hh_l0: 0.019520126283168793 0.15463607013225555
decider.linear1.weight: 0.0044158948585391045 0.12035969644784927
decider.linear1.bias: 0.008281158283352852 0.11432863771915436
decider.linear2.weight: 0.0033224611543118954 0.05441778898239136
decider.linear2.bias: 0.0030983034521341324 0.05316052958369255
decider.linear3.weight: -0.004788179881870747 0.06310718506574631
decider.linear3.bias: -0.016207406297326088 0.035492632538080215

Rewards:
74.4454
74.4454
74.4454
objective = 0.019238635897636414
==== episode 30000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9995 0.0004 0.0001

action = 2
probs = 0.0000 0.0001 0.9998 0.0001

Learning rate: 5.4716e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013819992309436202 0.08386552333831787
encoder.encoder.weight_hh_l0: -0.0011601371224969625 0.08557872474193573
encoder.encoder.bias_ih_l0: 0.007401170674711466 0.08918703347444534
encoder.encoder.bias_hh_l0: 0.02047312632203102 0.08636511117219925
encoder.encoder.weight_ih_l0_reverse: 0.001996637787669897 0.08473022282123566
encoder.encoder.weight_hh_l0_reverse: 0.00044829805847257376 0.08370206505060196
encoder.encoder.bias_ih_l0_reverse: 0.013464665040373802 0.0822765901684761
encoder.encoder.bias_hh_l0_reverse: 0.01375940814614296 0.0892464891076088
decider.lstm.weight_ih_l0: -0.0017867217538878322 0.14653797447681427
decider.lstm.weight_hh_l0: 0.005236704833805561 0.14634621143341064
decider.lstm.bias_ih_l0: -0.016249611973762512 0.14163616299629211
decider.lstm.bias_hh_l0: 0.019571295008063316 0.1546388864517212
decider.linear1.weight: 0.004419428296387196 0.12036815285682678
decider.linear1.bias: 0.008309463039040565 0.11434537917375565
decider.linear2.weight: 0.003337272210046649 0.05443384498357773
decider.linear2.bias: 0.0031172034796327353 0.05316902697086334
decider.linear3.weight: -0.004810405429452658 0.06317403167486191
decider.linear3.bias: -0.016229800879955292 0.035549331456422806

Rewards:
74.4454
74.4454
74.4454
objective = 0.017810581251978874
==== episode 30100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9995 0.0003 0.0001

action = 2
probs = 0.0000 0.0001 0.9998 0.0001

Learning rate: 5.4716e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013877780875191092 0.08387871086597443
encoder.encoder.weight_hh_l0: -0.0011629596119746566 0.08560001105070114
encoder.encoder.bias_ih_l0: 0.007468769792467356 0.08920183777809143
encoder.encoder.bias_hh_l0: 0.020540723577141762 0.08638405054807663
encoder.encoder.weight_ih_l0_reverse: 0.002000459237024188 0.08473636955022812
encoder.encoder.weight_hh_l0_reverse: 0.00044583482667803764 0.08371003717184067
encoder.encoder.bias_ih_l0_reverse: 0.013512855395674706 0.08228573203086853
encoder.encoder.bias_hh_l0_reverse: 0.013807594776153564 0.08925582468509674
decider.lstm.weight_ih_l0: -0.0017886151326820254 0.14654770493507385
decider.lstm.weight_hh_l0: 0.005248948931694031 0.14635422825813293
decider.lstm.bias_ih_l0: -0.016198929399251938 0.141633078455925
decider.lstm.bias_hh_l0: 0.019621962681412697 0.15464165806770325
decider.linear1.weight: 0.004422989208251238 0.1203765943646431
decider.linear1.bias: 0.0083375945687294 0.11436119675636292
decider.linear2.weight: 0.0033517121337354183 0.05444934219121933
decider.linear2.bias: 0.0031357367988675833 0.05317724868655205
decider.linear3.weight: -0.004831509664654732 0.06323711574077606
decider.linear3.bias: -0.016251619905233383 0.035603780299425125

Rewards:
74.4454
74.4454
74.4454
objective = 0.016570530831813812
==== episode 30200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9996 0.0003 0.0000

action = 2
probs = 0.0000 0.0001 0.9998 0.0001

Learning rate: 5.4716e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013936489121988416 0.08389170467853546
encoder.encoder.weight_hh_l0: -0.0011658624280244112 0.08562148362398148
encoder.encoder.bias_ih_l0: 0.007536796387284994 0.08921671658754349
encoder.encoder.bias_hh_l0: 0.020608749240636826 0.0864030197262764
encoder.encoder.weight_ih_l0_reverse: 0.00200439291074872 0.08474255353212357
encoder.encoder.weight_hh_l0_reverse: 0.0004433438298292458 0.08371806889772415
encoder.encoder.bias_ih_l0_reverse: 0.01356146577745676 0.08229468762874603
encoder.encoder.bias_hh_l0_reverse: 0.013856202363967896 0.08926505595445633
decider.lstm.weight_ih_l0: -0.0017905363347381353 0.14655740559101105
decider.lstm.weight_hh_l0: 0.005261227022856474 0.14636217057704926
decider.lstm.bias_ih_l0: -0.016148360446095467 0.14162975549697876
decider.lstm.bias_hh_l0: 0.019672539085149765 0.1546444296836853
decider.linear1.weight: 0.004426590166985989 0.12038510292768478
decider.linear1.bias: 0.008365731686353683 0.1143762543797493
decider.linear2.weight: 0.0033659779001027346 0.05446452274918556
decider.linear2.bias: 0.003154139034450054 0.053185317665338516
decider.linear3.weight: -0.004851863719522953 0.06329762190580368
decider.linear3.bias: -0.016273096203804016 0.035656701773405075

Rewards:
74.4454
74.4454
74.4454
objective = 0.015465185046195984
==== episode 30300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9996 0.0003 0.0000

action = 2
probs = 0.0000 0.0001 0.9998 0.0001

Learning rate: 5.4716e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013996106572449207 0.08390452712774277
encoder.encoder.weight_hh_l0: -0.0011688480153679848 0.08564314991235733
encoder.encoder.bias_ih_l0: 0.007605256978422403 0.08923166990280151
encoder.encoder.bias_hh_l0: 0.020677203312516212 0.08642200380563736
encoder.encoder.weight_ih_l0_reverse: 0.00200841948390007 0.0847487822175026
encoder.encoder.weight_hh_l0_reverse: 0.00044082425301894546 0.0837261751294136
encoder.encoder.bias_ih_l0_reverse: 0.013610484078526497 0.08230353146791458
encoder.encoder.bias_hh_l0_reverse: 0.01390521228313446 0.08927419036626816
decider.lstm.weight_ih_l0: -0.0017924881540238857 0.14656709134578705
decider.lstm.weight_hh_l0: 0.005273527465760708 0.146370068192482
decider.lstm.bias_ih_l0: -0.016097862273454666 0.14162616431713104
decider.lstm.bias_hh_l0: 0.019723055884242058 0.15464715659618378
decider.linear1.weight: 0.004430231638252735 0.12039369344711304
decider.linear1.bias: 0.00839392002671957 0.11439066380262375
decider.linear2.weight: 0.003380103735253215 0.05447941645979881
decider.linear2.bias: 0.003172434400767088 0.05319324508309364
decider.linear3.weight: -0.00487158028408885 0.06335596740245819
decider.linear3.bias: -0.01629432663321495 0.03570836782455444

Rewards:
74.4454
74.4454
74.4454
objective = 0.014472337439656258
==== episode 30400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0002 0.9984 0.0014 0.0001

action = 2
probs = 0.0000 0.0000 0.9999 0.0001

Learning rate: 5.4716e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013941734796389937 0.08384733647108078
encoder.encoder.weight_hh_l0: -0.001159990904852748 0.08560720831155777
encoder.encoder.bias_ih_l0: 0.007491457276046276 0.0892522931098938
encoder.encoder.bias_hh_l0: 0.02056340128183365 0.0864199846982956
encoder.encoder.weight_ih_l0_reverse: 0.0020123720169067383 0.08475939929485321
encoder.encoder.weight_hh_l0_reverse: 0.00044241236173547804 0.08373171091079712
encoder.encoder.bias_ih_l0_reverse: 0.013492780737578869 0.08224945515394211
encoder.encoder.bias_hh_l0_reverse: 0.013787508942186832 0.08925455063581467
decider.lstm.weight_ih_l0: -0.0017889004666358232 0.14653380215168
decider.lstm.weight_hh_l0: 0.005245623178780079 0.1463542878627777
decider.lstm.bias_ih_l0: -0.01620187610387802 0.14168120920658112
decider.lstm.bias_hh_l0: 0.019619042053818703 0.15468630194664001
decider.linear1.weight: 0.004427222069352865 0.12037276476621628
decider.linear1.bias: 0.008327539078891277 0.11417469382286072
decider.linear2.weight: 0.003349627833813429 0.05448158085346222
decider.linear2.bias: 0.0031379442662000656 0.053158484399318695
decider.linear3.weight: -0.004913884215056896 0.06334960460662842
decider.linear3.bias: -0.016340717673301697 0.03546943515539169

Rewards:
74.4454
74.4454
74.4454
objective = 0.04338083788752556
==== episode 30500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9987 0.0010 0.0001

action = 2
probs = 0.0000 0.0000 0.9999 0.0001

Learning rate: 5.4169e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013941131765022874 0.08385949581861496
encoder.encoder.weight_hh_l0: -0.0011611307272687554 0.08561919629573822
encoder.encoder.bias_ih_l0: 0.007519394159317017 0.0892525240778923
encoder.encoder.bias_hh_l0: 0.020591339096426964 0.08642279356718063
encoder.encoder.weight_ih_l0_reverse: 0.0020115175284445286 0.08475996553897858
encoder.encoder.weight_hh_l0_reverse: 0.00044143886771053076 0.08373356610536575
encoder.encoder.bias_ih_l0_reverse: 0.013515116646885872 0.08226186782121658
encoder.encoder.bias_hh_l0_reverse: 0.013809846714138985 0.08925942331552505
decider.lstm.weight_ih_l0: -0.0017901068786159158 0.1465417593717575
decider.lstm.weight_hh_l0: 0.005253937561064959 0.1463605761528015
decider.lstm.bias_ih_l0: -0.016166839748620987 0.1416759341955185
decider.lstm.bias_hh_l0: 0.019654076546430588 0.15468308329582214
decider.linear1.weight: 0.004429243970662355 0.12037961930036545
decider.linear1.bias: 0.008351010270416737 0.11421199142932892
decider.linear2.weight: 0.0033667124807834625 0.054501522332429886
decider.linear2.bias: 0.0031591439619660378 0.05316931754350662
decider.linear3.weight: -0.004949773661792278 0.06345117092132568
decider.linear3.bias: -0.0163810383528471 0.03556245192885399

Rewards:
74.4454
74.4454
74.4454
objective = 0.034629516303539276
==== episode 30600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9990 0.0008 0.0001

action = 2
probs = 0.0000 0.0000 0.9999 0.0001

Learning rate: 5.4169e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013958137715235353 0.08387206494808197
encoder.encoder.weight_hh_l0: -0.0011627872008830309 0.08563407510519028
encoder.encoder.bias_ih_l0: 0.00755971297621727 0.08925721049308777
encoder.encoder.bias_hh_l0: 0.020631661638617516 0.08643078804016113
encoder.encoder.weight_ih_l0_reverse: 0.0020121659617871046 0.08476220816373825
encoder.encoder.weight_hh_l0_reverse: 0.00043996915337629616 0.08373729884624481
encoder.encoder.bias_ih_l0_reverse: 0.013545673340559006 0.08227372169494629
encoder.encoder.bias_hh_l0_reverse: 0.013840403407812119 0.08926550298929214
decider.lstm.weight_ih_l0: -0.0017914496129378676 0.14655020833015442
decider.lstm.weight_hh_l0: 0.005263064056634903 0.146367147564888
decider.lstm.bias_ih_l0: -0.016128694638609886 0.14167068898677826
decider.lstm.bias_hh_l0: 0.019692212343215942 0.1546815037727356
decider.linear1.weight: 0.004431460052728653 0.12038665264844894
decider.linear1.bias: 0.008374671451747417 0.11424298584461212
decider.linear2.weight: 0.003382533323019743 0.05451996251940727
decider.linear2.bias: 0.00317871430888772 0.05317911133170128
decider.linear3.weight: -0.004981151316314936 0.06353757530450821
decider.linear3.bias: -0.016417991369962692 0.035643912851810455

Rewards:
74.4454
74.4454
74.4454
objective = 0.02888837270438671
==== episode 30700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9991 0.0007 0.0001

action = 2
probs = 0.0000 0.0001 0.9999 0.0001

Learning rate: 5.4169e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013986059930175543 0.0838848277926445
encoder.encoder.weight_hh_l0: -0.001164812594652176 0.08565082401037216
encoder.encoder.bias_ih_l0: 0.007607816252857447 0.0892646536231041
encoder.encoder.bias_hh_l0: 0.020679762586951256 0.08644194900989532
encoder.encoder.weight_ih_l0_reverse: 0.002013738267123699 0.08476550877094269
encoder.encoder.weight_hh_l0_reverse: 0.0004382096230983734 0.0837421864271164
encoder.encoder.bias_ih_l0_reverse: 0.013581323437392712 0.08228519558906555
encoder.encoder.bias_hh_l0_reverse: 0.013876054435968399 0.08927225321531296
decider.lstm.weight_ih_l0: -0.0017928843153640628 0.146558940410614
decider.lstm.weight_hh_l0: 0.005272722337394953 0.14637383818626404
decider.lstm.bias_ih_l0: -0.016088660806417465 0.1416654884815216
decider.lstm.bias_hh_l0: 0.019732236862182617 0.15468096733093262
decider.linear1.weight: 0.0044338274747133255 0.12039382755756378
decider.linear1.bias: 0.008398549631237984 0.11426988244056702
decider.linear2.weight: 0.003397786058485508 0.05453743040561676
decider.linear2.bias: 0.003197312355041504 0.05318824574351311
decider.linear3.weight: -0.0050097182393074036 0.06361467391252518
decider.linear3.bias: -0.016452843323349953 0.03571805730462074

Rewards:
74.4454
74.4454
74.4454
objective = 0.024794742465019226
==== episode 30800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9993 0.0006 0.0001

action = 2
probs = 0.0000 0.0001 0.9999 0.0001

Learning rate: 5.4169e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014021402457728982 0.083897665143013
encoder.encoder.weight_hh_l0: -0.0011671205284073949 0.0856688991189003
encoder.encoder.bias_ih_l0: 0.0076612005941569805 0.08927399665117264
encoder.encoder.bias_hh_l0: 0.020733144134283066 0.08645521104335785
encoder.encoder.weight_ih_l0_reverse: 0.0020159322302788496 0.08476950973272324
encoder.encoder.weight_hh_l0_reverse: 0.0004362651670817286 0.08374788612127304
encoder.encoder.bias_ih_l0_reverse: 0.013620381243526936 0.08229634910821915
encoder.encoder.bias_hh_l0_reverse: 0.013915108516812325 0.08927937597036362
decider.lstm.weight_ih_l0: -0.0017943866550922394 0.14656779170036316
decider.lstm.weight_hh_l0: 0.005282732658088207 0.14638061821460724
decider.lstm.bias_ih_l0: -0.016047468408942223 0.14166031777858734
decider.lstm.bias_hh_l0: 0.01977342553436756 0.15468110144138336
decider.linear1.weight: 0.00443631038069725 0.12040110677480698
decider.linear1.bias: 0.008422593586146832 0.11429381370544434
decider.linear2.weight: 0.0034126564860343933 0.054554104804992676
decider.linear2.bias: 0.0032152244821190834 0.05319688841700554
decider.linear3.weight: -0.005036236718297005 0.06368515640497208
decider.linear3.bias: -0.016486134380102158 0.03578690439462662

Rewards:
74.4454
74.4454
74.4454
objective = 0.021718692034482956
==== episode 30900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9994 0.0005 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0001

Learning rate: 5.4169e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014061826514080167 0.08391042798757553
encoder.encoder.weight_hh_l0: -0.0011696526780724525 0.08568788319826126
encoder.encoder.bias_ih_l0: 0.007718090433627367 0.08928460627794266
encoder.encoder.bias_hh_l0: 0.020790036767721176 0.0864698514342308
encoder.encoder.weight_ih_l0_reverse: 0.002018560655415058 0.08477400988340378
encoder.encoder.weight_hh_l0_reverse: 0.0004342004540376365 0.08375414460897446
encoder.encoder.bias_ih_l0_reverse: 0.013661644421517849 0.08230717480182648
encoder.encoder.bias_hh_l0_reverse: 0.013956373557448387 0.08928671479225159
decider.lstm.weight_ih_l0: -0.0017959361430257559 0.14657671749591827
decider.lstm.weight_hh_l0: 0.005292949266731739 0.14638739824295044
decider.lstm.bias_ih_l0: -0.01600567251443863 0.14165504276752472
decider.lstm.bias_hh_l0: 0.0198152307420969 0.15468169748783112
decider.linear1.weight: 0.0044388724491000175 0.12040846049785614
decider.linear1.bias: 0.00844668224453926 0.11431542783975601
decider.linear2.weight: 0.0034269681200385094 0.054570138454437256
decider.linear2.bias: 0.0032325650099664927 0.053205039352178574
decider.linear3.weight: -0.005061192438006401 0.06375069916248322
decider.linear3.bias: -0.016518188640475273 0.03585169464349747

Rewards:
74.4454
74.4454
74.4454
objective = 0.019317928701639175
==== episode 31000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9994 0.0004 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0001

Learning rate: 5.3627e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014106457820162177 0.08392314612865448
encoder.encoder.weight_hh_l0: -0.0011723866919055581 0.08570767194032669
encoder.encoder.bias_ih_l0: 0.007777991238981485 0.08929628133773804
encoder.encoder.bias_hh_l0: 0.02084992825984955 0.08648554235696793
encoder.encoder.weight_ih_l0_reverse: 0.002021517837420106 0.08477892726659775
encoder.encoder.weight_hh_l0_reverse: 0.0004320346633903682 0.08376093208789825
encoder.encoder.bias_ih_l0_reverse: 0.013704825192689896 0.08231779932975769
encoder.encoder.bias_hh_l0_reverse: 0.013999560847878456 0.08929426223039627
decider.lstm.weight_ih_l0: -0.0017975326627492905 0.14658571779727936
decider.lstm.weight_hh_l0: 0.005303367506712675 0.14639419317245483
decider.lstm.bias_ih_l0: -0.015963271260261536 0.14164979755878448
decider.lstm.bias_hh_l0: 0.01985762268304825 0.15468260645866394
decider.linear1.weight: 0.004441510420292616 0.12041591852903366
decider.linear1.bias: 0.00847086776047945 0.11433529108762741
decider.linear2.weight: 0.0034409065265208483 0.05458564683794975
decider.linear2.bias: 0.0032495222985744476 0.05321286991238594
decider.linear3.weight: -0.005084918811917305 0.06381242722272873
decider.linear3.bias: -0.016549281775951385 0.03591332957148552

Rewards:
74.4454
74.4454
74.4454
objective = 0.01738506555557251
==== episode 31100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9995 0.0004 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0001

Learning rate: 5.3627e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014153937809169292 0.0839356854557991
encoder.encoder.weight_hh_l0: -0.001175275887362659 0.08572794497013092
encoder.encoder.bias_ih_l0: 0.007839762605726719 0.0893087089061737
encoder.encoder.bias_hh_l0: 0.020911702886223793 0.08650194108486176
encoder.encoder.weight_ih_l0_reverse: 0.0020247064530849457 0.08478410542011261
encoder.encoder.weight_hh_l0_reverse: 0.00042980106081813574 0.08376805484294891
encoder.encoder.bias_ih_l0_reverse: 0.013749191537499428 0.08232813328504562
encoder.encoder.bias_hh_l0_reverse: 0.014043925330042839 0.08930191397666931
decider.lstm.weight_ih_l0: -0.0017991630593314767 0.14659470319747925
decider.lstm.weight_hh_l0: 0.005313877947628498 0.14640085399150848
decider.lstm.bias_ih_l0: -0.01592063531279564 0.14164456725120544
decider.lstm.bias_hh_l0: 0.019900251179933548 0.1546836793422699
decider.linear1.weight: 0.004444187507033348 0.12042340636253357
decider.linear1.bias: 0.008494934067130089 0.11435361951589584
decider.linear2.weight: 0.003454445395618677 0.054600588977336884
decider.linear2.bias: 0.003266042098402977 0.05322038382291794
decider.linear3.weight: -0.005107434466481209 0.06387055665254593
decider.linear3.bias: -0.0165792815387249 0.03597182780504227

Rewards:
74.4454
74.4454
74.4454
objective = 0.015811949968338013
==== episode 31200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9996 0.0004 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0001

Learning rate: 5.3627e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001420381129719317 0.08394815027713776
encoder.encoder.weight_hh_l0: -0.0011783152585849166 0.08574870228767395
encoder.encoder.bias_ih_l0: 0.007903244346380234 0.08932176232337952
encoder.encoder.bias_hh_l0: 0.02097516879439354 0.08651889115571976
encoder.encoder.weight_ih_l0_reverse: 0.002028131391853094 0.0847894623875618
encoder.encoder.weight_hh_l0_reverse: 0.0004275017126929015 0.08377543091773987
encoder.encoder.bias_ih_l0_reverse: 0.013794870115816593 0.08233816921710968
encoder.encoder.bias_hh_l0_reverse: 0.014089611358940601 0.08930962532758713
decider.lstm.weight_ih_l0: -0.001800835714675486 0.1466037482023239
decider.lstm.weight_hh_l0: 0.0053245387971401215 0.14640745520591736
decider.lstm.bias_ih_l0: -0.015877537429332733 0.1416390985250473
decider.lstm.bias_hh_l0: 0.019943349063396454 0.15468473732471466
decider.linear1.weight: 0.004446903709322214 0.12043096870183945
decider.linear1.bias: 0.008519046008586884 0.1143706813454628
decider.linear2.weight: 0.003467794507741928 0.05461519584059715
decider.linear2.bias: 0.003282367717474699 0.05322769656777382
decider.linear3.weight: -0.005129155702888966 0.06392628699541092
decider.linear3.bias: -0.016608620062470436 0.03602822497487068

Rewards:
74.4454
74.4454
74.4454
objective = 0.014478659257292747
==== episode 31300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9996 0.0003 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0001

Learning rate: 5.3627e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014255755813792348 0.08396056294441223
encoder.encoder.weight_hh_l0: -0.0011815008474513888 0.08576996624469757
encoder.encoder.bias_ih_l0: 0.007968275807797909 0.08933533728122711
encoder.encoder.bias_hh_l0: 0.02104020304977894 0.08653631061315536
encoder.encoder.weight_ih_l0_reverse: 0.0020317253656685352 0.0847950130701065
encoder.encoder.weight_hh_l0_reverse: 0.0004251505306456238 0.0837830975651741
encoder.encoder.bias_ih_l0_reverse: 0.013841625303030014 0.0823480635881424
encoder.encoder.bias_hh_l0_reverse: 0.01413636188954115 0.08931739628314972
decider.lstm.weight_ih_l0: -0.0018025528406724334 0.14661283791065216
decider.lstm.weight_hh_l0: 0.005335304886102676 0.14641401171684265
decider.lstm.bias_ih_l0: -0.01583406701683998 0.14163346588611603
decider.lstm.bias_hh_l0: 0.019986828789114952 0.154685840010643
decider.linear1.weight: 0.004449666477739811 0.12043862789869308
decider.linear1.bias: 0.008543306961655617 0.11438677459955215
decider.linear2.weight: 0.003481002990156412 0.05462953448295593
decider.linear2.bias: 0.0032985471189022064 0.05323486030101776
decider.linear3.weight: -0.00515021150931716 0.06398004293441772
decider.linear3.bias: -0.016637463122606277 0.036082979291677475

Rewards:
74.4454
74.4454
74.4454
objective = 0.01333336066454649
==== episode 31400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9996 0.0003 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0001

Learning rate: 5.3627e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014309465186670423 0.08397293090820312
encoder.encoder.weight_hh_l0: -0.0011848266003653407 0.0857917070388794
encoder.encoder.bias_ih_l0: 0.008034701459109783 0.08934935927391052
encoder.encoder.bias_hh_l0: 0.02110663801431656 0.08655411750078201
encoder.encoder.weight_ih_l0_reverse: 0.002035449491813779 0.08480075746774673
encoder.encoder.weight_hh_l0_reverse: 0.0004227476892992854 0.08379102498292923
encoder.encoder.bias_ih_l0_reverse: 0.013889321126043797 0.08235783874988556
encoder.encoder.bias_hh_l0_reverse: 0.014184053055942059 0.0893251970410347
decider.lstm.weight_ih_l0: -0.0018043153686448932 0.14662198722362518
decider.lstm.weight_hh_l0: 0.005346174351871014 0.14642050862312317
decider.lstm.bias_ih_l0: -0.015790224075317383 0.14162760972976685
decider.lstm.bias_hh_l0: 0.020030666142702103 0.15468691289424896
decider.linear1.weight: 0.004452311433851719 0.12044621258974075
decider.linear1.bias: 0.008567286655306816 0.11440181732177734
decider.linear2.weight: 0.00349410786293447 0.054643645882606506
decider.linear2.bias: 0.0033146177884191275 0.05324188992381096
decider.linear3.weight: -0.005170702002942562 0.06403214484453201
decider.linear3.bias: -0.01666577346622944 0.036136142909526825

Rewards:
74.4454
74.4454
74.4454
objective = 0.012340515851974487
==== episode 31500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9997 0.0003 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0001

Learning rate: 5.3091e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014364673988893628 0.08398525416851044
encoder.encoder.weight_hh_l0: -0.001188289257697761 0.08581389486789703
encoder.encoder.bias_ih_l0: 0.008102350868284702 0.08936374634504318
encoder.encoder.bias_hh_l0: 0.021174287423491478 0.08657221496105194
encoder.encoder.weight_ih_l0_reverse: 0.0020392790902405977 0.0848066657781601
encoder.encoder.weight_hh_l0_reverse: 0.0004202993877697736 0.08379919826984406
encoder.encoder.bias_ih_l0_reverse: 0.013937852345407009 0.08236751705408096
encoder.encoder.bias_hh_l0_reverse: 0.014232577756047249 0.08933303505182266
decider.lstm.weight_ih_l0: -0.0018061271402984858 0.1466311812400818
decider.lstm.weight_hh_l0: 0.005357123911380768 0.1464269608259201
decider.lstm.bias_ih_l0: -0.015746038407087326 0.14162155985832214
decider.lstm.bias_hh_l0: 0.020074844360351562 0.15468792617321014
decider.linear1.weight: 0.004454995505511761 0.12045390903949738
decider.linear1.bias: 0.008591461926698685 0.11441615968942642
decider.linear2.weight: 0.0035071370657533407 0.05465756356716156
decider.linear2.bias: 0.0033306085970252752 0.053248804062604904
decider.linear3.weight: -0.005190704017877579 0.06408283859491348
decider.linear3.bias: -0.016693735495209694 0.03618812933564186

Rewards:
74.4454
74.4454
74.4454
objective = 0.011467555537819862
==== episode 31600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9997 0.0002 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0001

Learning rate: 5.3091e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014419814106076956 0.08399733901023865
encoder.encoder.weight_hh_l0: -0.0011917935917153955 0.08583597093820572
encoder.encoder.bias_ih_l0: 0.008169233798980713 0.08937808126211166
encoder.encoder.bias_hh_l0: 0.02124115824699402 0.08659006655216217
encoder.encoder.weight_ih_l0_reverse: 0.0020430218428373337 0.08481251448392868
encoder.encoder.weight_hh_l0_reverse: 0.0004179171519353986 0.08380728214979172
encoder.encoder.bias_ih_l0_reverse: 0.01398561056703329 0.08237655460834503
encoder.encoder.bias_hh_l0_reverse: 0.014280333183705807 0.08934080600738525
decider.lstm.weight_ih_l0: -0.0018079426372423768 0.14664021134376526
decider.lstm.weight_hh_l0: 0.0053678350523114204 0.14643323421478271
decider.lstm.bias_ih_l0: -0.015702825039625168 0.1416151374578476
decider.lstm.bias_hh_l0: 0.02011805586516857 0.15468882024288177
decider.linear1.weight: 0.004457694478332996 0.12046167254447937
decider.linear1.bias: 0.008615517988801003 0.11442960053682327
decider.linear2.weight: 0.003519986756145954 0.054671190679073334
decider.linear2.bias: 0.0033463845029473305 0.053255558013916016
decider.linear3.weight: -0.0052100894972682 0.06413184851408005
decider.linear3.bias: -0.016721077263355255 0.036238521337509155

Rewards:
74.4454
74.4454
74.4454
objective = 0.010701148770749569
==== episode 31700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9997 0.0002 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0001

Learning rate: 5.3091e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014475584030151367 0.08400934934616089
encoder.encoder.weight_hh_l0: -0.0011953881476074457 0.08585825562477112
encoder.encoder.bias_ih_l0: 0.008236303925514221 0.08939255028963089
encoder.encoder.bias_hh_l0: 0.021308235824108124 0.08660794049501419
encoder.encoder.weight_ih_l0_reverse: 0.002046754816547036 0.08481840789318085
encoder.encoder.weight_hh_l0_reverse: 0.00041554620838724077 0.08381543308496475
encoder.encoder.bias_ih_l0_reverse: 0.014033402316272259 0.08238524943590164
encoder.encoder.bias_hh_l0_reverse: 0.014328123070299625 0.08934856206178665
decider.lstm.weight_ih_l0: -0.0018097960855811834 0.14664918184280396
decider.lstm.weight_hh_l0: 0.005378473550081253 0.14643938839435577
decider.lstm.bias_ih_l0: -0.01565978303551674 0.1416083723306656
decider.lstm.bias_hh_l0: 0.020161110907793045 0.15468956530094147
decider.linear1.weight: 0.0044602565467357635 0.12046947330236435
decider.linear1.bias: 0.008639093488454819 0.11444205790758133
decider.linear2.weight: 0.003532818052917719 0.05468468368053436
decider.linear2.bias: 0.0033621315378695726 0.05326223373413086
decider.linear3.weight: -0.0052291229367256165 0.06417988985776901
decider.linear3.bias: -0.01674797758460045 0.03628769889473915

Rewards:
74.4454
74.4454
74.4454
objective = 0.010013177990913391
==== episode 31800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9997 0.0002 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0001

Learning rate: 5.3091e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014532359782606363 0.08402132987976074
encoder.encoder.weight_hh_l0: -0.0011991049395874143 0.08588088303804398
encoder.encoder.bias_ih_l0: 0.008304190821945667 0.08940727263689041
encoder.encoder.bias_hh_l0: 0.021376118063926697 0.08662594109773636
encoder.encoder.weight_ih_l0_reverse: 0.002050545997917652 0.08482441306114197
encoder.encoder.weight_hh_l0_reverse: 0.00041313780820928514 0.0838237851858139
encoder.encoder.bias_ih_l0_reverse: 0.014081771485507488 0.0823938399553299
encoder.encoder.bias_hh_l0_reverse: 0.014376494102180004 0.08935636281967163
decider.lstm.weight_ih_l0: -0.0018117078579962254 0.14665822684764862
decider.lstm.weight_hh_l0: 0.005389165598899126 0.14644548296928406
decider.lstm.bias_ih_l0: -0.015616423450410366 0.14160127937793732
decider.lstm.bias_hh_l0: 0.02020447701215744 0.15469013154506683
decider.linear1.weight: 0.004463000688701868 0.12047749012708664
decider.linear1.bias: 0.008663509041070938 0.11445438861846924
decider.linear2.weight: 0.0035456428304314613 0.05469806492328644
decider.linear2.bias: 0.0033778618089854717 0.05326884612441063
decider.linear3.weight: -0.0052478439174592495 0.06422707438468933
decider.linear3.bias: -0.016774632036685944 0.036336060613393784

Rewards:
74.4454
74.4454
74.4454
objective = 0.009391799569129944
==== episode 31900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9998 0.0002 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0000

Learning rate: 5.3091e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001459001679904759 0.08403326570987701
encoder.encoder.weight_hh_l0: -0.001202942687086761 0.08590386062860489
encoder.encoder.bias_ih_l0: 0.008372806012630463 0.08942221850156784
encoder.encoder.bias_hh_l0: 0.021444737911224365 0.08664406836032867
encoder.encoder.weight_ih_l0_reverse: 0.002054383745416999 0.08483052253723145
encoder.encoder.weight_hh_l0_reverse: 0.00041069378494285047 0.08383232355117798
encoder.encoder.bias_ih_l0_reverse: 0.014130675233900547 0.08240232616662979
encoder.encoder.bias_hh_l0_reverse: 0.014425397850573063 0.0893642008304596
decider.lstm.weight_ih_l0: -0.0018136840080842376 0.14666734635829926
decider.lstm.weight_hh_l0: 0.0053998916409909725 0.14645150303840637
decider.lstm.bias_ih_l0: -0.015572745352983475 0.14159390330314636
decider.lstm.bias_hh_l0: 0.02024814672768116 0.15469053387641907
decider.linear1.weight: 0.004465784411877394 0.12048564106225967
decider.linear1.bias: 0.00868820771574974 0.1144663617014885
decider.linear2.weight: 0.0035584711004048586 0.05471135675907135
decider.linear2.bias: 0.0033935823012143373 0.05327540263533592
decider.linear3.weight: -0.005266290158033371 0.06427352875471115
decider.linear3.bias: -0.016801048070192337 0.03638368472456932

Rewards:
74.4454
74.4454
74.4454
objective = 0.008826653473079205
==== episode 32000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9998 0.0002 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0000

Learning rate: 5.2560e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014648493379354477 0.0840451717376709
encoder.encoder.weight_hh_l0: -0.0012069002259522676 0.08592715114355087
encoder.encoder.bias_ih_l0: 0.008442077785730362 0.08943737298250198
encoder.encoder.bias_hh_l0: 0.021513991057872772 0.08666226267814636
encoder.encoder.weight_ih_l0_reverse: 0.0020582610741257668 0.08483671396970749
encoder.encoder.weight_hh_l0_reverse: 0.0004082131781615317 0.08384104818105698
encoder.encoder.bias_ih_l0_reverse: 0.014180061407387257 0.08241073787212372
encoder.encoder.bias_hh_l0_reverse: 0.014474788680672646 0.08937206864356995
decider.lstm.weight_ih_l0: -0.001815727329812944 0.14667652547359467
decider.lstm.weight_hh_l0: 0.005410655401647091 0.1464574635028839
decider.lstm.bias_ih_l0: -0.015528742223978043 0.14158621430397034
decider.lstm.bias_hh_l0: 0.02029215171933174 0.1546906977891922
decider.linear1.weight: 0.004468540661036968 0.12049386650323868
decider.linear1.bias: 0.008712990209460258 0.11447791010141373
decider.linear2.weight: 0.0035713091492652893 0.0547245517373085
decider.linear2.bias: 0.0034092962741851807 0.053281910717487335
decider.linear3.weight: -0.005284481681883335 0.06431932002305984
decider.linear3.bias: -0.016827251762151718 0.03643062710762024

Rewards:
74.4454
74.4454
74.4454
objective = 0.008305901661515236
==== episode 32100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9998 0.0002 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0000

Learning rate: 5.2560e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014706748770549893 0.08405677229166031
encoder.encoder.weight_hh_l0: -0.0012109082890674472 0.08595030754804611
encoder.encoder.bias_ih_l0: 0.008510504849255085 0.08945240080356598
encoder.encoder.bias_hh_l0: 0.021582424640655518 0.08668012917041779
encoder.encoder.weight_ih_l0_reverse: 0.0020621430594474077 0.08484288305044174
encoder.encoder.weight_hh_l0_reverse: 0.0004057525657117367 0.08384986966848373
encoder.encoder.bias_ih_l0_reverse: 0.014228807762265205 0.0824187770485878
encoder.encoder.bias_hh_l0_reverse: 0.014523540623486042 0.08937974274158478
decider.lstm.weight_ih_l0: -0.0018177875317633152 0.14668557047843933
decider.lstm.weight_hh_l0: 0.005421174690127373 0.14646334946155548
decider.lstm.bias_ih_l0: -0.015485507436096668 0.14157821238040924
decider.lstm.bias_hh_l0: 0.0203353613615036 0.15469075739383698
decider.linear1.weight: 0.004471330903470516 0.12050220370292664
decider.linear1.bias: 0.00873781368136406 0.11448908597230911
decider.linear2.weight: 0.003583964193239808 0.05473761260509491
decider.linear2.bias: 0.003424854949116707 0.05328831449151039
decider.linear3.weight: -0.005302262958139181 0.06436407566070557
decider.linear3.bias: -0.016852980479598045 0.036476459354162216

Rewards:
74.4454
74.4454
74.4454
objective = 0.007835455238819122
==== episode 32200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9998 0.0002 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0000

Learning rate: 5.2560e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014763495419174433 0.08406783640384674
encoder.encoder.weight_hh_l0: -0.0012148832902312279 0.08597280830144882
encoder.encoder.bias_ih_l0: 0.008576474152505398 0.08946701884269714
encoder.encoder.bias_hh_l0: 0.021648388355970383 0.0866972953081131
encoder.encoder.weight_ih_l0_reverse: 0.0020661745220422745 0.08484905958175659
encoder.encoder.weight_hh_l0_reverse: 0.0004032839788123965 0.08385878056287766
encoder.encoder.bias_ih_l0_reverse: 0.014277370646595955 0.08242666721343994
encoder.encoder.bias_hh_l0_reverse: 0.014572110027074814 0.08938712626695633
decider.lstm.weight_ih_l0: -0.0018198407487943769 0.1466943621635437
decider.lstm.weight_hh_l0: 0.005431343801319599 0.14646941423416138
decider.lstm.bias_ih_l0: -0.015443568117916584 0.141570046544075
decider.lstm.bias_hh_l0: 0.020377349108457565 0.15469123423099518
decider.linear1.weight: 0.0044740717858076096 0.12051059305667877
decider.linear1.bias: 0.008762327954173088 0.11449944972991943
decider.linear2.weight: 0.0035963552072644234 0.054750800132751465
decider.linear2.bias: 0.0034403279423713684 0.05329457297921181
decider.linear3.weight: -0.005319854710251093 0.06440837681293488
decider.linear3.bias: -0.016878347843885422 0.03652139753103256

Rewards:
74.4454
74.4454
74.4454
objective = 0.007403479889035225
==== episode 32300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9999 0.0001 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0000

Learning rate: 5.2560e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014832234010100365 0.08407965302467346
encoder.encoder.weight_hh_l0: -0.0012195368763059378 0.08599813282489777
encoder.encoder.bias_ih_l0: 0.00865070428699255 0.08948449790477753
encoder.encoder.bias_hh_l0: 0.021722616627812386 0.0867178738117218
encoder.encoder.weight_ih_l0_reverse: 0.0020709221716970205 0.08485662937164307
encoder.encoder.weight_hh_l0_reverse: 0.00040001762681640685 0.08387094736099243
encoder.encoder.bias_ih_l0_reverse: 0.014332751743495464 0.08243618905544281
encoder.encoder.bias_hh_l0_reverse: 0.014627487398684025 0.08939425647258759
decider.lstm.weight_ih_l0: -0.0018221455393359065 0.14670363068580627
decider.lstm.weight_hh_l0: 0.0054422104731202126 0.14647583663463593
decider.lstm.bias_ih_l0: -0.015398705378174782 0.14156323671340942
decider.lstm.bias_hh_l0: 0.020422212779521942 0.15469148755073547
decider.linear1.weight: 0.004497351124882698 0.12056192755699158
decider.linear1.bias: 0.008891104720532894 0.11435537785291672
decider.linear2.weight: 0.003587767481803894 0.05479525402188301
decider.linear2.bias: 0.0034550740383565426 0.05330032482743263
decider.linear3.weight: -0.005336311645805836 0.06444984674453735
decider.linear3.bias: -0.01690252497792244 0.03656355291604996

Rewards:
74.4454
74.4454
74.4454
objective = 0.006049887277185917
==== episode 32400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9999 0.0001 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0000

Learning rate: 5.2560e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014900662936270237 0.08409081399440765
encoder.encoder.weight_hh_l0: -0.0012241596123203635 0.08602314442396164
encoder.encoder.bias_ih_l0: 0.008722629398107529 0.08950202912092209
encoder.encoder.bias_hh_l0: 0.02179454267024994 0.08673813194036484
encoder.encoder.weight_ih_l0_reverse: 0.00207566493190825 0.08486424386501312
encoder.encoder.weight_hh_l0_reverse: 0.00039671442937105894 0.08388330787420273
encoder.encoder.bias_ih_l0_reverse: 0.014386247843503952 0.08244559913873672
encoder.encoder.bias_hh_l0_reverse: 0.014680987223982811 0.08940014243125916
decider.lstm.weight_ih_l0: -0.0018243336817249656 0.14671207964420319
decider.lstm.weight_hh_l0: 0.005452057346701622 0.14648233354091644
decider.lstm.bias_ih_l0: -0.015357880853116512 0.14155808091163635
decider.lstm.bias_hh_l0: 0.02046305499970913 0.15469355881214142
decider.linear1.weight: 0.0045229471288621426 0.12061647325754166
decider.linear1.bias: 0.009038257412612438 0.11429231613874435
decider.linear2.weight: 0.0035721459425985813 0.0548550970852375
decider.linear2.bias: 0.0034685679711401463 0.05330534651875496
decider.linear3.weight: -0.005350600928068161 0.06448587030172348
decider.linear3.bias: -0.016924329102039337 0.036600373685359955

Rewards:
74.4454
74.4454
74.4454
objective = 0.004878304433077574
==== episode 32500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9999 0.0001 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0000

Learning rate: 5.2034e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014962279237806797 0.08410046994686127
encoder.encoder.weight_hh_l0: -0.0012283289106562734 0.08604571223258972
encoder.encoder.bias_ih_l0: 0.008786001242697239 0.08951789140701294
encoder.encoder.bias_hh_l0: 0.021857913583517075 0.08675596863031387
encoder.encoder.weight_ih_l0_reverse: 0.002080115955322981 0.08487117290496826
encoder.encoder.weight_hh_l0_reverse: 0.0003937575966119766 0.0838945060968399
encoder.encoder.bias_ih_l0_reverse: 0.014433657750487328 0.08245411515235901
encoder.encoder.bias_hh_l0_reverse: 0.014728395268321037 0.0894046500325203
decider.lstm.weight_ih_l0: -0.001826201332733035 0.14671914279460907
decider.lstm.weight_hh_l0: 0.00546020083129406 0.14648863673210144
decider.lstm.bias_ih_l0: -0.015323994681239128 0.14155443012714386
decider.lstm.bias_hh_l0: 0.020496925339102745 0.15469743311405182
decider.linear1.weight: 0.004545343574136496 0.12066815793514252
decider.linear1.bias: 0.009171122685074806 0.11430398374795914
decider.linear2.weight: 0.0035486877895891666 0.05492483079433441
decider.linear2.bias: 0.0034701665863394737 0.05330714210867882
decider.linear3.weight: -0.005362735595554113 0.06451648473739624
decider.linear3.bias: -0.016943706199526787 0.036632079631090164

Rewards:
74.4454
74.4454
74.4454
objective = 0.004082483239471912
==== episode 32600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 0.9999 0.0000 0.0000

action = 2
probs = 0.0000 0.0001 0.9999 0.0000

Learning rate: 5.2034e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015014630043879151 0.08410850912332535
encoder.encoder.weight_hh_l0: -0.001231837784871459 0.08606477826833725
encoder.encoder.bias_ih_l0: 0.00883850920945406 0.08953113853931427
encoder.encoder.bias_hh_l0: 0.021910423412919044 0.08677072077989578
encoder.encoder.weight_ih_l0_reverse: 0.0020840943325310946 0.08487725257873535
encoder.encoder.weight_hh_l0_reverse: 0.0003912890679202974 0.08390405029058456
encoder.encoder.bias_ih_l0_reverse: 0.01447391603142023 0.0824609324336052
encoder.encoder.bias_hh_l0_reverse: 0.014768660999834538 0.08940868079662323
decider.lstm.weight_ih_l0: -0.0018277610652148724 0.14672496914863586
decider.lstm.weight_hh_l0: 0.005466882139444351 0.1464943140745163
decider.lstm.bias_ih_l0: -0.015296155586838722 0.14155085384845734
decider.lstm.bias_hh_l0: 0.020524747669696808 0.15470166504383087
decider.linear1.weight: 0.004559386521577835 0.12070795148611069
decider.linear1.bias: 0.009260960854589939 0.11433793604373932
decider.linear2.weight: 0.0035406299866735935 0.05498310178518295
decider.linear2.bias: 0.003481390653178096 0.053310517221689224
decider.linear3.weight: -0.005373538006097078 0.06454377621412277
decider.linear3.bias: -0.016961492598056793 0.03666050359606743

Rewards:
74.4454
74.4454
74.4454
objective = 0.00359138916246593
==== episode 32700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 5.2034e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015064862091094255 0.08411618322134018
encoder.encoder.weight_hh_l0: -0.0012352503836154938 0.08608347922563553
encoder.encoder.bias_ih_l0: 0.008889622986316681 0.0895438939332962
encoder.encoder.bias_hh_l0: 0.02196153998374939 0.08678489178419113
encoder.encoder.weight_ih_l0_reverse: 0.0020879567600786686 0.08488314598798752
encoder.encoder.weight_hh_l0_reverse: 0.00038888081326149404 0.08391332626342773
encoder.encoder.bias_ih_l0_reverse: 0.014512919820845127 0.08246728032827377
encoder.encoder.bias_hh_l0_reverse: 0.014807662926614285 0.08941259980201721
decider.lstm.weight_ih_l0: -0.0018292873864993453 0.14673061668872833
decider.lstm.weight_hh_l0: 0.005473380908370018 0.14649975299835205
decider.lstm.bias_ih_l0: -0.015269062481820583 0.14154711365699768
decider.lstm.bias_hh_l0: 0.020551884546875954 0.15470580756664276
decider.linear1.weight: 0.004570812918245792 0.12074432522058487
decider.linear1.bias: 0.009336985647678375 0.11437122523784637
decider.linear2.weight: 0.0035371792037039995 0.05503256246447563
decider.linear2.bias: 0.0034924112260341644 0.05331355705857277
decider.linear3.weight: -0.005383598618209362 0.0645691528916359
decider.linear3.bias: -0.016978442668914795 0.0366872139275074

Rewards:
74.4454
74.4454
74.4454
objective = 0.0032156759407371283
==== episode 32800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 5.2034e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015113322297111154 0.0841236487030983
encoder.encoder.weight_hh_l0: -0.001238599419593811 0.0861019566655159
encoder.encoder.bias_ih_l0: 0.008939877152442932 0.08955643326044083
encoder.encoder.bias_hh_l0: 0.022011784836649895 0.08679866790771484
encoder.encoder.weight_ih_l0_reverse: 0.00209172535687685 0.08488886803388596
encoder.encoder.weight_hh_l0_reverse: 0.00038649296038784087 0.0839223563671112
encoder.encoder.bias_ih_l0_reverse: 0.014551223255693913 0.08247306942939758
encoder.encoder.bias_hh_l0_reverse: 0.014845963567495346 0.08941657841205597
decider.lstm.weight_ih_l0: -0.0018308485159650445 0.1467362642288208
decider.lstm.weight_hh_l0: 0.005479911342263222 0.14650489389896393
decider.lstm.bias_ih_l0: -0.015241808257997036 0.14154279232025146
decider.lstm.bias_hh_l0: 0.020579174160957336 0.15470938384532928
decider.linear1.weight: 0.004580557346343994 0.12077808380126953
decider.linear1.bias: 0.009403813630342484 0.11440275609493256
decider.linear2.weight: 0.0035365677904337645 0.05507713556289673
decider.linear2.bias: 0.003503285814076662 0.05331653356552124
decider.linear3.weight: -0.005393116734921932 0.06459313631057739
decider.linear3.bias: -0.016994765028357506 0.036712646484375

Rewards:
74.4454
74.4454
74.4454
objective = 0.002910965122282505
==== episode 32900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 5.2034e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015160813927650452 0.08413098007440567
encoder.encoder.weight_hh_l0: -0.0012419233098626137 0.08612032234668732
encoder.encoder.bias_ih_l0: 0.008989674970507622 0.08956877887248993
encoder.encoder.bias_hh_l0: 0.022061580792069435 0.08681223541498184
encoder.encoder.weight_ih_l0_reverse: 0.0020954792853444815 0.08489450067281723
encoder.encoder.weight_hh_l0_reverse: 0.0003841044381260872 0.08393127471208572
encoder.encoder.bias_ih_l0_reverse: 0.014589195139706135 0.0824786052107811
encoder.encoder.bias_hh_l0_reverse: 0.014883935451507568 0.08942055702209473
decider.lstm.weight_ih_l0: -0.0018324481789022684 0.14674192667007446
decider.lstm.weight_hh_l0: 0.005486458074301481 0.1465097963809967
decider.lstm.bias_ih_l0: -0.015214415267109871 0.14153827726840973
decider.lstm.bias_hh_l0: 0.020606588572263718 0.1547125279903412
decider.linear1.weight: 0.004588742274791002 0.12080845236778259
decider.linear1.bias: 0.009461695328354836 0.11443142592906952
decider.linear2.weight: 0.0035390625707805157 0.055116262286901474
decider.linear2.bias: 0.0035141606349498034 0.05331938713788986
decider.linear3.weight: -0.005402230657637119 0.06461605429649353
decider.linear3.bias: -0.01701059564948082 0.03673714026808739

Rewards:
74.4454
74.4454
74.4454
objective = 0.0026698592118918896
==== episode 33000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 5.1514e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001520734396763146 0.0841381773352623
encoder.encoder.weight_hh_l0: -0.0012452228693291545 0.086138516664505
encoder.encoder.bias_ih_l0: 0.009038812480866909 0.08958090841770172
encoder.encoder.bias_hh_l0: 0.02211071364581585 0.08682553470134735
encoder.encoder.weight_ih_l0_reverse: 0.0020991817582398653 0.08490002900362015
encoder.encoder.weight_hh_l0_reverse: 0.0003817319229710847 0.08394007384777069
encoder.encoder.bias_ih_l0_reverse: 0.014626595191657543 0.08248391002416611
encoder.encoder.bias_hh_l0_reverse: 0.014921342022716999 0.08942452073097229
decider.lstm.weight_ih_l0: -0.0018340706592425704 0.14674751460552216
decider.lstm.weight_hh_l0: 0.005492945667356253 0.14651453495025635
decider.lstm.bias_ih_l0: -0.015187189914286137 0.14153361320495605
decider.lstm.bias_hh_l0: 0.020633870735764503 0.15471535921096802
decider.linear1.weight: 0.004595947451889515 0.12083668261766434
decider.linear1.bias: 0.009513882920145988 0.11445879936218262
decider.linear2.weight: 0.0035432884469628334 0.05515202507376671
decider.linear2.bias: 0.0035249656066298485 0.05332215130329132
decider.linear3.weight: -0.00541105680167675 0.06463823467493057
decider.linear3.bias: -0.017026076093316078 0.03676097095012665

Rewards:
74.4454
74.4454
74.4454
objective = 0.0024642539210617542
==== episode 33100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 5.1514e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015252435114234686 0.08414513617753983
encoder.encoder.weight_hh_l0: -0.0012484642211347818 0.08615633100271225
encoder.encoder.bias_ih_l0: 0.009086593054234982 0.08959273248910904
encoder.encoder.bias_hh_l0: 0.022158503532409668 0.08683842420578003
encoder.encoder.weight_ih_l0_reverse: 0.0021027394104748964 0.08490540087223053
encoder.encoder.weight_hh_l0_reverse: 0.000379419099772349 0.08394858986139297
encoder.encoder.bias_ih_l0_reverse: 0.014662661589682102 0.08248880505561829
encoder.encoder.bias_hh_l0_reverse: 0.014957409352064133 0.08942847698926926
decider.lstm.weight_ih_l0: -0.0018356876680627465 0.1467529833316803
decider.lstm.weight_hh_l0: 0.005499275401234627 0.1465190201997757
decider.lstm.bias_ih_l0: -0.015160543844103813 0.14152871072292328
decider.lstm.bias_hh_l0: 0.02066054381430149 0.15471796691417694
decider.linear1.weight: 0.004602219443768263 0.12086256593465805
decider.linear1.bias: 0.009560503996908665 0.1144850105047226
decider.linear2.weight: 0.0035487920977175236 0.055184248834848404
decider.linear2.bias: 0.0035356224980205297 0.05332493409514427
decider.linear3.weight: -0.005419552326202393 0.06465955823659897
decider.linear3.bias: -0.017041075974702835 0.03678400442004204

Rewards:
74.4454
74.4454
74.4454
objective = 0.0022808362264186144
==== episode 33200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 5.1514e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015297330683097243 0.08415210992097855
encoder.encoder.weight_hh_l0: -0.0012517498107627034 0.08617431670427322
encoder.encoder.bias_ih_l0: 0.009134650230407715 0.08960463851690292
encoder.encoder.bias_hh_l0: 0.02220654860138893 0.08685131371021271
encoder.encoder.weight_ih_l0_reverse: 0.002106183674186468 0.08491073548793793
encoder.encoder.weight_hh_l0_reverse: 0.00037710825563408434 0.08395703136920929
encoder.encoder.bias_ih_l0_reverse: 0.014698147773742676 0.08249343186616898
encoder.encoder.bias_hh_l0_reverse: 0.014992892742156982 0.08943250775337219
decider.lstm.weight_ih_l0: -0.0018373624188825488 0.1467585265636444
decider.lstm.weight_hh_l0: 0.005505623295903206 0.14652325212955475
decider.lstm.bias_ih_l0: -0.015133668668568134 0.1415235698223114
decider.lstm.bias_hh_l0: 0.02068745717406273 0.1547202467918396
decider.linear1.weight: 0.004608059301972389 0.12088757753372192
decider.linear1.bias: 0.009604718536138535 0.11451095342636108
decider.linear2.weight: 0.003551399102434516 0.05521571263670921
decider.linear2.bias: 0.003541130805388093 0.05332955718040466
decider.linear3.weight: -0.005427862051874399 0.06468036770820618
decider.linear3.bias: -0.01705586165189743 0.036806680262088776

Rewards:
74.4454
74.4454
74.4454
objective = 0.0021181274205446243
==== episode 33300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 5.1514e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001534169539809227 0.08415903151035309
encoder.encoder.weight_hh_l0: -0.0012550497194752097 0.086192287504673
encoder.encoder.bias_ih_l0: 0.009182356297969818 0.08961648494005203
encoder.encoder.bias_hh_l0: 0.022254247218370438 0.08686404675245285
encoder.encoder.weight_ih_l0_reverse: 0.0021095387637615204 0.08491599559783936
encoder.encoder.weight_hh_l0_reverse: 0.00037480899482034147 0.08396538347005844
encoder.encoder.bias_ih_l0_reverse: 0.014733037911355495 0.08249788731336594
encoder.encoder.bias_hh_l0_reverse: 0.015027779154479504 0.08943658322095871
decider.lstm.weight_ih_l0: -0.0018390710465610027 0.14676402509212494
decider.lstm.weight_hh_l0: 0.005511905066668987 0.14652733504772186
decider.lstm.bias_ih_l0: -0.015106900595128536 0.14151827991008759
decider.lstm.bias_hh_l0: 0.020714305341243744 0.15472231805324554
decider.linear1.weight: 0.004613428842276335 0.12091153115034103
decider.linear1.bias: 0.009646302089095116 0.11453700065612793
decider.linear2.weight: 0.0035529222805052996 0.05524628609418869
decider.linear2.bias: 0.0035442812368273735 0.053335096687078476
decider.linear3.weight: -0.005436001345515251 0.06470074504613876
decider.linear3.bias: -0.01707041636109352 0.03682897984981537

Rewards:
74.4454
74.4454
74.4454
objective = 0.0019731689244508743
==== episode 33400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 5.1514e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015385401202365756 0.08416581898927689
encoder.encoder.weight_hh_l0: -0.001258339500054717 0.08621000498533249
encoder.encoder.bias_ih_l0: 0.009229172952473164 0.08962813764810562
encoder.encoder.bias_hh_l0: 0.02230105735361576 0.08687649667263031
encoder.encoder.weight_ih_l0_reverse: 0.0021128144580870867 0.08492118120193481
encoder.encoder.weight_hh_l0_reverse: 0.0003725886344909668 0.0839734897017479
encoder.encoder.bias_ih_l0_reverse: 0.014766894280910492 0.08250223100185394
encoder.encoder.bias_hh_l0_reverse: 0.0150616355240345 0.08944066613912582
decider.lstm.weight_ih_l0: -0.0018408017931506038 0.1467694789171219
decider.lstm.weight_hh_l0: 0.005518049001693726 0.14653125405311584
decider.lstm.bias_ih_l0: -0.015080667100846767 0.14151296019554138
decider.lstm.bias_hh_l0: 0.0207405723631382 0.15472419559955597
decider.linear1.weight: 0.004617537371814251 0.12093276530504227
decider.linear1.bias: 0.00968053936958313 0.11455818265676498
decider.linear2.weight: 0.00355970929376781 0.05527481064200401
decider.linear2.bias: 0.003554792609065771 0.053337983787059784
decider.linear3.weight: -0.005443988833576441 0.06472072750329971
decider.linear3.bias: -0.0170847587287426 0.0368509516119957

Rewards:
74.4454
74.4454
74.4454
objective = 0.0018400440458208323
==== episode 33500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 5.0999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015427654143422842 0.084172323346138
encoder.encoder.weight_hh_l0: -0.001261541503481567 0.08622704446315765
encoder.encoder.bias_ih_l0: 0.009274134412407875 0.08963931351900101
encoder.encoder.bias_hh_l0: 0.0223460141569376 0.086888387799263
encoder.encoder.weight_ih_l0_reverse: 0.0021159732714295387 0.08492616564035416
encoder.encoder.weight_hh_l0_reverse: 0.00037048381636850536 0.08398125320672989
encoder.encoder.bias_ih_l0_reverse: 0.014799298718571663 0.08250609040260315
encoder.encoder.bias_hh_l0_reverse: 0.0150940315797925 0.08944495767354965
decider.lstm.weight_ih_l0: -0.0018425589660182595 0.14677484333515167
decider.lstm.weight_hh_l0: 0.005524058826267719 0.14653490483760834
decider.lstm.bias_ih_l0: -0.015054784715175629 0.14150728285312653
decider.lstm.bias_hh_l0: 0.020766403526067734 0.15472543239593506
decider.linear1.weight: 0.0046195294708013535 0.12094944715499878
decider.linear1.bias: 0.009702974930405617 0.11456643790006638
decider.linear2.weight: 0.0035664071328938007 0.05530267581343651
decider.linear2.bias: 0.0035652155056595802 0.053340811282396317
decider.linear3.weight: -0.005451879929751158 0.06474043428897858
decider.linear3.bias: -0.017098965123295784 0.03687276318669319

Rewards:
74.4454
74.4454
74.4454
objective = 0.001729106530547142
==== episode 33600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 5.0999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015469338977709413 0.08417872339487076
encoder.encoder.weight_hh_l0: -0.0012647425755858421 0.08624390512704849
encoder.encoder.bias_ih_l0: 0.0093183983117342 0.08965036273002625
encoder.encoder.bias_hh_l0: 0.02239028364419937 0.08690010011196136
encoder.encoder.weight_ih_l0_reverse: 0.00211905175819993 0.08493106812238693
encoder.encoder.weight_hh_l0_reverse: 0.00036840111715719104 0.08398891240358353
encoder.encoder.bias_ih_l0_reverse: 0.014831061474978924 0.0825098305940628
encoder.encoder.bias_hh_l0_reverse: 0.015125798992812634 0.0894491970539093
decider.lstm.weight_ih_l0: -0.001844337792135775 0.14678014814853668
decider.lstm.weight_hh_l0: 0.005529945250600576 0.1465384066104889
decider.lstm.bias_ih_l0: -0.015029299072921276 0.1415015608072281
decider.lstm.bias_hh_l0: 0.020791860297322273 0.15472650527954102
decider.linear1.weight: 0.004621324595063925 0.12096544355154037
decider.linear1.bias: 0.009724374860525131 0.11457479000091553
decider.linear2.weight: 0.003572931047528982 0.055329859256744385
decider.linear2.bias: 0.003575467737391591 0.05334358662366867
decider.linear3.weight: -0.005459638312458992 0.06475977599620819
decider.linear3.bias: -0.01711292564868927 0.036894261837005615

Rewards:
74.4454
74.4454
74.4454
objective = 0.001625564880669117
==== episode 33700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015511044766753912 0.08418510109186172
encoder.encoder.weight_hh_l0: -0.001267985557205975 0.08626079559326172
encoder.encoder.bias_ih_l0: 0.009362561628222466 0.08966141939163208
encoder.encoder.bias_hh_l0: 0.02243444323539734 0.08691175282001495
encoder.encoder.weight_ih_l0_reverse: 0.0021220988128334284 0.08493594825267792
encoder.encoder.weight_hh_l0_reverse: 0.0003663078823592514 0.08399658650159836
encoder.encoder.bias_ih_l0_reverse: 0.01486258115619421 0.0825134739279747
encoder.encoder.bias_hh_l0_reverse: 0.015157320536673069 0.08945347368717194
decider.lstm.weight_ih_l0: -0.0018461713334545493 0.14678546786308289
decider.lstm.weight_hh_l0: 0.0055357832461595535 0.14654181897640228
decider.lstm.bias_ih_l0: -0.015003832057118416 0.14149560034275055
decider.lstm.bias_hh_l0: 0.020817378535866737 0.15472735464572906
decider.linear1.weight: 0.004622912500053644 0.12098082900047302
decider.linear1.bias: 0.009744820185005665 0.11458379775285721
decider.linear2.weight: 0.0035794652067124844 0.055356599390506744
decider.linear2.bias: 0.0035856864415109158 0.05334630608558655
decider.linear3.weight: -0.005467345472425222 0.06477897614240646
decider.linear3.bias: -0.017126837745308876 0.03691569343209267

Rewards:
74.4454
74.4454
74.4454
objective = 0.0015264612156897783
==== episode 33800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015552820404991508 0.0841914564371109
encoder.encoder.weight_hh_l0: -0.0012712872121483088 0.08627782016992569
encoder.encoder.bias_ih_l0: 0.009406826458871365 0.08967239409685135
encoder.encoder.bias_hh_l0: 0.022478708997368813 0.08692343533039093
encoder.encoder.weight_ih_l0_reverse: 0.002125149592757225 0.08494088053703308
encoder.encoder.weight_hh_l0_reverse: 0.00036415684735402465 0.0840044766664505
encoder.encoder.bias_ih_l0_reverse: 0.014894530177116394 0.08251747488975525
encoder.encoder.bias_hh_l0_reverse: 0.015189271420240402 0.08945763856172562
decider.lstm.weight_ih_l0: -0.0018480389844626188 0.1467907428741455
decider.lstm.weight_hh_l0: 0.005541527643799782 0.14654527604579926
decider.lstm.bias_ih_l0: -0.014978578314185143 0.1414898782968521
decider.lstm.bias_hh_l0: 0.020842645317316055 0.1547282487154007
decider.linear1.weight: 0.004624921828508377 0.12099726498126984
decider.linear1.bias: 0.009767528623342514 0.11458932608366013
decider.linear2.weight: 0.0035858906339854 0.055383022874593735
decider.linear2.bias: 0.003595831338316202 0.05334896966814995
decider.linear3.weight: -0.005475004203617573 0.0647980347275734
decider.linear3.bias: -0.017140580341219902 0.036936867982149124

Rewards:
74.4454
74.4454
74.4454
objective = 0.001437711762264371
==== episode 33900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015594535507261753 0.08419778943061829
encoder.encoder.weight_hh_l0: -0.0012746392749249935 0.08629495650529861
encoder.encoder.bias_ih_l0: 0.009451051242649555 0.08968334645032883
encoder.encoder.bias_hh_l0: 0.022522930055856705 0.08693509548902512
encoder.encoder.weight_ih_l0_reverse: 0.0021281924564391375 0.08494585007429123
encoder.encoder.weight_hh_l0_reverse: 0.00036196509608998895 0.08401253074407578
encoder.encoder.bias_ih_l0_reverse: 0.01492663100361824 0.08252163231372833
encoder.encoder.bias_hh_l0_reverse: 0.015221371315419674 0.08946174383163452
decider.lstm.weight_ih_l0: -0.0018499441212043166 0.14679598808288574
decider.lstm.weight_hh_l0: 0.005547189153730869 0.1465487778186798
decider.lstm.bias_ih_l0: -0.014953577890992165 0.14148426055908203
decider.lstm.bias_hh_l0: 0.02086767554283142 0.15472911298274994
decider.linear1.weight: 0.004627329763025045 0.12101469933986664
decider.linear1.bias: 0.00979236513376236 0.11459161341190338
decider.linear2.weight: 0.003592379856854677 0.05540911480784416
decider.linear2.bias: 0.0036058896221220493 0.05335158482193947
decider.linear3.weight: -0.005482596345245838 0.06481695175170898
decider.linear3.bias: -0.017154285684227943 0.036958031356334686

Rewards:
74.4454
74.4454
74.4454
objective = 0.001353400177322328
==== episode 34000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0489e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015636017778888345 0.0842040553689003
encoder.encoder.weight_hh_l0: -0.0012780239339917898 0.08631205558776855
encoder.encoder.bias_ih_l0: 0.009494937025010586 0.08969427645206451
encoder.encoder.bias_hh_l0: 0.022566813975572586 0.08694665133953094
encoder.encoder.weight_ih_l0_reverse: 0.0021311985328793526 0.08495079725980759
encoder.encoder.weight_hh_l0_reverse: 0.00035976938670501113 0.08402056246995926
encoder.encoder.bias_ih_l0_reverse: 0.014958459883928299 0.08252573013305664
encoder.encoder.bias_hh_l0_reverse: 0.015253196470439434 0.08946587145328522
decider.lstm.weight_ih_l0: -0.001851893961429596 0.1468012034893036
decider.lstm.weight_hh_l0: 0.005552771966904402 0.146552175283432
decider.lstm.bias_ih_l0: -0.014928705990314484 0.14147859811782837
decider.lstm.bias_hh_l0: 0.020892523229122162 0.15472982823848724
decider.linear1.weight: 0.004629645496606827 0.12103186547756195
decider.linear1.bias: 0.009816789999604225 0.1145937442779541
decider.linear2.weight: 0.00359894335269928 0.05543498694896698
decider.linear2.bias: 0.0036158813163638115 0.0533541776239872
decider.linear3.weight: -0.0054901340045034885 0.06483575701713562
decider.linear3.bias: -0.017167864367365837 0.03697895631194115

Rewards:
74.4454
74.4454
74.4454
objective = 0.0012750051682814956
==== episode 34100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0489e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015676884213462472 0.08421022444963455
encoder.encoder.weight_hh_l0: -0.0012814118526875973 0.08632899075746536
encoder.encoder.bias_ih_l0: 0.00953809916973114 0.08970507234334946
encoder.encoder.bias_hh_l0: 0.022609969601035118 0.08695801347494125
encoder.encoder.weight_ih_l0_reverse: 0.002134139183908701 0.08495566993951797
encoder.encoder.weight_hh_l0_reverse: 0.00035759081947617233 0.08402851223945618
encoder.encoder.bias_ih_l0_reverse: 0.014989718794822693 0.08252975344657898
encoder.encoder.bias_hh_l0_reverse: 0.015284453518688679 0.08946999162435532
decider.lstm.weight_ih_l0: -0.0018538710428401828 0.14680638909339905
decider.lstm.weight_hh_l0: 0.005558212287724018 0.14655551314353943
decider.lstm.bias_ih_l0: -0.014904221519827843 0.1414729505777359
decider.lstm.bias_hh_l0: 0.02091696858406067 0.15473045408725739
decider.linear1.weight: 0.004631868563592434 0.12104868143796921
decider.linear1.bias: 0.009840695187449455 0.11459570378065109
decider.linear2.weight: 0.003605491016060114 0.055460426956415176
decider.linear2.bias: 0.003625706769526005 0.053356729447841644
decider.linear3.weight: -0.005497554317116737 0.06485425680875778
decider.linear3.bias: -0.017181197181344032 0.03699951618909836

Rewards:
74.4454
74.4454
74.4454
objective = 0.001201047794893384
==== episode 34200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0489e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001571753527969122 0.08421631902456284
encoder.encoder.weight_hh_l0: -0.0012848357437178493 0.08634590357542038
encoder.encoder.bias_ih_l0: 0.009580888785421848 0.08971575647592545
encoder.encoder.bias_hh_l0: 0.022652754560112953 0.08696926385164261
encoder.encoder.weight_ih_l0_reverse: 0.0021370421163737774 0.08496052771806717
encoder.encoder.weight_hh_l0_reverse: 0.0003554153663571924 0.0840364396572113
encoder.encoder.bias_ih_l0_reverse: 0.015020661056041718 0.08253379911184311
encoder.encoder.bias_hh_l0_reverse: 0.01531539298593998 0.08947405219078064
decider.lstm.weight_ih_l0: -0.0018558729207143188 0.14681148529052734
decider.lstm.weight_hh_l0: 0.00556351849809289 0.14655880630016327
decider.lstm.bias_ih_l0: -0.014880135655403137 0.14146734774112701
decider.lstm.bias_hh_l0: 0.020941030234098434 0.15473110973834991
decider.linear1.weight: 0.0046339984983205795 0.12106524407863617
decider.linear1.bias: 0.009864182211458683 0.11459764838218689
decider.linear2.weight: 0.0036120496224611998 0.05548569932579994
decider.linear2.bias: 0.00363542465493083 0.05335923656821251
decider.linear3.weight: -0.005504927597939968 0.06487265974283218
decider.linear3.bias: -0.01719442382454872 0.03701993450522423

Rewards:
74.4454
74.4454
74.4454
objective = 0.0011344862869009376
==== episode 34300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0489e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015758025692775846 0.08422237634658813
encoder.encoder.weight_hh_l0: -0.0012883016606792808 0.08636283129453659
encoder.encoder.bias_ih_l0: 0.00962337851524353 0.08972637355327606
encoder.encoder.bias_hh_l0: 0.02269524708390236 0.086980439722538
encoder.encoder.weight_ih_l0_reverse: 0.0021399115212261677 0.08496536314487457
encoder.encoder.weight_hh_l0_reverse: 0.0003532388072926551 0.08404436707496643
encoder.encoder.bias_ih_l0_reverse: 0.01505135279148817 0.08253786712884903
encoder.encoder.bias_hh_l0_reverse: 0.01534609030932188 0.08947809785604477
decider.lstm.weight_ih_l0: -0.0018579127499833703 0.14681655168533325
decider.lstm.weight_hh_l0: 0.005568728782236576 0.14656206965446472
decider.lstm.bias_ih_l0: -0.014856324531137943 0.14146184921264648
decider.lstm.bias_hh_l0: 0.020964816212654114 0.15473173558712006
decider.linear1.weight: 0.0046360548585653305 0.12108158320188522
decider.linear1.bias: 0.009887345135211945 0.1145995557308197
decider.linear2.weight: 0.0036186231300234795 0.055510830134153366
decider.linear2.bias: 0.003645058022812009 0.05336171016097069
decider.linear3.weight: -0.005512251053005457 0.06489095836877823
decider.linear3.bias: -0.01720762439072132 0.037040337920188904

Rewards:
74.4454
74.4454
74.4454
objective = 0.0010708831250667572
==== episode 34400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0489e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015798347303643823 0.08422841131687164
encoder.encoder.weight_hh_l0: -0.001291814842261374 0.08637979626655579
encoder.encoder.bias_ih_l0: 0.009665630757808685 0.0897369533777237
encoder.encoder.bias_hh_l0: 0.022737497463822365 0.08699154108762741
encoder.encoder.weight_ih_l0_reverse: 0.00214274856261909 0.08497018367052078
encoder.encoder.weight_hh_l0_reverse: 0.00035105861024931073 0.08405228704214096
encoder.encoder.bias_ih_l0_reverse: 0.015081821009516716 0.08254190534353256
encoder.encoder.bias_hh_l0_reverse: 0.015376563183963299 0.08948212116956711
decider.lstm.weight_ih_l0: -0.0018599999602884054 0.14682160317897797
decider.lstm.weight_hh_l0: 0.005573865491896868 0.1465653032064438
decider.lstm.bias_ih_l0: -0.014832694083452225 0.14145630598068237
decider.lstm.bias_hh_l0: 0.02098841965198517 0.15473230183124542
decider.linear1.weight: 0.004638058133423328 0.12109776586294174
decider.linear1.bias: 0.009910276159644127 0.11460142582654953
decider.linear2.weight: 0.003625172656029463 0.05553586408495903
decider.linear2.bias: 0.0036546154879033566 0.053364142775535583
decider.linear3.weight: -0.00551952701061964 0.06490915268659592
decider.linear3.bias: -0.017220672219991684 0.03706044703722

Rewards:
74.4454
74.4454
74.4454
objective = 0.0010058009065687656
==== episode 34500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015838550170883536 0.08423441648483276
encoder.encoder.weight_hh_l0: -0.0012953822733834386 0.08639682829380035
encoder.encoder.bias_ih_l0: 0.009707712568342686 0.08974751830101013
encoder.encoder.bias_hh_l0: 0.02277957834303379 0.08700261265039444
encoder.encoder.weight_ih_l0_reverse: 0.002145554404705763 0.0849749818444252
encoder.encoder.weight_hh_l0_reverse: 0.00034887465881183743 0.0840601846575737
encoder.encoder.bias_ih_l0_reverse: 0.015112059190869331 0.08254589885473251
encoder.encoder.bias_hh_l0_reverse: 0.015406806021928787 0.08948614448308945
decider.lstm.weight_ih_l0: -0.0018621432827785611 0.14682666957378387
decider.lstm.weight_hh_l0: 0.005578942596912384 0.14656847715377808
decider.lstm.bias_ih_l0: -0.01480915118008852 0.1414507031440735
decider.lstm.bias_hh_l0: 0.021011918783187866 0.1547328233718872
decider.linear1.weight: 0.004639976657927036 0.12111355364322662
decider.linear1.bias: 0.009932774119079113 0.11460314691066742
decider.linear2.weight: 0.003632009495049715 0.05555986240506172
decider.linear2.bias: 0.0036641396582126617 0.05336660519242287
decider.linear3.weight: -0.005526769906282425 0.06492723524570465
decider.linear3.bias: -0.017233647406101227 0.03708048164844513

Rewards:
74.4454
74.4454
74.4454
objective = 0.0009495937265455723
==== episode 34600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001587831531651318 0.08424035459756851
encoder.encoder.weight_hh_l0: -0.001298975432291627 0.08641379326581955
encoder.encoder.bias_ih_l0: 0.009749257937073708 0.08975796401500702
encoder.encoder.bias_hh_l0: 0.022821124643087387 0.08701355010271072
encoder.encoder.weight_ih_l0_reverse: 0.002148308791220188 0.08497973531484604
encoder.encoder.weight_hh_l0_reverse: 0.0003467035130597651 0.08406803011894226
encoder.encoder.bias_ih_l0_reverse: 0.015141849406063557 0.08254985511302948
encoder.encoder.bias_hh_l0_reverse: 0.015436596237123013 0.08949010819196701
decider.lstm.weight_ih_l0: -0.001864320714958012 0.1468316614627838
decider.lstm.weight_hh_l0: 0.005583896767348051 0.14657160639762878
decider.lstm.bias_ih_l0: -0.014786011539399624 0.14144504070281982
decider.lstm.bias_hh_l0: 0.021035045385360718 0.15473324060440063
decider.linear1.weight: 0.004641820676624775 0.12112893164157867
decider.linear1.bias: 0.009954817593097687 0.11460453271865845
decider.linear2.weight: 0.003639132948592305 0.05558282136917114
decider.linear2.bias: 0.003673550672829151 0.053369052708148956
decider.linear3.weight: -0.005533912219107151 0.06494506448507309
decider.linear3.bias: -0.01724637672305107 0.037100210785865784

Rewards:
74.4454
74.4454
74.4454
objective = 0.0008978240075521171
==== episode 34700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015917778946459293 0.08424626290798187
encoder.encoder.weight_hh_l0: -0.0013026163214817643 0.08643078804016113
encoder.encoder.bias_ih_l0: 0.00979049876332283 0.08976835012435913
encoder.encoder.bias_hh_l0: 0.022862369194626808 0.08702441304922104
encoder.encoder.weight_ih_l0_reverse: 0.002151023130863905 0.08498445898294449
encoder.encoder.weight_hh_l0_reverse: 0.00034453446278348565 0.08407583087682724
encoder.encoder.bias_ih_l0_reverse: 0.015171363949775696 0.08255377411842346
encoder.encoder.bias_hh_l0_reverse: 0.015466112643480301 0.08949403464794159
decider.lstm.weight_ih_l0: -0.001866546575911343 0.14683666825294495
decider.lstm.weight_hh_l0: 0.00558874849230051 0.14657467603683472
decider.lstm.bias_ih_l0: -0.01476312056183815 0.14143937826156616
decider.lstm.bias_hh_l0: 0.02105795219540596 0.15473364293575287
decider.linear1.weight: 0.004643594846129417 0.12114383280277252
decider.linear1.bias: 0.009976418688893318 0.11460596323013306
decider.linear2.weight: 0.0036982446908950806 0.055612873286008835
decider.linear2.bias: 0.0037310076877474785 0.05332324653863907
decider.linear3.weight: -0.005638791713863611 0.06499136239290237
decider.linear3.bias: -0.017259059473872185 0.03711986541748047

Rewards:
74.4454
74.4454
74.4454
objective = 0.0008342214277945459
==== episode 34800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015956334536895156 0.08425205945968628
encoder.encoder.weight_hh_l0: -0.0013062565121799707 0.08644764870405197
encoder.encoder.bias_ih_l0: 0.009830929338932037 0.08977849781513214
encoder.encoder.bias_hh_l0: 0.022902797907590866 0.08703503757715225
encoder.encoder.weight_ih_l0_reverse: 0.0021536624990403652 0.08498909324407578
encoder.encoder.weight_hh_l0_reverse: 0.0003423948655836284 0.08408350497484207
encoder.encoder.bias_ih_l0_reverse: 0.015200220979750156 0.08255758136510849
encoder.encoder.bias_hh_l0_reverse: 0.015494969673454762 0.08949790149927139
decider.lstm.weight_ih_l0: -0.00186880212277174 0.14684157073497772
decider.lstm.weight_hh_l0: 0.005593439098447561 0.1465776562690735
decider.lstm.bias_ih_l0: -0.014740721322596073 0.1414336860179901
decider.lstm.bias_hh_l0: 0.02108035981655121 0.1547340452671051
decider.linear1.weight: 0.004645287059247494 0.12115756422281265
decider.linear1.bias: 0.009997012093663216 0.11460702866315842
decider.linear2.weight: 0.0037351748906075954 0.05565191060304642
decider.linear2.bias: 0.0037605727557092905 0.05330681428313255
decider.linear3.weight: -0.005721632391214371 0.06507957726716995
decider.linear3.bias: -0.01727144792675972 0.03713911026716232

Rewards:
74.4454
74.4454
74.4454
objective = 0.0007720981957390904
==== episode 34900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015993939014151692 0.08425772935152054
encoder.encoder.weight_hh_l0: -0.0013098872732371092 0.08646433800458908
encoder.encoder.bias_ih_l0: 0.009870439767837524 0.08978836238384247
encoder.encoder.bias_hh_l0: 0.022942308336496353 0.08704537153244019
encoder.encoder.weight_ih_l0_reverse: 0.0021562804467976093 0.08499366790056229
encoder.encoder.weight_hh_l0_reverse: 0.0003402687143534422 0.08409106731414795
encoder.encoder.bias_ih_l0_reverse: 0.01522866915911436 0.08256136626005173
encoder.encoder.bias_hh_l0_reverse: 0.015523414127528667 0.08950168639421463
decider.lstm.weight_ih_l0: -0.0018710778094828129 0.14684639871120453
decider.lstm.weight_hh_l0: 0.005597992800176144 0.14658060669898987
decider.lstm.bias_ih_l0: -0.014718805439770222 0.14142800867557526
decider.lstm.bias_hh_l0: 0.021102305501699448 0.15473441779613495
decider.linear1.weight: 0.004646906163543463 0.12117006629705429
decider.linear1.bias: 0.01001665648072958 0.1146077811717987
decider.linear2.weight: 0.0037643322721123695 0.05569041147828102
decider.linear2.bias: 0.003785555250942707 0.053295109421014786
decider.linear3.weight: -0.005783633328974247 0.06517495214939117
decider.linear3.bias: -0.017283549532294273 0.037158019840717316

Rewards:
74.4454
74.4454
74.4454
objective = 0.0007158914813771844
==== episode 35000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9484e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016030613332986832 0.08426325768232346
encoder.encoder.weight_hh_l0: -0.0013135018525645137 0.08648078888654709
encoder.encoder.bias_ih_l0: 0.009908948093652725 0.08979792892932892
encoder.encoder.bias_hh_l0: 0.022980818524956703 0.08705540001392365
encoder.encoder.weight_ih_l0_reverse: 0.0021589002572000027 0.08499819040298462
encoder.encoder.weight_hh_l0_reverse: 0.0003381488786544651 0.08409856259822845
encoder.encoder.bias_ih_l0_reverse: 0.015256810933351517 0.08256515115499496
encoder.encoder.bias_hh_l0_reverse: 0.015551550313830376 0.0895053967833519
decider.lstm.weight_ih_l0: -0.0018733697943389416 0.14685116708278656
decider.lstm.weight_hh_l0: 0.0056023914366960526 0.14658354222774506
decider.lstm.bias_ih_l0: -0.014697393402457237 0.1414223611354828
decider.lstm.bias_hh_l0: 0.021123772487044334 0.15473473072052002
decider.linear1.weight: 0.004648454021662474 0.12118162959814072
decider.linear1.bias: 0.010035520419478416 0.11460834741592407
decider.linear2.weight: 0.003788762027397752 0.05572730302810669
decider.linear2.bias: 0.003807058557868004 0.05328672006726265
decider.linear3.weight: -0.0058342572301626205 0.0652700662612915
decider.linear3.bias: -0.017295442521572113 0.037176713347435

Rewards:
74.4454
74.4454
74.4454
objective = 0.000667080283164978
==== episode 35100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9484e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016066365642473102 0.08426868170499802
encoder.encoder.weight_hh_l0: -0.0013171033933758736 0.08649703860282898
encoder.encoder.bias_ih_l0: 0.009946482256054878 0.08980722725391388
encoder.encoder.bias_hh_l0: 0.023018354550004005 0.08706517517566681
encoder.encoder.weight_ih_l0_reverse: 0.0021614369470626116 0.0850026085972786
encoder.encoder.weight_hh_l0_reverse: 0.00033607243676669896 0.08410586416721344
encoder.encoder.bias_ih_l0_reverse: 0.015284172259271145 0.08256880193948746
encoder.encoder.bias_hh_l0_reverse: 0.015578906051814556 0.0895090103149414
decider.lstm.weight_ih_l0: -0.0018756710924208164 0.14685580134391785
decider.lstm.weight_hh_l0: 0.005606622435152531 0.14658638834953308
decider.lstm.bias_ih_l0: -0.014676576480269432 0.1414167284965515
decider.lstm.bias_hh_l0: 0.021144581958651543 0.1547350287437439
decider.linear1.weight: 0.004649942275136709 0.12119239568710327
decider.linear1.bias: 0.010053617879748344 0.11460880190134048
decider.linear2.weight: 0.0038096990901976824 0.05576200783252716
decider.linear2.bias: 0.003825568128377199 0.05328085646033287
decider.linear3.weight: -0.005877099931240082 0.06536184251308441
decider.linear3.bias: -0.017307013273239136 0.03719498962163925

Rewards:
74.4454
74.4454
74.4454
objective = 0.0006241857190616429
==== episode 35200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9484e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016101694200187922 0.0842740386724472
encoder.encoder.weight_hh_l0: -0.001320740906521678 0.08651327341794968
encoder.encoder.bias_ih_l0: 0.009983533062040806 0.08981639891862869
encoder.encoder.bias_hh_l0: 0.023055408149957657 0.08707482367753983
encoder.encoder.weight_ih_l0_reverse: 0.002163922181352973 0.08500697463750839
encoder.encoder.weight_hh_l0_reverse: 0.0003340145049151033 0.08411310613155365
encoder.encoder.bias_ih_l0_reverse: 0.015311109833419323 0.08257238566875458
encoder.encoder.bias_hh_l0_reverse: 0.015605839900672436 0.08951257914304733
decider.lstm.weight_ih_l0: -0.0018780184909701347 0.14686043560504913
decider.lstm.weight_hh_l0: 0.00561075285077095 0.14658915996551514
decider.lstm.bias_ih_l0: -0.014656035229563713 0.14141109585762024
decider.lstm.bias_hh_l0: 0.021165069192647934 0.1547352373600006
decider.linear1.weight: 0.004651365801692009 0.12120255827903748
decider.linear1.bias: 0.010071130469441414 0.11460897326469421
decider.linear2.weight: 0.0038287441711872816 0.055795010179281235
decider.linear2.bias: 0.003842916339635849 0.05327603220939636
decider.linear3.weight: -0.0059147970750927925 0.06545066833496094
decider.linear3.bias: -0.017318304628133774 0.03721289336681366

Rewards:
74.4454
74.4454
74.4454
objective = 0.0005827702698297799
==== episode 35300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9484e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016136702615767717 0.0842793807387352
encoder.encoder.weight_hh_l0: -0.0013244240544736385 0.08652951568365097
encoder.encoder.bias_ih_l0: 0.010020196437835693 0.08982549607753754
encoder.encoder.bias_hh_l0: 0.02309207059442997 0.08708439022302628
encoder.encoder.weight_ih_l0_reverse: 0.0021663641091436148 0.0850113108754158
encoder.encoder.weight_hh_l0_reverse: 0.00033197077573277056 0.0841202661395073
encoder.encoder.bias_ih_l0_reverse: 0.015337689779698849 0.08257590979337692
encoder.encoder.bias_hh_l0_reverse: 0.015632420778274536 0.08951612561941147
decider.lstm.weight_ih_l0: -0.0018804151332005858 0.14686504006385803
decider.lstm.weight_hh_l0: 0.005614784546196461 0.1465918868780136
decider.lstm.bias_ih_l0: -0.014635767787694931 0.1414053589105606
decider.lstm.bias_hh_l0: 0.021185336634516716 0.15473538637161255
decider.linear1.weight: 0.004652735777199268 0.1212121993303299
decider.linear1.bias: 0.010088183917105198 0.11460919678211212
decider.linear2.weight: 0.0038461238145828247 0.05582643300294876
decider.linear2.bias: 0.003858843119814992 0.053272370249032974
decider.linear3.weight: -0.005948647391051054 0.0655364990234375
decider.linear3.bias: -0.0173295047134161 0.037230730056762695

Rewards:
74.4454
74.4454
74.4454
objective = 0.0005472713382914662
==== episode 35400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9484e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016171472379937768 0.0842847004532814
encoder.encoder.weight_hh_l0: -0.00132816715631634 0.08654585480690002
encoder.encoder.bias_ih_l0: 0.010056586936116219 0.08983452618122101
encoder.encoder.bias_hh_l0: 0.023128459230065346 0.08709391206502914
encoder.encoder.weight_ih_l0_reverse: 0.0021687669213861227 0.08501560240983963
encoder.encoder.weight_hh_l0_reverse: 0.0003299332456663251 0.08412739634513855
encoder.encoder.bias_ih_l0_reverse: 0.015363995917141438 0.08257940411567688
encoder.encoder.bias_hh_l0_reverse: 0.015658732503652573 0.0895196720957756
decider.lstm.weight_ih_l0: -0.0018828683532774448 0.14686964452266693
decider.lstm.weight_hh_l0: 0.005618745926767588 0.1465945839881897
decider.lstm.bias_ih_l0: -0.01461569219827652 0.1413995921611786
decider.lstm.bias_hh_l0: 0.021205447614192963 0.15473546087741852
decider.linear1.weight: 0.0046541038900613785 0.12122156471014023
decider.linear1.bias: 0.010105082765221596 0.1146092563867569
decider.linear2.weight: 0.0038623162545263767 0.05585644021630287
decider.linear2.bias: 0.0038738539442420006 0.053269434720277786
decider.linear3.weight: -0.0059795016422867775 0.06561944633722305
decider.linear3.bias: -0.017340566962957382 0.037248414009809494

Rewards:
74.4454
74.4454
74.4454
objective = 0.0005147305782884359
==== episode 35500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001620612689293921 0.08429000526666641
encoder.encoder.weight_hh_l0: -0.001331972423940897 0.08656228333711624
encoder.encoder.bias_ih_l0: 0.010092715732753277 0.08984348922967911
encoder.encoder.bias_hh_l0: 0.02316458150744438 0.08710338920354843
encoder.encoder.weight_ih_l0_reverse: 0.002171139931306243 0.08501987904310226
encoder.encoder.weight_hh_l0_reverse: 0.0003279049415141344 0.08413447439670563
encoder.encoder.bias_ih_l0_reverse: 0.015390035696327686 0.08258285373449326
encoder.encoder.bias_hh_l0_reverse: 0.01568477787077427 0.08952321112155914
decider.lstm.weight_ih_l0: -0.0018853864166885614 0.14687424898147583
decider.lstm.weight_hh_l0: 0.005622645374387503 0.1465972512960434
decider.lstm.bias_ih_l0: -0.014595742337405682 0.14139381051063538
decider.lstm.bias_hh_l0: 0.021225448697805405 0.1547354757785797
decider.linear1.weight: 0.004655386786907911 0.12123043835163116
decider.linear1.bias: 0.010121386498212814 0.11460921168327332
decider.linear2.weight: 0.0038776386063545942 0.055885083973407745
decider.linear2.bias: 0.003888256847858429 0.05326699838042259
decider.linear3.weight: -0.00600795540958643 0.0656997412443161
decider.linear3.bias: -0.017351433634757996 0.0372658334672451

Rewards:
74.4454
74.4454
74.4454
objective = 0.00048218993470072746
==== episode 35600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016240313416346908 0.08429526537656784
encoder.encoder.weight_hh_l0: -0.0013358036521822214 0.08657862991094589
encoder.encoder.bias_ih_l0: 0.010128227062523365 0.08985232561826706
encoder.encoder.bias_hh_l0: 0.02320009656250477 0.08711274713277817
encoder.encoder.weight_ih_l0_reverse: 0.002173455897718668 0.08502408862113953
encoder.encoder.weight_hh_l0_reverse: 0.00032590245245955884 0.08414144814014435
encoder.encoder.bias_ih_l0_reverse: 0.015415581874549389 0.08258622884750366
encoder.encoder.bias_hh_l0_reverse: 0.01571032404899597 0.0895267054438591
decider.lstm.weight_ih_l0: -0.0018879399867728353 0.14687877893447876
decider.lstm.weight_hh_l0: 0.0056264204904437065 0.14659984409809113
decider.lstm.bias_ih_l0: -0.014576131477952003 0.14138807356357574
decider.lstm.bias_hh_l0: 0.021245058625936508 0.15473543107509613
decider.linear1.weight: 0.004656642209738493 0.12123901396989822
decider.linear1.bias: 0.010137398727238178 0.11460915207862854
decider.linear2.weight: 0.003891930915415287 0.055912457406520844
decider.linear2.bias: 0.003901800373569131 0.053265124559402466
decider.linear3.weight: -0.0060341693460941315 0.06577681005001068
decider.linear3.bias: -0.017362046986818314 0.03728291764855385

Rewards:
74.4454
74.4454
74.4454
objective = 0.0004555658088065684
==== episode 35700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016274374211207032 0.08430053293704987
encoder.encoder.weight_hh_l0: -0.0013397042639553547 0.08659510314464569
encoder.encoder.bias_ih_l0: 0.010163526050746441 0.08986112475395203
encoder.encoder.bias_hh_l0: 0.023235399276018143 0.0871221050620079
encoder.encoder.weight_ih_l0_reverse: 0.0021757418289780617 0.085028275847435
encoder.encoder.weight_hh_l0_reverse: 0.00032390517299063504 0.08414840698242188
encoder.encoder.bias_ih_l0_reverse: 0.015440911054611206 0.08258959650993347
encoder.encoder.bias_hh_l0_reverse: 0.015735646709799767 0.08953019231557846
decider.lstm.weight_ih_l0: -0.001890557468868792 0.14688335359096527
decider.lstm.weight_hh_l0: 0.005630125757306814 0.14660239219665527
decider.lstm.bias_ih_l0: -0.01455663051456213 0.14138232171535492
decider.lstm.bias_hh_l0: 0.021264512091875076 0.15473522245883942
decider.linear1.weight: 0.004657848738133907 0.12124734371900558
decider.linear1.bias: 0.010153131559491158 0.11460888385772705
decider.linear2.weight: 0.003905388992279768 0.05593891814351082
decider.linear2.bias: 0.003914483357220888 0.053263865411281586
decider.linear3.weight: -0.00605876324698329 0.06585166603326797
decider.linear3.bias: -0.017372604459524155 0.037300001829862595

Rewards:
74.4454
74.4454
74.4454
objective = 0.0004289415664970875
==== episode 35800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016308320919051766 0.08430580049753189
encoder.encoder.weight_hh_l0: -0.001343670766800642 0.08661168813705444
encoder.encoder.bias_ih_l0: 0.010198589414358139 0.08986984193325043
encoder.encoder.bias_hh_l0: 0.02327047288417816 0.08713144063949585
encoder.encoder.weight_ih_l0_reverse: 0.0021780035458505154 0.08503244072198868
encoder.encoder.weight_hh_l0_reverse: 0.00032191319041885436 0.08415532112121582
encoder.encoder.bias_ih_l0_reverse: 0.015466026030480862 0.08259294927120209
encoder.encoder.bias_hh_l0_reverse: 0.01576075702905655 0.08953367173671722
decider.lstm.weight_ih_l0: -0.001893242821097374 0.14688792824745178
decider.lstm.weight_hh_l0: 0.005633766762912273 0.14660492539405823
decider.lstm.bias_ih_l0: -0.014537282288074493 0.14137651026248932
decider.lstm.bias_hh_l0: 0.021283825859427452 0.15473492443561554
decider.linear1.weight: 0.004659015219658613 0.12125550955533981
decider.linear1.bias: 0.010168679058551788 0.11460864543914795
decider.linear2.weight: 0.003918220289051533 0.05596484616398811
decider.linear2.bias: 0.003926766104996204 0.05326284468173981
decider.linear3.weight: -0.006081974133849144 0.0659244954586029
decider.linear3.bias: -0.017383137717843056 0.03731703758239746

Rewards:
74.4454
74.4454
74.4454
objective = 0.00040379661368206143
==== episode 35900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016341789159923792 0.0843111053109169
encoder.encoder.weight_hh_l0: -0.0013476820895448327 0.08662834018468857
encoder.encoder.bias_ih_l0: 0.010233263485133648 0.08987845480442047
encoder.encoder.bias_hh_l0: 0.023305144160985947 0.08714072406291962
encoder.encoder.weight_ih_l0_reverse: 0.0021802536211907864 0.08503656834363937
encoder.encoder.weight_hh_l0_reverse: 0.0003199297352693975 0.0841621458530426
encoder.encoder.bias_ih_l0_reverse: 0.015490860678255558 0.08259622007608414
encoder.encoder.bias_hh_l0_reverse: 0.015785591676831245 0.08953704684972763
decider.lstm.weight_ih_l0: -0.0018959876615554094 0.14689253270626068
decider.lstm.weight_hh_l0: 0.005637332797050476 0.14660745859146118
decider.lstm.bias_ih_l0: -0.014518098905682564 0.14137044548988342
decider.lstm.bias_hh_l0: 0.021302932873368263 0.15473458170890808
decider.linear1.weight: 0.004660158418118954 0.12126351147890091
decider.linear1.bias: 0.010184183716773987 0.11460833251476288
decider.linear2.weight: 0.003930613398551941 0.05599004030227661
decider.linear2.bias: 0.003938755951821804 0.05326200649142265
decider.linear3.weight: -0.006104007363319397 0.0659954622387886
decider.linear3.bias: -0.01739351451396942 0.037333812564611435

Rewards:
74.4454
74.4454
74.4454
objective = 0.0003801307175308466
==== episode 36000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8499e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016375180566683412 0.0843164324760437
encoder.encoder.weight_hh_l0: -0.0013517832849174738 0.08664520829916
encoder.encoder.bias_ih_l0: 0.010267863050103188 0.08988704532384872
encoder.encoder.bias_hh_l0: 0.02333974465727806 0.08715002238750458
encoder.encoder.weight_ih_l0_reverse: 0.0021824571304023266 0.08504069596529007
encoder.encoder.weight_hh_l0_reverse: 0.00031794223468750715 0.08416899293661118
encoder.encoder.bias_ih_l0_reverse: 0.015515520237386227 0.08259954303503036
encoder.encoder.bias_hh_l0_reverse: 0.015810253098607063 0.08954042941331863
decider.lstm.weight_ih_l0: -0.0018988061929121614 0.14689713716506958
decider.lstm.weight_hh_l0: 0.0056408466771245 0.14660994708538055
decider.lstm.bias_ih_l0: -0.014498965814709663 0.14136439561843872
decider.lstm.bias_hh_l0: 0.021321991458535194 0.15473423898220062
decider.linear1.weight: 0.0046612657606601715 0.12127136439085007
decider.linear1.bias: 0.01019958034157753 0.1146080270409584
decider.linear2.weight: 0.003942609298974276 0.05601456016302109
decider.linear2.bias: 0.003950424026697874 0.05326134338974953
decider.linear3.weight: -0.006124997977167368 0.06606472283601761
decider.linear3.bias: -0.017403803765773773 0.037350501865148544

Rewards:
74.4454
74.4454
74.4454
objective = 0.0003594231093302369
==== episode 36100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8499e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016408174997195601 0.08432172983884811
encoder.encoder.weight_hh_l0: -0.0013559329090639949 0.08666211366653442
encoder.encoder.bias_ih_l0: 0.0103020453825593 0.08989551663398743
encoder.encoder.bias_hh_l0: 0.023373931646347046 0.08715926855802536
encoder.encoder.weight_ih_l0_reverse: 0.0021845975425094366 0.08504480123519897
encoder.encoder.weight_hh_l0_reverse: 0.0003159681218676269 0.08417580276727676
encoder.encoder.bias_ih_l0_reverse: 0.01553977932780981 0.082602858543396
encoder.encoder.bias_hh_l0_reverse: 0.015834512189030647 0.08954381942749023
decider.lstm.weight_ih_l0: -0.0019016718724742532 0.1469017118215561
decider.lstm.weight_hh_l0: 0.005644270218908787 0.14661239087581635
decider.lstm.bias_ih_l0: -0.014480110257863998 0.1413584053516388
decider.lstm.bias_hh_l0: 0.021340809762477875 0.15473385155200958
decider.linear1.weight: 0.004662319086492062 0.12127898633480072
decider.linear1.bias: 0.010214705020189285 0.11460773646831512
decider.linear2.weight: 0.0039541348814964294 0.05603818967938423
decider.linear2.bias: 0.003961644601076841 0.0532609187066555
decider.linear3.weight: -0.006144885439425707 0.06613174825906754
decider.linear3.bias: -0.017413873225450516 0.03736687824130058

Rewards:
74.4454
74.4454
74.4454
objective = 0.00034019455779343843
==== episode 36200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8499e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016441154293715954 0.08432707190513611
encoder.encoder.weight_hh_l0: -0.0013601675163954496 0.08667921274900436
encoder.encoder.bias_ih_l0: 0.010336124338209629 0.08990398049354553
encoder.encoder.bias_hh_l0: 0.023408014327287674 0.08716852217912674
encoder.encoder.weight_ih_l0_reverse: 0.002186716301366687 0.08504889905452728
encoder.encoder.weight_hh_l0_reverse: 0.00031399395084008574 0.08418260514736176
encoder.encoder.bias_ih_l0_reverse: 0.015563888475298882 0.08260613679885864
encoder.encoder.bias_hh_l0_reverse: 0.015858624130487442 0.08954722434282303
decider.lstm.weight_ih_l0: -0.0019046181114390492 0.14690634608268738
decider.lstm.weight_hh_l0: 0.005647629499435425 0.14661480486392975
decider.lstm.bias_ih_l0: -0.014461275190114975 0.14135237038135529
decider.lstm.bias_hh_l0: 0.021359633654356003 0.15473337471485138
decider.linear1.weight: 0.004663353785872459 0.121286541223526
decider.linear1.bias: 0.01022979523986578 0.11460744589567184
decider.linear2.weight: 0.003965521696954966 0.05606124550104141
decider.linear2.bias: 0.003972912207245827 0.053260453045368195
decider.linear3.weight: -0.006163996644318104 0.06619738787412643
decider.linear3.bias: -0.01742391847074032 0.03738325461745262

Rewards:
74.4454
74.4454
74.4454
objective = 0.0003194869786966592
==== episode 36300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8499e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016474040457978845 0.08433244377374649
encoder.encoder.weight_hh_l0: -0.001364474301226437 0.08669646084308624
encoder.encoder.bias_ih_l0: 0.010370013304054737 0.08991240710020065
encoder.encoder.bias_hh_l0: 0.023441912606358528 0.08717778325080872
encoder.encoder.weight_ih_l0_reverse: 0.0021887978073209524 0.0850529745221138
encoder.encoder.weight_hh_l0_reverse: 0.0003120316832792014 0.08418937027454376
encoder.encoder.bias_ih_l0_reverse: 0.015587695874273777 0.08260937035083771
encoder.encoder.bias_hh_l0_reverse: 0.01588243618607521 0.08955062925815582
decider.lstm.weight_ih_l0: -0.0019076482858508825 0.14691102504730225
decider.lstm.weight_hh_l0: 0.005650936625897884 0.14661717414855957
decider.lstm.bias_ih_l0: -0.014442455023527145 0.1413463056087494
decider.lstm.bias_hh_l0: 0.021378424018621445 0.1547328233718872
decider.linear1.weight: 0.004664327949285507 0.12129390239715576
decider.linear1.bias: 0.0102445799857378 0.11460693180561066
decider.linear2.weight: 0.003976376727223396 0.056083761155605316
decider.linear2.bias: 0.003983399365097284 0.05326050892472267
decider.linear3.weight: -0.006182407960295677 0.06626177579164505
decider.linear3.bias: -0.017433907836675644 0.03739968687295914

Rewards:
74.4454
74.4454
74.4454
objective = 0.000304695829981938
==== episode 36400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8499e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016506907995790243 0.08433785289525986
encoder.encoder.weight_hh_l0: -0.0013688644394278526 0.08671390265226364
encoder.encoder.bias_ih_l0: 0.01040379237383604 0.08992083370685577
encoder.encoder.bias_hh_l0: 0.023475689813494682 0.08718706667423248
encoder.encoder.weight_ih_l0_reverse: 0.0021908634807914495 0.08505704998970032
encoder.encoder.weight_hh_l0_reverse: 0.00031006531207822263 0.08419614285230637
encoder.encoder.bias_ih_l0_reverse: 0.015611426904797554 0.08261260390281677
encoder.encoder.bias_hh_l0_reverse: 0.015906166285276413 0.08955405652523041
decider.lstm.weight_ih_l0: -0.00191075901966542 0.1469157487154007
decider.lstm.weight_hh_l0: 0.005654185079038143 0.1466195434331894
decider.lstm.bias_ih_l0: -0.014423644170165062 0.14134016633033752
decider.lstm.bias_hh_l0: 0.021397195756435394 0.15473227202892303
decider.linear1.weight: 0.004665283486247063 0.12130122631788254
decider.linear1.bias: 0.010259385220706463 0.11460669338703156
decider.linear2.weight: 0.0039872583001852036 0.05610588192939758
decider.linear2.bias: 0.003994259983301163 0.053260307759046555
decider.linear3.weight: -0.006200204137712717 0.06632500886917114
decider.linear3.bias: -0.01744379848241806 0.03741594776511192

Rewards:
74.4454
74.4454
74.4454
objective = 0.0002839882508851588
==== episode 36500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8014e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001653968240134418 0.0843433067202568
encoder.encoder.weight_hh_l0: -0.0013733332743868232 0.08673153072595596
encoder.encoder.bias_ih_l0: 0.01043740939348936 0.08992922306060791
encoder.encoder.bias_hh_l0: 0.023509301245212555 0.08719632774591446
encoder.encoder.weight_ih_l0_reverse: 0.0021929123904556036 0.08506113290786743
encoder.encoder.weight_hh_l0_reverse: 0.00030809739837422967 0.08420292288064957
encoder.encoder.bias_ih_l0_reverse: 0.015635056421160698 0.08261583745479584
encoder.encoder.bias_hh_l0_reverse: 0.015929801389575005 0.08955749124288559
decider.lstm.weight_ih_l0: -0.0019139464711770415 0.14692050218582153
decider.lstm.weight_hh_l0: 0.00565738370642066 0.1466219127178192
decider.lstm.bias_ih_l0: -0.014404857531189919 0.14133396744728088
decider.lstm.bias_hh_l0: 0.02141597308218479 0.15473167598247528
decider.linear1.weight: 0.004681065678596497 0.12131138145923615
decider.linear1.bias: 0.010293105617165565 0.11460146307945251
decider.linear2.weight: 0.004004251211881638 0.05612887069582939
decider.linear2.bias: 0.004004362039268017 0.05326060578227043
decider.linear3.weight: -0.006217418238520622 0.06638714671134949
decider.linear3.bias: -0.017453588545322418 0.03743202984333038

Rewards:
74.4454
74.4454
74.4454
objective = 0.0002706762170419097
==== episode 36600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8014e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016570213483646512 0.08434838056564331
encoder.encoder.weight_hh_l0: -0.0013775519328191876 0.08674804121255875
encoder.encoder.bias_ih_l0: 0.010468389838933945 0.08993694186210632
encoder.encoder.bias_hh_l0: 0.023540277034044266 0.0872049331665039
encoder.encoder.weight_ih_l0_reverse: 0.0021947992499917746 0.08506499230861664
encoder.encoder.weight_hh_l0_reverse: 0.00030623964266851544 0.08420933783054352
encoder.encoder.bias_ih_l0_reverse: 0.015657002106308937 0.08261893689632416
encoder.encoder.bias_hh_l0_reverse: 0.015951750800013542 0.08956063538789749
decider.lstm.weight_ih_l0: -0.001916872221045196 0.14692480862140656
decider.lstm.weight_hh_l0: 0.005660211201757193 0.1466241031885147
decider.lstm.bias_ih_l0: -0.014388013631105423 0.1413283497095108
decider.lstm.bias_hh_l0: 0.021432800218462944 0.15473142266273499
decider.linear1.weight: 0.004713183268904686 0.12136015295982361
decider.linear1.bias: 0.010472007095813751 0.11457525193691254
decider.linear2.weight: 0.004065448883920908 0.05615149438381195
decider.linear2.bias: 0.0040085637010633945 0.053263913840055466
decider.linear3.weight: -0.006233707070350647 0.06644698232412338
decider.linear3.bias: -0.017463097348809242 0.03744778037071228

Rewards:
74.4454
74.4454
74.4454
objective = 0.00023961486294865608
==== episode 36700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8014e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016594813205301762 0.08435248583555222
encoder.encoder.weight_hh_l0: -0.0013809874653816223 0.086761474609375
encoder.encoder.bias_ih_l0: 0.010493096895515919 0.08994310349225998
encoder.encoder.bias_hh_l0: 0.02356499433517456 0.08721186965703964
encoder.encoder.weight_ih_l0_reverse: 0.0021962872706353664 0.08506826311349869
encoder.encoder.weight_hh_l0_reverse: 0.0003047209174837917 0.08421465754508972
encoder.encoder.bias_ih_l0_reverse: 0.015674713999032974 0.0826215147972107
encoder.encoder.bias_hh_l0_reverse: 0.01596945896744728 0.0895632728934288
decider.lstm.weight_ih_l0: -0.0019191782921552658 0.14692813158035278
decider.lstm.weight_hh_l0: 0.005662375129759312 0.14662590622901917
decider.lstm.bias_ih_l0: -0.014374994672834873 0.14132384955883026
decider.lstm.bias_hh_l0: 0.021445851773023605 0.1547316163778305
decider.linear1.weight: 0.004741277080029249 0.12143450975418091
decider.linear1.bias: 0.010646061971783638 0.11457885056734085
decider.linear2.weight: 0.0040911524556577206 0.05619428679347038
decider.linear2.bias: 0.003993710037320852 0.05326768755912781
decider.linear3.weight: -0.006249233614653349 0.0665060430765152
decider.linear3.bias: -0.017471490427851677 0.037461936473846436

Rewards:
74.4454
74.4454
74.4454
objective = 0.00018932513194158673
==== episode 36800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8014e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016617017099633813 0.08435627818107605
encoder.encoder.weight_hh_l0: -0.0013841462787240744 0.08677379041910172
encoder.encoder.bias_ih_l0: 0.010515587404370308 0.0899488776922226
encoder.encoder.bias_hh_l0: 0.023587476462125778 0.08721823990345001
encoder.encoder.weight_ih_l0_reverse: 0.0021975075360387564 0.08507103472948074
encoder.encoder.weight_hh_l0_reverse: 0.00030339593649841845 0.0842193216085434
encoder.encoder.bias_ih_l0_reverse: 0.015690011903643608 0.08262350410223007
encoder.encoder.bias_hh_l0_reverse: 0.015984760597348213 0.08956566452980042
decider.lstm.weight_ih_l0: -0.0019213625928387046 0.14693129062652588
decider.lstm.weight_hh_l0: 0.00566436629742384 0.14662738144397736
decider.lstm.bias_ih_l0: -0.014362890273332596 0.14131957292556763
decider.lstm.bias_hh_l0: 0.021457992494106293 0.1547313928604126
decider.linear1.weight: 0.004761442542076111 0.12150663882493973
decider.linear1.bias: 0.010773316025733948 0.11459983885288239
decider.linear2.weight: 0.004121397156268358 0.05624353513121605
decider.linear2.bias: 0.00399738410487771 0.053269412368535995
decider.linear3.weight: -0.0062637063674628735 0.0665663555264473
decider.linear3.bias: -0.01747843064367771 0.03747391700744629

Rewards:
74.4454
74.4454
74.4454
objective = 0.00014791017747484148
==== episode 36900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8014e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016636601649224758 0.08435966074466705
encoder.encoder.weight_hh_l0: -0.0013869794784113765 0.08678477257490158
encoder.encoder.bias_ih_l0: 0.010535528883337975 0.08995407819747925
encoder.encoder.bias_hh_l0: 0.023607425391674042 0.08722390979528427
encoder.encoder.weight_ih_l0_reverse: 0.002198518719524145 0.08507338166236877
encoder.encoder.weight_hh_l0_reverse: 0.00030224394868128 0.08422338962554932
encoder.encoder.bias_ih_l0_reverse: 0.015703272074460983 0.08262520283460617
encoder.encoder.bias_hh_l0_reverse: 0.01599802076816559 0.08956779539585114
decider.lstm.weight_ih_l0: -0.0019233622588217258 0.1469341367483139
decider.lstm.weight_hh_l0: 0.005666140001267195 0.14662861824035645
decider.lstm.bias_ih_l0: -0.014352010563015938 0.1413157433271408
decider.lstm.bias_hh_l0: 0.021468931809067726 0.15473103523254395
decider.linear1.weight: 0.004775969311594963 0.12156882137060165
decider.linear1.bias: 0.01086561381816864 0.11462535709142685
decider.linear2.weight: 0.00414153840392828 0.05629066005349159
decider.linear2.bias: 0.0039923666045069695 0.053273823112249374
decider.linear3.weight: -0.006277347449213266 0.06662736088037491
decider.linear3.bias: -0.017484202980995178 0.037484053522348404

Rewards:
74.4454
74.4454
74.4454
objective = 0.00011832806922029704
==== episode 37000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016654363134875894 0.08436276018619537
encoder.encoder.weight_hh_l0: -0.0013895868323743343 0.08679480850696564
encoder.encoder.bias_ih_l0: 0.010553712956607342 0.08995886147022247
encoder.encoder.bias_hh_l0: 0.02362561598420143 0.08722908049821854
encoder.encoder.weight_ih_l0_reverse: 0.00219938438385725 0.08507543802261353
encoder.encoder.weight_hh_l0_reverse: 0.0003012135857716203 0.08422702550888062
encoder.encoder.bias_ih_l0_reverse: 0.015715045854449272 0.08262669295072556
encoder.encoder.bias_hh_l0_reverse: 0.01600979082286358 0.08956968784332275
decider.lstm.weight_ih_l0: -0.0019252242054790258 0.14693677425384521
decider.lstm.weight_hh_l0: 0.005667759105563164 0.1466296911239624
decider.lstm.bias_ih_l0: -0.014341986738145351 0.14131231606006622
decider.lstm.bias_hh_l0: 0.021478891372680664 0.15473045408725739
decider.linear1.weight: 0.0047879586927592754 0.12162617594003677
decider.linear1.bias: 0.010942626744508743 0.11465185880661011
decider.linear2.weight: 0.004194064065814018 0.05633675679564476
decider.linear2.bias: 0.004045076668262482 0.0533323660492897
decider.linear3.weight: -0.00631035165861249 0.06669516861438751
decider.linear3.bias: -0.017489058896899223 0.037492651492357254

Rewards:
74.4454
74.4454
74.4454
objective = 9.466242045164108e-05
==== episode 37100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001666834345087409 0.08436520397663116
encoder.encoder.weight_hh_l0: -0.0013916442403569818 0.08680269867181778
encoder.encoder.bias_ih_l0: 0.010567951016128063 0.08996263891458511
encoder.encoder.bias_hh_l0: 0.02363986149430275 0.08723315596580505
encoder.encoder.weight_ih_l0_reverse: 0.0022000407334417105 0.08507703244686127
encoder.encoder.weight_hh_l0_reverse: 0.00030041259014979005 0.08422987163066864
encoder.encoder.bias_ih_l0_reverse: 0.015724189579486847 0.08262787014245987
encoder.encoder.bias_hh_l0_reverse: 0.016018947586417198 0.08957114070653915
decider.lstm.weight_ih_l0: -0.0019266612362116575 0.14693881571292877
decider.lstm.weight_hh_l0: 0.005668995436280966 0.14663054049015045
decider.lstm.bias_ih_l0: -0.014334333129227161 0.1413097232580185
decider.lstm.bias_hh_l0: 0.02148655615746975 0.15473002195358276
decider.linear1.weight: 0.004796904977411032 0.12167274206876755
decider.linear1.bias: 0.011000235565006733 0.11467501521110535
decider.linear2.weight: 0.004283724818378687 0.05640040710568428
decider.linear2.bias: 0.004186626523733139 0.05352675914764404
decider.linear3.weight: -0.0064096758142113686 0.06679454445838928
decider.linear3.bias: -0.017492501065135002 0.0374983549118042

Rewards:
74.4454
74.4454
74.4454
objective = 6.803857104387134e-05
==== episode 37200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00166787626221776 0.08436700701713562
encoder.encoder.weight_hh_l0: -0.0013931685825809836 0.08680849522352219
encoder.encoder.bias_ih_l0: 0.010578478686511517 0.08996547758579254
encoder.encoder.bias_hh_l0: 0.0236503928899765 0.08723621070384979
encoder.encoder.weight_ih_l0_reverse: 0.00220051733776927 0.08507819473743439
encoder.encoder.weight_hh_l0_reverse: 0.00029982300475239754 0.08423198759555817
encoder.encoder.bias_ih_l0_reverse: 0.01573091559112072 0.0826287567615509
encoder.encoder.bias_hh_l0_reverse: 0.016025682911276817 0.08957216888666153
decider.lstm.weight_ih_l0: -0.001927702222019434 0.14694029092788696
decider.lstm.weight_hh_l0: 0.005669875536113977 0.14663119614124298
decider.lstm.bias_ih_l0: -0.01432882808148861 0.14130793511867523
decider.lstm.bias_hh_l0: 0.02149205282330513 0.15472975373268127
decider.linear1.weight: 0.004803274758160114 0.12170775979757309
decider.linear1.bias: 0.01104104146361351 0.11469309031963348
decider.linear2.weight: 0.004325123503804207 0.05647945776581764
decider.linear2.bias: 0.004281108267605305 0.053673092275857925
decider.linear3.weight: -0.006476051639765501 0.06690678000450134
decider.linear3.bias: -0.017494840547442436 0.037501975893974304

Rewards:
74.4454
74.4454
74.4454
objective = 5.176846025278792e-05
==== episode 37300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001668678829446435 0.08436838537454605
encoder.encoder.weight_hh_l0: -0.0013943311059847474 0.08681289106607437
encoder.encoder.bias_ih_l0: 0.010586504824459553 0.08996767550706863
encoder.encoder.bias_hh_l0: 0.02365841343998909 0.08723855018615723
encoder.encoder.weight_ih_l0_reverse: 0.002200883347541094 0.08507908135652542
encoder.encoder.weight_hh_l0_reverse: 0.0002993739035446197 0.0842336043715477
encoder.encoder.bias_ih_l0_reverse: 0.015736043453216553 0.08262949436903
encoder.encoder.bias_hh_l0_reverse: 0.016030818223953247 0.08957293629646301
decider.lstm.weight_ih_l0: -0.001928474404849112 0.14694136381149292
decider.lstm.weight_hh_l0: 0.005670513957738876 0.14663171768188477
decider.lstm.bias_ih_l0: -0.014324748888611794 0.14130672812461853
decider.lstm.bias_hh_l0: 0.021496111527085304 0.15472964942455292
decider.linear1.weight: 0.004808022640645504 0.12173482030630112
decider.linear1.bias: 0.011071231216192245 0.11470718681812286
decider.linear2.weight: 0.004349477589130402 0.05655882507562637
decider.linear2.bias: 0.004348902031779289 0.05378739908337593
decider.linear3.weight: -0.006525360979139805 0.06701722741127014
decider.linear3.bias: -0.01749655231833458 0.037504542618989944

Rewards:
74.4454
74.4454
74.4454
objective = 4.141476165386848e-05
==== episode 37400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016693287761881948 0.0843694806098938
encoder.encoder.weight_hh_l0: -0.0013952571898698807 0.08681638538837433
encoder.encoder.bias_ih_l0: 0.010592920705676079 0.0899694412946701
encoder.encoder.bias_hh_l0: 0.023664817214012146 0.08724045008420944
encoder.encoder.weight_ih_l0_reverse: 0.0022011813707649708 0.08507978916168213
encoder.encoder.weight_hh_l0_reverse: 0.0002990142675116658 0.08423490077257156
encoder.encoder.bias_ih_l0_reverse: 0.01574014313519001 0.08263009786605835
encoder.encoder.bias_hh_l0_reverse: 0.01603493094444275 0.08957350254058838
decider.lstm.weight_ih_l0: -0.0019290639320388436 0.14694218337535858
decider.lstm.weight_hh_l0: 0.0056710136123001575 0.1466321051120758
decider.lstm.bias_ih_l0: -0.014321593567728996 0.1413058489561081
decider.lstm.bias_hh_l0: 0.021499227732419968 0.15472954511642456
decider.linear1.weight: 0.004811740480363369 0.12175651639699936
decider.linear1.bias: 0.011094649322330952 0.1147184818983078
decider.linear2.weight: 0.00436633313074708 0.0566338449716568
decider.linear2.bias: 0.004401163198053837 0.05388043448328972
decider.linear3.weight: -0.0065650055184960365 0.06712257117033005
decider.linear3.bias: -0.01749790459871292 0.03750653192400932

Rewards:
74.4454
74.4454
74.4454
objective = 3.401926369406283e-05
==== episode 37500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7059e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016698652179911733 0.08437038213014603
encoder.encoder.weight_hh_l0: -0.0013960206415504217 0.08681923151016235
encoder.encoder.bias_ih_l0: 0.01059820968657732 0.08997087925672531
encoder.encoder.bias_hh_l0: 0.02367011271417141 0.08724202960729599
encoder.encoder.weight_ih_l0_reverse: 0.0022014298010617495 0.08508039265871048
encoder.encoder.weight_hh_l0_reverse: 0.0002987156331073493 0.08423599600791931
encoder.encoder.bias_ih_l0_reverse: 0.015743566676974297 0.08263067156076431
encoder.encoder.bias_hh_l0_reverse: 0.016038356348872185 0.08957399427890778
decider.lstm.weight_ih_l0: -0.0019295404199510813 0.1469428390264511
decider.lstm.weight_hh_l0: 0.005671410821378231 0.14663246273994446
decider.lstm.bias_ih_l0: -0.014319058507680893 0.14130523800849915
decider.lstm.bias_hh_l0: 0.021501775830984116 0.15472951531410217
decider.linear1.weight: 0.004814769607037306 0.12177451699972153
decider.linear1.bias: 0.011113566346466541 0.11472778767347336
decider.linear2.weight: 0.004378967918455601 0.05670381709933281
decider.linear2.bias: 0.004443488549441099 0.053958527743816376
decider.linear3.weight: -0.006598406471312046 0.06722219288349152
decider.linear3.bias: -0.017499007284641266 0.037508122622966766

Rewards:
74.4454
74.4454
74.4454
objective = 2.9581968192360364e-05
==== episode 37600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7059e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016703256405889988 0.08437113463878632
encoder.encoder.weight_hh_l0: -0.001396664185449481 0.08682163059711456
encoder.encoder.bias_ih_l0: 0.010602667927742004 0.08997213840484619
encoder.encoder.bias_hh_l0: 0.023674586787819862 0.08724338561296463
encoder.encoder.weight_ih_l0_reverse: 0.0022016458678990602 0.08508089184761047
encoder.encoder.weight_hh_l0_reverse: 0.000298462895443663 0.08423692733049393
encoder.encoder.bias_ih_l0_reverse: 0.015746481716632843 0.0826311856508255
encoder.encoder.bias_hh_l0_reverse: 0.01604127325117588 0.0895744115114212
decider.lstm.weight_ih_l0: -0.001929924706928432 0.1469433605670929
decider.lstm.weight_hh_l0: 0.0056717549450695515 0.14663274586200714
decider.lstm.bias_ih_l0: -0.01431693322956562 0.14130479097366333
decider.lstm.bias_hh_l0: 0.021503839641809464 0.15472953021526337
decider.linear1.weight: 0.004817298613488674 0.12178971618413925
decider.linear1.bias: 0.01112926285713911 0.11473563313484192
decider.linear2.weight: 0.004388811066746712 0.05676840990781784
decider.linear2.bias: 0.004478681832551956 0.05402510240674019
decider.linear3.weight: -0.006627146620303392 0.06731536239385605
decider.linear3.bias: -0.01749994605779648 0.037509478628635406

Rewards:
74.4454
74.4454
74.4454
objective = 2.3665572371101007e-05
==== episode 37700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7059e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001670729136094451 0.08437179774045944
encoder.encoder.weight_hh_l0: -0.0013972249580547214 0.08682369440793991
encoder.encoder.bias_ih_l0: 0.01060655526816845 0.08997320383787155
encoder.encoder.bias_hh_l0: 0.02367849089205265 0.08724459260702133
encoder.encoder.weight_ih_l0_reverse: 0.002201838418841362 0.0850813239812851
encoder.encoder.weight_hh_l0_reverse: 0.0002982428122777492 0.08423774689435959
encoder.encoder.bias_ih_l0_reverse: 0.015749027952551842 0.08263164013624191
encoder.encoder.bias_hh_l0_reverse: 0.016043823212385178 0.08957474678754807
decider.lstm.weight_ih_l0: -0.0019302564905956388 0.1469438076019287
decider.lstm.weight_hh_l0: 0.005672052968293428 0.14663301408290863
decider.lstm.bias_ih_l0: -0.014315168373286724 0.14130446314811707
decider.lstm.bias_hh_l0: 0.02150559425354004 0.15472958981990814
decider.linear1.weight: 0.0048194811679422855 0.12180297076702118
decider.linear1.bias: 0.011142710223793983 0.1147424653172493
decider.linear2.weight: 0.004396834410727024 0.05682889744639397
decider.linear2.bias: 0.004509054124355316 0.05408366024494171
decider.linear3.weight: -0.006652696058154106 0.06740359961986542
decider.linear3.bias: -0.01750072091817856 0.03751055896282196

Rewards:
74.4454
74.4454
74.4454
objective = 2.0707373550976627e-05
==== episode 37800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7059e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016710880445316434 0.084372378885746
encoder.encoder.weight_hh_l0: -0.001397721585817635 0.08682552725076675
encoder.encoder.bias_ih_l0: 0.010610011406242847 0.08997415751218796
encoder.encoder.bias_hh_l0: 0.023681962862610817 0.08724565804004669
encoder.encoder.weight_ih_l0_reverse: 0.0022020109463483095 0.08508171886205673
encoder.encoder.weight_hh_l0_reverse: 0.0002980461867991835 0.08423846960067749
encoder.encoder.bias_ih_l0_reverse: 0.015751296654343605 0.08263204991817474
encoder.encoder.bias_hh_l0_reverse: 0.01604609750211239 0.08957506716251373
decider.lstm.weight_ih_l0: -0.0019305426394566894 0.14694418013095856
decider.lstm.weight_hh_l0: 0.005672308150678873 0.14663323760032654
decider.lstm.bias_ih_l0: -0.014313720166683197 0.141304150223732
decider.lstm.bias_hh_l0: 0.021507106721401215 0.15472964942455292
decider.linear1.weight: 0.004821409471333027 0.12181475013494492
decider.linear1.bias: 0.011154508218169212 0.11474847793579102
decider.linear2.weight: 0.004403070546686649 0.056885793805122375
decider.linear2.bias: 0.004534914158284664 0.054136477410793304
decider.linear3.weight: -0.006675779819488525 0.06748733669519424
decider.linear3.bias: -0.01750143989920616 0.037511613219976425

Rewards:
74.4454
74.4454
74.4454
objective = 1.9228275050409138e-05
==== episode 37900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7059e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001671412494033575 0.08437290042638779
encoder.encoder.weight_hh_l0: -0.0013981688534840941 0.08682717382907867
encoder.encoder.bias_ih_l0: 0.010613136924803257 0.0899750292301178
encoder.encoder.bias_hh_l0: 0.02368508279323578 0.0872466117143631
encoder.encoder.weight_ih_l0_reverse: 0.002202165313065052 0.08508208394050598
encoder.encoder.weight_hh_l0_reverse: 0.0002978693228214979 0.08423913270235062
encoder.encoder.bias_ih_l0_reverse: 0.015753349289298058 0.08263245224952698
encoder.encoder.bias_hh_l0_reverse: 0.016048163175582886 0.08957532793283463
decider.lstm.weight_ih_l0: -0.0019307902548462152 0.14694450795650482
decider.lstm.weight_hh_l0: 0.005672519560903311 0.14663344621658325
decider.lstm.bias_ih_l0: -0.014312448911368847 0.14130383729934692
decider.lstm.bias_hh_l0: 0.021508444100618362 0.1547296941280365
decider.linear1.weight: 0.004823132883757353 0.12182536721229553
decider.linear1.bias: 0.011165049858391285 0.11475387215614319
decider.linear2.weight: 0.004408820532262325 0.05693962424993515
decider.linear2.bias: 0.0045588091015815735 0.05418400093913078
decider.linear3.weight: -0.006696891505271196 0.06756710261106491
decider.linear3.bias: -0.017502108588814735 0.03751252219080925

Rewards:
74.4454
74.4454
74.4454
objective = 1.627007804927416e-05
==== episode 38000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6588e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016717129619792104 0.0843733698129654
encoder.encoder.weight_hh_l0: -0.001398575841449201 0.08682866394519806
encoder.encoder.bias_ih_l0: 0.01061597466468811 0.08997581899166107
encoder.encoder.bias_hh_l0: 0.02368791587650776 0.08724746108055115
encoder.encoder.weight_ih_l0_reverse: 0.0022023057099431753 0.08508241176605225
encoder.encoder.weight_hh_l0_reverse: 0.0002977057301905006 0.08423973619937897
encoder.encoder.bias_ih_l0_reverse: 0.01575522869825363 0.08263281732797623
encoder.encoder.bias_hh_l0_reverse: 0.016050046309828758 0.08957556635141373
decider.lstm.weight_ih_l0: -0.0019310155184939504 0.1469447910785675
decider.lstm.weight_hh_l0: 0.005672714207321405 0.14663363993167877
decider.lstm.bias_ih_l0: -0.014311298727989197 0.14130349457263947
decider.lstm.bias_hh_l0: 0.021509651094675064 0.15472975373268127
decider.linear1.weight: 0.004824690520763397 0.12183505296707153
decider.linear1.bias: 0.011174576357007027 0.11475877463817596
decider.linear2.weight: 0.004413834773004055 0.05699076130986214
decider.linear2.bias: 0.004580451641231775 0.05422757565975189
decider.linear3.weight: -0.006716406904160976 0.06764335930347443
decider.linear3.bias: -0.01750262640416622 0.03751324117183685

Rewards:
74.4454
74.4454
74.4454
objective = 1.3311882867128588e-05
==== episode 38100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6588e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016719871200621128 0.08437380194664001
encoder.encoder.weight_hh_l0: -0.0013989439466968179 0.0868300199508667
encoder.encoder.bias_ih_l0: 0.010618552565574646 0.08997655659914017
encoder.encoder.bias_hh_l0: 0.023690499365329742 0.08724824339151382
encoder.encoder.weight_ih_l0_reverse: 0.002202431671321392 0.08508270233869553
encoder.encoder.weight_hh_l0_reverse: 0.000297558814054355 0.08424028754234314
encoder.encoder.bias_ih_l0_reverse: 0.015756938606500626 0.0826331377029419
encoder.encoder.bias_hh_l0_reverse: 0.016051767393946648 0.08957576006650925
decider.lstm.weight_ih_l0: -0.0019312178483232856 0.1469450443983078
decider.lstm.weight_hh_l0: 0.005672888830304146 0.1466337889432907
decider.lstm.bias_ih_l0: -0.014310273341834545 0.14130321145057678
decider.lstm.bias_hh_l0: 0.02151075378060341 0.15472982823848724
decider.linear1.weight: 0.004826100543141365 0.12184388190507889
decider.linear1.bias: 0.01118315290659666 0.11476324498653412
decider.linear2.weight: 0.00441824970766902 0.05703906714916229
decider.linear2.bias: 0.004600088112056255 0.0542675219476223
decider.linear3.weight: -0.006734402850270271 0.06771570444107056
decider.linear3.bias: -0.01750314049422741 0.03751397505402565

Rewards:
74.4454
74.4454
74.4454
objective = 1.18327843665611e-05
==== episode 38200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6588e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016722383443266153 0.08437419682741165
encoder.encoder.weight_hh_l0: -0.0013992879539728165 0.08683127164840698
encoder.encoder.bias_ih_l0: 0.010620961897075176 0.08997725695371628
encoder.encoder.bias_hh_l0: 0.023692898452281952 0.08724898099899292
encoder.encoder.weight_ih_l0_reverse: 0.0022025536745786667 0.08508298546075821
encoder.encoder.weight_hh_l0_reverse: 0.0002974240342155099 0.08424080908298492
encoder.encoder.bias_ih_l0_reverse: 0.015758518129587173 0.08263345062732697
encoder.encoder.bias_hh_l0_reverse: 0.016053354367613792 0.08957596123218536
decider.lstm.weight_ih_l0: -0.0019314028322696686 0.1469452828168869
decider.lstm.weight_hh_l0: 0.005673050414770842 0.14663392305374146
decider.lstm.bias_ih_l0: -0.014309308491647243 0.1413029581308365
decider.lstm.bias_hh_l0: 0.021511774510145187 0.1547299176454544
decider.linear1.weight: 0.004827406257390976 0.1218520924448967
decider.linear1.bias: 0.011191034689545631 0.11476738005876541
decider.linear2.weight: 0.004421932157129049 0.05708533897995949
decider.linear2.bias: 0.004617716185748577 0.05430508777499199
decider.linear3.weight: -0.006751298904418945 0.06778531521558762
decider.linear3.bias: -0.0175036434084177 0.03751469403505325

Rewards:
74.4454
74.4454
74.4454
objective = 1.18327843665611e-05
==== episode 38300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6588e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016724718734622002 0.0843745693564415
encoder.encoder.weight_hh_l0: -0.0013996115885674953 0.0868324339389801
encoder.encoder.bias_ih_l0: 0.01062321662902832 0.08997791260480881
encoder.encoder.bias_hh_l0: 0.023695148527622223 0.08724968880414963
encoder.encoder.weight_ih_l0_reverse: 0.0022026686929166317 0.0850832462310791
encoder.encoder.weight_hh_l0_reverse: 0.00029729705420322716 0.08424128592014313
encoder.encoder.bias_ih_l0_reverse: 0.015760008245706558 0.08263374865055084
encoder.encoder.bias_hh_l0_reverse: 0.01605484075844288 0.08957613259553909
decider.lstm.weight_ih_l0: -0.0019315718673169613 0.14694549143314362
decider.lstm.weight_hh_l0: 0.0056732092052698135 0.1466340720653534
decider.lstm.bias_ih_l0: -0.014308437705039978 0.14130277931690216
decider.lstm.bias_hh_l0: 0.02151266299188137 0.15472999215126038
decider.linear1.weight: 0.004828619305044413 0.12185977399349213
decider.linear1.bias: 0.011198366060853004 0.11477123200893402
decider.linear2.weight: 0.004425546154379845 0.05712983012199402
decider.linear2.bias: 0.004634604789316654 0.0543401725590229
decider.linear3.weight: -0.006767255254089832 0.0678524449467659
decider.linear3.bias: -0.017504163086414337 0.03751540184020996

Rewards:
74.4454
74.4454
74.4454
objective = 1.18327843665611e-05
==== episode 38400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6588e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016726910835132003 0.08437491953372955
encoder.encoder.weight_hh_l0: -0.0013999153161421418 0.08683352172374725
encoder.encoder.bias_ih_l0: 0.010625330731272697 0.08997851610183716
encoder.encoder.bias_hh_l0: 0.023697249591350555 0.08725038915872574
encoder.encoder.weight_ih_l0_reverse: 0.0022027716040611267 0.0850834921002388
encoder.encoder.weight_hh_l0_reverse: 0.00029717691359110177 0.08424173295497894
encoder.encoder.bias_ih_l0_reverse: 0.01576141268014908 0.08263405412435532
encoder.encoder.bias_hh_l0_reverse: 0.016056234017014503 0.08957632631063461
decider.lstm.weight_ih_l0: -0.001931730774231255 0.14694568514823914
decider.lstm.weight_hh_l0: 0.005673359148204327 0.14663420617580414
decider.lstm.bias_ih_l0: -0.014307638630270958 0.1413026601076126
decider.lstm.bias_hh_l0: 0.02151346206665039 0.15473008155822754
decider.linear1.weight: 0.004829754587262869 0.12186698615550995
decider.linear1.bias: 0.011205214075744152 0.11477484554052353
decider.linear2.weight: 0.004428889602422714 0.05717272683978081
decider.linear2.bias: 0.004650463350117207 0.054373301565647125
decider.linear3.weight: -0.006782397627830505 0.06791738420724869
decider.linear3.bias: -0.01750468835234642 0.03751610592007637

Rewards:
74.4454
74.4454
74.4454
objective = 1.18327843665611e-05
==== episode 38500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6122e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016728979535400867 0.08437525480985641
encoder.encoder.weight_hh_l0: -0.001400200417265296 0.08683454990386963
encoder.encoder.bias_ih_l0: 0.010627311654388905 0.08997903764247894
encoder.encoder.bias_hh_l0: 0.02369922399520874 0.08725100755691528
encoder.encoder.weight_ih_l0_reverse: 0.0022028647363185883 0.0850837305188179
encoder.encoder.weight_hh_l0_reverse: 0.00029706282657571137 0.08424216508865356
encoder.encoder.bias_ih_l0_reverse: 0.015762748196721077 0.082634337246418
encoder.encoder.bias_hh_l0_reverse: 0.016057543456554413 0.08957649022340775
decider.lstm.weight_ih_l0: -0.0019318804843351245 0.14694587886333466
decider.lstm.weight_hh_l0: 0.005673486273735762 0.14663434028625488
decider.lstm.bias_ih_l0: -0.014306887052953243 0.14130254089832306
decider.lstm.bias_hh_l0: 0.021514171734452248 0.1547301560640335
decider.linear1.weight: 0.004830818623304367 0.12187381088733673
decider.linear1.bias: 0.011211641132831573 0.11477826535701752
decider.linear2.weight: 0.004431849345564842 0.05721418559551239
decider.linear2.bias: 0.004665127955377102 0.05440490320324898
decider.linear3.weight: -0.00679683918133378 0.0679803341627121
decider.linear3.bias: -0.017505047842860222 0.03751654177904129

Rewards:
74.4454
74.4454
74.4454
objective = 1.18327843665611e-05
==== episode 38600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6122e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001673094928264618 0.08437556028366089
encoder.encoder.weight_hh_l0: -0.0014004678232595325 0.08683551847934723
encoder.encoder.bias_ih_l0: 0.010629162192344666 0.08997954428195953
encoder.encoder.bias_hh_l0: 0.023701084777712822 0.08725158125162125
encoder.encoder.weight_ih_l0_reverse: 0.0022029534447938204 0.08508393913507462
encoder.encoder.weight_hh_l0_reverse: 0.00029695453122258186 0.0842425599694252
encoder.encoder.bias_ih_l0_reverse: 0.01576400361955166 0.08263462781906128
encoder.encoder.bias_hh_l0_reverse: 0.016058780252933502 0.08957663923501968
decider.lstm.weight_ih_l0: -0.001932020764797926 0.1469460427761078
decider.lstm.weight_hh_l0: 0.005673589184880257 0.14663444459438324
decider.lstm.bias_ih_l0: -0.014306196011602879 0.1413024365901947
decider.lstm.bias_hh_l0: 0.02151482366025448 0.1547302007675171
decider.linear1.weight: 0.004831812344491482 0.12188022583723068
decider.linear1.bias: 0.011217644438147545 0.1147814616560936
decider.linear2.weight: 0.004434637259691954 0.057253964245319366
decider.linear2.bias: 0.0046789636835455894 0.05443468317389488
decider.linear3.weight: -0.006810523569583893 0.0680408775806427
decider.linear3.bias: -0.017505373805761337 0.03751689940690994

Rewards:
74.4454
74.4454
74.4454
objective = 1.18327843665611e-05
==== episode 38700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6122e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016732853837311268 0.08437588065862656
encoder.encoder.weight_hh_l0: -0.0014007402351126075 0.0868365466594696
encoder.encoder.bias_ih_l0: 0.01063100341707468 0.08998004347085953
encoder.encoder.bias_hh_l0: 0.023702947422862053 0.08725213259458542
encoder.encoder.weight_ih_l0_reverse: 0.0022030367981642485 0.08508415520191193
encoder.encoder.weight_hh_l0_reverse: 0.00029685001936741173 0.08424293994903564
encoder.encoder.bias_ih_l0_reverse: 0.015765193849802017 0.0826348066329956
encoder.encoder.bias_hh_l0_reverse: 0.016059961169958115 0.08957679569721222
decider.lstm.weight_ih_l0: -0.0019321944564580917 0.1469462513923645
decider.lstm.weight_hh_l0: 0.0056737130507826805 0.1466345340013504
decider.lstm.bias_ih_l0: -0.014305368065834045 0.14130213856697083
decider.lstm.bias_hh_l0: 0.021515661850571632 0.1547302007675171
decider.linear1.weight: 0.004832912236452103 0.12188741564750671
decider.linear1.bias: 0.011224639602005482 0.11478547751903534
decider.linear2.weight: 0.004440936725586653 0.0572843924164772
decider.linear2.bias: 0.004695337265729904 0.05447354167699814
decider.linear3.weight: -0.006821556482464075 0.06808607280254364
decider.linear3.bias: -0.017505642026662827 0.03751719743013382

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 38800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6122e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001673464779742062 0.08437618613243103
encoder.encoder.weight_hh_l0: -0.0014010007726028562 0.086837537586689
encoder.encoder.bias_ih_l0: 0.01063273660838604 0.08998052030801773
encoder.encoder.bias_hh_l0: 0.02370472438633442 0.0872526615858078
encoder.encoder.weight_ih_l0_reverse: 0.002203113166615367 0.08508434891700745
encoder.encoder.weight_hh_l0_reverse: 0.00029674998950213194 0.0842432901263237
encoder.encoder.bias_ih_l0_reverse: 0.015766317024827003 0.08263495564460754
encoder.encoder.bias_hh_l0_reverse: 0.016061071306467056 0.08957694470882416
decider.lstm.weight_ih_l0: -0.0019323717569932342 0.14694646000862122
decider.lstm.weight_hh_l0: 0.005673829931765795 0.14663460850715637
decider.lstm.bias_ih_l0: -0.01430454384535551 0.14130184054374695
decider.lstm.bias_hh_l0: 0.02151651307940483 0.1547302007675171
decider.linear1.weight: 0.0048339893110096455 0.1218944564461708
decider.linear1.bias: 0.011231539770960808 0.11478956043720245
decider.linear2.weight: 0.004447511862963438 0.057311318814754486
decider.linear2.bias: 0.0047111185267567635 0.054513100534677505
decider.linear3.weight: -0.006831379607319832 0.06812568008899689
decider.linear3.bias: -0.017505884170532227 0.0375174842774868

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 38900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6122e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736327670514584 0.08437646925449371
encoder.encoder.weight_hh_l0: -0.00140124571043998 0.08683845400810242
encoder.encoder.bias_ih_l0: 0.010634345933794975 0.08998095989227295
encoder.encoder.bias_hh_l0: 0.02370637282729149 0.0872531533241272
encoder.encoder.weight_ih_l0_reverse: 0.0022031862754374743 0.08508452028036118
encoder.encoder.weight_hh_l0_reverse: 0.00029665720649063587 0.08424361795186996
encoder.encoder.bias_ih_l0_reverse: 0.015767360106110573 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.01606210693717003 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325359025970101 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673938896507025 0.14663466811180115
decider.lstm.bias_ih_l0: -0.01430377084761858 0.14130154252052307
decider.lstm.bias_hh_l0: 0.02151729352772236 0.1547301858663559
decider.linear1.weight: 0.004834997467696667 0.12190104275941849
decider.linear1.bias: 0.011237965896725655 0.11479340493679047
decider.linear2.weight: 0.004453680478036404 0.057336993515491486
decider.linear2.bias: 0.004726055543869734 0.0545501746237278
decider.linear3.weight: -0.006840587593615055 0.0681634321808815
decider.linear3.bias: -0.017506130039691925 0.03751778230071068

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 39000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5661e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 39100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5661e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 39200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5661e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 39300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5661e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 39400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5661e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 39500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5204e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 39600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5204e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 39700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5204e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 39800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5204e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 39900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5204e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 40000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 40100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 40200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 40300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 40400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 40500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4305e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 40600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4305e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 40700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4305e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 40800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4305e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 40900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4305e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 41000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3862e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 41100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3862e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 41200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3862e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 41300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3862e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 41400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3862e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 41500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3423e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 41600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3423e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 41700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3423e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 41800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3423e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 41900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3423e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 42000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 42100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 42200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 42300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 42400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 42500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2559e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 42600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2559e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 42700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2559e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 42800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2559e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 42900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2559e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 43000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2133e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 43100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2133e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 43200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2133e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 43300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2133e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 43400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2133e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 43500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1712e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 43600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1712e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 43700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1712e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 43800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1712e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 43900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1712e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 44000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1295e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 44100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1295e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 44200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1295e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 44300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1295e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 44400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1295e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 44500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0882e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 44600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0882e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 44700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0882e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 44800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0882e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 44900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0882e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 45000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0473e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 45100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0473e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 45200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0473e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 45300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0473e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 45400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0473e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 45500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0068e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 45600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0068e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 45700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0068e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 45800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0068e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 45900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0068e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 46000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9668e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 46100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9668e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 46200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9668e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 46300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9668e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 46400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9668e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 46500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 46600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 46700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 46800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 46900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 47000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8878e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 47100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8878e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 47200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8878e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 47300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8878e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 47400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8878e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 47500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8490e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 47600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8490e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 47700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8490e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 47800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8490e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 47900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8490e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 48000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8105e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 48100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8105e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 48200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8105e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 48300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8105e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 48400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8105e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 48500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7724e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 48600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7724e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 48700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7724e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 48800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7724e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 48900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7724e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 49000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7346e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 49100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7346e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 49200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7346e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 49300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7346e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 49400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7346e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 49500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 49600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 49700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 49800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 49900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 50000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6603e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 50100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6603e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 50200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6603e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 50300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6603e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 50400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6603e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 50500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6237e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 50600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6237e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 50700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6237e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 50800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6237e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 50900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6237e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 51000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 51100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 51200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 51300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 51400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 51500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5516e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 51600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5516e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 51700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5516e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 51800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5516e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 51900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5516e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 52000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5161e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 52100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5161e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 52200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5161e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 52300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5161e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 52400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5161e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 52500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4809e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 52600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4809e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 52700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4809e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 52800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4809e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 52900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4809e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 53000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4461e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 53100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4461e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 53200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4461e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 53300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4461e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 53400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4461e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 53500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 53600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 53700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 53800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 53900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 54000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3775e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 54100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3775e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 54200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3775e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 54300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3775e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 54400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3775e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 54500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 54600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 54700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 54800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 54900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 55000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3103e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 55100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3103e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 55200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3103e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 55300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3103e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 55400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3103e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 55500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2772e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 55600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2772e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 55700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2772e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 55800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2772e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 55900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2772e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 56000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2445e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 56100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2445e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 56200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2445e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 56300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2445e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 56400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2445e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 56500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2120e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 56600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2120e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 56700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2120e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 56800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2120e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 56900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2120e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 57000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1799e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 57100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1799e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 57200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1799e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 57300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1799e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 57400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1799e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 57500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1481e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 57600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1481e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 57700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1481e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 57800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1481e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 57900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1481e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 58000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1166e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 58100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1166e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 58200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1166e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 58300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1166e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 58400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1166e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 58500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0854e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 58600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0854e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 58700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0854e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 58800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0854e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 58900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0854e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 59000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0546e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 59100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0546e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 59200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0546e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 59300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0546e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 59400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0546e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 59500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0240e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 59600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0240e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 59700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0240e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 59800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0240e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 59900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0240e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 60000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9938e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 60100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9938e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 60200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9938e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 60300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9938e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 60400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9938e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 60500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9639e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 60600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9639e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 60700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9639e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 60800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9639e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 60900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9639e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 61000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9342e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 61100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9342e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 61200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9342e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 61300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9342e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 61400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9342e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 61500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9049e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 61600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9049e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 61700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9049e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 61800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9049e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 61900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9049e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 62000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8758e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 62100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8758e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 62200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8758e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 62300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8758e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 62400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8758e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 62500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8471e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 62600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8471e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 62700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8471e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 62800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8471e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 62900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8471e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 63000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8186e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 63100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8186e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 63200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8186e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 63300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8186e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 63400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8186e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 63500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7904e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 63600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7904e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 63700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7904e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 63800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7904e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 63900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7904e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 64000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7625e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 64100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7625e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 64200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7625e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 64300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7625e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 64400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7625e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 64500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7349e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 64600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7349e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 64700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7349e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 64800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7349e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 64900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7349e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 65000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7075e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 65100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7075e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 65200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7075e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 65300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7075e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 65400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7075e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 65500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6805e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 65600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6805e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 65700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6805e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 65800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6805e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 65900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6805e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 66000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6537e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 66100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6537e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 66200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6537e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 66300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6537e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 66400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6537e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 66500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 66600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 66700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 66800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 66900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 67000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6009e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 67100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6009e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 67200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6009e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 67300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6009e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 67400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6009e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 67500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5748e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 67600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5748e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 67700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5748e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 67800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5748e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 67900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5748e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 68000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5491e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 68100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5491e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 68200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5491e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 68300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5491e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 68400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5491e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 68500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5236e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 68600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5236e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 68700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5236e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 68800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5236e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 68900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5236e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 69000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 69100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 69200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 69300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 69400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 69500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4734e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 69600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4734e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 69700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4734e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 69800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4734e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 69900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4734e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 70000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4487e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 70100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4487e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 70200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4487e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 70300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4487e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 70400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4487e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 70500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4242e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 70600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4242e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 70700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4242e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 70800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4242e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 70900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4242e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 71000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 71100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 71200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 71300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 71400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 71500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3759e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 71600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3759e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 71700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3759e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 71800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3759e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 71900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3759e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 72000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3522e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 72100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3522e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 72200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3522e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 72300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3522e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 72400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3522e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 72500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3286e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 72600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3286e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 72700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3286e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 72800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3286e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 72900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3286e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 73000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3054e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 73100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3054e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 73200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3054e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 73300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3054e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 73400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3054e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 73500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2823e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 73600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2823e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 73700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2823e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 73800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2823e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 73900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2823e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 74000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2595e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 74100/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2595e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 74200/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2595e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 74300/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2595e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 74400/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2595e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 74500/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2369e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 74600/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2369e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 74700/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2369e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 74800/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2369e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 74900/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2369e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
==== episode 75000/75000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2145e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016736430115997791 0.08437648415565491
encoder.encoder.weight_hh_l0: -0.0014012615429237485 0.0868385061621666
encoder.encoder.bias_ih_l0: 0.01063444372266531 0.08998097479343414
encoder.encoder.bias_hh_l0: 0.02370646595954895 0.08725317567586899
encoder.encoder.weight_ih_l0_reverse: 0.00220319046638906 0.08508452773094177
encoder.encoder.weight_hh_l0_reverse: 0.0002966509200632572 0.08424364030361176
encoder.encoder.bias_ih_l0_reverse: 0.015767421573400497 0.08263509720563889
encoder.encoder.bias_hh_l0_reverse: 0.016062166541814804 0.0895770788192749
decider.lstm.weight_ih_l0: -0.0019325452158227563 0.14694665372371674
decider.lstm.weight_hh_l0: 0.005673941224813461 0.14663466811180115
decider.lstm.bias_ih_l0: -0.014303742907941341 0.14130152761936188
decider.lstm.bias_hh_l0: 0.021517319604754448 0.1547301858663559
decider.linear1.weight: 0.004835058934986591 0.12190144509077072
decider.linear1.bias: 0.011238348670303822 0.11479365080595016
decider.linear2.weight: 0.00445401668548584 0.05733885243535042
decider.linear2.bias: 0.004726968705654144 0.054552286863327026
decider.linear3.weight: -0.0068412236869335175 0.06816617399454117
decider.linear3.bias: -0.017506137490272522 0.037517793476581573

Rewards:
74.4454
74.4454
74.4454
objective = 8.874589184415527e-06
[INFO] : learning runtime (h:mm:ss): 0:17:06
[INFO] : learning end time: 12/18/2023 10:27:42 AM
