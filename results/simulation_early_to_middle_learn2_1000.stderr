Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 12:26:38 PM
==== episode 1/10000 ====
action = 0
probs = 0.2500 0.2502 0.2499 0.2499

action = 0
probs = 0.2499 0.2502 0.2499 0.2499

action = 0
probs = 0.2499 0.2502 0.2499 0.2499

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003006539773195982 0.08382802456617355
encoder.encoder.weight_hh_l0: -0.00043466329225338995 0.08493997901678085
encoder.encoder.bias_ih_l0: 0.006773148197680712 0.08568770438432693
encoder.encoder.bias_hh_l0: 0.016770238056778908 0.08572612702846527
encoder.encoder.weight_ih_l0_reverse: 0.001637849141843617 0.08582916110754013
encoder.encoder.weight_hh_l0_reverse: 0.0022716904059052467 0.08397238701581955
encoder.encoder.bias_ih_l0_reverse: 0.022404054179787636 0.08511384576559067
encoder.encoder.bias_hh_l0_reverse: 0.014269489794969559 0.08350106328725815
decider.lstm.weight_ih_l0: -0.00036893284413963556 0.14689289033412933
decider.lstm.weight_hh_l0: -0.0014365544775500894 0.1459912806749344
decider.lstm.bias_ih_l0: 0.017449572682380676 0.15304474532604218
decider.lstm.bias_hh_l0: -0.0015379679389297962 0.1433926373720169
decider.linear1.weight: 0.001839313074015081 0.12068705260753632
decider.linear1.bias: 0.013287806883454323 0.11647670716047287
decider.linear2.weight: 0.0037795468233525753 0.055137280374765396
decider.linear2.bias: 0.004318030085414648 0.05695608630776405
decider.linear3.weight: -0.03095148876309395 0.0870521292090416
decider.linear3.bias: -0.018916616216301918 0.053618092089891434

Rewards:
206.9982
206.9982
206.9982
objective = 287.00653076171875
==== episode 100/10000 ====
action = 1
probs = 0.0133 0.9866 0.0001 0.0000

action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0002 0.9998 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00028854183619841933 0.0842103585600853
encoder.encoder.weight_hh_l0: -0.0005651271785609424 0.08551297336816788
encoder.encoder.bias_ih_l0: 0.008587289601564407 0.08617623895406723
encoder.encoder.bias_hh_l0: 0.01858437806367874 0.08621774613857269
encoder.encoder.weight_ih_l0_reverse: 0.001702789799310267 0.0862167552113533
encoder.encoder.weight_hh_l0_reverse: 0.0024770426098257303 0.08427759259939194
encoder.encoder.bias_ih_l0_reverse: 0.023699240759015083 0.08548852801322937
encoder.encoder.bias_hh_l0_reverse: 0.015564675442874432 0.0838208720088005
decider.lstm.weight_ih_l0: -0.00016542676894459873 0.14736951887607574
decider.lstm.weight_hh_l0: -0.001865969505161047 0.14638692140579224
decider.lstm.bias_ih_l0: 0.020352639257907867 0.15371564030647278
decider.lstm.bias_hh_l0: 0.0013651060871779919 0.14397042989730835
decider.linear1.weight: 0.001786408363841474 0.12092848122119904
decider.linear1.bias: 0.013732905499637127 0.11633296310901642
decider.linear2.weight: 0.00394407007843256 0.05531921610236168
decider.linear2.bias: 0.004516201559454203 0.057390328496694565
decider.linear3.weight: -0.0322943776845932 0.0884128287434578
decider.linear3.bias: -0.021306484937667847 0.056727852672338486

Rewards:
190.8927
190.8927
190.8927
objective = 0.8879618048667908
==== episode 200/10000 ====
action = 1
probs = 0.0019 0.9981 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00020965423027519137 0.08448729664087296
encoder.encoder.weight_hh_l0: -0.0007219808176159859 0.08618312329053879
encoder.encoder.bias_ih_l0: 0.010753218084573746 0.08641742169857025
encoder.encoder.bias_hh_l0: 0.02075030840933323 0.0864790603518486
encoder.encoder.weight_ih_l0_reverse: 0.0018311055609956384 0.08652465790510178
encoder.encoder.weight_hh_l0_reverse: 0.002696834970265627 0.08449386805295944
encoder.encoder.bias_ih_l0_reverse: 0.0255722776055336 0.08573741465806961
encoder.encoder.bias_hh_l0_reverse: 0.017437715083360672 0.08406741172075272
decider.lstm.weight_ih_l0: -5.3206662414595485e-05 0.14780209958553314
decider.lstm.weight_hh_l0: -0.0027292300947010517 0.14675790071487427
decider.lstm.bias_ih_l0: 0.02291322499513626 0.15409474074840546
decider.lstm.bias_hh_l0: 0.003925691358745098 0.14434516429901123
decider.linear1.weight: 0.0014904527924954891 0.12135113775730133
decider.linear1.bias: 0.0148400217294693 0.1162581518292427
decider.linear2.weight: 0.004560454748570919 0.05559788644313812
decider.linear2.bias: 0.005290974862873554 0.05752859637141228
decider.linear3.weight: -0.032621901482343674 0.08886053413152695
decider.linear3.bias: -0.021761776879429817 0.05849224701523781

Rewards:
190.8927
190.8927
190.8927
objective = 0.12424561381340027
==== episode 300/10000 ====
action = 1
probs = 0.0007 0.9993 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00015650152636226267 0.08458441495895386
encoder.encoder.weight_hh_l0: -0.000825032009743154 0.08654528856277466
encoder.encoder.bias_ih_l0: 0.011773145757615566 0.08650035411119461
encoder.encoder.bias_hh_l0: 0.021770233288407326 0.08647839725017548
encoder.encoder.weight_ih_l0_reverse: 0.001898499671369791 0.0866975486278534
encoder.encoder.weight_hh_l0_reverse: 0.002879375359043479 0.08468253910541534
encoder.encoder.bias_ih_l0_reverse: 0.026729395613074303 0.0857163667678833
encoder.encoder.bias_hh_l0_reverse: 0.018594831228256226 0.08416026830673218
decider.lstm.weight_ih_l0: -3.455435944488272e-05 0.14797750115394592
decider.lstm.weight_hh_l0: -0.0032061950769275427 0.14690001308918
decider.lstm.bias_ih_l0: 0.0237894244492054 0.15430641174316406
decider.lstm.bias_hh_l0: 0.004801888484507799 0.14433807134628296
decider.linear1.weight: 0.0012620501220226288 0.12159334123134613
decider.linear1.bias: 0.015435070730745792 0.11609731614589691
decider.linear2.weight: 0.004901638254523277 0.055764149874448776
decider.linear2.bias: 0.005627603270113468 0.05752856656908989
decider.linear3.weight: -0.03267291188240051 0.08897528797388077
decider.linear3.bias: -0.021795425564050674 0.05895086005330086

Rewards:
190.8927
190.8927
190.8927
objective = 0.04692886024713516
==== episode 400/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011107805767096579 0.08464792370796204
encoder.encoder.weight_hh_l0: -0.0009029633365571499 0.08682242780923843
encoder.encoder.bias_ih_l0: 0.012450522743165493 0.08654768019914627
encoder.encoder.bias_hh_l0: 0.02244761399924755 0.08642710745334625
encoder.encoder.weight_ih_l0_reverse: 0.00193611322902143 0.08682051301002502
encoder.encoder.weight_hh_l0_reverse: 0.003025855403393507 0.0848441869020462
encoder.encoder.bias_ih_l0_reverse: 0.02752218209207058 0.08564674854278564
encoder.encoder.bias_hh_l0_reverse: 0.0193876214325428 0.084198959171772
decider.lstm.weight_ih_l0: -2.453356864862144e-05 0.14809170365333557
decider.lstm.weight_hh_l0: -0.0035368904937058687 0.14698418974876404
decider.lstm.bias_ih_l0: 0.024276820942759514 0.15444643795490265
decider.lstm.bias_hh_l0: 0.0052892891690135 0.1442854106426239
decider.linear1.weight: 0.0010843246709555387 0.12177567183971405
decider.linear1.bias: 0.015813369303941727 0.11599164456129074
decider.linear2.weight: 0.005125365685671568 0.05589010939002037
decider.linear2.bias: 0.005824646912515163 0.05752614140510559
decider.linear3.weight: -0.03269278630614281 0.08904464542865753
decider.linear3.bias: -0.02180573157966137 0.05918610468506813

Rewards:
190.8927
190.8927
190.8927
objective = 0.023393800482153893
==== episode 500/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -7.398500747513026e-05 0.08469663560390472
encoder.encoder.weight_hh_l0: -0.000960418488830328 0.0870497077703476
encoder.encoder.bias_ih_l0: 0.012932603247463703 0.08657783269882202
encoder.encoder.bias_hh_l0: 0.022929688915610313 0.0863669216632843
encoder.encoder.weight_ih_l0_reverse: 0.0019588549621403217 0.08690621703863144
encoder.encoder.weight_hh_l0_reverse: 0.0031382807064801455 0.08497289568185806
encoder.encoder.bias_ih_l0_reverse: 0.028073085471987724 0.0855756476521492
encoder.encoder.bias_hh_l0_reverse: 0.019938521087169647 0.08420547842979431
decider.lstm.weight_ih_l0: -1.5208832337521017e-05 0.14817456901073456
decider.lstm.weight_hh_l0: -0.0037904575001448393 0.14704100787639618
decider.lstm.bias_ih_l0: 0.024591904133558273 0.15454739332199097
decider.lstm.bias_hh_l0: 0.005604379810392857 0.14421716332435608
decider.linear1.weight: 0.0009399861446581781 0.12191776931285858
decider.linear1.bias: 0.01606711931526661 0.11592591553926468
decider.linear2.weight: 0.005451386794447899 0.05601322278380394
decider.linear2.bias: 0.006171728018671274 0.05767008662223816
decider.linear3.weight: -0.03281894698739052 0.08914236724376678
decider.linear3.bias: -0.02181001752614975 0.059324052184820175

Rewards:
190.8927
190.8927
190.8927
objective = 0.011587731540203094
==== episode 600/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -4.735424954560585e-05 0.0847327783703804
encoder.encoder.weight_hh_l0: -0.0009992079576477408 0.08722439408302307
encoder.encoder.bias_ih_l0: 0.013260040432214737 0.08659891039133072
encoder.encoder.bias_hh_l0: 0.023257127031683922 0.08631882071495056
encoder.encoder.weight_ih_l0_reverse: 0.0019731600768864155 0.0869620218873024
encoder.encoder.weight_hh_l0_reverse: 0.0032170747872442007 0.08506510406732559
encoder.encoder.bias_ih_l0_reverse: 0.02843412384390831 0.0855194553732872
encoder.encoder.bias_hh_l0_reverse: 0.020299561321735382 0.08419652283191681
decider.lstm.weight_ih_l0: -6.155240953376051e-06 0.14823457598686218
decider.lstm.weight_hh_l0: -0.0039858147501945496 0.14708136022090912
decider.lstm.bias_ih_l0: 0.024801870808005333 0.15462233126163483
decider.lstm.bias_hh_l0: 0.005814347416162491 0.14414894580841064
decider.linear1.weight: 0.0008252772386185825 0.12202108651399612
decider.linear1.bias: 0.01623561419546604 0.11588222533464432
decider.linear2.weight: 0.00565052404999733 0.0561312735080719
decider.linear2.bias: 0.006374301854521036 0.05779743194580078
decider.linear3.weight: -0.0328921303153038 0.08924636244773865
decider.linear3.bias: -0.02181195095181465 0.059404198080301285

Rewards:
190.8927
190.8927
190.8927
objective = 0.006508598104119301
==== episode 700/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -2.7295089239487424e-05 0.08476115018129349
encoder.encoder.weight_hh_l0: -0.001027213758789003 0.08736582845449448
encoder.encoder.bias_ih_l0: 0.01350085437297821 0.08661659806966782
encoder.encoder.bias_hh_l0: 0.023497942835092545 0.08628300577402115
encoder.encoder.weight_ih_l0_reverse: 0.001983665395528078 0.08700139820575714
encoder.encoder.weight_hh_l0_reverse: 0.003276933915913105 0.08513590693473816
encoder.encoder.bias_ih_l0_reverse: 0.02869562990963459 0.08547336608171463
encoder.encoder.bias_hh_l0_reverse: 0.020561065524816513 0.08417872339487076
decider.lstm.weight_ih_l0: 2.6882626116275787e-06 0.14828374981880188
decider.lstm.weight_hh_l0: -0.0041551110334694386 0.1471155732870102
decider.lstm.bias_ih_l0: 0.024963220581412315 0.15468792617321014
decider.lstm.bias_hh_l0: 0.005975684151053429 0.14407892525196075
decider.linear1.weight: 0.0007278141565620899 0.12210190296173096
decider.linear1.bias: 0.016356706619262695 0.11585089564323425
decider.linear2.weight: 0.005786470603197813 0.05622943118214607
decider.linear2.bias: 0.00651125842705369 0.05790222808718681
decider.linear3.weight: -0.0329362116754055 0.08933386951684952
decider.linear3.bias: -0.02181302383542061 0.059456679970026016

Rewards:
190.8927
190.8927
190.8927
objective = 0.004050727933645248
==== episode 800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -1.1545121196832042e-05 0.08478430658578873
encoder.encoder.weight_hh_l0: -0.0010486773680895567 0.08748449385166168
encoder.encoder.bias_ih_l0: 0.013688504695892334 0.0866328626871109
encoder.encoder.bias_hh_l0: 0.02368559129536152 0.0862567275762558
encoder.encoder.weight_ih_l0_reverse: 0.0019923693034797907 0.08703083544969559
encoder.encoder.weight_hh_l0_reverse: 0.003325406927615404 0.0851936936378479
encoder.encoder.bias_ih_l0_reverse: 0.02889920212328434 0.0854334905743599
encoder.encoder.bias_hh_l0_reverse: 0.020764634013175964 0.08415458351373672
decider.lstm.weight_ih_l0: 1.1405460099922493e-05 0.14832821488380432
decider.lstm.weight_hh_l0: -0.004314008168876171 0.14714981615543365
decider.lstm.bias_ih_l0: 0.025100674480199814 0.15475226938724518
decider.lstm.bias_hh_l0: 0.006113131996244192 0.1440054476261139
decider.linear1.weight: 0.000641342718154192 0.1221688985824585
decider.linear1.bias: 0.016447870060801506 0.1158275455236435
decider.linear2.weight: 0.0058842869475483894 0.056308381259441376
decider.linear2.bias: 0.006611671764403582 0.05798949673771858
decider.linear3.weight: -0.03296582028269768 0.08940661698579788
decider.linear3.bias: -0.02181370183825493 0.05949375778436661

Rewards:
190.8927
190.8927
190.8927
objective = 0.0027042494621127844
==== episode 900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.2553482520161197e-06 0.08480377495288849
encoder.encoder.weight_hh_l0: -0.0010659953113645315 0.08758692443370819
encoder.encoder.bias_ih_l0: 0.01384161226451397 0.08664823323488235
encoder.encoder.bias_hh_l0: 0.023838698863983154 0.08623732626438141
encoder.encoder.weight_ih_l0_reverse: 0.0020002180244773626 0.08705384284257889
encoder.encoder.weight_hh_l0_reverse: 0.0033673064317554235 0.08524411916732788
encoder.encoder.bias_ih_l0_reverse: 0.029067926108837128 0.08539707213640213
encoder.encoder.bias_hh_l0_reverse: 0.020933356136083603 0.08412424474954605
decider.lstm.weight_ih_l0: 2.024393506872002e-05 0.1483716368675232
decider.lstm.weight_hh_l0: -0.004470453131943941 0.147189199924469
decider.lstm.bias_ih_l0: 0.02522685006260872 0.15482020378112793
decider.lstm.bias_hh_l0: 0.0062393262051045895 0.14392738044261932
decider.linear1.weight: 0.0005615391419269145 0.12222720682621002
decider.linear1.bias: 0.01651877909898758 0.11580940335988998
decider.linear2.weight: 0.005958735942840576 0.05637390539050102
decider.linear2.bias: 0.006688780151307583 0.05806294083595276
decider.linear3.weight: -0.032986775040626526 0.08946739137172699
decider.linear3.bias: -0.021814176812767982 0.05952128767967224

Rewards:
190.8927
190.8927
190.8927
objective = 0.0018849980551749468
==== episode 1000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.1572315997909755e-05 0.08481983840465546
encoder.encoder.weight_hh_l0: -0.0010799785377457738 0.0876736268401146
encoder.encoder.bias_ih_l0: 0.013966230675578117 0.08666206896305084
encoder.encoder.bias_hh_l0: 0.023963317275047302 0.08622335642576218
encoder.encoder.weight_ih_l0_reverse: 0.0020073808263987303 0.08707204461097717
encoder.encoder.weight_hh_l0_reverse: 0.0034055644646286964 0.08529075235128403
encoder.encoder.bias_ih_l0_reverse: 0.02921304665505886 0.08536311984062195
encoder.encoder.bias_hh_l0_reverse: 0.021078478544950485 0.08408743143081665
decider.lstm.weight_ih_l0: 2.9280632588779554e-05 0.14841513335704803
decider.lstm.weight_hh_l0: -0.004622401669621468 0.14723756909370422
decider.lstm.bias_ih_l0: 0.02534443885087967 0.15489152073860168
decider.lstm.bias_hh_l0: 0.006356921512633562 0.14384697377681732
decider.linear1.weight: 0.00046274898340925574 0.1223335713148117
decider.linear1.bias: 0.016879554837942123 0.11565564572811127
decider.linear2.weight: 0.006078182719647884 0.056484710425138474
decider.linear2.bias: 0.006712144240736961 0.05813371390104294
decider.linear3.weight: -0.0330008789896965 0.0895126685500145
decider.linear3.bias: -0.021814439445734024 0.05954146012663841

Rewards:
190.8927
190.8927
190.8927
objective = 0.0011529900366440415
==== episode 1100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.859299845818896e-05 0.08483121544122696
encoder.encoder.weight_hh_l0: -0.0010897773317992687 0.08773637562990189
encoder.encoder.bias_ih_l0: 0.014054281637072563 0.0866725966334343
encoder.encoder.bias_hh_l0: 0.024051368236541748 0.08621447533369064
encoder.encoder.weight_ih_l0_reverse: 0.0020128381438553333 0.08708474785089493
encoder.encoder.weight_hh_l0_reverse: 0.003437225939705968 0.08533040434122086
encoder.encoder.bias_ih_l0_reverse: 0.029323844239115715 0.0853358581662178
encoder.encoder.bias_hh_l0_reverse: 0.021189279854297638 0.08405216038227081
decider.lstm.weight_ih_l0: 3.721691609825939e-05 0.14845241606235504
decider.lstm.weight_hh_l0: -0.004746571183204651 0.1472875028848648
decider.lstm.bias_ih_l0: 0.025437496602535248 0.1549520641565323
decider.lstm.bias_hh_l0: 0.006449960637837648 0.1437801569700241
decider.linear1.weight: 0.00038858267362229526 0.12246204167604446
decider.linear1.bias: 0.017114531248807907 0.11561166495084763
decider.linear2.weight: 0.00617455318570137 0.05660705640912056
decider.linear2.bias: 0.006745752412825823 0.058175839483737946
decider.linear3.weight: -0.03300810977816582 0.08954500406980515
decider.linear3.bias: -0.021814581006765366 0.059554170817136765

Rewards:
190.8927
190.8927
190.8927
objective = 0.0006902744062244892
==== episode 1200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3355110897682607e-05 0.0848393589258194
encoder.encoder.weight_hh_l0: -0.0010967551497742534 0.08778202533721924
encoder.encoder.bias_ih_l0: 0.014117393642663956 0.08668068796396255
encoder.encoder.bias_hh_l0: 0.024114476516842842 0.0862087607383728
encoder.encoder.weight_ih_l0_reverse: 0.0020167117472738028 0.08709391951560974
encoder.encoder.weight_hh_l0_reverse: 0.0034634501207619905 0.08536436408758163
encoder.encoder.bias_ih_l0_reverse: 0.02940857782959938 0.08531485497951508
encoder.encoder.bias_hh_l0_reverse: 0.021274013444781303 0.08402220159769058
decider.lstm.weight_ih_l0: 4.3806954636238515e-05 0.14848266541957855
decider.lstm.weight_hh_l0: -0.004843786358833313 0.14733384549617767
decider.lstm.bias_ih_l0: 0.025507448241114616 0.15499833226203918
decider.lstm.bias_hh_l0: 0.006519911345094442 0.14372959733009338
decider.linear1.weight: 0.0003329333267174661 0.1225723996758461
decider.linear1.bias: 0.017267337068915367 0.11560651659965515
decider.linear2.weight: 0.006241973489522934 0.05670677497982979
decider.linear2.bias: 0.0067712184973061085 0.05820382386445999
decider.linear3.weight: -0.033011939376592636 0.08956771343946457
decider.linear3.bias: -0.021814662963151932 0.0595625676214695

Rewards:
190.8927
190.8927
190.8927
objective = 0.0004513324238359928
==== episode 1300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.676393705769442e-05 0.08484547585248947
encoder.encoder.weight_hh_l0: -0.0011019593803212047 0.08781668543815613
encoder.encoder.bias_ih_l0: 0.014164768159389496 0.08668715506792068
encoder.encoder.bias_hh_l0: 0.02416185475885868 0.08620486408472061
encoder.encoder.weight_ih_l0_reverse: 0.002019480336457491 0.08710093796253204
encoder.encoder.weight_hh_l0_reverse: 0.0034854926634579897 0.08539378643035889
encoder.encoder.bias_ih_l0_reverse: 0.029475344344973564 0.08529853820800781
encoder.encoder.bias_hh_l0_reverse: 0.021340778097510338 0.08399756997823715
decider.lstm.weight_ih_l0: 4.924349195789546e-05 0.14850719273090363
decider.lstm.weight_hh_l0: -0.004920957610011101 0.14737530052661896
decider.lstm.bias_ih_l0: 0.025560563430190086 0.15503282845020294
decider.lstm.bias_hh_l0: 0.006573064718395472 0.14369149506092072
decider.linear1.weight: 0.0002889153838623315 0.12266683578491211
decider.linear1.bias: 0.017379140481352806 0.11561453342437744
decider.linear2.weight: 0.006291379686444998 0.056790102273225784
decider.linear2.bias: 0.006789688020944595 0.05822458118200302
decider.linear3.weight: -0.0330142043530941 0.08958457410335541
decider.linear3.bias: -0.021814711391925812 0.059568583965301514

Rewards:
190.8927
190.8927
190.8927
objective = 0.00031858726288191974
==== episode 1400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.933509495051112e-05 0.0848502665758133
encoder.encoder.weight_hh_l0: -0.0011059915414080024 0.08784405887126923
encoder.encoder.bias_ih_l0: 0.014201761223375797 0.08669248223304749
encoder.encoder.bias_hh_l0: 0.024198850616812706 0.08620209991931915
encoder.encoder.weight_ih_l0_reverse: 0.0020215061958879232 0.08710654079914093
encoder.encoder.weight_hh_l0_reverse: 0.0035041263327002525 0.08541930466890335
encoder.encoder.bias_ih_l0_reverse: 0.029529141262173653 0.08528570830821991
encoder.encoder.bias_hh_l0_reverse: 0.021394576877355576 0.08397754281759262
decider.lstm.weight_ih_l0: 5.3727701015304774e-05 0.14852717518806458
decider.lstm.weight_hh_l0: -0.004983372520655394 0.14741180837154388
decider.lstm.bias_ih_l0: 0.02560165338218212 0.15505850315093994
decider.lstm.bias_hh_l0: 0.006614224519580603 0.14366242289543152
decider.linear1.weight: 0.00025279849069193006 0.12274900823831558
decider.linear1.bias: 0.017466755583882332 0.11562789231538773
decider.linear2.weight: 0.006329982075840235 0.056861620396375656
decider.linear2.bias: 0.006803900469094515 0.058240827172994614
decider.linear3.weight: -0.03301567584276199 0.08959781378507614
decider.linear3.bias: -0.021814752370119095 0.05957316234707832

Rewards:
190.8927
190.8927
190.8927
objective = 0.00023514758504461497
==== episode 1500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.136798841296695e-05 0.0848541334271431
encoder.encoder.weight_hh_l0: -0.0011092249769717455 0.0878664180636406
encoder.encoder.bias_ih_l0: 0.014231635257601738 0.08669697493314743
encoder.encoder.bias_hh_l0: 0.024228734895586967 0.08620006591081619
encoder.encoder.weight_ih_l0_reverse: 0.002023039385676384 0.08711116760969162
encoder.encoder.weight_hh_l0_reverse: 0.0035200119018554688 0.08544150739908218
encoder.encoder.bias_ih_l0_reverse: 0.029573431238532066 0.08527546375989914
encoder.encoder.bias_hh_l0_reverse: 0.021438870579004288 0.08396115154027939
decider.lstm.weight_ih_l0: 5.7465804275125265e-05 0.14854367077350616
decider.lstm.weight_hh_l0: -0.005034970119595528 0.14744389057159424
decider.lstm.bias_ih_l0: 0.025634264573454857 0.1550779789686203
decider.lstm.bias_hh_l0: 0.006646792404353619 0.14363957941532135
decider.linear1.weight: 0.00022230482136365026 0.12282177805900574
decider.linear1.bias: 0.017538608983159065 0.11564352363348007
decider.linear2.weight: 0.006362267304211855 0.05692301318049431
decider.linear2.bias: 0.006815357133746147 0.05825408175587654
decider.linear3.weight: -0.03301670029759407 0.08960866183042526
decider.linear3.bias: -0.02181478589773178 0.05957682430744171

Rewards:
190.8927
190.8927
190.8927
objective = 0.000185842378414236
==== episode 1600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.302633558632806e-05 0.08485732972621918
encoder.encoder.weight_hh_l0: -0.001111867604777217 0.08788502216339111
encoder.encoder.bias_ih_l0: 0.014256245456635952 0.08670081198215485
encoder.encoder.bias_hh_l0: 0.024253342300653458 0.08619849383831024
encoder.encoder.weight_ih_l0_reverse: 0.002024231245741248 0.08711506426334381
encoder.encoder.weight_hh_l0_reverse: 0.0035335817374289036 0.08546078950166702
encoder.encoder.bias_ih_l0_reverse: 0.02961031347513199 0.08526717871427536
encoder.encoder.bias_hh_l0_reverse: 0.02147574909031391 0.08394767343997955
decider.lstm.weight_ih_l0: 6.060816303943284e-05 0.14855742454528809
decider.lstm.weight_hh_l0: -0.005078177433460951 0.14747203886508942
decider.lstm.bias_ih_l0: 0.02566060982644558 0.15509290993213654
decider.lstm.bias_hh_l0: 0.006673095282167196 0.14362142980098724
decider.linear1.weight: 0.00019622643594630063 0.12288668006658554
decider.linear1.bias: 0.017599022015929222 0.11565999686717987
decider.linear2.weight: 0.006389797665178776 0.05697683244943619
decider.linear2.bias: 0.006824814714491367 0.058265138417482376
decider.linear3.weight: -0.033017441630363464 0.08961774408817291
decider.linear3.bias: -0.02181478589773178 0.05957982689142227

Rewards:
190.8927
190.8927
190.8927
objective = 0.00015170802362263203
==== episode 1700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.443248351686634e-05 0.08486006408929825
encoder.encoder.weight_hh_l0: -0.0011141047580167651 0.0879010334610939
encoder.encoder.bias_ih_l0: 0.014277233742177486 0.08670418709516525
encoder.encoder.bias_hh_l0: 0.024274324998259544 0.08619727939367294
encoder.encoder.weight_ih_l0_reverse: 0.002025200752541423 0.08711844682693481
encoder.encoder.weight_hh_l0_reverse: 0.0035454435274004936 0.08547786623239517
encoder.encoder.bias_ih_l0_reverse: 0.029641931876540184 0.08526024222373962
encoder.encoder.bias_hh_l0_reverse: 0.021507369354367256 0.08393627405166626
decider.lstm.weight_ih_l0: 6.332322664093226e-05 0.14856919646263123
decider.lstm.weight_hh_l0: -0.005115468520671129 0.14749719202518463
decider.lstm.bias_ih_l0: 0.025682594627141953 0.15510469675064087
decider.lstm.bias_hh_l0: 0.006695051211863756 0.1436065435409546
decider.linear1.weight: 0.00017327038221992552 0.12294599413871765
decider.linear1.bias: 0.017651613801717758 0.11567681282758713
decider.linear2.weight: 0.006413680035620928 0.057025808840990067
decider.linear2.bias: 0.006832907907664776 0.058274686336517334
decider.linear3.weight: -0.033018000423908234 0.08962562680244446
decider.linear3.bias: -0.021814797073602676 0.059582363814115524

Rewards:
190.8927
190.8927
190.8927
objective = 0.00012136639270465821
==== episode 1800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.5658998967846856e-05 0.08486245572566986
encoder.encoder.weight_hh_l0: -0.0011160473804920912 0.08791511505842209
encoder.encoder.bias_ih_l0: 0.01429554633796215 0.0867072120308876
encoder.encoder.bias_hh_l0: 0.02429262176156044 0.08619628846645355
encoder.encoder.weight_ih_l0_reverse: 0.00202602194622159 0.08712144941091537
encoder.encoder.weight_hh_l0_reverse: 0.003556065959855914 0.08549334108829498
encoder.encoder.bias_ih_l0_reverse: 0.02966977469623089 0.0852542519569397
encoder.encoder.bias_hh_l0_reverse: 0.021535219624638557 0.08392630517482758
decider.lstm.weight_ih_l0: 6.57241398585029e-05 0.14857956767082214
decider.lstm.weight_hh_l0: -0.005148419179022312 0.14752019941806793
decider.lstm.bias_ih_l0: 0.02570149302482605 0.15511442720890045
decider.lstm.bias_hh_l0: 0.006714000832289457 0.14359381794929504
decider.linear1.weight: 0.0001516857009846717 0.1230020597577095
decider.linear1.bias: 0.017698416486382484 0.11569351702928543
decider.linear2.weight: 0.006434815935790539 0.05707086995244026
decider.linear2.bias: 0.00683995708823204 0.058283064514398575
decider.linear3.weight: -0.03301844373345375 0.08963257819414139
decider.linear3.bias: -0.02181483432650566 0.059584613889455795

Rewards:
190.8927
190.8927
190.8927
objective = 0.00010619556996971369
==== episode 1900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.673911123769358e-05 0.08486456423997879
encoder.encoder.weight_hh_l0: -0.001117747277021408 0.08792762458324432
encoder.encoder.bias_ih_l0: 0.014311685226857662 0.08670992404222488
encoder.encoder.bias_hh_l0: 0.024308767169713974 0.0861954614520073
encoder.encoder.weight_ih_l0_reverse: 0.0020267206709831953 0.08712413161993027
encoder.encoder.weight_hh_l0_reverse: 0.0035655684769153595 0.08550731092691422
encoder.encoder.bias_ih_l0_reverse: 0.02969437465071678 0.08524907380342484
encoder.encoder.bias_hh_l0_reverse: 0.021559834480285645 0.08391761034727097
decider.lstm.weight_ih_l0: 6.78540745866485e-05 0.14858871698379517
decider.lstm.weight_hh_l0: -0.005177699029445648 0.14754118025302887
decider.lstm.bias_ih_l0: 0.025717899203300476 0.1551225185394287
decider.lstm.bias_hh_l0: 0.006730468478053808 0.14358288049697876
decider.linear1.weight: 0.00013196154031902552 0.12305448949337006
decider.linear1.bias: 0.017740465700626373 0.11571002751588821
decider.linear2.weight: 0.00645381398499012 0.05711274594068527
decider.linear2.bias: 0.006846201606094837 0.05829054117202759
decider.linear3.weight: -0.033018797636032104 0.08963879942893982
decider.linear3.bias: -0.021814808249473572 0.0595865324139595

Rewards:
190.8927
190.8927
190.8927
objective = 9.102477633859962e-05
==== episode 2000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.7700458051403984e-05 0.08486644178628922
encoder.encoder.weight_hh_l0: -0.001119256834499538 0.08793886750936508
encoder.encoder.bias_ih_l0: 0.014326084405183792 0.08671236783266068
encoder.encoder.bias_hh_l0: 0.02432316169142723 0.08619476854801178
encoder.encoder.weight_ih_l0_reverse: 0.002027323003858328 0.08712656050920486
encoder.encoder.weight_hh_l0_reverse: 0.003574116388335824 0.08551999181509018
encoder.encoder.bias_ih_l0_reverse: 0.02971629984676838 0.0852445438504219
encoder.encoder.bias_hh_l0_reverse: 0.021581755951046944 0.08390995115041733
decider.lstm.weight_ih_l0: 6.976258009672165e-05 0.1485968679189682
decider.lstm.weight_hh_l0: -0.005203969776630402 0.14756043255329132
decider.lstm.bias_ih_l0: 0.025732314214110374 0.1551292985677719
decider.lstm.bias_hh_l0: 0.006744926329702139 0.14357338845729828
decider.linear1.weight: 0.00011400034418329597 0.12310358881950378
decider.linear1.bias: 0.017778703942894936 0.11572638154029846
decider.linear2.weight: 0.0064710876904428005 0.0571519210934639
decider.linear2.bias: 0.006851783487945795 0.058297257870435715
decider.linear3.weight: -0.03301909193396568 0.0896444320678711
decider.linear3.bias: -0.021814808249473572 0.059588272124528885

Rewards:
190.8927
190.8927
190.8927
objective = 7.585396815557033e-05
==== episode 2100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.8564092392334715e-05 0.08486813306808472
encoder.encoder.weight_hh_l0: -0.001120596774853766 0.08794897049665451
encoder.encoder.bias_ih_l0: 0.01433894969522953 0.08671458810567856
encoder.encoder.bias_hh_l0: 0.024336015805602074 0.08619417995214462
encoder.encoder.weight_ih_l0_reverse: 0.0020278445445001125 0.08712876588106155
encoder.encoder.weight_hh_l0_reverse: 0.0035817939788103104 0.08553145825862885
encoder.encoder.bias_ih_l0_reverse: 0.02973584644496441 0.08524056524038315
encoder.encoder.bias_hh_l0_reverse: 0.021601304411888123 0.0839032456278801
decider.lstm.weight_ih_l0: 7.14724519639276e-05 0.1486041098833084
decider.lstm.weight_hh_l0: -0.005227560643106699 0.14757800102233887
decider.lstm.bias_ih_l0: 0.0257449708878994 0.155134916305542
decider.lstm.bias_hh_l0: 0.006757658906280994 0.14356520771980286
decider.linear1.weight: 9.766246512299404e-05 0.12314940243959427
decider.linear1.bias: 0.017813431099057198 0.11574231833219528
decider.linear2.weight: 0.006486835423856974 0.0571884885430336
decider.linear2.bias: 0.006856797728687525 0.05830333009362221
decider.linear3.weight: -0.03301933407783508 0.08964953571557999
decider.linear3.bias: -0.02181488275527954 0.059589873999357224

Rewards:
190.8927
190.8927
190.8927
objective = 6.82685713400133e-05
==== episode 2200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.9352999010588974e-05 0.08486966788768768
encoder.encoder.weight_hh_l0: -0.0011218126164749265 0.08795824646949768
encoder.encoder.bias_ih_l0: 0.01435065921396017 0.0867166593670845
encoder.encoder.bias_hh_l0: 0.024347718805074692 0.08619368821382523
encoder.encoder.weight_ih_l0_reverse: 0.0020283160265535116 0.08713078498840332
encoder.encoder.weight_hh_l0_reverse: 0.0035888217389583588 0.08554201573133469
encoder.encoder.bias_ih_l0_reverse: 0.02975361794233322 0.08523701131343842
encoder.encoder.bias_hh_l0_reverse: 0.021619081497192383 0.08389724791049957
decider.lstm.weight_ih_l0: 7.302637823158875e-05 0.14861071109771729
decider.lstm.weight_hh_l0: -0.005249151028692722 0.14759434759616852
decider.lstm.bias_ih_l0: 0.02575632743537426 0.1551397740840912
decider.lstm.bias_hh_l0: 0.006769041530787945 0.14355787634849548
decider.linear1.weight: 8.254090789705515e-05 0.12319283932447433
decider.linear1.bias: 0.017845597118139267 0.1157580316066742
decider.linear2.weight: 0.006501371040940285 0.057223137468099594
decider.linear2.bias: 0.006861385889351368 0.058308906853199005
decider.linear3.weight: -0.0330195352435112 0.08965423703193665
decider.linear3.bias: -0.021814852952957153 0.05959128215909004

Rewards:
190.8927
190.8927
190.8927
objective = 6.0683170886477455e-05
==== episode 2300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.007946699857712e-05 0.0848710909485817
encoder.encoder.weight_hh_l0: -0.00112292286939919 0.08796680718660355
encoder.encoder.bias_ih_l0: 0.014361436478793621 0.08671858161687851
encoder.encoder.bias_hh_l0: 0.024358469992876053 0.08619321137666702
encoder.encoder.weight_ih_l0_reverse: 0.002028742339462042 0.08713264763355255
encoder.encoder.weight_hh_l0_reverse: 0.0035952895414084196 0.08555179834365845
encoder.encoder.bias_ih_l0_reverse: 0.029769903048872948 0.08523377031087875
encoder.encoder.bias_hh_l0_reverse: 0.021635377779603004 0.08389182388782501
decider.lstm.weight_ih_l0: 7.44575954740867e-05 0.1486167311668396
decider.lstm.weight_hh_l0: -0.005269049666821957 0.1476096212863922
decider.lstm.bias_ih_l0: 0.02576657384634018 0.15514396131038666
decider.lstm.bias_hh_l0: 0.0067793140187859535 0.1435513198375702
decider.linear1.weight: 6.84545811964199e-05 0.12323418259620667
decider.linear1.bias: 0.017875565215945244 0.11577345430850983
decider.linear2.weight: 0.006514324806630611 0.05725562572479248
decider.linear2.bias: 0.006864616647362709 0.0583142451941967
decider.linear3.weight: -0.03301971033215523 0.08965861052274704
decider.linear3.bias: -0.02181481197476387 0.059592511504888535

Rewards:
190.8927
190.8927
190.8927
objective = 5.3097770432941616e-05
==== episode 2400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.075400283909403e-05 0.08487238734960556
encoder.encoder.weight_hh_l0: -0.0011239455780014396 0.08797476440668106
encoder.encoder.bias_ih_l0: 0.014371411874890327 0.08672039210796356
encoder.encoder.bias_hh_l0: 0.024368416517972946 0.08619280904531479
encoder.encoder.weight_ih_l0_reverse: 0.00202912837266922 0.08713439851999283
encoder.encoder.weight_hh_l0_reverse: 0.0036012763157486916 0.08556089550256729
encoder.encoder.bias_ih_l0_reverse: 0.029784921556711197 0.08523084223270416
encoder.encoder.bias_hh_l0_reverse: 0.021650400012731552 0.08388687670230865
decider.lstm.weight_ih_l0: 7.577776705147699e-05 0.1486223042011261
decider.lstm.weight_hh_l0: -0.005287510342895985 0.14762398600578308
decider.lstm.bias_ih_l0: 0.025775985792279243 0.15514765679836273
decider.lstm.bias_hh_l0: 0.006788686383515596 0.14354541897773743
decider.linear1.weight: 5.526190943783149e-05 0.12327372282743454
decider.linear1.bias: 0.017903674393892288 0.11578860878944397
decider.linear2.weight: 0.00652696518227458 0.05728648975491524
decider.linear2.bias: 0.0068681975826621056 0.05831911787390709
decider.linear3.weight: -0.033019863069057465 0.08966270089149475
decider.linear3.bias: -0.02181481197476387 0.05959366634488106

Rewards:
190.8927
190.8927
190.8927
objective = 5.3097770432941616e-05
==== episode 2500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.138376607443206e-05 0.08487360179424286
encoder.encoder.weight_hh_l0: -0.0011248902883380651 0.0879821926355362
encoder.encoder.bias_ih_l0: 0.014380689710378647 0.08672207593917847
encoder.encoder.bias_hh_l0: 0.02437767945230007 0.08619245886802673
encoder.encoder.weight_ih_l0_reverse: 0.0020294843707233667 0.08713603764772415
encoder.encoder.weight_hh_l0_reverse: 0.0036068472545593977 0.08556940406560898
encoder.encoder.bias_ih_l0_reverse: 0.029798856005072594 0.08522818237543106
encoder.encoder.bias_hh_l0_reverse: 0.0216643325984478 0.08388236910104752
decider.lstm.weight_ih_l0: 7.700431888224557e-05 0.14862744510173798
decider.lstm.weight_hh_l0: -0.005304734222590923 0.1476375311613083
decider.lstm.bias_ih_l0: 0.025784635916352272 0.155150905251503
decider.lstm.bias_hh_l0: 0.006797314155846834 0.14354003965854645
decider.linear1.weight: 4.2850017052842304e-05 0.12331162393093109
decider.linear1.bias: 0.01793011650443077 0.11580348014831543
decider.linear2.weight: 0.006539149675518274 0.05731609836220741
decider.linear2.bias: 0.0068718502297997475 0.05832361429929733
decider.linear3.weight: -0.03301998972892761 0.08966654539108276
decider.linear3.bias: -0.02181481197476387 0.05959482863545418

Rewards:
190.8927
190.8927
190.8927
objective = 4.551237361738458e-05
==== episode 2600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.196651207166724e-05 0.084874726831913
encoder.encoder.weight_hh_l0: -0.0011257622390985489 0.08798910677433014
encoder.encoder.bias_ih_l0: 0.01438926812261343 0.08672366291284561
encoder.encoder.bias_hh_l0: 0.024386253207921982 0.08619214594364166
encoder.encoder.weight_ih_l0_reverse: 0.0020298126619309187 0.08713756501674652
encoder.encoder.weight_hh_l0_reverse: 0.003612005617469549 0.08557731658220291
encoder.encoder.bias_ih_l0_reverse: 0.029811734333634377 0.08522574603557587
encoder.encoder.bias_hh_l0_reverse: 0.021677197888493538 0.08387824147939682
decider.lstm.weight_ih_l0: 7.814183481968939e-05 0.1486321985721588
decider.lstm.weight_hh_l0: -0.005320725962519646 0.14765021204948425
decider.lstm.bias_ih_l0: 0.025792574509978294 0.15515387058258057
decider.lstm.bias_hh_l0: 0.0068052117712795734 0.14353513717651367
decider.linear1.weight: 3.12389456667006e-05 0.12334772944450378
decider.linear1.bias: 0.017954910174012184 0.11581803858280182
decider.linear2.weight: 0.0065505350939929485 0.05734430253505707
decider.linear2.bias: 0.006875237450003624 0.058327801525592804
decider.linear3.weight: -0.033020105212926865 0.08967012912034988
decider.linear3.bias: -0.021814832463860512 0.05959595367312431

Rewards:
190.8927
190.8927
190.8927
objective = 4.551237361738458e-05
==== episode 2700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.251301288604736e-05 0.08487579226493835
encoder.encoder.weight_hh_l0: -0.001126580173149705 0.08799563348293304
encoder.encoder.bias_ih_l0: 0.014397320337593555 0.08672516793012619
encoder.encoder.bias_hh_l0: 0.024394307285547256 0.08619189262390137
encoder.encoder.weight_ih_l0_reverse: 0.002030115807428956 0.08713901042938232
encoder.encoder.weight_hh_l0_reverse: 0.003616851754486561 0.08558476716279984
encoder.encoder.bias_ih_l0_reverse: 0.02982378378510475 0.08522346615791321
encoder.encoder.bias_hh_l0_reverse: 0.02168925292789936 0.08387441188097
decider.lstm.weight_ih_l0: 7.92122955317609e-05 0.14863665401935577
decider.lstm.weight_hh_l0: -0.005335807800292969 0.14766229689121246
decider.lstm.bias_ih_l0: 0.02579992264509201 0.15515655279159546
decider.lstm.bias_hh_l0: 0.00681254081428051 0.1435307115316391
decider.linear1.weight: 2.0221923477947712e-05 0.12338259071111679
decider.linear1.bias: 0.017978481948375702 0.11583239585161209
decider.linear2.weight: 0.0065606459975242615 0.057371579110622406
decider.linear2.bias: 0.006877494044601917 0.0583319328725338
decider.linear3.weight: -0.03302020579576492 0.08967352658510208
decider.linear3.bias: -0.021814925596117973 0.059596944600343704

Rewards:
190.8927
190.8927
190.8927
objective = 3.792697680182755e-05
==== episode 2800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.303600508137606e-05 0.08487679064273834
encoder.encoder.weight_hh_l0: -0.0011273487471044064 0.08800181746482849
encoder.encoder.bias_ih_l0: 0.014404899440705776 0.08672655373811722
encoder.encoder.bias_hh_l0: 0.02440187893807888 0.08619165420532227
encoder.encoder.weight_ih_l0_reverse: 0.002030398463830352 0.08714038878679276
encoder.encoder.weight_hh_l0_reverse: 0.0036214212886989117 0.08559183031320572
encoder.encoder.bias_ih_l0_reverse: 0.029835134744644165 0.08522135764360428
encoder.encoder.bias_hh_l0_reverse: 0.021700603887438774 0.08387084305286407
decider.lstm.weight_ih_l0: 8.022457041079178e-05 0.14864082634449005
decider.lstm.weight_hh_l0: -0.005350066814571619 0.14767378568649292
decider.lstm.bias_ih_l0: 0.02580682560801506 0.15515896677970886
decider.lstm.bias_hh_l0: 0.0068193962797522545 0.14352664351463318
decider.linear1.weight: 9.730225428938866e-06 0.12341631203889847
decider.linear1.bias: 0.018000967800617218 0.11584652960300446
decider.linear2.weight: 0.00657089427113533 0.05739795044064522
decider.linear2.bias: 0.006880450062453747 0.05833571031689644
decider.linear3.weight: -0.033020298928022385 0.08967676758766174
decider.linear3.bias: -0.021815018728375435 0.059597935527563095

Rewards:
190.8927
190.8927
190.8927
objective = 3.792697680182755e-05
==== episode 2900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.3532920244615525e-05 0.08487775176763535
encoder.encoder.weight_hh_l0: -0.0011280731996521354 0.08800770342350006
encoder.encoder.bias_ih_l0: 0.014412078075110912 0.08672790974378586
encoder.encoder.bias_hh_l0: 0.02440905198454857 0.08619143813848495
encoder.encoder.weight_ih_l0_reverse: 0.0020306638907641172 0.08714170008897781
encoder.encoder.weight_hh_l0_reverse: 0.0036257437895983458 0.08559852838516235
encoder.encoder.bias_ih_l0_reverse: 0.029845843091607094 0.0852193757891655
encoder.encoder.bias_hh_l0_reverse: 0.021711310371756554 0.08386750519275665
decider.lstm.weight_ih_l0: 8.1182639405597e-05 0.14864477515220642
decider.lstm.weight_hh_l0: -0.005363611038774252 0.14768481254577637
decider.lstm.bias_ih_l0: 0.02581329457461834 0.15516114234924316
decider.lstm.bias_hh_l0: 0.006825833581387997 0.14352284371852875
decider.linear1.weight: -2.867891453206539e-07 0.12344901263713837
decider.linear1.bias: 0.018022477626800537 0.1158604696393013
decider.linear2.weight: 0.006580742541700602 0.057423509657382965
decider.linear2.bias: 0.00688332412391901 0.05833929404616356
decider.linear3.weight: -0.03302037715911865 0.08967986702919006
decider.linear3.bias: -0.02181505225598812 0.05959885194897652

Rewards:
190.8927
190.8927
190.8927
objective = 3.4134278394049034e-05
==== episode 3000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.399970202939585e-05 0.08487863838672638
encoder.encoder.weight_hh_l0: -0.0011287500383332372 0.08801323175430298
encoder.encoder.bias_ih_l0: 0.014418823644518852 0.08672917634248734
encoder.encoder.bias_hh_l0: 0.024415787309408188 0.08619124442338943
encoder.encoder.weight_ih_l0_reverse: 0.002030908362939954 0.0871429294347763
encoder.encoder.weight_hh_l0_reverse: 0.0036297934129834175 0.08560481667518616
encoder.encoder.bias_ih_l0_reverse: 0.02985585667192936 0.08521753549575806
encoder.encoder.bias_hh_l0_reverse: 0.02172134257853031 0.08386441320180893
decider.lstm.weight_ih_l0: 8.207879727706313e-05 0.1486484855413437
decider.lstm.weight_hh_l0: -0.005376328714191914 0.14769522845745087
decider.lstm.bias_ih_l0: 0.025819333270192146 0.15516310930252075
decider.lstm.bias_hh_l0: 0.006831813137978315 0.1435192972421646
decider.linear1.weight: -9.757874067872763e-06 0.12348039448261261
decider.linear1.bias: 0.018042858690023422 0.1158740445971489
decider.linear2.weight: 0.006696851458400488 0.05744488537311554
decider.linear2.bias: 0.007057130336761475 0.058512214571237564
decider.linear3.weight: -0.03302065655589104 0.0897233635187149
decider.linear3.bias: -0.02181495912373066 0.05959959328174591

Rewards:
190.8927
190.8927
190.8927
objective = 3.0341578167281114e-05
==== episode 3100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4323951442493126e-05 0.08487926423549652
encoder.encoder.weight_hh_l0: -0.0011292225681245327 0.08801712095737457
encoder.encoder.bias_ih_l0: 0.014423547312617302 0.08673007786273956
encoder.encoder.bias_hh_l0: 0.024420512840151787 0.08619111031293869
encoder.encoder.weight_ih_l0_reverse: 0.0020310834515839815 0.08714379370212555
encoder.encoder.weight_hh_l0_reverse: 0.0036326213739812374 0.08560921996831894
encoder.encoder.bias_ih_l0_reverse: 0.029862865805625916 0.08521629869937897
encoder.encoder.bias_hh_l0_reverse: 0.021728338673710823 0.08386228233575821
decider.lstm.weight_ih_l0: 8.27019612188451e-05 0.14865106344223022
decider.lstm.weight_hh_l0: -0.005385235417634249 0.14770257472991943
decider.lstm.bias_ih_l0: 0.025823503732681274 0.15516448020935059
decider.lstm.bias_hh_l0: 0.006836018059402704 0.14351674914360046
decider.linear1.weight: -1.652707578614354e-05 0.1235026940703392
decider.linear1.bias: 0.018057232722640038 0.11588379740715027
decider.linear2.weight: 0.006881657987833023 0.05754007771611214
decider.linear2.bias: 0.00733342207968235 0.058919355273246765
decider.linear3.weight: -0.033022668212652206 0.08985961973667145
decider.linear3.bias: -0.021814964711666107 0.05960015952587128

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.450667620403692e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129491487517953 0.08801933377981186
encoder.encoder.bias_ih_l0: 0.014426237903535366 0.08673056960105896
encoder.encoder.bias_hh_l0: 0.02442321553826332 0.08619102835655212
encoder.encoder.weight_ih_l0_reverse: 0.0020311791449785233 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.003634230699390173 0.0856117233633995
encoder.encoder.bias_ih_l0_reverse: 0.029866835102438927 0.08521557599306107
encoder.encoder.bias_hh_l0_reverse: 0.021732309833168983 0.0838610827922821
decider.lstm.weight_ih_l0: 8.305296069011092e-05 0.14865250885486603
decider.lstm.weight_hh_l0: -0.005390333943068981 0.1477067619562149
decider.lstm.bias_ih_l0: 0.025825785472989082 0.1551651805639267
decider.lstm.bias_hh_l0: 0.006838388275355101 0.14351531863212585
decider.linear1.weight: -2.0511875845841132e-05 0.12351545691490173
decider.linear1.bias: 0.01806538552045822 0.11588940024375916
decider.linear2.weight: 0.006982041522860527 0.05763569101691246
decider.linear2.bias: 0.007481780834496021 0.05920367315411568
decider.linear3.weight: -0.033024802803993225 0.08996286243200302
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 10000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.4508946302812546e-05 0.08487961441278458
encoder.encoder.weight_hh_l0: -0.001129495445638895 0.08801937103271484
encoder.encoder.bias_ih_l0: 0.01442627515643835 0.08673058450222015
encoder.encoder.bias_hh_l0: 0.024423250928521156 0.08619102090597153
encoder.encoder.weight_ih_l0_reverse: 0.0020311803091317415 0.08714430034160614
encoder.encoder.weight_hh_l0_reverse: 0.0036342565435916185 0.08561176061630249
encoder.encoder.bias_ih_l0_reverse: 0.029866892844438553 0.08521555364131927
encoder.encoder.bias_hh_l0_reverse: 0.02173236757516861 0.08386106044054031
decider.lstm.weight_ih_l0: 8.305858500534669e-05 0.14865252375602722
decider.lstm.weight_hh_l0: -0.005390417296439409 0.14770683646202087
decider.lstm.bias_ih_l0: 0.02582581713795662 0.1551651954650879
decider.lstm.bias_hh_l0: 0.00683841947466135 0.14351528882980347
decider.linear1.weight: -2.0578601834131405e-05 0.12351565808057785
decider.linear1.bias: 0.018065517768263817 0.11588948965072632
decider.linear2.weight: 0.006983745843172073 0.05763758346438408
decider.linear2.bias: 0.007484296336770058 0.05920889228582382
decider.linear3.weight: -0.03302484378218651 0.08996479213237762
decider.linear3.bias: -0.02181502804160118 0.059600502252578735

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
[INFO] : learning runtime (h:mm:ss): 0:02:32
[INFO] : learning end time: 12/17/2023 12:29:10 PM
