Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 03:10:22 PM
==== episode 1/10000 ====
action = 0
probs = 0.3033 0.6902 0.0024 0.0042

action = 0
probs = 0.3394 0.6597 0.0004 0.0005

action = 0
probs = 0.9261 0.0738 0.0001 0.0001

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00011593281669775024 0.08513031154870987
encoder.encoder.weight_hh_l0: -4.2495248635532334e-06 0.08702043443918228
encoder.encoder.bias_ih_l0: 0.013099625706672668 0.08853849768638611
encoder.encoder.bias_hh_l0: 0.023096704855561256 0.08665407449007034
encoder.encoder.weight_ih_l0_reverse: 0.0017385836690664291 0.08759177476167679
encoder.encoder.weight_hh_l0_reverse: 0.008568456396460533 0.08697551488876343
encoder.encoder.bias_ih_l0_reverse: 0.03424310311675072 0.08543726056814194
encoder.encoder.bias_hh_l0_reverse: 0.02610868401825428 0.08291465044021606
decider.lstm.weight_ih_l0: 0.0015342715196311474 0.14825068414211273
decider.lstm.weight_hh_l0: 0.002953602932393551 0.1479690819978714
decider.lstm.bias_ih_l0: 0.02269521728157997 0.1588483303785324
decider.lstm.bias_hh_l0: 0.0037077399902045727 0.14088194072246552
decider.linear1.weight: 0.004472303669899702 0.1214207336306572
decider.linear1.bias: 0.01926345005631447 0.11750095337629318
decider.linear2.weight: 0.005317486822605133 0.053652629256248474
decider.linear2.bias: 0.008689959533512592 0.05725189298391342
decider.linear3.weight: -0.01041199080646038 0.06001835688948631
decider.linear3.bias: 0.011718419380486012 0.05202840641140938

Rewards:
211.9920
211.9920
211.9920
objective = 166.09933471679688
==== episode 100/10000 ====
action = 0
probs = 0.4049 0.5921 0.0011 0.0019

action = 0
probs = 0.4537 0.5460 0.0002 0.0002

action = 0
probs = 0.9635 0.0364 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001054044405464083 0.08518513292074203
encoder.encoder.weight_hh_l0: -3.7809013520018198e-06 0.08709415793418884
encoder.encoder.bias_ih_l0: 0.013256648555397987 0.08863488584756851
encoder.encoder.bias_hh_l0: 0.023253725841641426 0.0866842120885849
encoder.encoder.weight_ih_l0_reverse: 0.001720528001897037 0.08763246983289719
encoder.encoder.weight_hh_l0_reverse: 0.00860617496073246 0.08698700368404388
encoder.encoder.bias_ih_l0_reverse: 0.03431246057152748 0.0854986235499382
encoder.encoder.bias_hh_l0_reverse: 0.026178045198321342 0.08285447210073471
decider.lstm.weight_ih_l0: 0.0015596122248098254 0.14832225441932678
decider.lstm.weight_hh_l0: 0.0029722037725150585 0.14800433814525604
decider.lstm.bias_ih_l0: 0.022847766056656837 0.15886296331882477
decider.lstm.bias_hh_l0: 0.003860275726765394 0.14110836386680603
decider.linear1.weight: 0.004468511790037155 0.12145591527223587
decider.linear1.bias: 0.019453417509794235 0.11754781007766724
decider.linear2.weight: 0.005446811206638813 0.053709954023361206
decider.linear2.bias: 0.008856037631630898 0.05732579529285431
decider.linear3.weight: -0.013525845482945442 0.061484433710575104
decider.linear3.bias: 0.007543083280324936 0.04949972778558731

Rewards:
211.9920
211.9920
211.9920
objective = 122.36177825927734
==== episode 200/10000 ====
action = 1
probs = 0.3275 0.6709 0.0006 0.0010

action = 1
probs = 0.4381 0.5617 0.0001 0.0001

action = 0
probs = 0.9771 0.0229 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00013658702664542943 0.08533350378274918
encoder.encoder.weight_hh_l0: -6.762790690117981e-06 0.08726560324430466
encoder.encoder.bias_ih_l0: 0.013758784160017967 0.08885105699300766
encoder.encoder.bias_hh_l0: 0.023755865171551704 0.08686845749616623
encoder.encoder.weight_ih_l0_reverse: 0.0017402606317773461 0.08782856911420822
encoder.encoder.weight_hh_l0_reverse: 0.00873703882098198 0.08710706233978271
encoder.encoder.bias_ih_l0_reverse: 0.03472431004047394 0.08559602499008179
encoder.encoder.bias_hh_l0_reverse: 0.0265898909419775 0.08289571106433868
decider.lstm.weight_ih_l0: 0.0016878850292414427 0.1484682559967041
decider.lstm.weight_hh_l0: 0.0030555156990885735 0.14808574318885803
decider.lstm.bias_ih_l0: 0.023481067270040512 0.1588829755783081
decider.lstm.bias_hh_l0: 0.004493568558245897 0.14103594422340393
decider.linear1.weight: 0.004471304826438427 0.12153086066246033
decider.linear1.bias: 0.019796786829829216 0.11764451116323471
decider.linear2.weight: 0.005564982071518898 0.05380053073167801
decider.linear2.bias: 0.008915670216083527 0.057381853461265564
decider.linear3.weight: -0.015461591072380543 0.06267941743135452
decider.linear3.bias: 0.004787025973200798 0.04849175363779068

Rewards:
230.1930
230.1930
230.1930
objective = 76.65939331054688
==== episode 300/10000 ====
action = 1
probs = 0.3319 0.6671 0.0004 0.0006

action = 0
probs = 0.6662 0.3337 0.0000 0.0000

action = 0
probs = 0.9917 0.0083 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00017206939810421318 0.0855121836066246
encoder.encoder.weight_hh_l0: -2.1875595848541707e-05 0.08749059587717056
encoder.encoder.bias_ih_l0: 0.01441030204296112 0.0891050174832344
encoder.encoder.bias_hh_l0: 0.024407386779785156 0.08706610649824142
encoder.encoder.weight_ih_l0_reverse: 0.0017520674737170339 0.08801165223121643
encoder.encoder.weight_hh_l0_reverse: 0.00882104504853487 0.08719167113304138
encoder.encoder.bias_ih_l0_reverse: 0.03505946695804596 0.08573462814092636
encoder.encoder.bias_hh_l0_reverse: 0.026925044134259224 0.08279754221439362
decider.lstm.weight_ih_l0: 0.0017795725725591183 0.148604154586792
decider.lstm.weight_hh_l0: 0.003121011657640338 0.14816828072071075
decider.lstm.bias_ih_l0: 0.023982681334018707 0.15888090431690216
decider.lstm.bias_hh_l0: 0.004995184019207954 0.14103662967681885
decider.linear1.weight: 0.004454006440937519 0.12160015851259232
decider.linear1.bias: 0.020174473524093628 0.11770503968000412
decider.linear2.weight: 0.0056544942781329155 0.05387011915445328
decider.linear2.bias: 0.009059623815119267 0.05744921788573265
decider.linear3.weight: -0.016790729016065598 0.06357575953006744
decider.linear3.bias: 0.0028748856857419014 0.04746124520897865

Rewards:
221.7540
221.7540
221.7540
objective = 60.55632781982422
==== episode 400/10000 ====
action = 0
probs = 0.1863 0.8131 0.0002 0.0004

action = 0
probs = 0.6465 0.3535 0.0000 0.0000

action = 0
probs = 0.9891 0.0109 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00021102286700624973 0.08553846925497055
encoder.encoder.weight_hh_l0: -1.86867946467828e-05 0.08749062567949295
encoder.encoder.bias_ih_l0: 0.014464538544416428 0.08910918980836868
encoder.encoder.bias_hh_l0: 0.024461621418595314 0.0870819240808487
encoder.encoder.weight_ih_l0_reverse: 0.0018115043640136719 0.08807633817195892
encoder.encoder.weight_hh_l0_reverse: 0.008944579400122166 0.08731681108474731
encoder.encoder.bias_ih_l0_reverse: 0.035336561501026154 0.08576996624469757
encoder.encoder.bias_hh_l0_reverse: 0.027202140539884567 0.08287475258111954
decider.lstm.weight_ih_l0: 0.0017947811866179109 0.14860408008098602
decider.lstm.weight_hh_l0: 0.003127081086859107 0.14818093180656433
decider.lstm.bias_ih_l0: 0.024003630504012108 0.15882965922355652
decider.lstm.bias_hh_l0: 0.005016142502427101 0.1407855600118637
decider.linear1.weight: 0.004442567005753517 0.12159973382949829
decider.linear1.bias: 0.020149802789092064 0.11764778941869736
decider.linear2.weight: 0.0055144852958619595 0.05385744199156761
decider.linear2.bias: 0.008901051245629787 0.05746696516871452
decider.linear3.weight: -0.01778886280953884 0.0642341822385788
decider.linear3.bias: 0.001446520909667015 0.04786155745387077

Rewards:
211.9920
211.9920
211.9920
objective = 150.33872985839844
==== episode 500/10000 ====
action = 1
probs = 0.1300 0.8696 0.0002 0.0003

action = 0
probs = 0.4454 0.5545 0.0000 0.0000

action = 0
probs = 0.9826 0.0174 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002308165276190266 0.08557330816984177
encoder.encoder.weight_hh_l0: -1.74322249222314e-05 0.08751903474330902
encoder.encoder.bias_ih_l0: 0.014549896121025085 0.08912376314401627
encoder.encoder.bias_hh_l0: 0.02454698458313942 0.08713026344776154
encoder.encoder.weight_ih_l0_reverse: 0.0018300601514056325 0.08812976628541946
encoder.encoder.weight_hh_l0_reverse: 0.008979742415249348 0.08736041933298111
encoder.encoder.bias_ih_l0_reverse: 0.03549141809344292 0.08578746020793915
encoder.encoder.bias_hh_l0_reverse: 0.027356991544365883 0.0829092413187027
decider.lstm.weight_ih_l0: 0.001825064653530717 0.14863097667694092
decider.lstm.weight_hh_l0: 0.003144766902551055 0.14820526540279388
decider.lstm.bias_ih_l0: 0.02412515878677368 0.15888573229312897
decider.lstm.bias_hh_l0: 0.005137670319527388 0.14072832465171814
decider.linear1.weight: 0.004439788870513439 0.12162597477436066
decider.linear1.bias: 0.020236050710082054 0.1176413744688034
decider.linear2.weight: 0.0055236476473510265 0.053870003670454025
decider.linear2.bias: 0.008855100721120834 0.057498086243867874
decider.linear3.weight: -0.018572617322206497 0.06481266021728516
decider.linear3.bias: 0.00036218203604221344 0.048019733279943466

Rewards:
221.7540
221.7540
221.7540
objective = 71.40512084960938
==== episode 600/10000 ====
action = 1
probs = 0.0809 0.9188 0.0001 0.0002

action = 0
probs = 0.2954 0.7046 0.0000 0.0000

action = 1
probs = 0.9767 0.0233 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002450565225444734 0.08561024069786072
encoder.encoder.weight_hh_l0: -1.5316461940528825e-05 0.08754716068506241
encoder.encoder.bias_ih_l0: 0.014605228789150715 0.08913236111402512
encoder.encoder.bias_hh_l0: 0.024602318182587624 0.08717868477106094
encoder.encoder.weight_ih_l0_reverse: 0.001850701286457479 0.08817951381206512
encoder.encoder.weight_hh_l0_reverse: 0.009024920873343945 0.08741728961467743
encoder.encoder.bias_ih_l0_reverse: 0.035655371844768524 0.08579026162624359
encoder.encoder.bias_hh_l0_reverse: 0.02752094157040119 0.0829659029841423
decider.lstm.weight_ih_l0: 0.00186597288120538 0.14866530895233154
decider.lstm.weight_hh_l0: 0.0031700781546533108 0.14822949469089508
decider.lstm.bias_ih_l0: 0.0242876298725605 0.15897169709205627
decider.lstm.bias_hh_l0: 0.005300145596265793 0.14070634543895721
decider.linear1.weight: 0.004438336938619614 0.12165532261133194
decider.linear1.bias: 0.02033255621790886 0.11761824041604996
decider.linear2.weight: 0.00550170848146081 0.05388028547167778
decider.linear2.bias: 0.00879076961427927 0.057548701763153076
decider.linear3.weight: -0.019176289439201355 0.06527310609817505
decider.linear3.bias: -0.0004574996419250965 0.048433609306812286

Rewards:
229.4037
229.4037
229.4037
objective = 387.04656982421875
==== episode 700/10000 ====
action = 1
probs = 0.0617 0.9381 0.0001 0.0001

action = 0
probs = 0.2227 0.7773 0.0000 0.0000

action = 0
probs = 0.9642 0.0358 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002510457707103342 0.08562824875116348
encoder.encoder.weight_hh_l0: -1.241146310348995e-05 0.08755804598331451
encoder.encoder.bias_ih_l0: 0.01460343785583973 0.08913321048021317
encoder.encoder.bias_hh_l0: 0.024600524455308914 0.08720642328262329
encoder.encoder.weight_ih_l0_reverse: 0.001856198301538825 0.0881858766078949
encoder.encoder.weight_hh_l0_reverse: 0.00906353909522295 0.08745832741260529
encoder.encoder.bias_ih_l0_reverse: 0.0357433520257473 0.08579026907682419
encoder.encoder.bias_hh_l0_reverse: 0.02760891802608967 0.08299525082111359
decider.lstm.weight_ih_l0: 0.001884905039332807 0.14868462085723877
decider.lstm.weight_hh_l0: 0.003180634928867221 0.1482492983341217
decider.lstm.bias_ih_l0: 0.024353211745619774 0.1590403914451599
decider.lstm.bias_hh_l0: 0.005365723744034767 0.14069567620754242
decider.linear1.weight: 0.004434484522789717 0.12165689468383789
decider.linear1.bias: 0.020314887166023254 0.11761228740215302
decider.linear2.weight: 0.005438871216028929 0.053876377642154694
decider.linear2.bias: 0.008724993094801903 0.057548705488443375
decider.linear3.weight: -0.01965431123971939 0.06561005860567093
decider.linear3.bias: -0.0010999876540154219 0.048661090433597565

Rewards:
221.7540
221.7540
221.7540
objective = 118.43865966796875
==== episode 800/10000 ====
action = 1
probs = 0.0497 0.9502 0.0001 0.0001

action = 1
probs = 0.1338 0.8661 0.0000 0.0000

action = 0
probs = 0.8349 0.1651 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002536191313993186 0.08553077280521393
encoder.encoder.weight_hh_l0: -8.582818736613262e-06 0.08740638941526413
encoder.encoder.bias_ih_l0: 0.014263498596847057 0.08894222229719162
encoder.encoder.bias_hh_l0: 0.02426058240234852 0.08709414303302765
encoder.encoder.weight_ih_l0_reverse: 0.0018618667963892221 0.08806146681308746
encoder.encoder.weight_hh_l0_reverse: 0.00909458752721548 0.08746882528066635
encoder.encoder.bias_ih_l0_reverse: 0.035721305757761 0.08569562435150146
encoder.encoder.bias_hh_l0_reverse: 0.027586879208683968 0.08301909267902374
decider.lstm.weight_ih_l0: 0.0018001541029661894 0.14857442677021027
decider.lstm.weight_hh_l0: 0.003113755490630865 0.14817307889461517
decider.lstm.bias_ih_l0: 0.023886099457740784 0.15907111763954163
decider.lstm.bias_hh_l0: 0.0048986198380589485 0.14054489135742188
decider.linear1.weight: 0.004429147578775883 0.12158682942390442
decider.linear1.bias: 0.01995808258652687 0.11754520237445831
decider.linear2.weight: 0.005250450223684311 0.053791966289281845
decider.linear2.bias: 0.008533773012459278 0.057549990713596344
decider.linear3.weight: -0.02007531374692917 0.06578788161277771
decider.linear3.bias: -0.001656966283917427 0.049177464097738266

Rewards:
230.1930
230.1930
230.1930
objective = 28.791976928710938
==== episode 900/10000 ====
action = 1
probs = 0.0375 0.9624 0.0000 0.0001

action = 1
probs = 0.1239 0.8761 0.0000 0.0000

action = 0
probs = 0.9216 0.0784 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002630910312291235 0.08565401285886765
encoder.encoder.weight_hh_l0: -5.441761004476575e-06 0.08757776021957397
encoder.encoder.bias_ih_l0: 0.014583750627934933 0.08917329460382462
encoder.encoder.bias_hh_l0: 0.024580836296081543 0.08728519827127457
encoder.encoder.weight_ih_l0_reverse: 0.0018683081725612283 0.08821049332618713
encoder.encoder.weight_hh_l0_reverse: 0.009157788008451462 0.0875612124800682
encoder.encoder.bias_ih_l0_reverse: 0.0359342098236084 0.08582152426242828
encoder.encoder.bias_hh_l0_reverse: 0.027799779549241066 0.08308415114879608
decider.lstm.weight_ih_l0: 0.0019387768115848303 0.14874739944934845
decider.lstm.weight_hh_l0: 0.0032069799490273 0.14830556511878967
decider.lstm.bias_ih_l0: 0.024551257491111755 0.15915757417678833
decider.lstm.bias_hh_l0: 0.005563776940107346 0.14074493944644928
decider.linear1.weight: 0.004425840452313423 0.12166038155555725
decider.linear1.bias: 0.02026321180164814 0.11755441874265671
decider.linear2.weight: 0.005343342665582895 0.05385871231555939
decider.linear2.bias: 0.008655378594994545 0.05756915733218193
decider.linear3.weight: -0.02044454589486122 0.06618223339319229
decider.linear3.bias: -0.002098729368299246 0.049116846174001694

Rewards:
230.1930
230.1930
230.1930
objective = 19.357770919799805
==== episode 1000/10000 ====
action = 1
probs = 0.0365 0.9634 0.0000 0.0001

action = 1
probs = 0.1141 0.8859 0.0000 0.0000

action = 1
probs = 0.9150 0.0850 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002534830418881029 0.08564917743206024
encoder.encoder.weight_hh_l0: -5.984365998301655e-06 0.08757103979587555
encoder.encoder.bias_ih_l0: 0.014530820772051811 0.08914494514465332
encoder.encoder.bias_hh_l0: 0.024527907371520996 0.08729531615972519
encoder.encoder.weight_ih_l0_reverse: 0.001855222973972559 0.08819496631622314
encoder.encoder.weight_hh_l0_reverse: 0.009151071310043335 0.08755369484424591
encoder.encoder.bias_ih_l0_reverse: 0.03588298335671425 0.08580819517374039
encoder.encoder.bias_hh_l0_reverse: 0.027748551219701767 0.08308268338441849
decider.lstm.weight_ih_l0: 0.001941667404025793 0.14875362813472748
decider.lstm.weight_hh_l0: 0.0032074344344437122 0.1483074426651001
decider.lstm.bias_ih_l0: 0.024562714621424675 0.15916982293128967
decider.lstm.bias_hh_l0: 0.005575231742113829 0.14074914157390594
decider.linear1.weight: 0.004425667226314545 0.12165684998035431
decider.linear1.bias: 0.020264342427253723 0.11754094064235687
decider.linear2.weight: 0.005324408877640963 0.053855571895837784
decider.linear2.bias: 0.008641738444566727 0.057572122663259506
decider.linear3.weight: -0.020772146061062813 0.06639619171619415
decider.linear3.bias: -0.0024798917584121227 0.04913518205285072

Rewards:
217.8160
217.8160
217.8160
objective = 190.47250366210938
==== episode 1100/10000 ====
action = 1
probs = 0.0208 0.9791 0.0000 0.0000

action = 1
probs = 0.0497 0.9503 0.0000 0.0000

action = 0
probs = 0.7138 0.2862 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00028001450118608773 0.08569939434528351
encoder.encoder.weight_hh_l0: -4.333090600994183e-06 0.0876041054725647
encoder.encoder.bias_ih_l0: 0.014625783078372478 0.08912090957164764
encoder.encoder.bias_hh_l0: 0.02462286502122879 0.08732514083385468
encoder.encoder.weight_ih_l0_reverse: 0.0018575810827314854 0.08820430189371109
encoder.encoder.weight_hh_l0_reverse: 0.00919946376234293 0.08759933710098267
encoder.encoder.bias_ih_l0_reverse: 0.036033160984516144 0.08576717227697372
encoder.encoder.bias_hh_l0_reverse: 0.02789873071014881 0.08314342051744461
decider.lstm.weight_ih_l0: 0.001969220582395792 0.1487772911787033
decider.lstm.weight_hh_l0: 0.00321993138641119 0.14833228290081024
decider.lstm.bias_ih_l0: 0.024654686450958252 0.15931449830532074
decider.lstm.bias_hh_l0: 0.005667198449373245 0.14069992303848267
decider.linear1.weight: 0.004416290204972029 0.12165632098913193
decider.linear1.bias: 0.020248152315616608 0.1174721047282219
decider.linear2.weight: 0.005231210496276617 0.05382213369011879
decider.linear2.bias: 0.008543369360268116 0.05763419717550278
decider.linear3.weight: -0.021069979295134544 0.0665615126490593
decider.linear3.bias: -0.0028126651886850595 0.05006014183163643

Rewards:
230.1930
230.1930
230.1930
objective = 31.39743423461914
==== episode 1200/10000 ====
action = 1
probs = 0.0277 0.9722 0.0000 0.0000

action = 1
probs = 0.0723 0.9277 0.0000 0.0000

action = 0
probs = 0.6910 0.3090 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00026607271865941584 0.08565137535333633
encoder.encoder.weight_hh_l0: -1.1446713870100211e-06 0.0875336229801178
encoder.encoder.bias_ih_l0: 0.014435195364058018 0.08906104415655136
encoder.encoder.bias_hh_l0: 0.02443227916955948 0.08722800761461258
encoder.encoder.weight_ih_l0_reverse: 0.0018605395453050733 0.08811341971158981
encoder.encoder.weight_hh_l0_reverse: 0.009212492033839226 0.08759552240371704
encoder.encoder.bias_ih_l0_reverse: 0.03587786480784416 0.08569685369729996
encoder.encoder.bias_hh_l0_reverse: 0.02774343453347683 0.08307477831840515
decider.lstm.weight_ih_l0: 0.001909768208861351 0.14872366189956665
decider.lstm.weight_hh_l0: 0.0031734094955027103 0.14828652143478394
decider.lstm.bias_ih_l0: 0.02433072216808796 0.15930792689323425
decider.lstm.bias_hh_l0: 0.005343235097825527 0.1406763345003128
decider.linear1.weight: 0.0044154818169772625 0.12159709632396698
decider.linear1.bias: 0.01997939869761467 0.1174837127327919
decider.linear2.weight: 0.005152009427547455 0.053795091807842255
decider.linear2.bias: 0.008434206247329712 0.0575963631272316
decider.linear3.weight: -0.021369272843003273 0.06666633486747742
decider.linear3.bias: -0.0031328764744102955 0.04978184029459953

Rewards:
230.1930
230.1930
230.1930
objective = 36.28456115722656
==== episode 1300/10000 ====
action = 1
probs = 0.0485 0.9513 0.0000 0.0001

action = 1
probs = 0.1015 0.8985 0.0000 0.0000

action = 1
probs = 0.6255 0.3744 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002380645164521411 0.08543704450130463
encoder.encoder.weight_hh_l0: -5.249369223747635e-06 0.08726967871189117
encoder.encoder.bias_ih_l0: 0.013833502307534218 0.08875617384910583
encoder.encoder.bias_hh_l0: 0.023830588907003403 0.08697719126939774
encoder.encoder.weight_ih_l0_reverse: 0.0018724252004176378 0.08792780339717865
encoder.encoder.weight_hh_l0_reverse: 0.00912565179169178 0.08748553693294525
encoder.encoder.bias_ih_l0_reverse: 0.035547539591789246 0.08556428551673889
encoder.encoder.bias_hh_l0_reverse: 0.02741311304271221 0.08303137123584747
decider.lstm.weight_ih_l0: 0.0016971182776615024 0.14847129583358765
decider.lstm.weight_hh_l0: 0.00304336566478014 0.14808447659015656
decider.lstm.bias_ih_l0: 0.023280737921595573 0.15914344787597656
decider.lstm.bias_hh_l0: 0.0042932541109621525 0.1404554396867752
decider.linear1.weight: 0.004427448846399784 0.12150491774082184
decider.linear1.bias: 0.01960599049925804 0.11746927350759506
decider.linear2.weight: 0.005049771163612604 0.0537482351064682
decider.linear2.bias: 0.008288662880659103 0.05753984674811363
decider.linear3.weight: -0.02176763489842415 0.06683779507875443
decider.linear3.bias: -0.0036154796835035086 0.049343887716531754

Rewards:
217.8160
217.8160
217.8160
objective = 82.7110824584961
==== episode 1400/10000 ====
action = 1
probs = 0.0564 0.9435 0.0001 0.0001

action = 1
probs = 0.1132 0.8868 0.0000 0.0000

action = 1
probs = 0.6275 0.3724 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00020750700787175447 0.08529545366764069
encoder.encoder.weight_hh_l0: -2.060368024103809e-05 0.08710185438394547
encoder.encoder.bias_ih_l0: 0.013354675844311714 0.08856848627328873
encoder.encoder.bias_hh_l0: 0.0233517624437809 0.08683783560991287
encoder.encoder.weight_ih_l0_reverse: 0.0018834531074389815 0.08779464662075043
encoder.encoder.weight_hh_l0_reverse: 0.009118781425058842 0.0874645784497261
encoder.encoder.bias_ih_l0_reverse: 0.03534461557865143 0.08547500520944595
encoder.encoder.bias_hh_l0_reverse: 0.027210185304284096 0.0830116868019104
decider.lstm.weight_ih_l0: 0.00157986581325531 0.14835897088050842
decider.lstm.weight_hh_l0: 0.0029759404715150595 0.14797887206077576
decider.lstm.bias_ih_l0: 0.022708967328071594 0.15903641283512115
decider.lstm.bias_hh_l0: 0.003721483051776886 0.1403517723083496
decider.linear1.weight: 0.004431411158293486 0.12143702059984207
decider.linear1.bias: 0.019345959648489952 0.11742784082889557
decider.linear2.weight: 0.00490657240152359 0.05370539799332619
decider.linear2.bias: 0.008024550043046474 0.05738035961985588
decider.linear3.weight: -0.021847739815711975 0.06687512993812561
decider.linear3.bias: -0.0035884049721062183 0.049169231206178665

Rewards:
217.8160
217.8160
217.8160
objective = 84.66194152832031
==== episode 1500/10000 ====
action = 1
probs = 0.0767 0.9230 0.0001 0.0001

action = 1
probs = 0.1870 0.8130 0.0000 0.0000

action = 1
probs = 0.7650 0.2350 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00018478918354958296 0.08528159558773041
encoder.encoder.weight_hh_l0: -2.3321461412706412e-05 0.08710088580846786
encoder.encoder.bias_ih_l0: 0.013275022618472576 0.08860870450735092
encoder.encoder.bias_hh_l0: 0.023272106423974037 0.08679834008216858
encoder.encoder.weight_ih_l0_reverse: 0.0018910468788817525 0.08777838200330734
encoder.encoder.weight_hh_l0_reverse: 0.009183916263282299 0.08752239495515823
encoder.encoder.bias_ih_l0_reverse: 0.03528153523802757 0.08549495041370392
encoder.encoder.bias_hh_l0_reverse: 0.02714710682630539 0.08293917775154114
decider.lstm.weight_ih_l0: 0.0015850680647417903 0.14839422702789307
decider.lstm.weight_hh_l0: 0.0029780068434774876 0.14801035821437836
decider.lstm.bias_ih_l0: 0.022718429565429688 0.15897732973098755
decider.lstm.bias_hh_l0: 0.0037309378385543823 0.14049342274665833
decider.linear1.weight: 0.004433684516698122 0.12142236530780792
decider.linear1.bias: 0.019283847883343697 0.11745111644268036
decider.linear2.weight: 0.004927339032292366 0.05371759086847305
decider.linear2.bias: 0.008049244061112404 0.05733197182416916
decider.linear3.weight: -0.02235056459903717 0.06733094155788422
decider.linear3.bias: -0.00398170156404376 0.04836282506585121

Rewards:
217.8160
217.8160
217.8160
objective = 125.99617004394531
==== episode 1600/10000 ====
action = 1
probs = 0.1173 0.8824 0.0001 0.0001

action = 1
probs = 0.3440 0.6559 0.0000 0.0000

action = 1
probs = 0.8996 0.1004 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00017049844609573483 0.08531611412763596
encoder.encoder.weight_hh_l0: -1.7145872334367596e-05 0.0871526375412941
encoder.encoder.bias_ih_l0: 0.013362530618906021 0.08873387426137924
encoder.encoder.bias_hh_l0: 0.023359617218375206 0.08679807186126709
encoder.encoder.weight_ih_l0_reverse: 0.0018849943298846483 0.08779696375131607
encoder.encoder.weight_hh_l0_reverse: 0.009245254099369049 0.08757661283016205
encoder.encoder.bias_ih_l0_reverse: 0.03525855764746666 0.08555477112531662
encoder.encoder.bias_hh_l0_reverse: 0.027124132961034775 0.08283756673336029
decider.lstm.weight_ih_l0: 0.0016229291213676333 0.14847083389759064
decider.lstm.weight_hh_l0: 0.0029948600567877293 0.14806845784187317
decider.lstm.bias_ih_l0: 0.022896084934473038 0.15899498760700226
decider.lstm.bias_hh_l0: 0.003908599726855755 0.14066855609416962
decider.linear1.weight: 0.004436080809682608 0.12143152952194214
decider.linear1.bias: 0.019340436905622482 0.11749947816133499
decider.linear2.weight: 0.0050064753741025925 0.05375167727470398
decider.linear2.bias: 0.00816834345459938 0.057313453406095505
decider.linear3.weight: -0.022858573123812675 0.06783217936754227
decider.linear3.bias: -0.004518489353358746 0.047277215868234634

Rewards:
217.8160
217.8160
217.8160
objective = 206.623779296875
==== episode 1700/10000 ====
action = 1
probs = 0.1339 0.8658 0.0001 0.0001

action = 1
probs = 0.5198 0.4802 0.0000 0.0000

action = 0
probs = 0.9573 0.0427 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00019163540855515748 0.08549590408802032
encoder.encoder.weight_hh_l0: 1.0129332395081292e-06 0.08735115081071854
encoder.encoder.bias_ih_l0: 0.01387704536318779 0.08902045339345932
encoder.encoder.bias_hh_l0: 0.023874128237366676 0.08695545792579651
encoder.encoder.weight_ih_l0_reverse: 0.0018616357119753957 0.087916299700737
encoder.encoder.weight_hh_l0_reverse: 0.009313498623669147 0.08764870464801788
encoder.encoder.bias_ih_l0_reverse: 0.035434331744909286 0.08568720519542694
encoder.encoder.bias_hh_l0_reverse: 0.027299903333187103 0.08274742215871811
decider.lstm.weight_ih_l0: 0.0017625452019274235 0.14866289496421814
decider.lstm.weight_hh_l0: 0.0030668298713862896 0.14822497963905334
decider.lstm.bias_ih_l0: 0.02359011396765709 0.15920579433441162
decider.lstm.bias_hh_l0: 0.0046026259660720825 0.14084367454051971
decider.linear1.weight: 0.004426326137036085 0.12149745970964432
decider.linear1.bias: 0.01961814984679222 0.11756250262260437
decider.linear2.weight: 0.005101608578115702 0.0538129024207592
decider.linear2.bias: 0.008326586335897446 0.05732835456728935
decider.linear3.weight: -0.023369979113340378 0.06844064593315125
decider.linear3.bias: -0.005071725696325302 0.04655219241976738

Rewards:
230.1930
230.1930
230.1930
objective = 70.69195556640625
==== episode 1800/10000 ====
action = 1
probs = 0.0700 0.9298 0.0001 0.0001

action = 1
probs = 0.3182 0.6818 0.0000 0.0000

action = 0
probs = 0.9186 0.0814 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00020684949413407594 0.08552227169275284
encoder.encoder.weight_hh_l0: -3.805994992944761e-06 0.08736103773117065
encoder.encoder.bias_ih_l0: 0.013828789815306664 0.08901288360357285
encoder.encoder.bias_hh_l0: 0.0238258745521307 0.08704003691673279
encoder.encoder.weight_ih_l0_reverse: 0.0018919702852144837 0.08794322609901428
encoder.encoder.weight_hh_l0_reverse: 0.009379532188177109 0.08772283792495728
encoder.encoder.bias_ih_l0_reverse: 0.03561009466648102 0.0856960266828537
encoder.encoder.bias_hh_l0_reverse: 0.027475668117403984 0.08285759389400482
decider.lstm.weight_ih_l0: 0.0018099599983543158 0.1487068384885788
decider.lstm.weight_hh_l0: 0.0030869678594172 0.14827577769756317
decider.lstm.bias_ih_l0: 0.023793723434209824 0.15927691757678986
decider.lstm.bias_hh_l0: 0.004806238692253828 0.14076465368270874
decider.linear1.weight: 0.0044183069840073586 0.12149479240179062
decider.linear1.bias: 0.01956508308649063 0.11753124743700027
decider.linear2.weight: 0.004990484565496445 0.053798697888851166
decider.linear2.bias: 0.008156431838870049 0.057322487235069275
decider.linear3.weight: -0.02378186210989952 0.0689033716917038
decider.linear3.bias: -0.005469031631946564 0.04749836400151253

Rewards:
230.1930
230.1930
230.1930
objective = 41.48565673828125
==== episode 1900/10000 ====
action = 1
probs = 0.0599 0.9400 0.0001 0.0000

action = 0
probs = 0.3777 0.6222 0.0000 0.0000

action = 0
probs = 0.9478 0.0522 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002274046855745837 0.08566359430551529
encoder.encoder.weight_hh_l0: 4.466831796889892e-06 0.0875161662697792
encoder.encoder.bias_ih_l0: 0.014225787483155727 0.08921264857053757
encoder.encoder.bias_hh_l0: 0.02422286942601204 0.08715946227312088
encoder.encoder.weight_ih_l0_reverse: 0.0018771070754155517 0.08804119378328323
encoder.encoder.weight_hh_l0_reverse: 0.00939150620251894 0.08775151520967484
encoder.encoder.bias_ih_l0_reverse: 0.03571544587612152 0.08576399087905884
encoder.encoder.bias_hh_l0_reverse: 0.027581023052334785 0.0828055739402771
decider.lstm.weight_ih_l0: 0.0019049167167395353 0.14883264899253845
decider.lstm.weight_hh_l0: 0.0031419533770531416 0.14837677776813507
decider.lstm.bias_ih_l0: 0.024276450276374817 0.1593790501356125
decider.lstm.bias_hh_l0: 0.005288960877805948 0.14086827635765076
decider.linear1.weight: 0.004407040309160948 0.12155046314001083
decider.linear1.bias: 0.019777489826083183 0.11751379817724228
decider.linear2.weight: 0.005066304933279753 0.053842585533857346
decider.linear2.bias: 0.008269557729363441 0.05729043856263161
decider.linear3.weight: -0.02413502149283886 0.06941474974155426
decider.linear3.bias: -0.005788025911897421 0.04729655757546425

Rewards:
221.7540
221.7540
221.7540
objective = 80.50064086914062
==== episode 2000/10000 ====
action = 1
probs = 0.0443 0.9556 0.0001 0.0000

action = 0
probs = 0.2929 0.7070 0.0000 0.0000

action = 0
probs = 0.9198 0.0802 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002346652327105403 0.08567565679550171
encoder.encoder.weight_hh_l0: 3.5277128063171403e-06 0.0875149592757225
encoder.encoder.bias_ih_l0: 0.014181418344378471 0.08919573575258255
encoder.encoder.bias_hh_l0: 0.024178504943847656 0.08717672526836395
encoder.encoder.weight_ih_l0_reverse: 0.0018924855394288898 0.08803962916135788
encoder.encoder.weight_hh_l0_reverse: 0.009425793774425983 0.0877896323800087
encoder.encoder.bias_ih_l0_reverse: 0.03579056262969971 0.0857611745595932
encoder.encoder.bias_hh_l0_reverse: 0.02765614166855812 0.08285535126924515
decider.lstm.weight_ih_l0: 0.0019183334661647677 0.14884161949157715
decider.lstm.weight_hh_l0: 0.003146118950098753 0.14839552342891693
decider.lstm.bias_ih_l0: 0.02431314066052437 0.15940797328948975
decider.lstm.bias_hh_l0: 0.0053256540559232235 0.1408352255821228
decider.linear1.weight: 0.004400446079671383 0.12154406309127808
decider.linear1.bias: 0.01971966028213501 0.1174871176481247
decider.linear2.weight: 0.005004131235182285 0.053831253200769424
decider.linear2.bias: 0.00818614475429058 0.05729212984442711
decider.linear3.weight: -0.024424977600574493 0.06978342682123184
decider.linear3.bias: -0.006027748342603445 0.04779333248734474

Rewards:
221.7540
221.7540
221.7540
objective = 100.29528045654297
==== episode 2100/10000 ====
action = 1
probs = 0.0251 0.9748 0.0000 0.0000

action = 1
probs = 0.1854 0.8146 0.0000 0.0000

action = 0
probs = 0.8746 0.1254 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00025493092834949493 0.08576473593711853
encoder.encoder.weight_hh_l0: 3.283536443632329e-06 0.08760207146406174
encoder.encoder.bias_ih_l0: 0.014373652637004852 0.08925844728946686
encoder.encoder.bias_hh_l0: 0.024370739236474037 0.0872839167714119
encoder.encoder.weight_ih_l0_reverse: 0.001897378358989954 0.08810142427682877
encoder.encoder.weight_hh_l0_reverse: 0.009457115083932877 0.08783134073019028
encoder.encoder.bias_ih_l0_reverse: 0.035966694355010986 0.08578535914421082
encoder.encoder.bias_hh_l0_reverse: 0.0278322733938694 0.08291055262088776
decider.lstm.weight_ih_l0: 0.001987091964110732 0.14891161024570465
decider.lstm.weight_hh_l0: 0.0031874498818069696 0.14846448600292206
decider.lstm.bias_ih_l0: 0.02464567869901657 0.15948916971683502
decider.lstm.bias_hh_l0: 0.005658194422721863 0.14083923399448395
decider.linear1.weight: 0.004388581495732069 0.12158139795064926
decider.linear1.bias: 0.019829988479614258 0.11745216697454453
decider.linear2.weight: 0.004974092822521925 0.05383797734975815
decider.linear2.bias: 0.008142446167767048 0.057298436760902405
decider.linear3.weight: -0.02468259260058403 0.07015398144721985
decider.linear3.bias: -0.006211164407432079 0.04850997030735016

Rewards:
230.1930
230.1930
230.1930
objective = 27.978530883789062
==== episode 2200/10000 ====
action = 1
probs = 0.0135 0.9865 0.0000 0.0000

action = 1
probs = 0.0994 0.9006 0.0000 0.0000

action = 0
probs = 0.7970 0.2030 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002776178007479757 0.08585789054632187
encoder.encoder.weight_hh_l0: 1.8198012412540265e-06 0.0876966193318367
encoder.encoder.bias_ih_l0: 0.01460479199886322 0.08931375294923782
encoder.encoder.bias_hh_l0: 0.024601878598332405 0.08739365637302399
encoder.encoder.weight_ih_l0_reverse: 0.0018975542625412345 0.08817555755376816
encoder.encoder.weight_hh_l0_reverse: 0.009465973824262619 0.08785506337881088
encoder.encoder.bias_ih_l0_reverse: 0.03613746166229248 0.08580199629068375
encoder.encoder.bias_hh_l0_reverse: 0.028003038838505745 0.0829738974571228
decider.lstm.weight_ih_l0: 0.002054117387160659 0.14897219836711884
decider.lstm.weight_hh_l0: 0.0032318809535354376 0.14852555096149445
decider.lstm.bias_ih_l0: 0.024985451251268387 0.1595700979232788
decider.lstm.bias_hh_l0: 0.00599796324968338 0.14083515107631683
decider.linear1.weight: 0.004378023557364941 0.12163321673870087
decider.linear1.bias: 0.019994957372546196 0.11741463094949722
decider.linear2.weight: 0.004957905970513821 0.05384804680943489
decider.linear2.bias: 0.008116599172353745 0.0573190301656723
decider.linear3.weight: -0.024883240461349487 0.07047510147094727
decider.linear3.bias: -0.006305395625531673 0.04924771934747696

Rewards:
230.1930
230.1930
230.1930
objective = 26.48237419128418
==== episode 2300/10000 ====
action = 1
probs = 0.0181 0.9819 0.0000 0.0000

action = 1
probs = 0.1815 0.8185 0.0000 0.0000

action = 0
probs = 0.9370 0.0630 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00026539998361840844 0.0858844593167305
encoder.encoder.weight_hh_l0: -1.940298034242005e-06 0.08775944262742996
encoder.encoder.bias_ih_l0: 0.014704491943120956 0.08944772183895111
encoder.encoder.bias_hh_l0: 0.02470158040523529 0.08744683116674423
encoder.encoder.weight_ih_l0_reverse: 0.0018948223441839218 0.08822821825742722
encoder.encoder.weight_hh_l0_reverse: 0.009436366148293018 0.08784415572881699
encoder.encoder.bias_ih_l0_reverse: 0.0360979400575161 0.08588279783725739
encoder.encoder.bias_hh_l0_reverse: 0.02796352282166481 0.08289561420679092
decider.lstm.weight_ih_l0: 0.0020823476370424032 0.14902262389659882
decider.lstm.weight_hh_l0: 0.003258349373936653 0.14855962991714478
decider.lstm.bias_ih_l0: 0.02517610788345337 0.15955239534378052
decider.lstm.bias_hh_l0: 0.006188622675836086 0.1409270018339157
decider.linear1.weight: 0.004384636413305998 0.12167771905660629
decider.linear1.bias: 0.020183688029646873 0.11747577786445618
decider.linear2.weight: 0.00510053988546133 0.053902767598629
decider.linear2.bias: 0.008308490738272667 0.05728992447257042
decider.linear3.weight: -0.02506231889128685 0.07081995159387589
decider.linear3.bias: -0.006377689074724913 0.04838349297642708

Rewards:
230.1930
230.1930
230.1930
objective = 21.76052474975586
==== episode 2400/10000 ====
action = 1
probs = 0.0164 0.9836 0.0000 0.0000

action = 1
probs = 0.2344 0.7656 0.0000 0.0000

action = 0
probs = 0.9674 0.0326 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00028250724426470697 0.08596774935722351
encoder.encoder.weight_hh_l0: -6.52047401672462e-06 0.0878634974360466
encoder.encoder.bias_ih_l0: 0.014989360235631466 0.08958519995212555
encoder.encoder.bias_hh_l0: 0.024986447766423225 0.08751479536294937
encoder.encoder.weight_ih_l0_reverse: 0.0019039572216570377 0.08831185847520828
encoder.encoder.weight_hh_l0_reverse: 0.00941458623856306 0.08784399926662445
encoder.encoder.bias_ih_l0_reverse: 0.036184266209602356 0.08593636751174927
encoder.encoder.bias_hh_l0_reverse: 0.028049848973751068 0.08285225927829742
decider.lstm.weight_ih_l0: 0.0021298425272107124 0.14907880127429962
decider.lstm.weight_hh_l0: 0.003294432768598199 0.1486043483018875
decider.lstm.bias_ih_l0: 0.02545233629643917 0.1595870554447174
decider.lstm.bias_hh_l0: 0.006464852951467037 0.1409555822610855
decider.linear1.weight: 0.004381406120955944 0.12173889577388763
decider.linear1.bias: 0.02040662243962288 0.11747017502784729
decider.linear2.weight: 0.005196744576096535 0.05395686998963356
decider.linear2.bias: 0.008443369530141354 0.05726263299584389
decider.linear3.weight: -0.025240067392587662 0.07117193192243576
decider.linear3.bias: -0.006462370976805687 0.04808220639824867

Rewards:
230.1930
230.1930
230.1930
objective = 24.308256149291992
==== episode 2500/10000 ====
action = 1
probs = 0.0122 0.9878 0.0000 0.0000

action = 0
probs = 0.1425 0.8575 0.0000 0.0000

action = 1
probs = 0.9252 0.0748 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00027742443489842117 0.08594190329313278
encoder.encoder.weight_hh_l0: -2.6377915673947427e-06 0.08781368285417557
encoder.encoder.bias_ih_l0: 0.01480366475880146 0.08950448036193848
encoder.encoder.bias_hh_l0: 0.024800756946206093 0.08748859912157059
encoder.encoder.weight_ih_l0_reverse: 0.001907349331304431 0.08826376497745514
encoder.encoder.weight_hh_l0_reverse: 0.0094494903460145 0.08788277953863144
encoder.encoder.bias_ih_l0_reverse: 0.036169860512018204 0.08588904142379761
encoder.encoder.bias_hh_l0_reverse: 0.028035445138812065 0.082926444709301
decider.lstm.weight_ih_l0: 0.002116961870342493 0.14904502034187317
decider.lstm.weight_hh_l0: 0.0032774514984339476 0.14858554303646088
decider.lstm.bias_ih_l0: 0.02533508464694023 0.1595892459154129
decider.lstm.bias_hh_l0: 0.006347596645355225 0.140904039144516
decider.linear1.weight: 0.0043764011934399605 0.12169923633337021
decider.linear1.bias: 0.020230576395988464 0.11742199212312698
decider.linear2.weight: 0.0050819749012589455 0.053914815187454224
decider.linear2.bias: 0.008289150893688202 0.05729137361049652
decider.linear3.weight: -0.02543189935386181 0.07137516140937805
decider.linear3.bias: -0.006551234982907772 0.04875839129090309

Rewards:
229.4037
229.4037
229.4037
objective = 348.24188232421875
==== episode 2600/10000 ====
action = 1
probs = 0.0077 0.9922 0.0000 0.0000

action = 1
probs = 0.0964 0.9036 0.0000 0.0000

action = 0
probs = 0.9199 0.0801 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002968037442769855 0.08602096140384674
encoder.encoder.weight_hh_l0: -8.923006134864409e-06 0.08790608495473862
encoder.encoder.bias_ih_l0: 0.015046806074678898 0.08958294242620468
encoder.encoder.bias_hh_l0: 0.025043897330760956 0.08757595717906952
encoder.encoder.weight_ih_l0_reverse: 0.0019141261000186205 0.08834574371576309
encoder.encoder.weight_hh_l0_reverse: 0.009435693733394146 0.08788671344518661
encoder.encoder.bias_ih_l0_reverse: 0.03629439324140549 0.08591853827238083
encoder.encoder.bias_hh_l0_reverse: 0.0281599760055542 0.0829521045088768
decider.lstm.weight_ih_l0: 0.002170918043702841 0.14909370243549347
decider.lstm.weight_hh_l0: 0.003318216186016798 0.14863061904907227
decider.lstm.bias_ih_l0: 0.025629453361034393 0.1596430093050003
decider.lstm.bias_hh_l0: 0.0066419667564332485 0.14090865850448608
decider.linear1.weight: 0.004372546914964914 0.12175419926643372
decider.linear1.bias: 0.02043386548757553 0.1174330860376358
decider.linear2.weight: 0.005129714496433735 0.05394214764237404
decider.linear2.bias: 0.008363918401300907 0.05728904530405998
decider.linear3.weight: -0.02559792622923851 0.0716768205165863
decider.linear3.bias: -0.006606400944292545 0.04907490685582161

Rewards:
230.1930
230.1930
230.1930
objective = 14.78293228149414
==== episode 2700/10000 ====
action = 1
probs = 0.0071 0.9929 0.0000 0.0000

action = 1
probs = 0.0840 0.9160 0.0000 0.0000

action = 0
probs = 0.9229 0.0771 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00030083052115514874 0.08602838963270187
encoder.encoder.weight_hh_l0: -1.021902517095441e-05 0.08791445195674896
encoder.encoder.bias_ih_l0: 0.01506585069000721 0.08958499133586884
encoder.encoder.bias_hh_l0: 0.02506294474005699 0.08760140836238861
encoder.encoder.weight_ih_l0_reverse: 0.0019154577748849988 0.0883704125881195
encoder.encoder.weight_hh_l0_reverse: 0.009428084827959538 0.08788759261369705
encoder.encoder.bias_ih_l0_reverse: 0.036319199949502945 0.08592815697193146
encoder.encoder.bias_hh_l0_reverse: 0.028184784576296806 0.08297374099493027
decider.lstm.weight_ih_l0: 0.002182957949116826 0.1491052210330963
decider.lstm.weight_hh_l0: 0.003327655605971813 0.1486419439315796
decider.lstm.bias_ih_l0: 0.025693465024232864 0.1596544086933136
decider.lstm.bias_hh_l0: 0.006705972366034985 0.14092427492141724
decider.linear1.weight: 0.0043731629848480225 0.12176600098609924
decider.linear1.bias: 0.020482085645198822 0.11744566261768341
decider.linear2.weight: 0.005138053093105555 0.053946543484926224
decider.linear2.bias: 0.008372586220502853 0.05729277804493904
decider.linear3.weight: -0.02575204148888588 0.07190307229757309
decider.linear3.bias: -0.0066520581021904945 0.049185339361429214

Rewards:
230.1930
230.1930
230.1930
objective = 13.439112663269043
==== episode 2800/10000 ====
action = 1
probs = 0.0057 0.9943 0.0000 0.0000

action = 1
probs = 0.0572 0.9428 0.0000 0.0000

action = 0
probs = 0.9032 0.0968 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00030452318605966866 0.08602771908044815
encoder.encoder.weight_hh_l0: -1.146411887020804e-05 0.08790979534387589
encoder.encoder.bias_ih_l0: 0.015051822178065777 0.08955976366996765
encoder.encoder.bias_hh_l0: 0.025048919022083282 0.08763456344604492
encoder.encoder.weight_ih_l0_reverse: 0.0019179072696715593 0.0883919969201088
encoder.encoder.weight_hh_l0_reverse: 0.0094243623316288 0.08788991719484329
encoder.encoder.bias_ih_l0_reverse: 0.036372531205415726 0.08593345433473587
encoder.encoder.bias_hh_l0_reverse: 0.02823811210691929 0.0830201581120491
decider.lstm.weight_ih_l0: 0.002194429514929652 0.14911112189292908
decider.lstm.weight_hh_l0: 0.0033365958370268345 0.14865046739578247
decider.lstm.bias_ih_l0: 0.02575034275650978 0.1596575230360031
decider.lstm.bias_hh_l0: 0.0067628538236021996 0.14093199372291565
decider.linear1.weight: 0.00437228474766016 0.12177950888872147
decider.linear1.bias: 0.020515473559498787 0.1174476146697998
decider.linear2.weight: 0.005106890574097633 0.053950246423482895
decider.linear2.bias: 0.008352523669600487 0.05731293559074402
decider.linear3.weight: -0.02589958906173706 0.0721244290471077
decider.linear3.bias: -0.006687412038445473 0.04948112741112709

Rewards:
230.1930
230.1930
230.1930
objective = 12.767051696777344
==== episode 2900/10000 ====
action = 1
probs = 0.0043 0.9957 0.0000 0.0000

action = 1
probs = 0.0411 0.9589 0.0000 0.0000

action = 0
probs = 0.8481 0.1519 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003137350722681731 0.08606458455324173
encoder.encoder.weight_hh_l0: -1.0678827493393328e-05 0.08794216811656952
encoder.encoder.bias_ih_l0: 0.015125028789043427 0.08956292271614075
encoder.encoder.bias_hh_l0: 0.025122126564383507 0.08765191584825516
encoder.encoder.weight_ih_l0_reverse: 0.0019157003844156861 0.08839824795722961
encoder.encoder.weight_hh_l0_reverse: 0.009437056258320808 0.08790751546621323
encoder.encoder.bias_ih_l0_reverse: 0.0364241860806942 0.08591926842927933
encoder.encoder.bias_hh_l0_reverse: 0.028289765119552612 0.08304429054260254
decider.lstm.weight_ih_l0: 0.0022074568551033735 0.14911414682865143
decider.lstm.weight_hh_l0: 0.0033433199860155582 0.14865630865097046
decider.lstm.bias_ih_l0: 0.025806430727243423 0.1596856713294983
decider.lstm.bias_hh_l0: 0.0068189348094165325 0.1408938765525818
decider.linear1.weight: 0.004365180153399706 0.12178249657154083
decider.linear1.bias: 0.020500030368566513 0.11742380261421204
decider.linear2.weight: 0.005069485865533352 0.0539432168006897
decider.linear2.bias: 0.008302903734147549 0.05733746662735939
decider.linear3.weight: -0.026051726192235947 0.07232597470283508
decider.linear3.bias: -0.006724349223077297 0.04990547522902489

Rewards:
230.1930
230.1930
230.1930
objective = 16.195837020874023
==== episode 3000/10000 ====
action = 1
probs = 0.0038 0.9962 0.0000 0.0000

action = 0
probs = 0.0349 0.9651 0.0000 0.0000

action = 1
probs = 0.7863 0.2137 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00031309123733080924 0.08607368171215057
encoder.encoder.weight_hh_l0: -6.125557320046937e-06 0.0879412591457367
encoder.encoder.bias_ih_l0: 0.015097715891897678 0.08954371511936188
encoder.encoder.bias_hh_l0: 0.025094814598560333 0.08765246719121933
encoder.encoder.weight_ih_l0_reverse: 0.0019087354885414243 0.08837525546550751
encoder.encoder.weight_hh_l0_reverse: 0.00945316907018423 0.08791998773813248
encoder.encoder.bias_ih_l0_reverse: 0.036414436995983124 0.08589792251586914
encoder.encoder.bias_hh_l0_reverse: 0.028280014172196388 0.08305951207876205
decider.lstm.weight_ih_l0: 0.0022022987250238657 0.1491025984287262
decider.lstm.weight_hh_l0: 0.0033352277241647243 0.14865060150623322
decider.lstm.bias_ih_l0: 0.02576274797320366 0.1597028225660324
decider.lstm.bias_hh_l0: 0.006775247864425182 0.14085270464420319
decider.linear1.weight: 0.004359287675470114 0.12176759541034698
decider.linear1.bias: 0.020413609221577644 0.1173972338438034
decider.linear2.weight: 0.005007872357964516 0.05392999202013016
decider.linear2.bias: 0.008217977359890938 0.05735471844673157
decider.linear3.weight: -0.026211176067590714 0.07251566648483276
decider.linear3.bias: -0.006756772752851248 0.050208929926157

Rewards:
229.4037
229.4037
229.4037
objective = 374.8614196777344
==== episode 3100/10000 ====
action = 1
probs = 0.0040 0.9960 0.0000 0.0000

action = 1
probs = 0.0391 0.9609 0.0000 0.0000

action = 0
probs = 0.7849 0.2151 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00030683400109410286 0.08607868105173111
encoder.encoder.weight_hh_l0: -3.966510121244937e-06 0.08794660866260529
encoder.encoder.bias_ih_l0: 0.015059204772114754 0.08956149220466614
encoder.encoder.bias_hh_l0: 0.025056298822164536 0.08766345679759979
encoder.encoder.weight_ih_l0_reverse: 0.0019087159307673573 0.08836163580417633
encoder.encoder.weight_hh_l0_reverse: 0.009465635754168034 0.08793275058269501
encoder.encoder.bias_ih_l0_reverse: 0.03638342395424843 0.08590098470449448
encoder.encoder.bias_hh_l0_reverse: 0.028249001130461693 0.08305138349533081
decider.lstm.weight_ih_l0: 0.0021993746049702168 0.14910021424293518
decider.lstm.weight_hh_l0: 0.0033310637809336185 0.14864984154701233
decider.lstm.bias_ih_l0: 0.025742340832948685 0.1597038060426712
decider.lstm.bias_hh_l0: 0.006754841655492783 0.14083923399448395
decider.linear1.weight: 0.004355087876319885 0.12176061421632767
decider.linear1.bias: 0.020365428179502487 0.11738543212413788
decider.linear2.weight: 0.005006309598684311 0.053928159177303314
decider.linear2.bias: 0.008214733563363552 0.0573405921459198
decider.linear3.weight: -0.02638496831059456 0.07276374846696854
decider.linear3.bias: -0.006793268956243992 0.050140153616666794

Rewards:
230.1930
230.1930
230.1930
objective = 21.947277069091797
==== episode 3200/10000 ====
action = 1
probs = 0.0051 0.9949 0.0000 0.0000

action = 1
probs = 0.0673 0.9327 0.0000 0.0000

action = 0
probs = 0.8920 0.1080 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00029169503250159323 0.08607932925224304
encoder.encoder.weight_hh_l0: -3.5504101560945855e-06 0.0879603922367096
encoder.encoder.bias_ih_l0: 0.015017618425190449 0.0896344855427742
encoder.encoder.bias_hh_l0: 0.025014715269207954 0.08768688887357712
encoder.encoder.weight_ih_l0_reverse: 0.0019156822236254811 0.0883622094988823
encoder.encoder.weight_hh_l0_reverse: 0.009473741985857487 0.08794625103473663
encoder.encoder.bias_ih_l0_reverse: 0.0363326370716095 0.08594349771738052
encoder.encoder.bias_hh_l0_reverse: 0.02819821797311306 0.08300352841615677
decider.lstm.weight_ih_l0: 0.0022004153579473495 0.14911460876464844
decider.lstm.weight_hh_l0: 0.003332222579047084 0.14865991473197937
decider.lstm.bias_ih_l0: 0.02575935237109661 0.1596805304288864
decider.lstm.bias_hh_l0: 0.006771851796656847 0.14086474478244781
decider.linear1.weight: 0.004355012904852629 0.12177028506994247
decider.linear1.bias: 0.02039189822971821 0.11739837378263474
decider.linear2.weight: 0.005079026333987713 0.053950294852256775
decider.linear2.bias: 0.008317308500409126 0.057282954454422
decider.linear3.weight: -0.026572898030281067 0.07308393716812134
decider.linear3.bias: -0.00683620385825634 0.04951721057295799

Rewards:
230.1930
230.1930
230.1930
objective = 14.508479118347168
==== episode 3300/10000 ====
action = 1
probs = 0.0045 0.9955 0.0000 0.0000

action = 1
probs = 0.0565 0.9434 0.0000 0.0000

action = 0
probs = 0.8311 0.1689 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000291347416350618 0.08608439564704895
encoder.encoder.weight_hh_l0: 1.2685298997894279e-06 0.08795064687728882
encoder.encoder.bias_ih_l0: 0.014965525828301907 0.08960370719432831
encoder.encoder.bias_hh_l0: 0.024962622672319412 0.08766952157020569
encoder.encoder.weight_ih_l0_reverse: 0.0019109973218291998 0.08832382410764694
encoder.encoder.weight_hh_l0_reverse: 0.009497996419668198 0.08796791732311249
encoder.encoder.bias_ih_l0_reverse: 0.03631707280874252 0.08591309934854507
encoder.encoder.bias_hh_l0_reverse: 0.02818264439702034 0.08301547169685364
decider.lstm.weight_ih_l0: 0.0021893067751079798 0.14909709990024567
decider.lstm.weight_hh_l0: 0.0033195060677826405 0.14865128695964813
decider.lstm.bias_ih_l0: 0.02568080648779869 0.15969717502593994
decider.lstm.bias_hh_l0: 0.006693301256746054 0.14081647992134094
decider.linear1.weight: 0.004347692243754864 0.12174859642982483
decider.linear1.bias: 0.020271755754947662 0.11737317591905594
decider.linear2.weight: 0.005019061267375946 0.05393242835998535
decider.linear2.bias: 0.008227339945733547 0.05729535222053528
decider.linear3.weight: -0.02675968036055565 0.07333716005086899
decider.linear3.bias: -0.006877283565700054 0.04983910918235779

Rewards:
230.1930
230.1930
230.1930
objective = 19.010133743286133
==== episode 3400/10000 ====
action = 1
probs = 0.0035 0.9965 0.0000 0.0000

action = 1
probs = 0.0516 0.9484 0.0000 0.0000

action = 0
probs = 0.8852 0.1148 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00029945038841106 0.0861525684595108
encoder.encoder.weight_hh_l0: -5.204546141612809e-06 0.08804205060005188
encoder.encoder.bias_ih_l0: 0.015167214907705784 0.08971864730119705
encoder.encoder.bias_hh_l0: 0.02516431361436844 0.08776886016130447
encoder.encoder.weight_ih_l0_reverse: 0.0019183967960998416 0.08841437101364136
encoder.encoder.weight_hh_l0_reverse: 0.009477619081735611 0.08797118067741394
encoder.encoder.bias_ih_l0_reverse: 0.03640107810497284 0.08597135543823242
encoder.encoder.bias_hh_l0_reverse: 0.028266659006476402 0.083027184009552
decider.lstm.weight_ih_l0: 0.002240427304059267 0.14914798736572266
decider.lstm.weight_hh_l0: 0.003358485409989953 0.14869272708892822
decider.lstm.bias_ih_l0: 0.025971785187721252 0.15972557663917542
decider.lstm.bias_hh_l0: 0.006984280422329903 0.14084234833717346
decider.linear1.weight: 0.004346832633018494 0.12180545181035995
decider.linear1.bias: 0.020506763830780983 0.11736731976270676
decider.linear2.weight: 0.005099072121083736 0.05397135764360428
decider.linear2.bias: 0.00834554061293602 0.05729063227772713
decider.linear3.weight: -0.02694854885339737 0.07373477518558502
decider.linear3.bias: -0.006922232918441296 0.04973774775862694

Rewards:
230.1930
230.1930
230.1930
objective = 13.695834159851074
==== episode 3500/10000 ====
action = 1
probs = 0.0031 0.9969 0.0000 0.0000

action = 1
probs = 0.0501 0.9499 0.0000 0.0000

action = 1
probs = 0.9105 0.0895 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003053574182558805 0.08619221299886703
encoder.encoder.weight_hh_l0: -8.596896805102006e-06 0.0880940780043602
encoder.encoder.bias_ih_l0: 0.015280988067388535 0.08978428691625595
encoder.encoder.bias_hh_l0: 0.025278091430664062 0.08782805502414703
encoder.encoder.weight_ih_l0_reverse: 0.0019260859116911888 0.08846329152584076
encoder.encoder.weight_hh_l0_reverse: 0.009470543824136257 0.08797746151685715
encoder.encoder.bias_ih_l0_reverse: 0.036459486931562424 0.08600375056266785
encoder.encoder.bias_hh_l0_reverse: 0.028325065970420837 0.08303200453519821
decider.lstm.weight_ih_l0: 0.002267539966851473 0.14917394518852234
decider.lstm.weight_hh_l0: 0.0033788029104471207 0.14871522784233093
decider.lstm.bias_ih_l0: 0.026125848293304443 0.15974368155002594
decider.lstm.bias_hh_l0: 0.007138342596590519 0.14084629714488983
decider.linear1.weight: 0.004346537869423628 0.12183848768472672
decider.linear1.bias: 0.020645737648010254 0.11735161393880844
decider.linear2.weight: 0.005146212875843048 0.05399547889828682
decider.linear2.bias: 0.00841537769883871 0.057280149310827255
decider.linear3.weight: -0.027109015733003616 0.07405786216259003
decider.linear3.bias: -0.006954969372600317 0.049673594534397125

Rewards:
217.8160
217.8160
217.8160
objective = 179.1695556640625
==== episode 3600/10000 ====
action = 1
probs = 0.0049 0.9951 0.0000 0.0000

action = 1
probs = 0.1007 0.8993 0.0000 0.0000

action = 0
probs = 0.9456 0.0544 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00028161838417872787 0.08615849912166595
encoder.encoder.weight_hh_l0: -3.306281541881617e-06 0.08806029707193375
encoder.encoder.bias_ih_l0: 0.015136467292904854 0.08980412781238556
encoder.encoder.bias_hh_l0: 0.025133570656180382 0.0877772718667984
encoder.encoder.weight_ih_l0_reverse: 0.0019168280996382236 0.08840762078762054
encoder.encoder.weight_hh_l0_reverse: 0.009477552957832813 0.08798262476921082
encoder.encoder.bias_ih_l0_reverse: 0.0363006517291069 0.08600746095180511
encoder.encoder.bias_hh_l0_reverse: 0.02816622518002987 0.08296685665845871
decider.lstm.weight_ih_l0: 0.00223546358756721 0.14916154742240906
decider.lstm.weight_hh_l0: 0.0033539682626724243 0.14870226383209229
decider.lstm.bias_ih_l0: 0.02595839835703373 0.15971358120441437
decider.lstm.bias_hh_l0: 0.006970889866352081 0.1408538669347763
decider.linear1.weight: 0.0043477872386574745 0.12181563675403595
decider.linear1.bias: 0.020517608150839806 0.11738596856594086
decider.linear2.weight: 0.005173279903829098 0.053995195776224136
decider.linear2.bias: 0.008451716043055058 0.05722916126251221
decider.linear3.weight: -0.027278948575258255 0.07432065159082413
decider.linear3.bias: -0.006989423651248217 0.04898820444941521

Rewards:
230.1930
230.1930
230.1930
objective = 12.80896282196045
==== episode 3700/10000 ====
action = 1
probs = 0.0065 0.9935 0.0000 0.0000

action = 1
probs = 0.1853 0.8147 0.0000 0.0000

action = 0
probs = 0.9763 0.0237 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002876219223253429 0.0862051397562027
encoder.encoder.weight_hh_l0: -6.615960501221707e-06 0.08812616765499115
encoder.encoder.bias_ih_l0: 0.015314568765461445 0.08991695195436478
encoder.encoder.bias_hh_l0: 0.02531166933476925 0.08782412856817245
encoder.encoder.weight_ih_l0_reverse: 0.0019138648640364408 0.08845779299736023
encoder.encoder.weight_hh_l0_reverse: 0.009450733661651611 0.08796066045761108
encoder.encoder.bias_ih_l0_reverse: 0.036307550966739655 0.08605412393808365
encoder.encoder.bias_hh_l0_reverse: 0.02817312628030777 0.0828922837972641
decider.lstm.weight_ih_l0: 0.0022527289111167192 0.14920292794704437
decider.lstm.weight_hh_l0: 0.0033702824730426073 0.14873196184635162
decider.lstm.bias_ih_l0: 0.026092424988746643 0.15973040461540222
decider.lstm.bias_hh_l0: 0.007104912772774696 0.14088477194309235
decider.linear1.weight: 0.004349716939032078 0.12186249345541
decider.linear1.bias: 0.020682349801063538 0.11741138994693756
decider.linear2.weight: 0.005285374354571104 0.054038580507040024
decider.linear2.bias: 0.00861422810703516 0.05718835070729256
decider.linear3.weight: -0.027451083064079285 0.07467532902956009
decider.linear3.bias: -0.0070398906245827675 0.048259466886520386

Rewards:
230.1930
230.1930
230.1930
objective = 18.063615798950195
==== episode 3800/10000 ====
action = 1
probs = 0.0049 0.9951 0.0000 0.0000

action = 1
probs = 0.1528 0.8472 0.0000 0.0000

action = 0
probs = 0.9763 0.0237 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000301107473205775 0.08624923229217529
encoder.encoder.weight_hh_l0: -9.216475518769585e-06 0.0881737470626831
encoder.encoder.bias_ih_l0: 0.015412084758281708 0.08996358513832092
encoder.encoder.bias_hh_l0: 0.02540918067097664 0.08788049221038818
encoder.encoder.weight_ih_l0_reverse: 0.0019217046210542321 0.08849684149026871
encoder.encoder.weight_hh_l0_reverse: 0.009449174627661705 0.08797381073236465
encoder.encoder.bias_ih_l0_reverse: 0.03637973219156265 0.08607286214828491
encoder.encoder.bias_hh_l0_reverse: 0.02824530564248562 0.08290490508079529
decider.lstm.weight_ih_l0: 0.00227683549746871 0.14922231435775757
decider.lstm.weight_hh_l0: 0.0033859186805784702 0.14875668287277222
decider.lstm.bias_ih_l0: 0.02622906118631363 0.1597648411989212
decider.lstm.bias_hh_l0: 0.007241549901664257 0.1408562958240509
decider.linear1.weight: 0.004344799555838108 0.12189023941755295
decider.linear1.bias: 0.02078884467482567 0.11742092669010162
decider.linear2.weight: 0.005300397984683514 0.05406137555837631
decider.linear2.bias: 0.008646408095955849 0.05711626634001732
decider.linear3.weight: -0.02761562168598175 0.0749916210770607
decider.linear3.bias: -0.00708630308508873 0.04843604192137718

Rewards:
230.1930
230.1930
230.1930
objective = 14.938423156738281
==== episode 3900/10000 ====
action = 1
probs = 0.0054 0.9946 0.0000 0.0000

action = 1
probs = 0.1513 0.8487 0.0000 0.0000

action = 0
probs = 0.9765 0.0235 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00029614954837597907 0.0862065926194191
encoder.encoder.weight_hh_l0: -6.2925696511229035e-06 0.08812367916107178
encoder.encoder.bias_ih_l0: 0.015276927500963211 0.08991191536188126
encoder.encoder.bias_hh_l0: 0.02527402527630329 0.08784717321395874
encoder.encoder.weight_ih_l0_reverse: 0.0019216170767322183 0.08847848325967789
encoder.encoder.weight_hh_l0_reverse: 0.009449133649468422 0.08797846734523773
encoder.encoder.bias_ih_l0_reverse: 0.036338768899440765 0.08606604486703873
encoder.encoder.bias_hh_l0_reverse: 0.028204340487718582 0.08292285352945328
decider.lstm.weight_ih_l0: 0.0022648668382316828 0.1492142230272293
decider.lstm.weight_hh_l0: 0.0033739160280674696 0.1487550288438797
decider.lstm.bias_ih_l0: 0.02615397982299328 0.15975943207740784
decider.lstm.bias_hh_l0: 0.007166466675698757 0.1408763974905014
decider.linear1.weight: 0.004345552530139685 0.12186939269304276
decider.linear1.bias: 0.020712794736027718 0.11743883043527603
decider.linear2.weight: 0.00528712198138237 0.05404936894774437
decider.linear2.bias: 0.008626233786344528 0.05710797756910324
decider.linear3.weight: -0.02776098996400833 0.07523498684167862
decider.linear3.bias: -0.0071256402879953384 0.048405811190605164

Rewards:
230.1930
230.1930
230.1930
objective = 14.830424308776855
==== episode 4000/10000 ====
action = 1
probs = 0.0063 0.9937 0.0000 0.0000

action = 1
probs = 0.1579 0.8421 0.0000 0.0000

action = 0
probs = 0.9727 0.0273 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00028359732823446393 0.08615833520889282
encoder.encoder.weight_hh_l0: -2.7711032544175396e-06 0.08806553483009338
encoder.encoder.bias_ih_l0: 0.015107854269444942 0.08985628187656403
encoder.encoder.bias_hh_l0: 0.025104951113462448 0.08779119700193405
encoder.encoder.weight_ih_l0_reverse: 0.0019169547595083714 0.08843062818050385
encoder.encoder.weight_hh_l0_reverse: 0.009461511857807636 0.08799085766077042
encoder.encoder.bias_ih_l0_reverse: 0.03625863417983055 0.08604207634925842
encoder.encoder.bias_hh_l0_reverse: 0.028124207630753517 0.08294229209423065
decider.lstm.weight_ih_l0: 0.002241358859464526 0.1491864174604416
decider.lstm.weight_hh_l0: 0.003353424370288849 0.14873237907886505
decider.lstm.bias_ih_l0: 0.026005543768405914 0.1597355157136917
decider.lstm.bias_hh_l0: 0.0070180282928049564 0.1408635824918747
decider.linear1.weight: 0.004347688984125853 0.1218356043100357
decider.linear1.bias: 0.02056456357240677 0.11743851751089096
decider.linear2.weight: 0.005249847657978535 0.05402633547782898
decider.linear2.bias: 0.008570576086640358 0.05711125209927559
decider.linear3.weight: -0.027943827211856842 0.07552871853113174
decider.linear3.bias: -0.007180728018283844 0.048421118408441544

Rewards:
230.1930
230.1930
230.1930
objective = 15.793458938598633
==== episode 4100/10000 ====
action = 1
probs = 0.0070 0.9930 0.0000 0.0000

action = 0
probs = 0.2166 0.7834 0.0000 0.0000

action = 0
probs = 0.9823 0.0177 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000285067391814664 0.08619417995214462
encoder.encoder.weight_hh_l0: -1.6084909475466702e-06 0.08810846507549286
encoder.encoder.bias_ih_l0: 0.015218283981084824 0.08993683010339737
encoder.encoder.bias_hh_l0: 0.025215383619070053 0.08782467991113663
encoder.encoder.weight_ih_l0_reverse: 0.0019149152794852853 0.08846037089824677
encoder.encoder.weight_hh_l0_reverse: 0.009457170963287354 0.08799044042825699
encoder.encoder.bias_ih_l0_reverse: 0.03626486286520958 0.08607476204633713
encoder.encoder.bias_hh_l0_reverse: 0.028130434453487396 0.08291125297546387
decider.lstm.weight_ih_l0: 0.0022536334581673145 0.14921502768993378
decider.lstm.weight_hh_l0: 0.0033626295626163483 0.14875659346580505
decider.lstm.bias_ih_l0: 0.02608165144920349 0.15975269675254822
decider.lstm.bias_hh_l0: 0.007094136439263821 0.14087949693202972
decider.linear1.weight: 0.004347015637904406 0.1218625158071518
decider.linear1.bias: 0.02064954861998558 0.11744000762701035
decider.linear2.weight: 0.005304682068526745 0.054054148495197296
decider.linear2.bias: 0.008644696325063705 0.05710191652178764
decider.linear3.weight: -0.02814081311225891 0.0759250670671463
decider.linear3.bias: -0.007239939644932747 0.048045434057712555

Rewards:
221.7540
221.7540
221.7540
objective = 114.92528533935547
==== episode 4200/10000 ====
action = 1
probs = 0.0042 0.9958 0.0000 0.0000

action = 1
probs = 0.1383 0.8617 0.0000 0.0000

action = 0
probs = 0.9754 0.0246 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003056274144910276 0.08625497668981552
encoder.encoder.weight_hh_l0: -4.518150944932131e-06 0.0881720557808876
encoder.encoder.bias_ih_l0: 0.0153506426140666 0.08998427540063858
encoder.encoder.bias_hh_l0: 0.02534775249660015 0.08790501952171326
encoder.encoder.weight_ih_l0_reverse: 0.001924623386003077 0.08850781619548798
encoder.encoder.weight_hh_l0_reverse: 0.009456945583224297 0.08800848573446274
encoder.encoder.bias_ih_l0_reverse: 0.03637101501226425 0.08608970791101456
encoder.encoder.bias_hh_l0_reverse: 0.02823658473789692 0.08293703198432922
decider.lstm.weight_ih_l0: 0.0022872283589094877 0.1492380052804947
decider.lstm.weight_hh_l0: 0.0033840849064290524 0.14878450334072113
decider.lstm.bias_ih_l0: 0.02625495195388794 0.15980218350887299
decider.lstm.bias_hh_l0: 0.007267442997545004 0.14085102081298828
decider.linear1.weight: 0.004338807426393032 0.12188920378684998
decider.linear1.bias: 0.020734185352921486 0.11742508411407471
decider.linear2.weight: 0.00529111735522747 0.05406738445162773
decider.linear2.bias: 0.008613688871264458 0.057103481143713
decider.linear3.weight: -0.028336051851511 0.07632908970117569
decider.linear3.bias: -0.007300004828721285 0.048554424196481705

Rewards:
230.1930
230.1930
230.1930
objective = 13.659141540527344
==== episode 4300/10000 ====
action = 1
probs = 0.0054 0.9946 0.0000 0.0000

action = 1
probs = 0.2210 0.7790 0.0000 0.0000

action = 0
probs = 0.9854 0.0146 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00030198736931197345 0.08627437800168991
encoder.encoder.weight_hh_l0: -3.6209821701049805e-06 0.08819905668497086
encoder.encoder.bias_ih_l0: 0.015423135831952095 0.09005261212587357
encoder.encoder.bias_hh_l0: 0.02542024292051792 0.0879158303141594
encoder.encoder.weight_ih_l0_reverse: 0.001920095644891262 0.08852013945579529
encoder.encoder.weight_hh_l0_reverse: 0.009451089426875114 0.08800022304058075
encoder.encoder.bias_ih_l0_reverse: 0.03634078800678253 0.08611033856868744
encoder.encoder.bias_hh_l0_reverse: 0.02820635214447975 0.08289577066898346
decider.lstm.weight_ih_l0: 0.0022895471192896366 0.14925575256347656
decider.lstm.weight_hh_l0: 0.0033874150831252337 0.1487964540719986
decider.lstm.bias_ih_l0: 0.02627977356314659 0.15980371832847595
decider.lstm.bias_hh_l0: 0.00729226041585207 0.1408648043870926
decider.linear1.weight: 0.004340628162026405 0.12191201001405716
decider.linear1.bias: 0.02080666646361351 0.11743001639842987
decider.linear2.weight: 0.0053498465567827225 0.0540938638150692
decider.linear2.bias: 0.008694260381162167 0.05709385871887207
decider.linear3.weight: -0.028512943536043167 0.07669690251350403
decider.linear3.bias: -0.007353121414780617 0.048063311725854874

Rewards:
230.1930
230.1930
230.1930
objective = 20.708274841308594
==== episode 4400/10000 ====
action = 1
probs = 0.0055 0.9945 0.0000 0.0000

action = 1
probs = 0.2686 0.7314 0.0000 0.0000

action = 0
probs = 0.9885 0.0115 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003019374853465706 0.08630046248435974
encoder.encoder.weight_hh_l0: -2.841853984136833e-06 0.08822879940271378
encoder.encoder.bias_ih_l0: 0.015483281575143337 0.09010136872529984
encoder.encoder.bias_hh_l0: 0.02548038400709629 0.08794049173593521
encoder.encoder.weight_ih_l0_reverse: 0.0019171041203662753 0.08853429555892944
encoder.encoder.weight_hh_l0_reverse: 0.009450322948396206 0.08800093829631805
encoder.encoder.bias_ih_l0_reverse: 0.03634132072329521 0.08612881600856781
encoder.encoder.bias_hh_l0_reverse: 0.02820688858628273 0.0828772783279419
decider.lstm.weight_ih_l0: 0.0022959664929658175 0.1492714285850525
decider.lstm.weight_hh_l0: 0.003392560174688697 0.14881107211112976
decider.lstm.bias_ih_l0: 0.026321567595005035 0.15982145071029663
decider.lstm.bias_hh_l0: 0.007334050722420216 0.14085990190505981
decider.linear1.weight: 0.00433861929923296 0.12193170934915543
decider.linear1.bias: 0.020870041102170944 0.11742934584617615
decider.linear2.weight: 0.005380589514970779 0.05411396920681
decider.linear2.bias: 0.00873437151312828 0.057081423699855804
decider.linear3.weight: -0.028700808063149452 0.07709099352359772
decider.linear3.bias: -0.007406481541693211 0.04788042604923248

Rewards:
230.1930
230.1930
230.1930
objective = 25.31049919128418
==== episode 4500/10000 ====
action = 1
probs = 0.0077 0.9923 0.0000 0.0000

action = 1
probs = 0.2818 0.7182 0.0000 0.0000

action = 0
probs = 0.9912 0.0088 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00029976319638080895 0.08623524755239487
encoder.encoder.weight_hh_l0: -1.9590854662965285e-06 0.08815614879131317
encoder.encoder.bias_ih_l0: 0.015343709848821163 0.09002172946929932
encoder.encoder.bias_hh_l0: 0.025340816006064415 0.08787822723388672
encoder.encoder.weight_ih_l0_reverse: 0.0019247704185545444 0.0885365828871727
encoder.encoder.weight_hh_l0_reverse: 0.009433596394956112 0.08799199759960175
encoder.encoder.bias_ih_l0_reverse: 0.03631278872489929 0.08612076193094254
encoder.encoder.bias_hh_l0_reverse: 0.028178362175822258 0.08288002759218216
decider.lstm.weight_ih_l0: 0.0022822620812803507 0.14927034080028534
decider.lstm.weight_hh_l0: 0.003380988258868456 0.14881771802902222
decider.lstm.bias_ih_l0: 0.026252415031194687 0.1598140150308609
decider.lstm.bias_hh_l0: 0.007264896761626005 0.1409391313791275
decider.linear1.weight: 0.0043480596505105495 0.12191089242696762
decider.linear1.bias: 0.02081930823624134 0.11745347827672958
decider.linear2.weight: 0.0054190196096897125 0.05410769209265709
decider.linear2.bias: 0.008752488531172276 0.05708518624305725
decider.linear3.weight: -0.028877122327685356 0.07744863629341125
decider.linear3.bias: -0.0074607739225029945 0.04758480563759804

Rewards:
230.1930
230.1930
230.1930
objective = 26.672409057617188
==== episode 4600/10000 ====
action = 1
probs = 0.0056 0.9944 0.0000 0.0000

action = 1
probs = 0.2420 0.7580 0.0000 0.0000

action = 0
probs = 0.9894 0.0106 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000305704161291942 0.08626308292150497
encoder.encoder.weight_hh_l0: -4.958391173204291e-07 0.0881766527891159
encoder.encoder.bias_ih_l0: 0.015346065163612366 0.09003570675849915
encoder.encoder.bias_hh_l0: 0.025343172252178192 0.08789384365081787
encoder.encoder.weight_ih_l0_reverse: 0.001935821259394288 0.08853779733181
encoder.encoder.weight_hh_l0_reverse: 0.009450141340494156 0.08802333474159241
encoder.encoder.bias_ih_l0_reverse: 0.03635013848543167 0.08612228184938431
encoder.encoder.bias_hh_l0_reverse: 0.028215710073709488 0.0828947126865387
decider.lstm.weight_ih_l0: 0.0022937713656574488 0.14927835762500763
decider.lstm.weight_hh_l0: 0.0033871405757963657 0.14883926510810852
decider.lstm.bias_ih_l0: 0.026291264221072197 0.15986715257167816
decider.lstm.bias_hh_l0: 0.0073037464171648026 0.14089494943618774
decider.linear1.weight: 0.0043441299349069595 0.12192435562610626
decider.linear1.bias: 0.020822441205382347 0.11742829531431198
decider.linear2.weight: 0.005376739427447319 0.05412540212273598
decider.linear2.bias: 0.008706187829375267 0.057094451040029526
decider.linear3.weight: -0.029092812910676003 0.07790402323007584
decider.linear3.bias: -0.007532014511525631 0.04786146804690361

Rewards:
230.1930
230.1930
230.1930
objective = 22.512617111206055
==== episode 4700/10000 ====
action = 1
probs = 0.0055 0.9945 0.0000 0.0000

action = 1
probs = 0.1519 0.8481 0.0000 0.0000

action = 0
probs = 0.9721 0.0279 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00028363816090859473 0.08611062914133072
encoder.encoder.weight_hh_l0: 3.8133143789309543e-06 0.08798923343420029
encoder.encoder.bias_ih_l0: 0.014827549457550049 0.08977707475423813
encoder.encoder.bias_hh_l0: 0.024824656546115875 0.08772176504135132
encoder.encoder.weight_ih_l0_reverse: 0.0019341465085744858 0.0884043425321579
encoder.encoder.weight_hh_l0_reverse: 0.009484890848398209 0.08805648237466812
encoder.encoder.bias_ih_l0_reverse: 0.03620046377182007 0.0860428512096405
encoder.encoder.bias_hh_l0_reverse: 0.028066039085388184 0.08297786116600037
decider.lstm.weight_ih_l0: 0.0022223065607249737 0.14917351305484772
decider.lstm.weight_hh_l0: 0.0033327299170196056 0.14876970648765564
decider.lstm.bias_ih_l0: 0.025876136496663094 0.15983544290065765
decider.lstm.bias_hh_l0: 0.006888632662594318 0.14082071185112
decider.linear1.weight: 0.004343561362475157 0.12183745950460434
decider.linear1.bias: 0.020452046766877174 0.11739812046289444
decider.linear2.weight: 0.00522274523973465 0.054047148674726486
decider.linear2.bias: 0.008516937494277954 0.05704604461789131
decider.linear3.weight: -0.029280852526426315 0.07818644493818283
decider.linear3.bias: -0.007591863162815571 0.04845524951815605

Rewards:
230.1930
230.1930
230.1930
objective = 15.234911918640137
==== episode 4800/10000 ====
action = 1
probs = 0.0052 0.9948 0.0000 0.0000

action = 0
probs = 0.1289 0.8711 0.0000 0.0000

action = 0
probs = 0.9781 0.0219 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00029404571978375316 0.08612378686666489
encoder.encoder.weight_hh_l0: 2.09178915611119e-06 0.08800998330116272
encoder.encoder.bias_ih_l0: 0.014894885942339897 0.08979130536317825
encoder.encoder.bias_hh_l0: 0.024891996756196022 0.08777669072151184
encoder.encoder.weight_ih_l0_reverse: 0.001933305524289608 0.08846081048250198
encoder.encoder.weight_hh_l0_reverse: 0.00946012046188116 0.08805014938116074
encoder.encoder.bias_ih_l0_reverse: 0.03625364601612091 0.08607427030801773
encoder.encoder.bias_hh_l0_reverse: 0.02811921387910843 0.08298641443252563
decider.lstm.weight_ih_l0: 0.0022423663176596165 0.14919191598892212
decider.lstm.weight_hh_l0: 0.0033454138319939375 0.14879067242145538
decider.lstm.bias_ih_l0: 0.025997217744588852 0.15984924137592316
decider.lstm.bias_hh_l0: 0.007009705528616905 0.14085975289344788
decider.linear1.weight: 0.004350222181528807 0.12186059355735779
decider.linear1.bias: 0.02057773806154728 0.11744465678930283
decider.linear2.weight: 0.005272970534861088 0.0540652871131897
decider.linear2.bias: 0.008564255200326443 0.057029906660318375
decider.linear3.weight: -0.029482560232281685 0.07864191383123398
decider.linear3.bias: -0.007655911613255739 0.048437200486660004

Rewards:
221.7540
221.7540
221.7540
objective = 153.43704223632812
==== episode 4900/10000 ====
action = 1
probs = 0.0043 0.9957 0.0000 0.0000

action = 1
probs = 0.1054 0.8945 0.0000 0.0000

action = 0
probs = 0.9599 0.0401 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002815739717334509 0.08610668033361435
encoder.encoder.weight_hh_l0: 4.320311290939571e-06 0.08797512203454971
encoder.encoder.bias_ih_l0: 0.01473703607916832 0.08974402397871017
encoder.encoder.bias_hh_l0: 0.024734146893024445 0.08773796260356903
encoder.encoder.weight_ih_l0_reverse: 0.0019360613077878952 0.08839699625968933
encoder.encoder.weight_hh_l0_reverse: 0.009491745382547379 0.08807814866304398
encoder.encoder.bias_ih_l0_reverse: 0.03619086369872093 0.0860356017947197
encoder.encoder.bias_hh_l0_reverse: 0.028056427836418152 0.08302148431539536
decider.lstm.weight_ih_l0: 0.0022268423344939947 0.14916546642780304
decider.lstm.weight_hh_l0: 0.0033310630824416876 0.14876903593540192
decider.lstm.bias_ih_l0: 0.025876138359308243 0.1598469763994217
decider.lstm.bias_hh_l0: 0.006888633128255606 0.14080050587654114
decider.linear1.weight: 0.0043409294448792934 0.12182705849409103
decider.linear1.bias: 0.0203932486474514 0.11738137900829315
decider.linear2.weight: 0.005167992319911718 0.05403623357415199
decider.linear2.bias: 0.008435062132775784 0.05706871673464775
decider.linear3.weight: -0.02969025820493698 0.07902594655752182
decider.linear3.bias: -0.007722052279859781 0.048863496631383896

Rewards:
230.1930
230.1930
230.1930
objective = 12.025385856628418
==== episode 5000/10000 ====
action = 1
probs = 0.0058 0.9942 0.0000 0.0000

action = 1
probs = 0.1139 0.8861 0.0000 0.0000

action = 0
probs = 0.9704 0.0296 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00027159086312167346 0.08601509034633636
encoder.encoder.weight_hh_l0: 2.5835395263129612e-06 0.08787978440523148
encoder.encoder.bias_ih_l0: 0.014534241519868374 0.08961521834135056
encoder.encoder.bias_hh_l0: 0.024531351402401924 0.08767253160476685
encoder.encoder.weight_ih_l0_reverse: 0.0019273679936304688 0.08837741613388062
encoder.encoder.weight_hh_l0_reverse: 0.009464944712817669 0.0880502387881279
encoder.encoder.bias_ih_l0_reverse: 0.03612830117344856 0.08602945506572723
encoder.encoder.bias_hh_l0_reverse: 0.027993859723210335 0.0830167606472969
decider.lstm.weight_ih_l0: 0.002176981884986162 0.1491064876317978
decider.lstm.weight_hh_l0: 0.003300173906609416 0.1487293392419815
decider.lstm.bias_ih_l0: 0.025664670392870903 0.159779891371727
decider.lstm.bias_hh_l0: 0.006677162833511829 0.14081351459026337
decider.linear1.weight: 0.004349495749920607 0.1218140572309494
decider.linear1.bias: 0.020395882427692413 0.11745733767747879
decider.linear2.weight: 0.005206522531807423 0.05402899160981178
decider.linear2.bias: 0.008491487242281437 0.057001855224370956
decider.linear3.weight: -0.029902756214141846 0.07948160171508789
decider.linear3.bias: -0.007788956165313721 0.04859036207199097

Rewards:
230.1930
230.1930
230.1930
objective = 12.032733917236328
==== episode 5100/10000 ====
action = 1
probs = 0.0083 0.9917 0.0000 0.0000

action = 0
probs = 0.1643 0.8357 0.0000 0.0000

action = 0
probs = 0.9678 0.0322 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002433199406368658 0.08591615408658981
encoder.encoder.weight_hh_l0: 5.0514936447143555e-06 0.08775781095027924
encoder.encoder.bias_ih_l0: 0.014199790544807911 0.08950049430131912
encoder.encoder.bias_hh_l0: 0.02419690042734146 0.08752133697271347
encoder.encoder.weight_ih_l0_reverse: 0.0019343507010489702 0.08826246857643127
encoder.encoder.weight_hh_l0_reverse: 0.009500323794782162 0.08806628733873367
encoder.encoder.bias_ih_l0_reverse: 0.03595803678035736 0.08596759289503098
encoder.encoder.bias_hh_l0_reverse: 0.02782360091805458 0.08300158381462097
decider.lstm.weight_ih_l0: 0.0021097247954458 0.14905284345149994
decider.lstm.weight_hh_l0: 0.0032542042899876833 0.14868274331092834
decider.lstm.bias_ih_l0: 0.025303915143013 0.1597224324941635
decider.lstm.bias_hh_l0: 0.006316408049315214 0.14078688621520996
decider.linear1.weight: 0.0043415832333266735 0.12175455689430237
decider.linear1.bias: 0.020124707370996475 0.11741368472576141
decider.linear2.weight: 0.00513103324919939 0.05399613082408905
decider.linear2.bias: 0.008411407470703125 0.05702339485287666
decider.linear3.weight: -0.030174270272254944 0.07997995615005493
decider.linear3.bias: -0.007880778051912785 0.048297613859176636

Rewards:
221.7540
221.7540
221.7540
objective = 136.52987670898438
==== episode 5200/10000 ====
action = 1
probs = 0.0115 0.9885 0.0000 0.0000

action = 1
probs = 0.2661 0.7339 0.0000 0.0000

action = 0
probs = 0.9838 0.0162 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002432217006571591 0.08595556020736694
encoder.encoder.weight_hh_l0: 7.858145181671716e-06 0.08780977874994278
encoder.encoder.bias_ih_l0: 0.014343301765620708 0.08960234373807907
encoder.encoder.bias_hh_l0: 0.024340417236089706 0.08756332099437714
encoder.encoder.weight_ih_l0_reverse: 0.0019186475547030568 0.0882960706949234
encoder.encoder.weight_hh_l0_reverse: 0.00948373693972826 0.08805736154317856
encoder.encoder.bias_ih_l0_reverse: 0.03594059869647026 0.08599534630775452
encoder.encoder.bias_hh_l0_reverse: 0.02780616283416748 0.08294511586427689
decider.lstm.weight_ih_l0: 0.0021315657068043947 0.14910081028938293
decider.lstm.weight_hh_l0: 0.003267180873081088 0.14871670305728912
decider.lstm.bias_ih_l0: 0.02543528750538826 0.15970897674560547
decider.lstm.bias_hh_l0: 0.0064477818086743355 0.14084862172603607
decider.linear1.weight: 0.004347046837210655 0.1217799112200737
decider.linear1.bias: 0.02025066874921322 0.11745470017194748
decider.linear2.weight: 0.005222066771239042 0.05403067544102669
decider.linear2.bias: 0.008528755977749825 0.05701420083642006
decider.linear3.weight: -0.03050587698817253 0.08072749525308609
decider.linear3.bias: -0.008007101714611053 0.04767709597945213

Rewards:
230.1930
230.1930
230.1930
objective = 25.883373260498047
==== episode 5300/10000 ====
action = 1
probs = 0.0090 0.9910 0.0000 0.0000

action = 1
probs = 0.1295 0.8705 0.0000 0.0000

action = 0
probs = 0.9709 0.0291 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00024586261133663356 0.08585865050554276
encoder.encoder.weight_hh_l0: 4.265713414497441e-06 0.08769046515226364
encoder.encoder.bias_ih_l0: 0.014032687991857529 0.08938123285770416
encoder.encoder.bias_hh_l0: 0.024029802531003952 0.08753471076488495
encoder.encoder.weight_ih_l0_reverse: 0.0019187235739082098 0.08827796578407288
encoder.encoder.weight_hh_l0_reverse: 0.009451978839933872 0.08803405612707138
encoder.encoder.bias_ih_l0_reverse: 0.03593854978680611 0.08597004413604736
encoder.encoder.bias_hh_l0_reverse: 0.027804112061858177 0.08302619308233261
decider.lstm.weight_ih_l0: 0.002064359840005636 0.14897030591964722
decider.lstm.weight_hh_l0: 0.003224004991352558 0.148627370595932
decider.lstm.bias_ih_l0: 0.02511952631175518 0.1596655249595642
decider.lstm.bias_hh_l0: 0.0061320168897509575 0.14075635373592377
decider.linear1.weight: 0.004349189810454845 0.1217583417892456
decider.linear1.bias: 0.020167147740721703 0.11749774217605591
decider.linear2.weight: 0.005177237559109926 0.05399781093001366
decider.linear2.bias: 0.008432582952082157 0.0569523461163044
decider.linear3.weight: -0.030787939205765724 0.0813174918293953
decider.linear3.bias: -0.008120790123939514 0.048395998775959015

Rewards:
230.1930
230.1930
230.1930
objective = 13.608318328857422
==== episode 5400/10000 ====
action = 1
probs = 0.0070 0.9930 0.0000 0.0000

action = 1
probs = 0.0783 0.9216 0.0000 0.0000

action = 0
probs = 0.9114 0.0886 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002421166718704626 0.0857844278216362
encoder.encoder.weight_hh_l0: 2.7198909720027586e-06 0.08759184926748276
encoder.encoder.bias_ih_l0: 0.013722416013479233 0.08918725699186325
encoder.encoder.bias_hh_l0: 0.023719528689980507 0.08747118711471558
encoder.encoder.weight_ih_l0_reverse: 0.0019154304172843695 0.0881691426038742
encoder.encoder.weight_hh_l0_reverse: 0.009432574734091759 0.08799514919519424
encoder.encoder.bias_ih_l0_reverse: 0.035845689475536346 0.08587638288736343
encoder.encoder.bias_hh_l0_reverse: 0.02771124802529812 0.08309149742126465
decider.lstm.weight_ih_l0: 0.0019858218729496002 0.14885318279266357
decider.lstm.weight_hh_l0: 0.003175740595906973 0.14854009449481964
decider.lstm.bias_ih_l0: 0.024714361876249313 0.15976595878601074
decider.lstm.bias_hh_l0: 0.005726859904825687 0.14056988060474396
decider.linear1.weight: 0.004327056929469109 0.12170073390007019
decider.linear1.bias: 0.019861338660120964 0.11743196845054626
decider.linear2.weight: 0.005014085676521063 0.053936317563056946
decider.linear2.bias: 0.00822655763477087 0.05699668079614639
decider.linear3.weight: -0.03109268844127655 0.08187755942344666
decider.linear3.bias: -0.008232813328504562 0.0491882860660553

Rewards:
230.1930
230.1930
230.1930
objective = 13.918075561523438
==== episode 5500/10000 ====
action = 1
probs = 0.0062 0.9938 0.0000 0.0000

action = 1
probs = 0.0806 0.9194 0.0000 0.0000

action = 0
probs = 0.9369 0.0631 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00024349130399059504 0.08588393032550812
encoder.encoder.weight_hh_l0: 1.7889141190607916e-06 0.08771277219057083
encoder.encoder.bias_ih_l0: 0.013948404230177402 0.0893547460436821
encoder.encoder.bias_hh_l0: 0.02394552156329155 0.08758571743965149
encoder.encoder.weight_ih_l0_reverse: 0.0019155206391587853 0.08824429661035538
encoder.encoder.weight_hh_l0_reverse: 0.009514219127595425 0.08810100704431534
encoder.encoder.bias_ih_l0_reverse: 0.03594684228301048 0.0859459638595581
encoder.encoder.bias_hh_l0_reverse: 0.027812404558062553 0.08307313919067383
decider.lstm.weight_ih_l0: 0.0020937882363796234 0.14901652932167053
decider.lstm.weight_hh_l0: 0.003238196950405836 0.1486552208662033
decider.lstm.bias_ih_l0: 0.025244124233722687 0.15973877906799316
decider.lstm.bias_hh_l0: 0.006256624590605497 0.14073772728443146
decider.linear1.weight: 0.0043328930623829365 0.12173442542552948
decider.linear1.bias: 0.019987132400274277 0.11745098978281021
decider.linear2.weight: 0.00505785783752799 0.053966548293828964
decider.linear2.bias: 0.008274834603071213 0.056993186473846436
decider.linear3.weight: -0.03143828362226486 0.0826776847243309
decider.linear3.bias: -0.00834038108587265 0.04907657578587532

Rewards:
230.1930
230.1930
230.1930
objective = 11.919233322143555
==== episode 5600/10000 ====
action = 1
probs = 0.0043 0.9957 0.0000 0.0000

action = 0
probs = 0.0606 0.9394 0.0000 0.0000

action = 0
probs = 0.9504 0.0496 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002596875128801912 0.08599884808063507
encoder.encoder.weight_hh_l0: -1.660525754232367e-06 0.08785393834114075
encoder.encoder.bias_ih_l0: 0.014270484447479248 0.08952277898788452
encoder.encoder.bias_hh_l0: 0.02426760084927082 0.08773798495531082
encoder.encoder.weight_ih_l0_reverse: 0.0019079819321632385 0.08834441751241684
encoder.encoder.weight_hh_l0_reverse: 0.00950256735086441 0.08811461925506592
encoder.encoder.bias_ih_l0_reverse: 0.0360802486538887 0.08600600808858871
encoder.encoder.bias_hh_l0_reverse: 0.027945810928940773 0.08306995034217834
decider.lstm.weight_ih_l0: 0.0021840145345777273 0.1491193324327469
decider.lstm.weight_hh_l0: 0.0032984591089189053 0.14873571693897247
decider.lstm.bias_ih_l0: 0.025717217475175858 0.15980181097984314
decider.lstm.bias_hh_l0: 0.006729724816977978 0.14080308377742767
decider.linear1.weight: 0.004345459397882223 0.12179450690746307
decider.linear1.bias: 0.02023862674832344 0.11748416721820831
decider.linear2.weight: 0.005119689274579287 0.05400800704956055
decider.linear2.bias: 0.008351804688572884 0.05700616538524628
decider.linear3.weight: -0.03167133778333664 0.08327291160821915
decider.linear3.bias: -0.008413460105657578 0.04924969747662544

Rewards:
221.7540
221.7540
221.7540
objective = 211.31712341308594
==== episode 5700/10000 ====
action = 1
probs = 0.0047 0.9953 0.0000 0.0000

action = 1
probs = 0.0654 0.9346 0.0000 0.0000

action = 0
probs = 0.9652 0.0348 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002588507195468992 0.08599824458360672
encoder.encoder.weight_hh_l0: -2.8924464459123556e-06 0.08785849064588547
encoder.encoder.bias_ih_l0: 0.014291378669440746 0.08954019844532013
encoder.encoder.bias_hh_l0: 0.024288492277264595 0.08775512874126434
encoder.encoder.weight_ih_l0_reverse: 0.001908317324705422 0.08837533742189407
encoder.encoder.weight_hh_l0_reverse: 0.009492166340351105 0.08811147511005402
encoder.encoder.bias_ih_l0_reverse: 0.036102961748838425 0.08603230863809586
encoder.encoder.bias_hh_l0_reverse: 0.027968522161245346 0.083062544465065
decider.lstm.weight_ih_l0: 0.0021884175948798656 0.14912177622318268
decider.lstm.weight_hh_l0: 0.003302458208054304 0.14873895049095154
decider.lstm.bias_ih_l0: 0.025758542120456696 0.15976814925670624
decider.lstm.bias_hh_l0: 0.0067710573785007 0.14083972573280334
decider.linear1.weight: 0.004356258548796177 0.12181448936462402
decider.linear1.bias: 0.02034951001405716 0.11752136051654816
decider.linear2.weight: 0.0051673343405127525 0.054027821868658066
decider.linear2.bias: 0.00841415487229824 0.056975968182086945
decider.linear3.weight: -0.0318777859210968 0.08377156406641006
decider.linear3.bias: -0.008483704179525375 0.04906999319791794

Rewards:
230.1930
230.1930
230.1930
objective = 8.274250984191895
==== episode 5800/10000 ====
action = 1
probs = 0.0060 0.9940 0.0000 0.0000

action = 1
probs = 0.0695 0.9305 0.0000 0.0000

action = 0
probs = 0.9729 0.0271 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002501975395716727 0.08590879291296005
encoder.encoder.weight_hh_l0: -1.148915316662169e-06 0.08775520324707031
encoder.encoder.bias_ih_l0: 0.014068374410271645 0.08942294865846634
encoder.encoder.bias_hh_l0: 0.02406548149883747 0.08768156915903091
encoder.encoder.weight_ih_l0_reverse: 0.0019088438712060452 0.0883568748831749
encoder.encoder.weight_hh_l0_reverse: 0.009469231590628624 0.08809005469083786
encoder.encoder.bias_ih_l0_reverse: 0.03604810684919357 0.08602764457464218
encoder.encoder.bias_hh_l0_reverse: 0.027913665398955345 0.08307309448719025
decider.lstm.weight_ih_l0: 0.00212689395993948 0.1490306705236435
decider.lstm.weight_hh_l0: 0.003260072786360979 0.1486785113811493
decider.lstm.bias_ih_l0: 0.025464404374361038 0.15965479612350464
decider.lstm.bias_hh_l0: 0.006476930342614651 0.1408485770225525
decider.linear1.weight: 0.004363866522908211 0.12180479615926743
decider.linear1.bias: 0.020343059673905373 0.11757108569145203
decider.linear2.weight: 0.005186149850487709 0.05402827262878418
decider.linear2.bias: 0.00844697467982769 0.05692952871322632
decider.linear3.weight: -0.03205269202589989 0.08417393267154694
decider.linear3.bias: -0.008546258322894573 0.04887950420379639

Rewards:
230.1930
230.1930
230.1930
objective = 8.097029685974121
==== episode 5900/10000 ====
action = 1
probs = 0.0062 0.9938 0.0000 0.0000

action = 1
probs = 0.0831 0.9169 0.0000 0.0000

action = 0
probs = 0.9793 0.0207 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000250901619438082 0.08595497906208038
encoder.encoder.weight_hh_l0: -6.50954234515666e-07 0.08780995011329651
encoder.encoder.bias_ih_l0: 0.014189998619258404 0.0895121768116951
encoder.encoder.bias_hh_l0: 0.024187106639146805 0.08771989494562149
encoder.encoder.weight_ih_l0_reverse: 0.0019088595872744918 0.08838310092687607
encoder.encoder.weight_hh_l0_reverse: 0.009479864500463009 0.0881061926484108
encoder.encoder.bias_ih_l0_reverse: 0.036062415689229965 0.08605027198791504
encoder.encoder.bias_hh_l0_reverse: 0.027927974238991737 0.08304900676012039
decider.lstm.weight_ih_l0: 0.002166377380490303 0.14909692108631134
decider.lstm.weight_hh_l0: 0.0032846175599843264 0.14872801303863525
decider.lstm.bias_ih_l0: 0.0256565622985363 0.1597093641757965
decider.lstm.bias_hh_l0: 0.006669091992080212 0.14087717235088348
decider.linear1.weight: 0.004367589019238949 0.12182208895683289
decider.linear1.bias: 0.020400499925017357 0.11758459359407425
decider.linear2.weight: 0.005222109146416187 0.05404810979962349
decider.linear2.bias: 0.008488555438816547 0.056934505701065063
decider.linear3.weight: -0.03225008025765419 0.08463644236326218
decider.linear3.bias: -0.00862138532102108 0.04865773022174835

Rewards:
230.1930
230.1930
230.1930
objective = 8.73337459564209
==== episode 6000/10000 ====
action = 1
probs = 0.0068 0.9932 0.0000 0.0000

action = 1
probs = 0.1177 0.8823 0.0000 0.0000

action = 0
probs = 0.9871 0.0129 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002534448285587132 0.08600932359695435
encoder.encoder.weight_hh_l0: -5.984306312711851e-07 0.0878741443157196
encoder.encoder.bias_ih_l0: 0.014349753968417645 0.08962221443653107
encoder.encoder.bias_hh_l0: 0.024346863850951195 0.0877678170800209
encoder.encoder.weight_ih_l0_reverse: 0.0019105866085737944 0.0884203314781189
encoder.encoder.weight_hh_l0_reverse: 0.009490453638136387 0.0881209447979927
encoder.encoder.bias_ih_l0_reverse: 0.0360955186188221 0.08608107268810272
encoder.encoder.bias_hh_l0_reverse: 0.02796107716858387 0.08301475644111633
decider.lstm.weight_ih_l0: 0.002206947887316346 0.1491689383983612
decider.lstm.weight_hh_l0: 0.003310116473585367 0.1487819105386734
decider.lstm.bias_ih_l0: 0.025860019028186798 0.1597583293914795
decider.lstm.bias_hh_l0: 0.006872542202472687 0.14092016220092773
decider.linear1.weight: 0.004373043309897184 0.12184743583202362
decider.linear1.bias: 0.020492790266871452 0.1175839751958847
decider.linear2.weight: 0.005280832760035992 0.05408177524805069
decider.linear2.bias: 0.008556479588150978 0.05693703517317772
decider.linear3.weight: -0.03245162218809128 0.08512228727340698
decider.linear3.bias: -0.008703093975782394 0.048319704830646515

Rewards:
230.1930
230.1930
230.1930
objective = 11.132342338562012
==== episode 6100/10000 ====
action = 1
probs = 0.0027 0.9973 0.0000 0.0000

action = 1
probs = 0.0329 0.9671 0.0000 0.0000

action = 0
probs = 0.9505 0.0495 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00028471541008912027 0.08610835671424866
encoder.encoder.weight_hh_l0: -7.2040315899357665e-06 0.08798208087682724
encoder.encoder.bias_ih_l0: 0.014569138176739216 0.08963342756032944
encoder.encoder.bias_hh_l0: 0.024566249921917915 0.08792100846767426
encoder.encoder.weight_ih_l0_reverse: 0.0019014003919437528 0.08847955614328384
encoder.encoder.weight_hh_l0_reverse: 0.009470575489103794 0.08810317516326904
encoder.encoder.bias_ih_l0_reverse: 0.03624913468956947 0.08608781546354294
encoder.encoder.bias_hh_l0_reverse: 0.028114695101976395 0.08309000730514526
decider.lstm.weight_ih_l0: 0.0022669450845569372 0.14920416474342346
decider.lstm.weight_hh_l0: 0.003353764768689871 0.14880609512329102
decider.lstm.bias_ih_l0: 0.026182476431131363 0.15985655784606934
decider.lstm.bias_hh_l0: 0.007194989360868931 0.14085212349891663
decider.linear1.weight: 0.004359628073871136 0.12186329066753387
decider.linear1.bias: 0.02051088586449623 0.11755727976560593
decider.linear2.weight: 0.005184635519981384 0.05406983196735382
decider.linear2.bias: 0.008419923484325409 0.057003650814294815
decider.linear3.weight: -0.032605357468128204 0.08548640459775925
decider.linear3.bias: -0.008762473240494728 0.04966515675187111

Rewards:
230.1930
230.1930
230.1930
objective = 6.671389579772949
==== episode 6200/10000 ====
action = 1
probs = 0.0012 0.9988 0.0000 0.0000

action = 1
probs = 0.0079 0.9921 0.0000 0.0000

action = 1
probs = 0.4451 0.5548 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003368527686689049 0.08616576343774796
encoder.encoder.weight_hh_l0: -9.068012332136277e-06 0.08802318572998047
encoder.encoder.bias_ih_l0: 0.014848506078124046 0.08949372917413712
encoder.encoder.bias_hh_l0: 0.024845613166689873 0.08788342028856277
encoder.encoder.weight_ih_l0_reverse: 0.0018472507363185287 0.08848816156387329
encoder.encoder.weight_hh_l0_reverse: 0.009399989619851112 0.08800292015075684
encoder.encoder.bias_ih_l0_reverse: 0.036278411746025085 0.08599059283733368
encoder.encoder.bias_hh_l0_reverse: 0.028143972158432007 0.08321630209684372
decider.lstm.weight_ih_l0: 0.0022775058168917894 0.1491723507642746
decider.lstm.weight_hh_l0: 0.003362164832651615 0.1487828940153122
decider.lstm.bias_ih_l0: 0.026220448315143585 0.16003301739692688
decider.lstm.bias_hh_l0: 0.00723295146599412 0.14067894220352173
decider.linear1.weight: 0.004347675014287233 0.12181800603866577
decider.linear1.bias: 0.020430471748113632 0.11741176247596741
decider.linear2.weight: 0.005071671679615974 0.05399462953209877
decider.linear2.bias: 0.008230729028582573 0.0572059229016304
decider.linear3.weight: -0.03278264403343201 0.08581911772489548
decider.linear3.bias: -0.008797802031040192 0.05137338489294052

Rewards:
217.8160
217.8160
217.8160
objective = 43.43798065185547
==== episode 6300/10000 ====
action = 1
probs = 0.0015 0.9985 0.0000 0.0000

action = 1
probs = 0.0106 0.9894 0.0000 0.0000

action = 0
probs = 0.5571 0.4429 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00031408952781930566 0.0861411839723587
encoder.encoder.weight_hh_l0: 1.164436298495275e-07 0.08799134194850922
encoder.encoder.bias_ih_l0: 0.014676494523882866 0.08950204402208328
encoder.encoder.bias_hh_l0: 0.02467360906302929 0.08787840604782104
encoder.encoder.weight_ih_l0_reverse: 0.0018476492259651423 0.08844146877527237
encoder.encoder.weight_hh_l0_reverse: 0.009429113939404488 0.08803562074899673
encoder.encoder.bias_ih_l0_reverse: 0.036190006881952286 0.0859932228922844
encoder.encoder.bias_hh_l0_reverse: 0.028055565431714058 0.08320257812738419
decider.lstm.weight_ih_l0: 0.0022629834711551666 0.1491689383983612
decider.lstm.weight_hh_l0: 0.0033477237448096275 0.1487734317779541
decider.lstm.bias_ih_l0: 0.02613586187362671 0.15997838973999023
decider.lstm.bias_hh_l0: 0.007148365955799818 0.1406927853822708
decider.linear1.weight: 0.00433650566264987 0.12180346995592117
decider.linear1.bias: 0.020335275679826736 0.11742247641086578
decider.linear2.weight: 0.005064681638032198 0.0540030412375927
decider.linear2.bias: 0.008207465521991253 0.05716186389327049
decider.linear3.weight: -0.03293626010417938 0.08620385080575943
decider.linear3.bias: -0.00882560946047306 0.05104194954037666

Rewards:
230.1930
230.1930
230.1930
objective = 45.81831359863281
==== episode 6400/10000 ====
action = 1
probs = 0.0022 0.9977 0.0000 0.0000

action = 1
probs = 0.0238 0.9762 0.0000 0.0000

action = 0
probs = 0.8507 0.1493 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002734169247560203 0.0861063301563263
encoder.encoder.weight_hh_l0: 5.086529199616052e-06 0.08796358853578568
encoder.encoder.bias_ih_l0: 0.014457623474299908 0.08957257866859436
encoder.encoder.bias_hh_l0: 0.024454738944768906 0.08788356930017471
encoder.encoder.weight_ih_l0_reverse: 0.0018722617533057928 0.08840576559305191
encoder.encoder.weight_hh_l0_reverse: 0.00947942491620779 0.08809368312358856
encoder.encoder.bias_ih_l0_reverse: 0.03612983971834183 0.08601828664541245
encoder.encoder.bias_hh_l0_reverse: 0.0279953982681036 0.08312003314495087
decider.lstm.weight_ih_l0: 0.00225579715333879 0.14919395744800568
decider.lstm.weight_hh_l0: 0.003340131137520075 0.14878502488136292
decider.lstm.bias_ih_l0: 0.02609787881374359 0.15988360345363617
decider.lstm.bias_hh_l0: 0.007110379636287689 0.14077605307102203
decider.linear1.weight: 0.004335134290158749 0.1218155175447464
decider.linear1.bias: 0.020321037620306015 0.1174476221203804
decider.linear2.weight: 0.005128446035087109 0.05403663590550423
decider.linear2.bias: 0.008289345540106297 0.05705831199884415
decider.linear3.weight: -0.03315214067697525 0.08679516613483429
decider.linear3.bias: -0.008868411183357239 0.05007142201066017

Rewards:
230.1930
230.1930
230.1930
objective = 14.421487808227539
==== episode 6500/10000 ====
action = 1
probs = 0.0042 0.9958 0.0000 0.0000

action = 1
probs = 0.0539 0.9461 0.0000 0.0000

action = 0
probs = 0.9587 0.0413 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00024224426306318492 0.08601871877908707
encoder.encoder.weight_hh_l0: 1.0433924217068125e-05 0.08787641674280167
encoder.encoder.bias_ih_l0: 0.014204601757228374 0.0895509421825409
encoder.encoder.bias_hh_l0: 0.024201717227697372 0.08779387921094894
encoder.encoder.weight_ih_l0_reverse: 0.0018937361892312765 0.08838289976119995
encoder.encoder.weight_hh_l0_reverse: 0.009498823434114456 0.0881204679608345
encoder.encoder.bias_ih_l0_reverse: 0.036098919808864594 0.08603233844041824
encoder.encoder.bias_hh_l0_reverse: 0.027964476495981216 0.0830421969294548
decider.lstm.weight_ih_l0: 0.0022148641292005777 0.1491616815328598
decider.lstm.weight_hh_l0: 0.003308613318949938 0.14876611530780792
decider.lstm.bias_ih_l0: 0.025888070464134216 0.15975122153759003
decider.lstm.bias_hh_l0: 0.00690055824816227 0.1408545821905136
decider.linear1.weight: 0.004347244277596474 0.12182889878749847
decider.linear1.bias: 0.02035459876060486 0.11750738322734833
decider.linear2.weight: 0.005203799344599247 0.05406974256038666
decider.linear2.bias: 0.008405832573771477 0.05697504058480263
decider.linear3.weight: -0.03334507718682289 0.08731557428836823
decider.linear3.bias: -0.00891985185444355 0.049045804888010025

Rewards:
230.1930
230.1930
230.1930
objective = 7.807762145996094
==== episode 6600/10000 ====
action = 1
probs = 0.0087 0.9913 0.0000 0.0000

action = 0
probs = 0.1692 0.8307 0.0000 0.0000

action = 0
probs = 0.9876 0.0124 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022459961473941803 0.08599076420068741
encoder.encoder.weight_hh_l0: 1.709858224785421e-05 0.08785008639097214
encoder.encoder.bias_ih_l0: 0.014161629602313042 0.08961408585309982
encoder.encoder.bias_hh_l0: 0.024158744141459465 0.08769619464874268
encoder.encoder.weight_ih_l0_reverse: 0.0019090514397248626 0.08836589008569717
encoder.encoder.weight_hh_l0_reverse: 0.009536080993711948 0.08815786242485046
encoder.encoder.bias_ih_l0_reverse: 0.036068692803382874 0.08605768531560898
encoder.encoder.bias_hh_l0_reverse: 0.027934255078434944 0.08294713497161865
decider.lstm.weight_ih_l0: 0.002200751332566142 0.14919963479042053
decider.lstm.weight_hh_l0: 0.0032906446140259504 0.14880366623401642
decider.lstm.bias_ih_l0: 0.025761185213923454 0.15977326035499573
decider.lstm.bias_hh_l0: 0.006773666478693485 0.14092540740966797
decider.linear1.weight: 0.00435564573854208 0.1218494102358818
decider.linear1.bias: 0.020404867827892303 0.11751507222652435
decider.linear2.weight: 0.005295456852763891 0.054098740220069885
decider.linear2.bias: 0.008538903668522835 0.05697639659047127
decider.linear3.weight: -0.03354036062955856 0.08777367323637009
decider.linear3.bias: -0.009003834798932076 0.04784759506583214

Rewards:
221.7540
221.7540
221.7540
objective = 132.87603759765625
==== episode 6700/10000 ====
action = 1
probs = 0.0090 0.9910 0.0000 0.0000

action = 1
probs = 0.2273 0.7726 0.0000 0.0000

action = 0
probs = 0.9921 0.0079 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00023652716481592506 0.08607948571443558
encoder.encoder.weight_hh_l0: 1.5731107851024717e-05 0.08795315772294998
encoder.encoder.bias_ih_l0: 0.014420087449252605 0.08976677805185318
encoder.encoder.bias_hh_l0: 0.024417199194431305 0.08779451251029968
encoder.encoder.weight_ih_l0_reverse: 0.0018994720885530114 0.08843424916267395
encoder.encoder.weight_hh_l0_reverse: 0.00952978152781725 0.08816082030534744
encoder.encoder.bias_ih_l0_reverse: 0.03613612428307533 0.08610383421182632
encoder.encoder.bias_hh_l0_reverse: 0.028001688420772552 0.08291786909103394
decider.lstm.weight_ih_l0: 0.0022570532746613026 0.14929461479187012
decider.lstm.weight_hh_l0: 0.003322997596114874 0.14887869358062744
decider.lstm.bias_ih_l0: 0.026060983538627625 0.15985554456710815
decider.lstm.bias_hh_l0: 0.007073464337736368 0.14097939431667328
decider.linear1.weight: 0.0043615056201815605 0.12189622968435287
decider.linear1.bias: 0.02058609202504158 0.11751940846443176
decider.linear2.weight: 0.005358962342143059 0.05413835495710373
decider.linear2.bias: 0.00862262025475502 0.05699924752116203
decider.linear3.weight: -0.0337865985929966 0.08839570730924606
decider.linear3.bias: -0.009119692258536816 0.04751657694578171

Rewards:
230.1930
230.1930
230.1930
objective = 21.09305191040039
==== episode 6800/10000 ====
action = 1
probs = 0.0285 0.9715 0.0000 0.0000

action = 0
probs = 0.5010 0.4990 0.0000 0.0000

action = 0
probs = 0.9966 0.0034 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002187906502513215 0.08592380583286285
encoder.encoder.weight_hh_l0: 2.1876072423765436e-05 0.08779364824295044
encoder.encoder.bias_ih_l0: 0.014133326709270477 0.089602530002594
encoder.encoder.bias_hh_l0: 0.0241304412484169 0.08754744380712509
encoder.encoder.weight_ih_l0_reverse: 0.001897525740787387 0.08836539089679718
encoder.encoder.weight_hh_l0_reverse: 0.009529093280434608 0.08814285695552826
encoder.encoder.bias_ih_l0_reverse: 0.03602023050189018 0.08608587086200714
encoder.encoder.bias_hh_l0_reverse: 0.027885789051651955 0.08286367356777191
decider.lstm.weight_ih_l0: 0.002135590650141239 0.14916644990444183
decider.lstm.weight_hh_l0: 0.003251281101256609 0.14877350628376007
decider.lstm.bias_ih_l0: 0.02542906440794468 0.15971454977989197
decider.lstm.bias_hh_l0: 0.006441535893827677 0.14099164307117462
decider.linear1.weight: 0.004371372517198324 0.12186644971370697
decider.linear1.bias: 0.020534198731184006 0.1175934374332428
decider.linear2.weight: 0.005462695844471455 0.0541333444416523
decider.linear2.bias: 0.008798656985163689 0.05698214843869209
decider.linear3.weight: -0.0340946689248085 0.08907994627952576
decider.linear3.bias: -0.009270603768527508 0.046263325959444046

Rewards:
221.7540
221.7540
221.7540
objective = 53.483150482177734
==== episode 6900/10000 ====
action = 1
probs = 0.0178 0.9821 0.0000 0.0000

action = 1
probs = 0.2959 0.7041 0.0000 0.0000

action = 0
probs = 0.9941 0.0059 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00021326437126845121 0.08589904010295868
encoder.encoder.weight_hh_l0: 1.9024180801352486e-05 0.08775633573532104
encoder.encoder.bias_ih_l0: 0.013939824886620045 0.08950252830982208
encoder.encoder.bias_hh_l0: 0.023936940357089043 0.08758240938186646
encoder.encoder.weight_ih_l0_reverse: 0.0018965724157169461 0.08834384381771088
encoder.encoder.weight_hh_l0_reverse: 0.009514388628304005 0.08813793212175369
encoder.encoder.bias_ih_l0_reverse: 0.03602426126599312 0.086053267121315
encoder.encoder.bias_hh_l0_reverse: 0.02788981795310974 0.08291330188512802
decider.lstm.weight_ih_l0: 0.002141377655789256 0.14914722740650177
decider.lstm.weight_hh_l0: 0.0032586646266281605 0.14877603948116302
decider.lstm.bias_ih_l0: 0.025495117530226707 0.1597386747598648
decider.lstm.bias_hh_l0: 0.0065076001919806 0.14091716706752777
decider.linear1.weight: 0.004377424251288176 0.12185264378786087
decider.linear1.bias: 0.020429937168955803 0.117604561150074
decider.linear2.weight: 0.005395217798650265 0.054118286818265915
decider.linear2.bias: 0.008657461032271385 0.05694408714771271
decider.linear3.weight: -0.03446570783853531 0.08989488333463669
decider.linear3.bias: -0.009466465562582016 0.04704466462135315

Rewards:
230.1930
230.1930
230.1930
objective = 28.754009246826172
==== episode 7000/10000 ====
action = 1
probs = 0.0113 0.9887 0.0000 0.0000

action = 1
probs = 0.1953 0.8047 0.0000 0.0000

action = 0
probs = 0.9931 0.0069 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000224019619054161 0.08597169816493988
encoder.encoder.weight_hh_l0: 1.4017402463650797e-05 0.08783620595932007
encoder.encoder.bias_ih_l0: 0.014092352241277695 0.08958286046981812
encoder.encoder.bias_hh_l0: 0.02408946491777897 0.08773186057806015
encoder.encoder.weight_ih_l0_reverse: 0.0018910238286480308 0.08840958774089813
encoder.encoder.weight_hh_l0_reverse: 0.00950609240680933 0.08814696967601776
encoder.encoder.bias_ih_l0_reverse: 0.03613090515136719 0.08609060198068619
encoder.encoder.bias_hh_l0_reverse: 0.02799646370112896 0.08295083045959473
decider.lstm.weight_ih_l0: 0.0022119253408163786 0.14923185110092163
decider.lstm.weight_hh_l0: 0.0033044531010091305 0.14883917570114136
decider.lstm.bias_ih_l0: 0.025899890810251236 0.15981274843215942
decider.lstm.bias_hh_l0: 0.00691236462444067 0.1409262865781784
decider.linear1.weight: 0.004382545128464699 0.12188360840082169
decider.linear1.bias: 0.020530754700303078 0.11760496348142624
decider.linear2.weight: 0.005395879503339529 0.05413636565208435
decider.linear2.bias: 0.008623605594038963 0.05693851411342621
decider.linear3.weight: -0.034740716218948364 0.09053615480661392
decider.linear3.bias: -0.00961688905954361 0.04754337668418884

Rewards:
230.1930
230.1930
230.1930
objective = 18.077552795410156
==== episode 7100/10000 ====
action = 1
probs = 0.0081 0.9919 0.0000 0.0000

action = 1
probs = 0.1243 0.8757 0.0000 0.0000

action = 0
probs = 0.9868 0.0132 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022322169388644397 0.0859692245721817
encoder.encoder.weight_hh_l0: 1.5314579286496155e-05 0.0878240093588829
encoder.encoder.bias_ih_l0: 0.01399632915854454 0.08955196291208267
encoder.encoder.bias_hh_l0: 0.023993439972400665 0.0877397283911705
encoder.encoder.weight_ih_l0_reverse: 0.001892011146992445 0.08838160336017609
encoder.encoder.weight_hh_l0_reverse: 0.009516661055386066 0.08816203474998474
encoder.encoder.bias_ih_l0_reverse: 0.036095988005399704 0.08606689423322678
encoder.encoder.bias_hh_l0_reverse: 0.027961544692516327 0.08300606161355972
decider.lstm.weight_ih_l0: 0.0022265345323830843 0.1492338478565216
decider.lstm.weight_hh_l0: 0.003310915781185031 0.14884087443351746
decider.lstm.bias_ih_l0: 0.02594827115535736 0.15984998643398285
decider.lstm.bias_hh_l0: 0.00696074403822422 0.1408848613500595
decider.linear1.weight: 0.0043706526048481464 0.12186045944690704
decider.linear1.bias: 0.020393364131450653 0.11758141964673996
decider.linear2.weight: 0.005312108434736729 0.054108601063489914
decider.linear2.bias: 0.008512287400662899 0.056947652250528336
decider.linear3.weight: -0.03498133644461632 0.09105637669563293
decider.linear3.bias: -0.009747028350830078 0.048165615648031235

Rewards:
230.1930
230.1930
230.1930
objective = 11.825480461120605
==== episode 7200/10000 ====
action = 1
probs = 0.0045 0.9955 0.0000 0.0000

action = 1
probs = 0.0702 0.9298 0.0000 0.0000

action = 0
probs = 0.9861 0.0139 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00025399692822247744 0.0861085057258606
encoder.encoder.weight_hh_l0: 4.663503204938024e-06 0.08798976242542267
encoder.encoder.bias_ih_l0: 0.014398377388715744 0.08972403407096863
encoder.encoder.bias_hh_l0: 0.024395490065217018 0.08795289695262909
encoder.encoder.weight_ih_l0_reverse: 0.0018948130309581757 0.08851654082536697
encoder.encoder.weight_hh_l0_reverse: 0.009492208249866962 0.08816780149936676
encoder.encoder.bias_ih_l0_reverse: 0.036310698837041855 0.08613934367895126
encoder.encoder.bias_hh_l0_reverse: 0.028176259249448776 0.08303431421518326
decider.lstm.weight_ih_l0: 0.0023286575451493263 0.14934656023979187
decider.lstm.weight_hh_l0: 0.0033884146250784397 0.14891409873962402
decider.lstm.bias_ih_l0: 0.026539340615272522 0.15993283689022064
decider.lstm.bias_hh_l0: 0.007551814429461956 0.14093248546123505
decider.linear1.weight: 0.004386307671666145 0.12193077057600021
decider.linear1.bias: 0.02066132239997387 0.11761315912008286
decider.linear2.weight: 0.005351540166884661 0.054158445447683334
decider.linear2.bias: 0.008535540662705898 0.05696936696767807
decider.linear3.weight: -0.03514416888356209 0.09152251482009888
decider.linear3.bias: -0.009830085560679436 0.04871848598122597

Rewards:
230.1930
230.1930
230.1930
objective = 7.004924774169922
==== episode 7300/10000 ====
action = 1
probs = 0.0057 0.9943 0.0000 0.0000

action = 1
probs = 0.1065 0.8935 0.0000 0.0000

action = 0
probs = 0.9890 0.0110 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00023735821014270186 0.08609359711408615
encoder.encoder.weight_hh_l0: 1.0091149306390435e-05 0.08796969056129456
encoder.encoder.bias_ih_l0: 0.01432082150131464 0.08974209427833557
encoder.encoder.bias_hh_l0: 0.02431793138384819 0.08790580928325653
encoder.encoder.weight_ih_l0_reverse: 0.001893389504402876 0.0884748324751854
encoder.encoder.weight_hh_l0_reverse: 0.009518078528344631 0.08819148689508438
encoder.encoder.bias_ih_l0_reverse: 0.03623024374246597 0.08612023293972015
encoder.encoder.bias_hh_l0_reverse: 0.028095802292227745 0.08300600945949554
decider.lstm.weight_ih_l0: 0.002319080987945199 0.1493624895811081
decider.lstm.weight_hh_l0: 0.003372715087607503 0.14893171191215515
decider.lstm.bias_ih_l0: 0.02643999084830284 0.15995073318481445
decider.lstm.bias_hh_l0: 0.007452458143234253 0.14094413816928864
decider.linear1.weight: 0.0043816473335027695 0.12191236764192581
decider.linear1.bias: 0.020604681223630905 0.11757002770900726
decider.linear2.weight: 0.005347592290490866 0.054150909185409546
decider.linear2.bias: 0.008535368368029594 0.05697443708777428
decider.linear3.weight: -0.03527577221393585 0.0918092131614685
decider.linear3.bias: -0.009896003641188145 0.048332490026950836

Rewards:
230.1930
230.1930
230.1930
objective = 9.933005332946777
==== episode 7400/10000 ====
action = 1
probs = 0.0068 0.9932 0.0000 0.0000

action = 1
probs = 0.1250 0.8750 0.0000 0.0000

action = 0
probs = 0.9916 0.0084 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00023368975962512195 0.08607103675603867
encoder.encoder.weight_hh_l0: 1.2089097253920045e-05 0.08794271945953369
encoder.encoder.bias_ih_l0: 0.014261889271438122 0.08972550928592682
encoder.encoder.bias_hh_l0: 0.024258999153971672 0.08787736296653748
encoder.encoder.weight_ih_l0_reverse: 0.0018921622540801764 0.08847446739673615
encoder.encoder.weight_hh_l0_reverse: 0.009513597004115582 0.08819287270307541
encoder.encoder.bias_ih_l0_reverse: 0.036206331104040146 0.08612297475337982
encoder.encoder.bias_hh_l0_reverse: 0.028071891516447067 0.08299652487039566
decider.lstm.weight_ih_l0: 0.0023058655206114054 0.14935031533241272
decider.lstm.weight_hh_l0: 0.0033604097552597523 0.14893148839473724
decider.lstm.bias_ih_l0: 0.026372278109192848 0.15992821753025055
decider.lstm.bias_hh_l0: 0.007384751457720995 0.14096607267856598
decider.linear1.weight: 0.00438666669651866 0.12191405147314072
decider.linear1.bias: 0.02061988227069378 0.11760023236274719
decider.linear2.weight: 0.005377761088311672 0.054160747677087784
decider.linear2.bias: 0.008562600240111351 0.05695667117834091
decider.linear3.weight: -0.03543736785650253 0.09220925718545914
decider.linear3.bias: -0.009978956542909145 0.04813269525766373

Rewards:
230.1930
230.1930
230.1930
objective = 11.422453880310059
==== episode 7500/10000 ====
action = 1
probs = 0.0061 0.9939 0.0000 0.0000

action = 1
probs = 0.1050 0.8950 0.0000 0.0000

action = 0
probs = 0.9920 0.0080 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002460532123222947 0.08608981966972351
encoder.encoder.weight_hh_l0: 9.780465916264802e-06 0.08796355128288269
encoder.encoder.bias_ih_l0: 0.014325357042253017 0.08973760902881622
encoder.encoder.bias_hh_l0: 0.024322466924786568 0.08792055398225784
encoder.encoder.weight_ih_l0_reverse: 0.0018931099912151694 0.08851908892393112
encoder.encoder.weight_hh_l0_reverse: 0.009498169645667076 0.08818613737821579
encoder.encoder.bias_ih_l0_reverse: 0.036264218389987946 0.08615366369485855
encoder.encoder.bias_hh_l0_reverse: 0.028129776939749718 0.08301445096731186
decider.lstm.weight_ih_l0: 0.0023213985841721296 0.14935950934886932
decider.lstm.weight_hh_l0: 0.0033730959985405207 0.14894255995750427
decider.lstm.bias_ih_l0: 0.02648070454597473 0.159930020570755
decider.lstm.bias_hh_l0: 0.007493168581277132 0.14097827672958374
decider.linear1.weight: 0.004393788520246744 0.1219346895813942
decider.linear1.bias: 0.0206869225949049 0.11763708293437958
decider.linear2.weight: 0.005403007380664349 0.054184701293706894
decider.linear2.bias: 0.008574233390390873 0.0569467656314373
decider.linear3.weight: -0.035611145198345184 0.09265902638435364
decider.linear3.bias: -0.010070886462926865 0.04829854518175125

Rewards:
230.1930
230.1930
230.1930
objective = 9.601210594177246
==== episode 7600/10000 ====
action = 1
probs = 0.0075 0.9925 0.0000 0.0000

action = 1
probs = 0.1602 0.8397 0.0000 0.0000

action = 0
probs = 0.9954 0.0046 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00024346898135263473 0.08612091094255447
encoder.encoder.weight_hh_l0: 1.0160696547245607e-05 0.0880013033747673
encoder.encoder.bias_ih_l0: 0.014421370811760426 0.08982392400503159
encoder.encoder.bias_hh_l0: 0.024418482556939125 0.08793434500694275
encoder.encoder.weight_ih_l0_reverse: 0.0018960785819217563 0.08853567391633987
encoder.encoder.weight_hh_l0_reverse: 0.009507128968834877 0.08820261061191559
encoder.encoder.bias_ih_l0_reverse: 0.03627237305045128 0.08616432547569275
encoder.encoder.bias_hh_l0_reverse: 0.02813793160021305 0.08296811580657959
decider.lstm.weight_ih_l0: 0.0023410876747220755 0.1494106501340866
decider.lstm.weight_hh_l0: 0.003382793627679348 0.14898091554641724
decider.lstm.bias_ih_l0: 0.026569046080112457 0.15996086597442627
decider.lstm.bias_hh_l0: 0.007581520825624466 0.14102667570114136
decider.linear1.weight: 0.004402122460305691 0.12195646017789841
decider.linear1.bias: 0.020789265632629395 0.11763441562652588
decider.linear2.weight: 0.005453213583678007 0.05423874780535698
decider.linear2.bias: 0.008629555813968182 0.056949399411678314
decider.linear3.weight: -0.035759665071964264 0.09304104745388031
decider.linear3.bias: -0.010149553418159485 0.047867804765701294

Rewards:
230.1930
230.1930
230.1930
objective = 14.329703330993652
==== episode 7700/10000 ====
action = 1
probs = 0.0061 0.9939 0.0000 0.0000

action = 1
probs = 0.1152 0.8848 0.0000 0.0000

action = 0
probs = 0.9948 0.0052 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002544400922488421 0.08613195270299911
encoder.encoder.weight_hh_l0: 8.83348002389539e-06 0.08800997585058212
encoder.encoder.bias_ih_l0: 0.014435240998864174 0.08981458842754364
encoder.encoder.bias_hh_l0: 0.0244323518127203 0.08796470612287521
encoder.encoder.weight_ih_l0_reverse: 0.0018982657929882407 0.08856802433729172
encoder.encoder.weight_hh_l0_reverse: 0.009495094418525696 0.08819883316755295
encoder.encoder.bias_ih_l0_reverse: 0.03631952032446861 0.08619140088558197
encoder.encoder.bias_hh_l0_reverse: 0.028185077011585236 0.08299946784973145
decider.lstm.weight_ih_l0: 0.002353596966713667 0.14941099286079407
decider.lstm.weight_hh_l0: 0.003394101280719042 0.14898231625556946
decider.lstm.bias_ih_l0: 0.02665630914270878 0.15996360778808594
decider.lstm.bias_hh_l0: 0.007668768055737019 0.1410187929868698
decider.linear1.weight: 0.004407546482980251 0.12196803838014603
decider.linear1.bias: 0.020799703896045685 0.11767569184303284
decider.linear2.weight: 0.005459384061396122 0.05425180494785309
decider.linear2.bias: 0.008609267883002758 0.05693569406867027
decider.linear3.weight: -0.03592396527528763 0.09346626698970795
decider.linear3.bias: -0.010237595997750759 0.04815472289919853

Rewards:
230.1930
230.1930
230.1930
objective = 10.256101608276367
==== episode 7800/10000 ====
action = 1
probs = 0.0038 0.9962 0.0000 0.0000

action = 1
probs = 0.0643 0.9357 0.0000 0.0000

action = 0
probs = 0.9879 0.0121 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002618629077915102 0.08618206530809402
encoder.encoder.weight_hh_l0: 7.4281811066612136e-06 0.08806224167346954
encoder.encoder.bias_ih_l0: 0.014503534883260727 0.0898309201002121
encoder.encoder.bias_hh_l0: 0.024500641971826553 0.08805076032876968
encoder.encoder.weight_ih_l0_reverse: 0.0018932630773633718 0.08858679234981537
encoder.encoder.weight_hh_l0_reverse: 0.009497929364442825 0.08820420503616333
encoder.encoder.bias_ih_l0_reverse: 0.036352477967739105 0.08620758354663849
encoder.encoder.bias_hh_l0_reverse: 0.02821803092956543 0.08306039124727249
decider.lstm.weight_ih_l0: 0.002384854480624199 0.14943425357341766
decider.lstm.weight_hh_l0: 0.0034152581356465816 0.14899218082427979
decider.lstm.bias_ih_l0: 0.02681216225028038 0.16001780331134796
decider.lstm.bias_hh_l0: 0.007824631407856941 0.14096640050411224
decider.linear1.weight: 0.004393668845295906 0.12195973098278046
decider.linear1.bias: 0.02071584016084671 0.11762486398220062
decider.linear2.weight: 0.005385890603065491 0.054225288331508636
decider.linear2.bias: 0.00851976964622736 0.05696721747517586
decider.linear3.weight: -0.03606025129556656 0.09378337115049362
decider.linear3.bias: -0.010309183970093727 0.04883848875761032

Rewards:
230.1930
230.1930
230.1930
objective = 6.3241987228393555
==== episode 7900/10000 ====
action = 1
probs = 0.0076 0.9924 0.0000 0.0000

action = 0
probs = 0.1512 0.8488 0.0000 0.0000

action = 0
probs = 0.9953 0.0047 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00023594990489073098 0.08609867095947266
encoder.encoder.weight_hh_l0: 1.5091562090674415e-05 0.087964728474617
encoder.encoder.bias_ih_l0: 0.01428912952542305 0.0897943377494812
encoder.encoder.bias_hh_l0: 0.024286240339279175 0.0878988653421402
encoder.encoder.weight_ih_l0_reverse: 0.001894320361316204 0.08851957321166992
encoder.encoder.weight_hh_l0_reverse: 0.00951493438333273 0.08822204917669296
encoder.encoder.bias_ih_l0_reverse: 0.03621222451329231 0.08617376536130905
encoder.encoder.bias_hh_l0_reverse: 0.028077783063054085 0.08299475163221359
decider.lstm.weight_ih_l0: 0.002333349548280239 0.1494045853614807
decider.lstm.weight_hh_l0: 0.0033723616506904364 0.14898596704006195
decider.lstm.bias_ih_l0: 0.02651599980890751 0.15995444357395172
decider.lstm.bias_hh_l0: 0.007528459187597036 0.1410231590270996
decider.linear1.weight: 0.004399222321808338 0.12194044888019562
decider.linear1.bias: 0.020686015486717224 0.11764214187860489
decider.linear2.weight: 0.005439757369458675 0.05424032360315323
decider.linear2.bias: 0.00859153177589178 0.056933894753456116
decider.linear3.weight: -0.0362248569726944 0.09417840093374252
decider.linear3.bias: -0.010397123172879219 0.04788598790764809

Rewards:
221.7540
221.7540
221.7540
objective = 140.56979370117188
==== episode 8000/10000 ====
action = 1
probs = 0.0107 0.9893 0.0000 0.0000

action = 1
probs = 0.2361 0.7639 0.0000 0.0000

action = 0
probs = 0.9968 0.0032 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022709480253979564 0.08607691526412964
encoder.encoder.weight_hh_l0: 1.8391847333987243e-05 0.08793698996305466
encoder.encoder.bias_ih_l0: 0.01423221081495285 0.08980337530374527
encoder.encoder.bias_hh_l0: 0.024229323491454124 0.08782994747161865
encoder.encoder.weight_ih_l0_reverse: 0.0018983053741976619 0.08849877864122391
encoder.encoder.weight_hh_l0_reverse: 0.009526210837066174 0.08823563158512115
encoder.encoder.bias_ih_l0_reverse: 0.03615754470229149 0.08616286516189575
encoder.encoder.bias_hh_l0_reverse: 0.028023099526762962 0.08296718448400497
decider.lstm.weight_ih_l0: 0.0023218803107738495 0.1494091898202896
decider.lstm.weight_hh_l0: 0.0033614400308579206 0.14899253845214844
decider.lstm.bias_ih_l0: 0.026433788239955902 0.1599462628364563
decider.lstm.bias_hh_l0: 0.007446246221661568 0.1410517394542694
decider.linear1.weight: 0.004403958097100258 0.12193680554628372
decider.linear1.bias: 0.02068159356713295 0.11762125790119171
decider.linear2.weight: 0.0054650697857141495 0.05425594374537468
decider.linear2.bias: 0.008618660271167755 0.056933868676424026
decider.linear3.weight: -0.03647001087665558 0.09478500485420227
decider.linear3.bias: -0.01053297147154808 0.04741646721959114

Rewards:
230.1930
230.1930
230.1930
objective = 21.734149932861328
==== episode 8100/10000 ====
action = 1
probs = 0.0664 0.9336 0.0000 0.0000

action = 0
probs = 0.8078 0.1922 0.0000 0.0000

action = 0
probs = 0.9995 0.0005 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022397379507310688 0.08599140495061874
encoder.encoder.weight_hh_l0: 2.328699702047743e-05 0.0878741517663002
encoder.encoder.bias_ih_l0: 0.014334650710225105 0.08983129262924194
encoder.encoder.bias_hh_l0: 0.02433175966143608 0.08761375397443771
encoder.encoder.weight_ih_l0_reverse: 0.001890311948955059 0.08850150555372238
encoder.encoder.weight_hh_l0_reverse: 0.009553344920277596 0.08825244009494781
encoder.encoder.bias_ih_l0_reverse: 0.036183055490255356 0.08622442185878754
encoder.encoder.bias_hh_l0_reverse: 0.028048602864146233 0.08280911296606064
decider.lstm.weight_ih_l0: 0.002200545510277152 0.14934159815311432
decider.lstm.weight_hh_l0: 0.0032855381723493338 0.1489511877298355
decider.lstm.bias_ih_l0: 0.025844765827059746 0.15979555249214172
decider.lstm.bias_hh_l0: 0.0068572270683944225 0.1412370502948761
decider.linear1.weight: 0.004408295266330242 0.12193920463323593
decider.linear1.bias: 0.020942825824022293 0.11768024414777756
decider.linear2.weight: 0.005668749567121267 0.054312389343976974
decider.linear2.bias: 0.009043312631547451 0.05697181448340416
decider.linear3.weight: -0.03693404421210289 0.0956294909119606
decider.linear3.bias: -0.010742106474936008 0.04497114568948746

Rewards:
221.7540
221.7540
221.7540
objective = 20.886505126953125
==== episode 8200/10000 ====
action = 1
probs = 0.0541 0.9459 0.0000 0.0000

action = 0
probs = 0.8281 0.1719 0.0000 0.0000

action = 0
probs = 0.9996 0.0004 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00023551768390461802 0.08604170382022858
encoder.encoder.weight_hh_l0: 2.5379405997227877e-05 0.08792363852262497
encoder.encoder.bias_ih_l0: 0.014475959353148937 0.08990936726331711
encoder.encoder.bias_hh_l0: 0.024473071098327637 0.08768045157194138
encoder.encoder.weight_ih_l0_reverse: 0.0018881814321503043 0.08855132013559341
encoder.encoder.weight_hh_l0_reverse: 0.009563615545630455 0.08827712386846542
encoder.encoder.bias_ih_l0_reverse: 0.03624807298183441 0.0862850472331047
encoder.encoder.bias_hh_l0_reverse: 0.02811361663043499 0.08282110095024109
decider.lstm.weight_ih_l0: 0.0022530187852680683 0.14941950142383575
decider.lstm.weight_hh_l0: 0.003313435474410653 0.14905346930027008
decider.lstm.bias_ih_l0: 0.02612609788775444 0.15989024937152863
decider.lstm.bias_hh_l0: 0.0071385628543794155 0.14123259484767914
decider.linear1.weight: 0.004411329049617052 0.12197982519865036
decider.linear1.bias: 0.02116757072508335 0.11756397783756256
decider.linear2.weight: 0.005649958737194538 0.0543815977871418
decider.linear2.bias: 0.009031391702592373 0.05700589716434479
decider.linear3.weight: -0.03744683042168617 0.09678684920072556
decider.linear3.bias: -0.011019478552043438 0.04511767998337746

Rewards:
221.7540
221.7540
221.7540
objective = 18.08175277709961
==== episode 8300/10000 ====
action = 1
probs = 0.0527 0.9473 0.0000 0.0000

action = 1
probs = 0.7857 0.2143 0.0000 0.0000

action = 0
probs = 0.9996 0.0004 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022326868202071637 0.08594971150159836
encoder.encoder.weight_hh_l0: 3.0601368052884936e-05 0.0878184363245964
encoder.encoder.bias_ih_l0: 0.014185207895934582 0.08977697044610977
encoder.encoder.bias_hh_l0: 0.02418231964111328 0.08754085004329681
encoder.encoder.weight_ih_l0_reverse: 0.0019064157968387008 0.0884845033288002
encoder.encoder.weight_hh_l0_reverse: 0.009581295773386955 0.08829765766859055
encoder.encoder.bias_ih_l0_reverse: 0.03617681935429573 0.08624143153429031
encoder.encoder.bias_hh_l0_reverse: 0.02804235927760601 0.08284018188714981
decider.lstm.weight_ih_l0: 0.0022018090821802616 0.149336040019989
decider.lstm.weight_hh_l0: 0.0032845954410731792 0.14900082349777222
decider.lstm.bias_ih_l0: 0.025809338316321373 0.1598283052444458
decider.lstm.bias_hh_l0: 0.006821802817285061 0.14117716252803802
decider.linear1.weight: 0.004425976425409317 0.12198478728532791
decider.linear1.bias: 0.021165713667869568 0.11747509986162186
decider.linear2.weight: 0.00571230985224247 0.054503586143255234
decider.linear2.bias: 0.008955095894634724 0.056988175958395004
decider.linear3.weight: -0.03793947771191597 0.09790188074111938
decider.linear3.bias: -0.011300245299935341 0.04531266540288925

Rewards:
230.1930
230.1930
230.1930
objective = 122.38093566894531
==== episode 8400/10000 ====
action = 1
probs = 0.0387 0.9613 0.0000 0.0000

action = 0
probs = 0.7450 0.2550 0.0000 0.0000

action = 0
probs = 0.9997 0.0003 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022395576525013894 0.08597459644079208
encoder.encoder.weight_hh_l0: 3.3855689252959564e-05 0.0878371000289917
encoder.encoder.bias_ih_l0: 0.01417797151952982 0.08979658037424088
encoder.encoder.bias_hh_l0: 0.024175085127353668 0.08757703006267548
encoder.encoder.weight_ih_l0_reverse: 0.0019039296312257648 0.08848577737808228
encoder.encoder.weight_hh_l0_reverse: 0.0095905102789402 0.08831864595413208
encoder.encoder.bias_ih_l0_reverse: 0.036171820014715195 0.08625411987304688
encoder.encoder.bias_hh_l0_reverse: 0.028037356212735176 0.08285689353942871
decider.lstm.weight_ih_l0: 0.002240355359390378 0.14938421547412872
decider.lstm.weight_hh_l0: 0.003302845172584057 0.1490599513053894
decider.lstm.bias_ih_l0: 0.025996757671236992 0.15990883111953735
decider.lstm.bias_hh_l0: 0.007009217515587807 0.14114902913570404
decider.linear1.weight: 0.004427575506269932 0.12200681120157242
decider.linear1.bias: 0.021188940852880478 0.11743738502264023
decider.linear2.weight: 0.005711250938475132 0.05457552522420883
decider.linear2.bias: 0.008900639601051807 0.05699199438095093
decider.linear3.weight: -0.03838454186916351 0.09899727255105972
decider.linear3.bias: -0.011537190526723862 0.04568508267402649

Rewards:
221.7540
221.7540
221.7540
objective = 24.699893951416016
==== episode 8500/10000 ====
action = 1
probs = 0.0182 0.9818 0.0000 0.0000

action = 1
probs = 0.3295 0.6705 0.0000 0.0000

action = 0
probs = 0.9985 0.0015 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00020600091374944896 0.08573970943689346
encoder.encoder.weight_hh_l0: 2.564638816693332e-05 0.08755024522542953
encoder.encoder.bias_ih_l0: 0.013395803980529308 0.08938426524400711
encoder.encoder.bias_hh_l0: 0.023392915725708008 0.08735258877277374
encoder.encoder.weight_ih_l0_reverse: 0.0019456831505522132 0.08831574022769928
encoder.encoder.weight_hh_l0_reverse: 0.009589164517819881 0.08828889578580856
encoder.encoder.bias_ih_l0_reverse: 0.035963088274002075 0.0860915407538414
encoder.encoder.bias_hh_l0_reverse: 0.027828620746731758 0.08298246562480927
decider.lstm.weight_ih_l0: 0.0020697664003819227 0.1490921527147293
decider.lstm.weight_hh_l0: 0.003220141399651766 0.14887985587120056
decider.lstm.bias_ih_l0: 0.025105899199843407 0.15979346632957458
decider.lstm.bias_hh_l0: 0.006118354387581348 0.14086078107357025
decider.linear1.weight: 0.004443255718797445 0.12195757031440735
decider.linear1.bias: 0.02089260146021843 0.11739011108875275
decider.linear2.weight: 0.005551390815526247 0.054523102939128876
decider.linear2.bias: 0.008593209087848663 0.05698308348655701
decider.linear3.weight: -0.038773246109485626 0.09990697354078293
decider.linear3.bias: -0.011757337488234043 0.04714568704366684

Rewards:
230.1930
230.1930
230.1930
objective = 32.20193099975586
==== episode 8600/10000 ====
action = 1
probs = 0.0252 0.9748 0.0000 0.0000

action = 1
probs = 0.3577 0.6423 0.0000 0.0000

action = 0
probs = 0.9986 0.0014 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00018886047473642975 0.08559989184141159
encoder.encoder.weight_hh_l0: 1.985182643693406e-05 0.08739808201789856
encoder.encoder.bias_ih_l0: 0.013050870969891548 0.08920475840568542
encoder.encoder.bias_hh_l0: 0.023047979921102524 0.08717423677444458
encoder.encoder.weight_ih_l0_reverse: 0.001965056639164686 0.08824249356985092
encoder.encoder.weight_hh_l0_reverse: 0.009571163915097713 0.08825964480638504
encoder.encoder.bias_ih_l0_reverse: 0.035833168774843216 0.08604125678539276
encoder.encoder.bias_hh_l0_reverse: 0.02769869938492775 0.08298222720623016
decider.lstm.weight_ih_l0: 0.0019332224037498236 0.14891187846660614
decider.lstm.weight_hh_l0: 0.0031514661386609077 0.1487412005662918
decider.lstm.bias_ih_l0: 0.02444600686430931 0.15965589880943298
decider.lstm.bias_hh_l0: 0.005458462983369827 0.14079251885414124
decider.linear1.weight: 0.004449191503226757 0.1219208613038063
decider.linear1.bias: 0.02075764536857605 0.11741519719362259
decider.linear2.weight: 0.005555326119065285 0.05451790988445282
decider.linear2.bias: 0.008579138666391373 0.05696719139814377
decider.linear3.weight: -0.039099883288145065 0.10062354803085327
decider.linear3.bias: -0.011983908712863922 0.04695471003651619

Rewards:
230.1930
230.1930
230.1930
objective = 36.0426025390625
==== episode 8700/10000 ====
action = 1
probs = 0.0158 0.9842 0.0000 0.0000

action = 1
probs = 0.2051 0.7949 0.0000 0.0000

action = 0
probs = 0.9978 0.0022 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00019250235345680267 0.08561597764492035
encoder.encoder.weight_hh_l0: 1.7704665879136883e-05 0.08739722520112991
encoder.encoder.bias_ih_l0: 0.013016893528401852 0.08917929977178574
encoder.encoder.bias_hh_l0: 0.02301400527358055 0.08728694170713425
encoder.encoder.weight_ih_l0_reverse: 0.0019481177441775799 0.08827667683362961
encoder.encoder.weight_hh_l0_reverse: 0.009559696540236473 0.08824558556079865
encoder.encoder.bias_ih_l0_reverse: 0.03587544709444046 0.08602914959192276
encoder.encoder.bias_hh_l0_reverse: 0.02774098888039589 0.08309134840965271
decider.lstm.weight_ih_l0: 0.001981153152883053 0.148969367146492
decider.lstm.weight_hh_l0: 0.0031741070561110973 0.1487743854522705
decider.lstm.bias_ih_l0: 0.024678926914930344 0.1597907990217209
decider.lstm.bias_hh_l0: 0.00569138815626502 0.1408056914806366
decider.linear1.weight: 0.004451022017747164 0.12193877249956131
decider.linear1.bias: 0.020770402625203133 0.11746762692928314
decider.linear2.weight: 0.005547350272536278 0.054528940469026566
decider.linear2.bias: 0.008526390418410301 0.056978873908519745
decider.linear3.weight: -0.039440106600522995 0.10139358043670654
decider.linear3.bias: -0.012231899425387383 0.047792114317417145

Rewards:
230.1930
230.1930
230.1930
objective = 19.006654739379883
==== episode 8800/10000 ====
action = 1
probs = 0.0270 0.9730 0.0000 0.0000

action = 1
probs = 0.3886 0.6114 0.0000 0.0000

action = 0
probs = 0.9991 0.0009 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00019257984240539372 0.08563970029354095
encoder.encoder.weight_hh_l0: 2.1513627871172503e-05 0.08743532001972198
encoder.encoder.bias_ih_l0: 0.013099097646772861 0.08926496654748917
encoder.encoder.bias_hh_l0: 0.02309621125459671 0.0872076004743576
encoder.encoder.weight_ih_l0_reverse: 0.0019609706941992044 0.08826431632041931
encoder.encoder.weight_hh_l0_reverse: 0.009617097675800323 0.08830220997333527
encoder.encoder.bias_ih_l0_reverse: 0.03586530685424805 0.0860663577914238
encoder.encoder.bias_hh_l0_reverse: 0.02773084118962288 0.0829809308052063
decider.lstm.weight_ih_l0: 0.0020009176805615425 0.14903923869132996
decider.lstm.weight_hh_l0: 0.0031814470421522856 0.14882352948188782
decider.lstm.bias_ih_l0: 0.024755999445915222 0.15976782143115997
decider.lstm.bias_hh_l0: 0.005768452771008015 0.14090631902217865
decider.linear1.weight: 0.0044525908306241035 0.12192204594612122
decider.linear1.bias: 0.020752757787704468 0.11744960397481918
decider.linear2.weight: 0.005627182312309742 0.05455911159515381
decider.linear2.bias: 0.008643954992294312 0.057041093707084656
decider.linear3.weight: -0.03979852795600891 0.10216083377599716
decider.linear3.bias: -0.012491848319768906 0.046982813626527786

Rewards:
230.1930
230.1930
230.1930
objective = 39.92876434326172
==== episode 8900/10000 ====
action = 1
probs = 0.0256 0.9744 0.0000 0.0000

action = 1
probs = 0.4732 0.5267 0.0000 0.0000

action = 0
probs = 0.9994 0.0006 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00020908653095830232 0.08579995483160019
encoder.encoder.weight_hh_l0: 2.837561260093935e-05 0.08761107176542282
encoder.encoder.bias_ih_l0: 0.013478469103574753 0.08949920535087585
encoder.encoder.bias_hh_l0: 0.023475583642721176 0.08736598491668701
encoder.encoder.weight_ih_l0_reverse: 0.001945129013620317 0.08834810554981232
encoder.encoder.weight_hh_l0_reverse: 0.009663794189691544 0.08836629241704941
encoder.encoder.bias_ih_l0_reverse: 0.03600497171282768 0.08614934980869293
encoder.encoder.bias_hh_l0_reverse: 0.027870506048202515 0.08294151723384857
decider.lstm.weight_ih_l0: 0.002138282638043165 0.14924566447734833
decider.lstm.weight_hh_l0: 0.0032501115929335356 0.14897161722183228
decider.lstm.bias_ih_l0: 0.025425221771001816 0.15987657010555267
decider.lstm.bias_hh_l0: 0.0064376844093203545 0.14102907478809357
decider.linear1.weight: 0.004448458552360535 0.12195324152708054
decider.linear1.bias: 0.020893000066280365 0.11742457747459412
decider.linear2.weight: 0.005673006176948547 0.054603461176157
decider.linear2.bias: 0.008705196902155876 0.05707759037613869
decider.linear3.weight: -0.04023647680878639 0.10299544036388397
decider.linear3.bias: -0.012786326929926872 0.046842679381370544

Rewards:
230.1930
230.1930
230.1930
objective = 51.223968505859375
==== episode 9000/10000 ====
action = 1
probs = 0.0364 0.9636 0.0000 0.0000

action = 0
probs = 0.6529 0.3471 0.0000 0.0000

action = 0
probs = 0.9997 0.0003 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00021808604651596397 0.08585967868566513
encoder.encoder.weight_hh_l0: 3.347468373249285e-05 0.08768147975206375
encoder.encoder.bias_ih_l0: 0.013647828251123428 0.0896095484495163
encoder.encoder.bias_hh_l0: 0.023644933477044106 0.08736448734998703
encoder.encoder.weight_ih_l0_reverse: 0.0019424554193392396 0.08836974203586578
encoder.encoder.weight_hh_l0_reverse: 0.009679777547717094 0.08839801698923111
encoder.encoder.bias_ih_l0_reverse: 0.036033499985933304 0.08620654791593552
encoder.encoder.bias_hh_l0_reverse: 0.027899030596017838 0.08287090063095093
decider.lstm.weight_ih_l0: 0.002165288897231221 0.14930322766304016
decider.lstm.weight_hh_l0: 0.003262600861489773 0.14901462197303772
decider.lstm.bias_ih_l0: 0.025568995624780655 0.1598830670118332
decider.lstm.bias_hh_l0: 0.006581453140825033 0.1410866677761078
decider.linear1.weight: 0.004446846432983875 0.12196077406406403
decider.linear1.bias: 0.020968876779079437 0.11740090698003769
decider.linear2.weight: 0.005723834037780762 0.05463673546910286
decider.linear2.bias: 0.008786998689174652 0.05711750313639641
decider.linear3.weight: -0.040654104202985764 0.10380470752716064
decider.linear3.bias: -0.013074841350317001 0.046265870332717896

Rewards:
221.7540
221.7540
221.7540
objective = 34.280494689941406
==== episode 9100/10000 ====
action = 1
probs = 0.0302 0.9698 0.0000 0.0000

action = 0
probs = 0.6755 0.3245 0.0000 0.0000

action = 0
probs = 0.9997 0.0003 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022607299615629017 0.08595827966928482
encoder.encoder.weight_hh_l0: 3.6297071346780285e-05 0.08778519928455353
encoder.encoder.bias_ih_l0: 0.013888334855437279 0.08974000066518784
encoder.encoder.bias_hh_l0: 0.023885441944003105 0.08748095482587814
encoder.encoder.weight_ih_l0_reverse: 0.0019299706909805536 0.0884326845407486
encoder.encoder.weight_hh_l0_reverse: 0.00967913307249546 0.0884150043129921
encoder.encoder.bias_ih_l0_reverse: 0.036105647683143616 0.08624812215566635
encoder.encoder.bias_hh_l0_reverse: 0.027971183881163597 0.08285932242870331
decider.lstm.weight_ih_l0: 0.002233478706330061 0.14939624071121216
decider.lstm.weight_hh_l0: 0.0033002281561493874 0.1490815132856369
decider.lstm.bias_ih_l0: 0.025930173695087433 0.15992753207683563
decider.lstm.bias_hh_l0: 0.006942627485841513 0.14112304151058197
decider.linear1.weight: 0.004441438242793083 0.1219923198223114
decider.linear1.bias: 0.021082639694213867 0.11738693714141846
decider.linear2.weight: 0.005746874958276749 0.054666921496391296
decider.linear2.bias: 0.008817601017653942 0.05713300034403801
decider.linear3.weight: -0.041027870029211044 0.10459455102682114
decider.linear3.bias: -0.013329063542187214 0.04637417197227478

Rewards:
221.7540
221.7540
221.7540
objective = 31.283405303955078
==== episode 9200/10000 ====
action = 1
probs = 0.0165 0.9835 0.0000 0.0000

action = 1
probs = 0.4394 0.5606 0.0000 0.0000

action = 0
probs = 0.9994 0.0006 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002195537817897275 0.08590207993984222
encoder.encoder.weight_hh_l0: 3.497092620818876e-05 0.08769878000020981
encoder.encoder.bias_ih_l0: 0.01364085916429758 0.0896122083067894
encoder.encoder.bias_hh_l0: 0.023637963458895683 0.08745577186346054
encoder.encoder.weight_ih_l0_reverse: 0.001948375953361392 0.08839015662670135
encoder.encoder.weight_hh_l0_reverse: 0.009682634845376015 0.08841709047555923
encoder.encoder.bias_ih_l0_reverse: 0.03604116290807724 0.08617423474788666
encoder.encoder.bias_hh_l0_reverse: 0.02790670096874237 0.08293202519416809
decider.lstm.weight_ih_l0: 0.002222812967374921 0.14935091137886047
decider.lstm.weight_hh_l0: 0.003289139363914728 0.14906105399131775
decider.lstm.bias_ih_l0: 0.025837745517492294 0.15994632244110107
decider.lstm.bias_hh_l0: 0.006850195117294788 0.1410181075334549
decider.linear1.weight: 0.004450339823961258 0.12198397517204285
decider.linear1.bias: 0.02095838636159897 0.11735948175191879
decider.linear2.weight: 0.005661127623170614 0.05464256554841995
decider.linear2.bias: 0.008650810457766056 0.05710957571864128
decider.linear3.weight: -0.04129587486386299 0.10514514148235321
decider.linear3.bias: -0.013510662131011486 0.047311168164014816

Rewards:
230.1930
230.1930
230.1930
objective = 45.73974609375
==== episode 9300/10000 ====
action = 1
probs = 0.0176 0.9824 0.0000 0.0000

action = 1
probs = 0.4705 0.5295 0.0000 0.0000

action = 0
probs = 0.9994 0.0006 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00021887957700528204 0.08591237664222717
encoder.encoder.weight_hh_l0: 3.661299706436694e-05 0.08770899474620819
encoder.encoder.bias_ih_l0: 0.013650350272655487 0.0896354541182518
encoder.encoder.bias_hh_l0: 0.023647457361221313 0.08745540678501129
encoder.encoder.weight_ih_l0_reverse: 0.0019494520965963602 0.08839454501867294
encoder.encoder.weight_hh_l0_reverse: 0.009694096632301807 0.08843204379081726
encoder.encoder.bias_ih_l0_reverse: 0.0360381044447422 0.08618490397930145
encoder.encoder.bias_hh_l0_reverse: 0.027903644368052483 0.0829283595085144
decider.lstm.weight_ih_l0: 0.0022324903402477503 0.14937224984169006
decider.lstm.weight_hh_l0: 0.003293054411187768 0.14907841384410858
decider.lstm.bias_ih_l0: 0.025874687358736992 0.15995445847511292
decider.lstm.bias_hh_l0: 0.006887122523039579 0.141041561961174
decider.linear1.weight: 0.004451921209692955 0.12198282778263092
decider.linear1.bias: 0.02095191739499569 0.11735504120588303
decider.linear2.weight: 0.005675924941897392 0.054654449224472046
decider.linear2.bias: 0.008651722222566605 0.05711425840854645
decider.linear3.weight: -0.04155264049768448 0.1056879460811615
decider.linear3.bias: -0.013690357096493244 0.04726221412420273

Rewards:
230.1930
230.1930
230.1930
objective = 50.188262939453125
==== episode 9400/10000 ====
action = 1
probs = 0.0096 0.9904 0.0000 0.0000

action = 1
probs = 0.2989 0.7011 0.0000 0.0000

action = 0
probs = 0.9991 0.0009 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022812477254774421 0.0859718918800354
encoder.encoder.weight_hh_l0: 3.6641657061409205e-05 0.08776207268238068
encoder.encoder.bias_ih_l0: 0.013728941790759563 0.08966200798749924
encoder.encoder.bias_hh_l0: 0.023726047948002815 0.08759025484323502
encoder.encoder.weight_ih_l0_reverse: 0.0019435494905337691 0.08843228220939636
encoder.encoder.weight_hh_l0_reverse: 0.009688621386885643 0.08843602240085602
encoder.encoder.bias_ih_l0_reverse: 0.0360998809337616 0.08618161082267761
encoder.encoder.bias_hh_l0_reverse: 0.027965420857071877 0.08298350870609283
decider.lstm.weight_ih_l0: 0.0022938731126487255 0.1494346708059311
decider.lstm.weight_hh_l0: 0.0033263415098190308 0.14913976192474365
decider.lstm.bias_ih_l0: 0.026166105642914772 0.16005738079547882
decider.lstm.bias_hh_l0: 0.007178547326475382 0.1410175859928131
decider.linear1.weight: 0.004453219007700682 0.1220129057765007
decider.linear1.bias: 0.020994240418076515 0.1173752173781395
decider.linear2.weight: 0.005671516992151737 0.05466485023498535
decider.linear2.bias: 0.008614972233772278 0.057135097682476044
decider.linear3.weight: -0.041778407990932465 0.10618335753679276
decider.linear3.bias: -0.013845483772456646 0.048043228685855865

Rewards:
230.1930
230.1930
230.1930
objective = 28.0504207611084
==== episode 9500/10000 ====
action = 1
probs = 0.0115 0.9885 0.0000 0.0000

action = 1
probs = 0.3622 0.6378 0.0000 0.0000

action = 0
probs = 0.9993 0.0007 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002258260064991191 0.08595909178256989
encoder.encoder.weight_hh_l0: 3.842647129204124e-05 0.08774575591087341
encoder.encoder.bias_ih_l0: 0.013684915378689766 0.08966521173715591
encoder.encoder.bias_hh_l0: 0.023682022467255592 0.08753868192434311
encoder.encoder.weight_ih_l0_reverse: 0.0019473887514322996 0.08841738849878311
encoder.encoder.weight_hh_l0_reverse: 0.009702004492282867 0.08844877034425735
encoder.encoder.bias_ih_l0_reverse: 0.036062825471162796 0.08619073033332825
encoder.encoder.bias_hh_l0_reverse: 0.027928369119763374 0.08296748250722885
decider.lstm.weight_ih_l0: 0.0022819088771939278 0.14943385124206543
decider.lstm.weight_hh_l0: 0.0033179018646478653 0.14914116263389587
decider.lstm.bias_ih_l0: 0.026100611314177513 0.1600429117679596
decider.lstm.bias_hh_l0: 0.007113059051334858 0.14103499054908752
decider.linear1.weight: 0.004454866051673889 0.12200374156236649
decider.linear1.bias: 0.02097064070403576 0.11736509203910828
decider.linear2.weight: 0.005693227984011173 0.05468359589576721
decider.linear2.bias: 0.008609085343778133 0.05711670592427254
decider.linear3.weight: -0.042003240436315536 0.10658109933137894
decider.linear3.bias: -0.013975356705486774 0.04780279099941254

Rewards:
230.1930
230.1930
230.1930
objective = 35.45238494873047
==== episode 9600/10000 ====
action = 1
probs = 0.0068 0.9932 0.0000 0.0000

action = 0
probs = 0.2312 0.7688 0.0000 0.0000

action = 0
probs = 0.9990 0.0010 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002410151355434209 0.08602486550807953
encoder.encoder.weight_hh_l0: 3.847576226689853e-05 0.08781392127275467
encoder.encoder.bias_ih_l0: 0.013836096040904522 0.08970862627029419
encoder.encoder.bias_hh_l0: 0.023833200335502625 0.08766890317201614
encoder.encoder.weight_ih_l0_reverse: 0.0019425457576289773 0.08847185224294662
encoder.encoder.weight_hh_l0_reverse: 0.009689010679721832 0.08844763040542603
encoder.encoder.bias_ih_l0_reverse: 0.03616122528910637 0.08620230853557587
encoder.encoder.bias_hh_l0_reverse: 0.028026770800352097 0.08301494270563126
decider.lstm.weight_ih_l0: 0.002339791739359498 0.14948700368404388
decider.lstm.weight_hh_l0: 0.0033510560169816017 0.14918813109397888
decider.lstm.bias_ih_l0: 0.02638213150203228 0.16013331711292267
decider.lstm.bias_hh_l0: 0.0073945666663348675 0.14102517068386078
decider.linear1.weight: 0.004456215538084507 0.12203961610794067
decider.linear1.bias: 0.021082943305373192 0.11736658215522766
decider.linear2.weight: 0.005710763856768608 0.05470580235123634
decider.linear2.bias: 0.0086011728271842 0.05712627246975899
decider.linear3.weight: -0.042220454663038254 0.10698676109313965
decider.linear3.bias: -0.014097834005951881 0.04842536523938179

Rewards:
221.7540
221.7540
221.7540
objective = 108.83042907714844
==== episode 9700/10000 ====
action = 1
probs = 0.0085 0.9915 0.0000 0.0000

action = 1
probs = 0.2435 0.7565 0.0000 0.0000

action = 0
probs = 0.9990 0.0010 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022965304378885776 0.08593574166297913
encoder.encoder.weight_hh_l0: 3.676832784549333e-05 0.08770902454853058
encoder.encoder.bias_ih_l0: 0.013590660877525806 0.08959513157606125
encoder.encoder.bias_hh_l0: 0.02358776517212391 0.08755848556756973
encoder.encoder.weight_ih_l0_reverse: 0.0019491312559694052 0.08841728419065475
encoder.encoder.weight_hh_l0_reverse: 0.009692969731986523 0.08844359964132309
encoder.encoder.bias_ih_l0_reverse: 0.0360647477209568 0.08616992086172104
encoder.encoder.bias_hh_l0_reverse: 0.027930287644267082 0.08303382992744446
decider.lstm.weight_ih_l0: 0.0022828392684459686 0.14941230416297913
decider.lstm.weight_hh_l0: 0.0033166008070111275 0.14914017915725708
decider.lstm.bias_ih_l0: 0.026101764291524887 0.16007915139198303
decider.lstm.bias_hh_l0: 0.007114201318472624 0.14097817242145538
decider.linear1.weight: 0.004461695905774832 0.12201331555843353
decider.linear1.bias: 0.020985057577490807 0.11737198382616043
decider.linear2.weight: 0.005708369892090559 0.0547058992087841
decider.linear2.bias: 0.008555630221962929 0.05710829049348831
decider.linear3.weight: -0.042427368462085724 0.10734366625547409
decider.linear3.bias: -0.014216474257409573 0.04836161062121391

Rewards:
230.1930
230.1930
230.1930
objective = 22.14594268798828
==== episode 9800/10000 ====
action = 1
probs = 0.0073 0.9927 0.0000 0.0000

action = 1
probs = 0.2350 0.7650 0.0000 0.0000

action = 0
probs = 0.9991 0.0009 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000238897351664491 0.08599329739809036
encoder.encoder.weight_hh_l0: 3.907173595507629e-05 0.08777260035276413
encoder.encoder.bias_ih_l0: 0.013727107085287571 0.08966848999261856
encoder.encoder.bias_hh_l0: 0.023724211379885674 0.08763089776039124
encoder.encoder.weight_ih_l0_reverse: 0.0019469513790681958 0.08845657110214233
encoder.encoder.weight_hh_l0_reverse: 0.009699210524559021 0.08845894783735275
encoder.encoder.bias_ih_l0_reverse: 0.03613010421395302 0.08619976043701172
encoder.encoder.bias_hh_l0_reverse: 0.027995647862553596 0.08304165303707123
decider.lstm.weight_ih_l0: 0.0023275346029549837 0.14947223663330078
decider.lstm.weight_hh_l0: 0.0033416380174458027 0.14918501675128937
decider.lstm.bias_ih_l0: 0.026311829686164856 0.1601320207118988
decider.lstm.bias_hh_l0: 0.007324266247451305 0.14101070165634155
decider.linear1.weight: 0.004463959019631147 0.12203449755907059
decider.linear1.bias: 0.021066728979349136 0.11735942214727402
decider.linear2.weight: 0.005749765783548355 0.0547458790242672
decider.linear2.bias: 0.008576007559895515 0.057121243327856064
decider.linear3.weight: -0.04262780398130417 0.10774345695972443
decider.linear3.bias: -0.01433747261762619 0.048465073108673096

Rewards:
230.1930
230.1930
230.1930
objective = 21.187158584594727
==== episode 9900/10000 ====
action = 1
probs = 0.0102 0.9898 0.0000 0.0000

action = 1
probs = 0.3551 0.6449 0.0000 0.0000

action = 0
probs = 0.9995 0.0005 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022903576609678566 0.08600009232759476
encoder.encoder.weight_hh_l0: 4.150543099967763e-05 0.08778278529644012
encoder.encoder.bias_ih_l0: 0.013728589750826359 0.0897199735045433
encoder.encoder.bias_hh_l0: 0.023725688457489014 0.08759050816297531
encoder.encoder.weight_ih_l0_reverse: 0.001944946008734405 0.08844715356826782
encoder.encoder.weight_hh_l0_reverse: 0.009715680032968521 0.088475301861763
encoder.encoder.bias_ih_l0_reverse: 0.03608916327357292 0.08621907234191895
encoder.encoder.bias_hh_l0_reverse: 0.02795470505952835 0.08299240469932556
decider.lstm.weight_ih_l0: 0.0023207427002489567 0.14949215948581696
decider.lstm.weight_hh_l0: 0.0033369322773069143 0.14919206500053406
decider.lstm.bias_ih_l0: 0.026276733726263046 0.16009554266929626
decider.lstm.bias_hh_l0: 0.007289170287549496 0.14106124639511108
decider.linear1.weight: 0.0044648051261901855 0.12202661484479904
decider.linear1.bias: 0.021061532199382782 0.11736273765563965
decider.linear2.weight: 0.005799822509288788 0.05477983132004738
decider.linear2.bias: 0.008619343861937523 0.05712487921118736
decider.linear3.weight: -0.042861681431531906 0.10818009823560715
decider.linear3.bias: -0.014473821967840195 0.04797544330358505

Rewards:
230.1930
230.1930
230.1930
objective = 34.48783493041992
==== episode 10000/10000 ====
action = 1
probs = 0.0054 0.9946 0.0000 0.0000

action = 1
probs = 0.1563 0.8437 0.0000 0.0000

action = 0
probs = 0.9990 0.0010 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002296578895766288 0.08602091670036316
encoder.encoder.weight_hh_l0: 3.445423863013275e-05 0.08780094981193542
encoder.encoder.bias_ih_l0: 0.013774726539850235 0.08967840671539307
encoder.encoder.bias_hh_l0: 0.023771824315190315 0.087724469602108
encoder.encoder.weight_ih_l0_reverse: 0.0019324790919199586 0.08849222958087921
encoder.encoder.weight_hh_l0_reverse: 0.009662522934377193 0.0884309858083725
encoder.encoder.bias_ih_l0_reverse: 0.0361492782831192 0.08618640154600143
encoder.encoder.bias_hh_l0_reverse: 0.02801482193171978 0.0830598697066307
decider.lstm.weight_ih_l0: 0.002352322917431593 0.14948312938213348
decider.lstm.weight_hh_l0: 0.003357678186148405 0.14919109642505646
decider.lstm.bias_ih_l0: 0.026454197242856026 0.1601390838623047
decider.lstm.bias_hh_l0: 0.007466644048690796 0.14100080728530884
decider.linear1.weight: 0.004470278508961201 0.12206300348043442
decider.linear1.bias: 0.02117079123854637 0.11743248254060745
decider.linear2.weight: 0.0057847341522574425 0.0548035092651844
decider.linear2.bias: 0.008549712598323822 0.057111624628305435
decider.linear3.weight: -0.043054498732089996 0.10856795310974121
decider.linear3.bias: -0.014591880142688751 0.048971787095069885

Rewards:
230.1930
230.1930
230.1930
objective = 13.538969039916992
[INFO] : learning runtime (h:mm:ss): 0:02:23
[INFO] : learning end time: 12/17/2023 03:12:45 PM
