Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 04:02:42 PM
==== episode 1/10000 ====
action = 0
probs = 0.2519 0.2494 0.2494 0.2494

action = 0
probs = 0.2519 0.2494 0.2494 0.2494

action = 0
probs = 0.2519 0.2494 0.2494 0.2494

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0005200859741307795 0.08475914597511292
encoder.encoder.weight_hh_l0: 0.0008237144211307168 0.08828172832727432
encoder.encoder.bias_ih_l0: 0.01849159598350525 0.08796855807304382
encoder.encoder.bias_hh_l0: 0.028488701209425926 0.08873540163040161
encoder.encoder.weight_ih_l0_reverse: 0.001578424940817058 0.08688799291849136
encoder.encoder.weight_hh_l0_reverse: -0.0014257141156122088 0.08629430085420609
encoder.encoder.bias_ih_l0_reverse: 0.03178305923938751 0.08633430302143097
encoder.encoder.bias_hh_l0_reverse: 0.02364862896502018 0.08459167182445526
decider.lstm.weight_ih_l0: -0.0017140329582616687 0.14881344139575958
decider.lstm.weight_hh_l0: -0.006261657457798719 0.14818455278873444
decider.lstm.bias_ih_l0: 0.026137040928006172 0.1616394966840744
decider.lstm.bias_hh_l0: 0.007149966433644295 0.13842350244522095
decider.linear1.weight: -0.00020374699670355767 0.12212848663330078
decider.linear1.bias: 0.01934218406677246 0.11891002207994461
decider.linear2.weight: 0.005843617022037506 0.05393996462225914
decider.linear2.bias: 0.009083179756999016 0.056268129497766495
decider.linear3.weight: -0.007791588082909584 0.06059786304831505
decider.linear3.bias: 0.01761479675769806 0.04956234246492386

Rewards:
147.5939
147.5939
147.5939
objective = 203.50308227539062
==== episode 100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007098482456058264 0.08507730811834335
encoder.encoder.weight_hh_l0: 0.0009942578617483377 0.0888633131980896
encoder.encoder.bias_ih_l0: 0.020295223221182823 0.08825641125440598
encoder.encoder.bias_hh_l0: 0.03029232658445835 0.08914480358362198
encoder.encoder.weight_ih_l0_reverse: 0.0016003255732357502 0.08735029399394989
encoder.encoder.weight_hh_l0_reverse: -0.0014262580079957843 0.08633808046579361
encoder.encoder.bias_ih_l0_reverse: 0.033033981919288635 0.08671202510595322
encoder.encoder.bias_hh_l0_reverse: 0.024899546056985855 0.08480044454336166
decider.lstm.weight_ih_l0: -0.0016464017098769546 0.14910754561424255
decider.lstm.weight_hh_l0: -0.006549793295562267 0.14843374490737915
decider.lstm.bias_ih_l0: 0.027288448065519333 0.16210711002349854
decider.lstm.bias_hh_l0: 0.0083013866096735 0.1385820060968399
decider.linear1.weight: -0.0005141108995303512 0.12277583032846451
decider.linear1.bias: 0.021453022956848145 0.11939501017332077
decider.linear2.weight: 0.006592064630240202 0.054306596517562866
decider.linear2.bias: 0.010038215667009354 0.05676921829581261
decider.linear3.weight: -0.00862179696559906 0.06136837974190712
decider.linear3.bias: 0.016261575743556023 0.04634398594498634

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 10000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00071092409780249 0.08507920056581497
encoder.encoder.weight_hh_l0: 0.0009953140979632735 0.08886675536632538
encoder.encoder.bias_ih_l0: 0.02030557580292225 0.08825793862342834
encoder.encoder.bias_hh_l0: 0.030302677303552628 0.08914706110954285
encoder.encoder.weight_ih_l0_reverse: 0.0016004214994609356 0.08735325932502747
encoder.encoder.weight_hh_l0_reverse: -0.0014262599870562553 0.08633831143379211
encoder.encoder.bias_ih_l0_reverse: 0.03304172307252884 0.08671437948942184
encoder.encoder.bias_hh_l0_reverse: 0.024907294660806656 0.08480177074670792
decider.lstm.weight_ih_l0: -0.001645954791456461 0.149109348654747
decider.lstm.weight_hh_l0: -0.006551457569003105 0.14843524992465973
decider.lstm.bias_ih_l0: 0.027295084670186043 0.1621098816394806
decider.lstm.bias_hh_l0: 0.008308026008307934 0.13858304917812347
decider.linear1.weight: -0.0005162230227142572 0.12278012931346893
decider.linear1.bias: 0.021467028185725212 0.1193980872631073
decider.linear2.weight: 0.006597773637622595 0.05430914834141731
decider.linear2.bias: 0.010045452043414116 0.05677281692624092
decider.linear3.weight: -0.008627329021692276 0.06137407198548317
decider.linear3.bias: 0.016252463683485985 0.04632354527711868

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
[INFO] : learning runtime (h:mm:ss): 0:02:24
[INFO] : learning end time: 12/17/2023 04:05:06 PM
