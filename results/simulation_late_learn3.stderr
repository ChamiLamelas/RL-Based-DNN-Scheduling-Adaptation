Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(18, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/18/2023 10:45:42 AM
==== episode 1/75000 ====
action = 0
probs = 0.2618 0.2681 0.1975 0.2726

action = 0
probs = 0.2389 0.2173 0.1966 0.3472

action = 0
probs = 0.2240 0.2396 0.2330 0.3035

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000498846173286438 0.08069586753845215
encoder.encoder.weight_hh_l0: -0.0001977701613213867 0.08174465596675873
encoder.encoder.bias_ih_l0: -0.007144351955503225 0.08528584986925125
encoder.encoder.bias_hh_l0: 0.005927643738687038 0.08270595222711563
encoder.encoder.weight_ih_l0_reverse: 0.0004341825842857361 0.0824473574757576
encoder.encoder.weight_hh_l0_reverse: 0.0005494445795193315 0.08147525787353516
encoder.encoder.bias_ih_l0_reverse: 0.006783168297261 0.0796634778380394
encoder.encoder.bias_hh_l0_reverse: 0.007077816408127546 0.08428147435188293
decider.lstm.weight_ih_l0: -0.0014929547905921936 0.1448022425174713
decider.lstm.weight_hh_l0: 0.001902752323076129 0.14436547458171844
decider.lstm.bias_ih_l0: -0.031133398413658142 0.1402314305305481
decider.lstm.bias_hh_l0: 0.004687394946813583 0.15230867266654968
decider.linear1.weight: 0.003402101807296276 0.11740438640117645
decider.linear1.bias: -0.0026356312446296215 0.11448632180690765
decider.linear2.weight: 0.00037240044912323356 0.05117296800017357
decider.linear2.bias: -0.0016950062708929181 0.05175203084945679
decider.linear3.weight: 0.00025426794309169054 0.05124053731560707
decider.linear3.bias: -0.01404849998652935 0.022185705602169037

Rewards:
56.1059
56.1059
56.1059
objective = 79.82449340820312
==== episode 100/75000 ====
action = 0
probs = 0.2923 0.2110 0.1660 0.3307

action = 3
probs = 0.2600 0.1637 0.1956 0.3807

action = 3
probs = 0.2384 0.1950 0.2503 0.3163

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00046002346789464355 0.0806983932852745
encoder.encoder.weight_hh_l0: -0.00021036490215919912 0.08176123350858688
encoder.encoder.bias_ih_l0: -0.006971996743232012 0.0854671373963356
encoder.encoder.bias_hh_l0: 0.006099999882280827 0.08274786174297333
encoder.encoder.weight_ih_l0_reverse: 0.0004398913588374853 0.0824284553527832
encoder.encoder.weight_hh_l0_reverse: 0.000557607039809227 0.08147995173931122
encoder.encoder.bias_ih_l0_reverse: 0.006815363187342882 0.07973586767911911
encoder.encoder.bias_hh_l0_reverse: 0.007110010366886854 0.08420258015394211
decider.lstm.weight_ih_l0: -0.0014933028724044561 0.14480604231357574
decider.lstm.weight_hh_l0: 0.0018798670498654246 0.14435003697872162
decider.lstm.bias_ih_l0: -0.03107311762869358 0.14020821452140808
decider.lstm.bias_hh_l0: 0.004747673869132996 0.1523774415254593
decider.linear1.weight: 0.0034121216740459204 0.11740653961896896
decider.linear1.bias: -0.0024900767020881176 0.11451132595539093
decider.linear2.weight: 0.0003796066448558122 0.05118393152952194
decider.linear2.bias: -0.001712394063360989 0.051620472222566605
decider.linear3.weight: 5.92345604673028e-05 0.05129849165678024
decider.linear3.bias: -0.014255496673285961 0.021440403535962105

Rewards:
55.5291
55.5291
55.5291
objective = 61.94903564453125
==== episode 200/75000 ====
action = 3
probs = 0.2850 0.2030 0.1625 0.3495

action = 3
probs = 0.2610 0.1569 0.1914 0.3907

action = 0
probs = 0.2410 0.1744 0.2754 0.3092

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00044655255624093115 0.08070645481348038
encoder.encoder.weight_hh_l0: -0.00020192479132674634 0.08176922798156738
encoder.encoder.bias_ih_l0: -0.006967752240598202 0.08552911877632141
encoder.encoder.bias_hh_l0: 0.006104237865656614 0.0828264132142067
encoder.encoder.weight_ih_l0_reverse: 0.0004394677234813571 0.08241936564445496
encoder.encoder.weight_hh_l0_reverse: 0.0005608987994492054 0.08149541169404984
encoder.encoder.bias_ih_l0_reverse: 0.006831470411270857 0.07979816943407059
encoder.encoder.bias_hh_l0_reverse: 0.007126115262508392 0.08415737748146057
decider.lstm.weight_ih_l0: -0.0014925756258890033 0.14481189846992493
decider.lstm.weight_hh_l0: 0.0018731099553406239 0.1443423479795456
decider.lstm.bias_ih_l0: -0.031059931963682175 0.14014989137649536
decider.lstm.bias_hh_l0: 0.004760853946208954 0.15237966179847717
decider.linear1.weight: 0.003418179228901863 0.11741267144680023
decider.linear1.bias: -0.0025135143660008907 0.11454207450151443
decider.linear2.weight: 0.00037027342477813363 0.05118703097105026
decider.linear2.bias: -0.0017270417883992195 0.05157006159424782
decider.linear3.weight: 3.259116783738136e-05 0.05131460726261139
decider.linear3.bias: -0.014270738698542118 0.02122552879154682

Rewards:
55.3442
55.3442
55.3442
objective = 62.986053466796875
==== episode 300/75000 ====
action = 3
probs = 0.2930 0.2511 0.1608 0.2950

action = 0
probs = 0.3123 0.1873 0.1830 0.3174

action = 2
probs = 0.2964 0.2087 0.2491 0.2458

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005010339082218707 0.08069969713687897
encoder.encoder.weight_hh_l0: -0.00018569373060017824 0.08176682889461517
encoder.encoder.bias_ih_l0: -0.0070354086346924305 0.08541646599769592
encoder.encoder.bias_hh_l0: 0.006036580540239811 0.08282230794429779
encoder.encoder.weight_ih_l0_reverse: 0.00041886806138791144 0.08240170776844025
encoder.encoder.weight_hh_l0_reverse: 0.0005524097359739244 0.0814913734793663
encoder.encoder.bias_ih_l0_reverse: 0.0067286198027431965 0.07978476583957672
encoder.encoder.bias_hh_l0_reverse: 0.007023264653980732 0.08432383835315704
decider.lstm.weight_ih_l0: -0.0015007001347839832 0.14479875564575195
decider.lstm.weight_hh_l0: 0.0018930460792034864 0.1443151980638504
decider.lstm.bias_ih_l0: -0.03114016354084015 0.1400398463010788
decider.lstm.bias_hh_l0: 0.004680626094341278 0.15239883959293365
decider.linear1.weight: 0.0034230081364512444 0.11739571392536163
decider.linear1.bias: -0.002657694276422262 0.11455502361059189
decider.linear2.weight: 0.00030882336432114244 0.051184751093387604
decider.linear2.bias: -0.0018380740657448769 0.05156399682164192
decider.linear3.weight: 5.292869172990322e-05 0.05125069245696068
decider.linear3.bias: -0.01420840434730053 0.022791236639022827

Rewards:
54.2413
54.2413
54.2413
objective = 68.24078369140625
==== episode 400/75000 ====
action = 0
probs = 0.2965 0.2562 0.1770 0.2704

action = 0
probs = 0.3441 0.1875 0.1987 0.2697

action = 3
probs = 0.3480 0.2352 0.2275 0.1893

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005305844242684543 0.08070499449968338
encoder.encoder.weight_hh_l0: -0.00017601618310436606 0.08175922930240631
encoder.encoder.bias_ih_l0: -0.007141008973121643 0.08529023826122284
encoder.encoder.bias_hh_l0: 0.005930980201810598 0.08274447172880173
encoder.encoder.weight_ih_l0_reverse: 0.00041777221485972404 0.08241003006696701
encoder.encoder.weight_hh_l0_reverse: 0.0005441634566523135 0.08149021118879318
encoder.encoder.bias_ih_l0_reverse: 0.006663250736892223 0.07975376397371292
encoder.encoder.bias_hh_l0_reverse: 0.006957899313420057 0.08437538146972656
decider.lstm.weight_ih_l0: -0.0015051367226988077 0.14479564130306244
decider.lstm.weight_hh_l0: 0.0019853943958878517 0.14431793987751007
decider.lstm.bias_ih_l0: -0.031340695917606354 0.1400163769721985
decider.lstm.bias_hh_l0: 0.0044800890609622 0.15234963595867157
decider.linear1.weight: 0.003429711563512683 0.11737591028213501
decider.linear1.bias: -0.0027509480714797974 0.11449015885591507
decider.linear2.weight: 0.00026469328440725803 0.05118066444993019
decider.linear2.bias: -0.001928004203364253 0.05157121643424034
decider.linear3.weight: 6.22275983914733e-05 0.05119297653436661
decider.linear3.bias: -0.014198275282979012 0.023581814020872116

Rewards:
55.1187
55.1187
55.1187
objective = 72.51970672607422
==== episode 500/75000 ====
action = 3
probs = 0.3208 0.2675 0.1804 0.2312

action = 2
probs = 0.3740 0.2006 0.1990 0.2265

action = 0
probs = 0.3984 0.2127 0.2016 0.1873

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005353199667297304 0.08070980757474899
encoder.encoder.weight_hh_l0: -0.0001655902888160199 0.08177018910646439
encoder.encoder.bias_ih_l0: -0.007175670005381107 0.08523740619421005
encoder.encoder.bias_hh_l0: 0.005896319635212421 0.0827191174030304
encoder.encoder.weight_ih_l0_reverse: 0.0004245580639690161 0.08241185545921326
encoder.encoder.weight_hh_l0_reverse: 0.0005462280823849142 0.08149849623441696
encoder.encoder.bias_ih_l0_reverse: 0.006637546233832836 0.07970871031284332
encoder.encoder.bias_hh_l0_reverse: 0.00693219481036067 0.08451295644044876
decider.lstm.weight_ih_l0: -0.0015029414789751172 0.14478766918182373
decider.lstm.weight_hh_l0: 0.002028997987508774 0.1443430483341217
decider.lstm.bias_ih_l0: -0.03142322599887848 0.1401369273662567
decider.lstm.bias_hh_l0: 0.004397561773657799 0.1522485911846161
decider.linear1.weight: 0.0034268000163137913 0.11736543476581573
decider.linear1.bias: -0.002686353400349617 0.11454705148935318
decider.linear2.weight: 0.00024971284437924623 0.051189571619033813
decider.linear2.bias: -0.0019533378072082996 0.05156335607171059
decider.linear3.weight: 5.995994433760643e-05 0.05118665471673012
decider.linear3.bias: -0.01420170720666647 0.02447611279785633

Rewards:
56.3540
56.3540
56.3540
objective = 75.12395477294922
==== episode 600/75000 ====
action = 3
probs = 0.3144 0.2671 0.2116 0.2070

action = 0
probs = 0.3895 0.2028 0.2131 0.1946

action = 1
probs = 0.4398 0.2147 0.1969 0.1485

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005362840020097792 0.08072146773338318
encoder.encoder.weight_hh_l0: -0.0001704535388853401 0.08178089559078217
encoder.encoder.bias_ih_l0: -0.007188472431153059 0.08516262471675873
encoder.encoder.bias_hh_l0: 0.005883520934730768 0.08274108916521072
encoder.encoder.weight_ih_l0_reverse: 0.00042165874037891626 0.08241163939237595
encoder.encoder.weight_hh_l0_reverse: 0.0005555098177865148 0.08150423318147659
encoder.encoder.bias_ih_l0_reverse: 0.006709537468850613 0.07964995503425598
encoder.encoder.bias_hh_l0_reverse: 0.00700418883934617 0.08465567231178284
decider.lstm.weight_ih_l0: -0.0015087142819538713 0.14479096233844757
decider.lstm.weight_hh_l0: 0.0020147128961980343 0.1443459689617157
decider.lstm.bias_ih_l0: -0.031410425901412964 0.1401546746492386
decider.lstm.bias_hh_l0: 0.0044103581458330154 0.15211716294288635
decider.linear1.weight: 0.0034010231029242277 0.11737413704395294
decider.linear1.bias: -0.002573041245341301 0.1145656555891037
decider.linear2.weight: 0.00021820007532369345 0.05119948461651802
decider.linear2.bias: -0.0020137575920671225 0.05158549174666405
decider.linear3.weight: 5.890103057026863e-05 0.05118592455983162
decider.linear3.bias: -0.014195768162608147 0.025214476510882378

Rewards:
55.7553
55.7553
55.7553
objective = 75.39115905761719
==== episode 700/75000 ====
action = 1
probs = 0.4153 0.2201 0.1805 0.1840

action = 0
probs = 0.4739 0.1661 0.1810 0.1791

action = 0
probs = 0.4911 0.1833 0.1794 0.1462

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005287779495120049 0.08071890473365784
encoder.encoder.weight_hh_l0: -0.0001764821499818936 0.08180553466081619
encoder.encoder.bias_ih_l0: -0.007181256078183651 0.08522577583789825
encoder.encoder.bias_hh_l0: 0.0058907377533614635 0.08273176848888397
encoder.encoder.weight_ih_l0_reverse: 0.0004283302987460047 0.08241917937994003
encoder.encoder.weight_hh_l0_reverse: 0.0005526659078896046 0.08151238411664963
encoder.encoder.bias_ih_l0_reverse: 0.0066589126363396645 0.07967917621135712
encoder.encoder.bias_hh_l0_reverse: 0.006953563541173935 0.0846506729722023
decider.lstm.weight_ih_l0: -0.001504343468695879 0.1447916179895401
decider.lstm.weight_hh_l0: 0.00209024827927351 0.14439518749713898
decider.lstm.bias_ih_l0: -0.03168068826198578 0.14038576185703278
decider.lstm.bias_hh_l0: 0.004140092991292477 0.15208180248737335
decider.linear1.weight: 0.003379386616870761 0.11735167354345322
decider.linear1.bias: -0.0023638480342924595 0.11455345898866653
decider.linear2.weight: 0.00023065904679242522 0.05121138319373131
decider.linear2.bias: -0.0020002510864287615 0.05148761719465256
decider.linear3.weight: 2.182088792324066e-05 0.05120118334889412
decider.linear3.bias: -0.014294357970356941 0.025614909827709198

Rewards:
57.1223
57.1223
57.1223
objective = 56.57826232910156
==== episode 800/75000 ====
action = 0
probs = 0.4098 0.2476 0.1700 0.1726

action = 0
probs = 0.4718 0.1682 0.1887 0.1714

action = 0
probs = 0.4157 0.2128 0.2135 0.1580

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005330721032805741 0.08071859180927277
encoder.encoder.weight_hh_l0: -0.00017371524882037193 0.08181123435497284
encoder.encoder.bias_ih_l0: -0.007182643283158541 0.08525460213422775
encoder.encoder.bias_hh_l0: 0.00588934775441885 0.0827706903219223
encoder.encoder.weight_ih_l0_reverse: 0.0004324504698161036 0.08241676539182663
encoder.encoder.weight_hh_l0_reverse: 0.0005497756064869463 0.0815136656165123
encoder.encoder.bias_ih_l0_reverse: 0.006640051491558552 0.079670250415802
encoder.encoder.bias_hh_l0_reverse: 0.006934700068086386 0.08467064797878265
decider.lstm.weight_ih_l0: -0.001508665387518704 0.1447833627462387
decider.lstm.weight_hh_l0: 0.002033932600170374 0.144354447722435
decider.lstm.bias_ih_l0: -0.03149853274226189 0.14042437076568604
decider.lstm.bias_hh_l0: 0.004322253167629242 0.15212930738925934
decider.linear1.weight: 0.0034311353228986263 0.11735506355762482
decider.linear1.bias: -0.002481057308614254 0.11460941284894943
decider.linear2.weight: 0.00020594013039954007 0.05120952054858208
decider.linear2.bias: -0.0020249749068170786 0.051487162709236145
decider.linear3.weight: 3.0257971957325935e-05 0.051196128129959106
decider.linear3.bias: -0.014266559854149818 0.025732439011335373

Rewards:
56.1059
56.1059
56.1059
objective = 47.15023422241211
==== episode 900/75000 ====
action = 2
probs = 0.3195 0.2945 0.2034 0.1826

action = 3
probs = 0.3542 0.2288 0.2195 0.1975

action = 0
probs = 0.3700 0.2222 0.2296 0.1782

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000557278108317405 0.08070863783359528
encoder.encoder.weight_hh_l0: -0.00016838969895616174 0.08181556314229965
encoder.encoder.bias_ih_l0: -0.007315189111977816 0.08512894064188004
encoder.encoder.bias_hh_l0: 0.005756798665970564 0.08276708424091339
encoder.encoder.weight_ih_l0_reverse: 0.000415656715631485 0.08246063441038132
encoder.encoder.weight_hh_l0_reverse: 0.0005394015461206436 0.0815211609005928
encoder.encoder.bias_ih_l0_reverse: 0.006523788906633854 0.07967130094766617
encoder.encoder.bias_hh_l0_reverse: 0.006818439811468124 0.08462493121623993
decider.lstm.weight_ih_l0: -0.0015038243727758527 0.14477840065956116
decider.lstm.weight_hh_l0: 0.0019863892812281847 0.14435352385044098
decider.lstm.bias_ih_l0: -0.03135841339826584 0.140437513589859
decider.lstm.bias_hh_l0: 0.004462379030883312 0.15225593745708466
decider.linear1.weight: 0.0035474514588713646 0.11733822524547577
decider.linear1.bias: -0.00302297156304121 0.11455733329057693
decider.linear2.weight: 0.00010526254482101649 0.05118635669350624
decider.linear2.bias: -0.0021982265170663595 0.051515139639377594
decider.linear3.weight: 8.426234126091003e-05 0.0510680116713047
decider.linear3.bias: -0.014139335602521896 0.02514319121837616

Rewards:
53.4915
53.4915
53.4915
objective = 75.04588317871094
==== episode 1000/75000 ====
action = 2
probs = 0.3129 0.2980 0.2182 0.1709

action = 2
probs = 0.3463 0.2254 0.2442 0.1841

action = 1
probs = 0.3631 0.2112 0.2625 0.1631

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005487087764777243 0.08070802688598633
encoder.encoder.weight_hh_l0: -0.00016406073700636625 0.08181965351104736
encoder.encoder.bias_ih_l0: -0.00731317326426506 0.0851026326417923
encoder.encoder.bias_hh_l0: 0.005758815445005894 0.08278446644544601
encoder.encoder.weight_ih_l0_reverse: 0.0004149651504121721 0.08245985954999924
encoder.encoder.weight_hh_l0_reverse: 0.0005470042815431952 0.0815277025103569
encoder.encoder.bias_ih_l0_reverse: 0.006602727808058262 0.0796852633357048
encoder.encoder.bias_hh_l0_reverse: 0.006897375453263521 0.08471471071243286
decider.lstm.weight_ih_l0: -0.0015033906092867255 0.14478398859500885
decider.lstm.weight_hh_l0: 0.002033864613622427 0.1443178802728653
decider.lstm.bias_ih_l0: -0.03146044909954071 0.1404815912246704
decider.lstm.bias_hh_l0: 0.004360344260931015 0.15213659405708313
decider.linear1.weight: 0.0035437527112662792 0.11734314262866974
decider.linear1.bias: -0.0029843500815331936 0.11454012244939804
decider.linear2.weight: 7.340576848946512e-05 0.05119398981332779
decider.linear2.bias: -0.002245356095954776 0.051470205187797546
decider.linear3.weight: 8.040689863264561e-05 0.051077112555503845
decider.linear3.bias: -0.014140024781227112 0.025468528270721436

Rewards:
54.4245
54.4245
54.4245
objective = 81.40280151367188
==== episode 1100/75000 ====
action = 0
probs = 0.2615 0.3222 0.2333 0.1831

action = 2
probs = 0.2885 0.2549 0.2525 0.2041

action = 0
probs = 0.3133 0.2402 0.2679 0.1786

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005456052604131401 0.08071735501289368
encoder.encoder.weight_hh_l0: -0.0001659941190155223 0.08182109892368317
encoder.encoder.bias_ih_l0: -0.007303659338504076 0.08505933731794357
encoder.encoder.bias_hh_l0: 0.005768327508121729 0.08282392472028732
encoder.encoder.weight_ih_l0_reverse: 0.00042204424971714616 0.08249583095312119
encoder.encoder.weight_hh_l0_reverse: 0.0005394650506787002 0.08154720813035965
encoder.encoder.bias_ih_l0_reverse: 0.006604948081076145 0.07973014563322067
encoder.encoder.bias_hh_l0_reverse: 0.006899594329297543 0.08470548689365387
decider.lstm.weight_ih_l0: -0.0015000972198322415 0.1447973996400833
decider.lstm.weight_hh_l0: 0.0019526196410879493 0.14427731931209564
decider.lstm.bias_ih_l0: -0.03125879168510437 0.14051011204719543
decider.lstm.bias_hh_l0: 0.004561996087431908 0.15223759412765503
decider.linear1.weight: 0.003643738105893135 0.11734231561422348
decider.linear1.bias: -0.003288889769464731 0.11447315663099289
decider.linear2.weight: 1.6247533494606614e-05 0.0511837899684906
decider.linear2.bias: -0.002349930815398693 0.051506634801626205
decider.linear3.weight: 0.00011441181413829327 0.051004160195589066
decider.linear3.bias: -0.01405478548258543 0.02489309199154377

Rewards:
55.2622
55.2622
55.2622
objective = 71.43896484375
==== episode 1200/75000 ====
action = 2
probs = 0.2685 0.3063 0.2371 0.1880

action = 1
probs = 0.2837 0.2348 0.2667 0.2148

action = 2
probs = 0.2727 0.2241 0.3167 0.1865

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005199527367949486 0.08070292323827744
encoder.encoder.weight_hh_l0: -0.0001697336119832471 0.08183310925960541
encoder.encoder.bias_ih_l0: -0.007317233365029097 0.0850529745221138
encoder.encoder.bias_hh_l0: 0.005754751618951559 0.08282069116830826
encoder.encoder.weight_ih_l0_reverse: 0.00042259407928213477 0.08250049501657486
encoder.encoder.weight_hh_l0_reverse: 0.0005309537518769503 0.08153942972421646
encoder.encoder.bias_ih_l0_reverse: 0.006579672452062368 0.07975807785987854
encoder.encoder.bias_hh_l0_reverse: 0.006874320562928915 0.08468466252088547
decider.lstm.weight_ih_l0: -0.0014996352838352323 0.14479492604732513
decider.lstm.weight_hh_l0: 0.0019565289840102196 0.14425472915172577
decider.lstm.bias_ih_l0: -0.031262658536434174 0.14048995077610016
decider.lstm.bias_hh_l0: 0.004558133892714977 0.15224404633045197
decider.linear1.weight: 0.0036499109119176865 0.11733665317296982
decider.linear1.bias: -0.0033196760341525078 0.11454400420188904
decider.linear2.weight: 1.4151984942145646e-05 0.051184918731451035
decider.linear2.bias: -0.0023507706355303526 0.05146002396941185
decider.linear3.weight: 0.00011690706014633179 0.05101832002401352
decider.linear3.bias: -0.014038915745913982 0.024552693590521812

Rewards:
52.9272
52.9272
52.9272
objective = 71.24430084228516
==== episode 1300/75000 ====
action = 1
probs = 0.2912 0.2799 0.2197 0.2092

action = 1
probs = 0.2989 0.2130 0.2484 0.2397

action = 2
probs = 0.2522 0.2392 0.3173 0.1912

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005343119264580309 0.08068963885307312
encoder.encoder.weight_hh_l0: -0.00015731171879451722 0.08182558417320251
encoder.encoder.bias_ih_l0: -0.007254765368998051 0.08514542132616043
encoder.encoder.bias_hh_l0: 0.005817220080643892 0.08282513916492462
encoder.encoder.weight_ih_l0_reverse: 0.00041091738967224956 0.08249694108963013
encoder.encoder.weight_hh_l0_reverse: 0.0005353312590159476 0.08153755217790604
encoder.encoder.bias_ih_l0_reverse: 0.006543522700667381 0.07981150597333908
encoder.encoder.bias_hh_l0_reverse: 0.0068381731398403645 0.08462823182344437
decider.lstm.weight_ih_l0: -0.0015054316027089953 0.14479656517505646
decider.lstm.weight_hh_l0: 0.0019316489342600107 0.1442217081785202
decider.lstm.bias_ih_l0: -0.03123023733496666 0.14042584598064423
decider.lstm.bias_hh_l0: 0.00459055881947279 0.15231911838054657
decider.linear1.weight: 0.003663345007225871 0.11732704192399979
decider.linear1.bias: -0.0033974172547459602 0.11458846926689148
decider.linear2.weight: 1.5463490854017437e-05 0.05118340253829956
decider.linear2.bias: -0.0023503759875893593 0.05141342803835869
decider.linear3.weight: 0.00011598039418458939 0.05101558938622475
decider.linear3.bias: -0.014037201181054115 0.024006441235542297

Rewards:
54.1804
54.1804
54.1804
objective = 71.6531982421875
==== episode 1400/75000 ====
action = 0
probs = 0.3134 0.2584 0.2093 0.2190

action = 0
probs = 0.3391 0.1850 0.2302 0.2457

action = 1
probs = 0.2857 0.2387 0.2933 0.1822

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005412879982031882 0.08071079850196838
encoder.encoder.weight_hh_l0: -0.00014909128367435187 0.08182884007692337
encoder.encoder.bias_ih_l0: -0.0072019509971141815 0.08520396798849106
encoder.encoder.bias_hh_l0: 0.005870032124221325 0.0828479528427124
encoder.encoder.weight_ih_l0_reverse: 0.00041620820411480963 0.08248084783554077
encoder.encoder.weight_hh_l0_reverse: 0.0005437438958324492 0.08154274523258209
encoder.encoder.bias_ih_l0_reverse: 0.006543485913425684 0.07985416054725647
encoder.encoder.bias_hh_l0_reverse: 0.006838138680905104 0.08466634154319763
decider.lstm.weight_ih_l0: -0.0015086188213899732 0.14479854702949524
decider.lstm.weight_hh_l0: 0.0019717963878065348 0.14420770108699799
decider.lstm.bias_ih_l0: -0.03134390711784363 0.14039850234985352
decider.lstm.bias_hh_l0: 0.004476883448660374 0.15229925513267517
decider.linear1.weight: 0.0036843016277998686 0.11731187999248505
decider.linear1.bias: -0.003470060881227255 0.11460671573877335
decider.linear2.weight: 3.264645056333393e-05 0.05118127912282944
decider.linear2.bias: -0.0023215636610984802 0.0513768345117569
decider.linear3.weight: 9.917211718857288e-05 0.051005423069000244
decider.linear3.bias: -0.014073573984205723 0.023970818147063255

Rewards:
56.0027
56.0027
56.0027
objective = 68.58642578125
==== episode 1500/75000 ====
action = 0
probs = 0.3018 0.2773 0.2153 0.2056

action = 3
probs = 0.3292 0.1953 0.2464 0.2291

action = 1
probs = 0.2909 0.2268 0.2894 0.1929

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000553696823772043 0.08072376251220703
encoder.encoder.weight_hh_l0: -0.00013672585191670805 0.08183268457651138
encoder.encoder.bias_ih_l0: -0.007181985769420862 0.08517660200595856
encoder.encoder.bias_hh_l0: 0.005890001077204943 0.08287407457828522
encoder.encoder.weight_ih_l0_reverse: 0.000428603874752298 0.08248651772737503
encoder.encoder.weight_hh_l0_reverse: 0.0005588827189058065 0.08154793083667755
encoder.encoder.bias_ih_l0_reverse: 0.006617786828428507 0.07981972396373749
encoder.encoder.bias_hh_l0_reverse: 0.006912439130246639 0.08470678329467773
decider.lstm.weight_ih_l0: -0.0015049035428091884 0.14480729401111603
decider.lstm.weight_hh_l0: 0.0019233212806284428 0.14420674741268158
decider.lstm.bias_ih_l0: -0.031191863119602203 0.1403726488351822
decider.lstm.bias_hh_l0: 0.004628920927643776 0.15225976705551147
decider.linear1.weight: 0.0037059225142002106 0.11731937527656555
decider.linear1.bias: -0.003531062975525856 0.1145867183804512
decider.linear2.weight: 2.643020707182586e-06 0.051182325929403305
decider.linear2.bias: -0.00237570283934474 0.05140044167637825
decider.linear3.weight: 0.00010175921488553286 0.050961434841156006
decider.linear3.bias: -0.01406921073794365 0.0241868756711483

Rewards:
56.7064
56.7064
56.7064
objective = 78.53976440429688
==== episode 1600/75000 ====
action = 0
probs = 0.2920 0.3108 0.2062 0.1911

action = 1
probs = 0.3418 0.2080 0.2384 0.2117

action = 1
probs = 0.2875 0.2416 0.2931 0.1778

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005248893285170197 0.08072830736637115
encoder.encoder.weight_hh_l0: -0.000151377433212474 0.08185822516679764
encoder.encoder.bias_ih_l0: -0.007128987926989794 0.08517513424158096
encoder.encoder.bias_hh_l0: 0.005942997056990862 0.08289969712495804
encoder.encoder.weight_ih_l0_reverse: 0.000436120928497985 0.08247847855091095
encoder.encoder.weight_hh_l0_reverse: 0.0005606147460639477 0.08155356347560883
encoder.encoder.bias_ih_l0_reverse: 0.006668728310614824 0.07981183379888535
encoder.encoder.bias_hh_l0_reverse: 0.006963381543755531 0.08480484783649445
decider.lstm.weight_ih_l0: -0.0015011229552328587 0.14480863511562347
decider.lstm.weight_hh_l0: 0.0019420079188421369 0.1441836655139923
decider.lstm.bias_ih_l0: -0.031230712309479713 0.1403786987066269
decider.lstm.bias_hh_l0: 0.004590075463056564 0.15225405991077423
decider.linear1.weight: 0.003696148283779621 0.11732857674360275
decider.linear1.bias: -0.003460661508142948 0.11452214419841766
decider.linear2.weight: 7.441602065227926e-06 0.051192328333854675
decider.linear2.bias: -0.002360717160627246 0.05144202709197998
decider.linear3.weight: 9.275716729462147e-05 0.05098092555999756
decider.linear3.bias: -0.01408318243920803 0.024789955466985703

Rewards:
53.3704
53.3704
53.3704
objective = 75.10685729980469
==== episode 1700/75000 ====
action = 2
probs = 0.3007 0.3010 0.2106 0.1877

action = 2
probs = 0.3473 0.2016 0.2472 0.2039

action = 2
probs = 0.2596 0.2262 0.3343 0.1799

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005023058620281518 0.08071108162403107
encoder.encoder.weight_hh_l0: -0.00015692510351072997 0.08186815679073334
encoder.encoder.bias_ih_l0: -0.0071721188724040985 0.08513016253709793
encoder.encoder.bias_hh_l0: 0.005899868439882994 0.08283454179763794
encoder.encoder.weight_ih_l0_reverse: 0.0004268361662980169 0.08247528970241547
encoder.encoder.weight_hh_l0_reverse: 0.000545948394574225 0.08154524117708206
encoder.encoder.bias_ih_l0_reverse: 0.006644705310463905 0.07980941236019135
encoder.encoder.bias_hh_l0_reverse: 0.00693935714662075 0.08479787409305573
decider.lstm.weight_ih_l0: -0.0014966960297897458 0.14480669796466827
decider.lstm.weight_hh_l0: 0.0019573774188756943 0.14418059587478638
decider.lstm.bias_ih_l0: -0.031287357211112976 0.14034150540828705
decider.lstm.bias_hh_l0: 0.004533441737294197 0.15221205353736877
decider.linear1.weight: 0.0036577717401087284 0.11734536290168762
decider.linear1.bias: -0.0033316481858491898 0.11458466202020645
decider.linear2.weight: -5.223380867391825e-06 0.05120553448796272
decider.linear2.bias: -0.002361674327403307 0.051424819976091385
decider.linear3.weight: 8.24023736640811e-05 0.051018718630075455
decider.linear3.bias: -0.014082616195082664 0.02475886605679989

Rewards:
54.2413
54.2413
54.2413
objective = 73.24834442138672
==== episode 1800/75000 ====
action = 0
probs = 0.2826 0.3290 0.2088 0.1796

action = 2
probs = 0.3413 0.2157 0.2614 0.1815

action = 2
probs = 0.2569 0.2360 0.3533 0.1537

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004982955870218575 0.08072000741958618
encoder.encoder.weight_hh_l0: -0.000159956791321747 0.0818849429488182
encoder.encoder.bias_ih_l0: -0.007167167495936155 0.08512147516012192
encoder.encoder.bias_hh_l0: 0.005904821213334799 0.08286610245704651
encoder.encoder.weight_ih_l0_reverse: 0.0004297386039979756 0.08247224241495132
encoder.encoder.weight_hh_l0_reverse: 0.0005490861949510872 0.08155179768800735
encoder.encoder.bias_ih_l0_reverse: 0.006731748580932617 0.07978753000497818
encoder.encoder.bias_hh_l0_reverse: 0.007026398554444313 0.08488941937685013
decider.lstm.weight_ih_l0: -0.0014938517706468701 0.14481063187122345
decider.lstm.weight_hh_l0: 0.0019698201213032007 0.14417679607868195
decider.lstm.bias_ih_l0: -0.031330499798059464 0.1403864622116089
decider.lstm.bias_hh_l0: 0.0044903019443154335 0.1522214561700821
decider.linear1.weight: 0.003646516241133213 0.11736294627189636
decider.linear1.bias: -0.0032807043753564358 0.11455346643924713
decider.linear2.weight: -4.0632294258102775e-06 0.05121351405978203
decider.linear2.bias: -0.002362200291827321 0.05146164819598198
decider.linear3.weight: 7.098808418959379e-05 0.0510408952832222
decider.linear3.bias: -0.014100556261837482 0.025420505553483963

Rewards:
55.0778
55.0778
55.0778
objective = 66.93492889404297
==== episode 1900/75000 ====
action = 1
probs = 0.2942 0.3258 0.2219 0.1581

action = 0
probs = 0.3530 0.2237 0.2668 0.1564

action = 2
probs = 0.2725 0.2532 0.3434 0.1310

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004759068542625755 0.08073830604553223
encoder.encoder.weight_hh_l0: -0.00015648407861590385 0.08189531415700912
encoder.encoder.bias_ih_l0: -0.007235080003738403 0.08509621769189835
encoder.encoder.bias_hh_l0: 0.0058369082398712635 0.08291096240282059
encoder.encoder.weight_ih_l0_reverse: 0.00043471617391332984 0.0824785828590393
encoder.encoder.weight_hh_l0_reverse: 0.0005659857415594161 0.08157391846179962
encoder.encoder.bias_ih_l0_reverse: 0.006757644936442375 0.0797102227807045
encoder.encoder.bias_hh_l0_reverse: 0.007052296306937933 0.08501769602298737
decider.lstm.weight_ih_l0: -0.0014977813698351383 0.14479577541351318
decider.lstm.weight_hh_l0: 0.0020044250413775444 0.14419057965278625
decider.lstm.bias_ih_l0: -0.03142833709716797 0.1405569463968277
decider.lstm.bias_hh_l0: 0.004392461851239204 0.15206025540828705
decider.linear1.weight: 0.0036353236064314842 0.11736582964658737
decider.linear1.bias: -0.0031495876610279083 0.11457210779190063
decider.linear2.weight: -3.0283117666840553e-06 0.05121923238039017
decider.linear2.bias: -0.0023804688826203346 0.05148840323090553
decider.linear3.weight: 5.366408731788397e-05 0.051036056131124496
decider.linear3.bias: -0.014151155948638916 0.02634376287460327

Rewards:
63.5281
63.5281
63.5281
objective = 68.43360137939453
==== episode 2000/75000 ====
action = 3
probs = 0.2698 0.3395 0.2278 0.1629

action = 0
probs = 0.3147 0.2424 0.2797 0.1631

action = 1
probs = 0.2287 0.2733 0.3728 0.1251

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004696462128777057 0.08072756975889206
encoder.encoder.weight_hh_l0: -0.00015530652308370918 0.08189570158720016
encoder.encoder.bias_ih_l0: -0.007315408904105425 0.08508986234664917
encoder.encoder.bias_hh_l0: 0.005756580736488104 0.08289261907339096
encoder.encoder.weight_ih_l0_reverse: 0.00042380555532872677 0.0824972614645958
encoder.encoder.weight_hh_l0_reverse: 0.000543817994184792 0.08157680183649063
encoder.encoder.bias_ih_l0_reverse: 0.006612425670027733 0.07978276163339615
encoder.encoder.bias_hh_l0_reverse: 0.006907075643539429 0.0849386602640152
decider.lstm.weight_ih_l0: -0.0014970056945458055 0.1447756588459015
decider.lstm.weight_hh_l0: 0.0019837915897369385 0.14417926967144012
decider.lstm.bias_ih_l0: -0.031363505870103836 0.14067421853542328
decider.lstm.bias_hh_l0: 0.004457294009625912 0.15216970443725586
decider.linear1.weight: 0.003616184461861849 0.11738263070583344
decider.linear1.bias: -0.0031565790995955467 0.11456577479839325
decider.linear2.weight: 1.3697645044885576e-05 0.05122346803545952
decider.linear2.bias: -0.0023611343931406736 0.05153566226363182
decider.linear3.weight: 6.0737947933375835e-05 0.05106951296329498
decider.linear3.bias: -0.014123834669589996 0.026250053197145462

Rewards:
55.7553
55.7553
55.7553
objective = 79.31993103027344
==== episode 2100/75000 ====
action = 2
probs = 0.2456 0.3613 0.2169 0.1762

action = 1
probs = 0.3019 0.2736 0.2537 0.1709

action = 1
probs = 0.2197 0.2911 0.3550 0.1342

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000491458922624588 0.08074330538511276
encoder.encoder.weight_hh_l0: -0.00015659465861972421 0.08191021531820297
encoder.encoder.bias_ih_l0: -0.007271356415003538 0.0850628986954689
encoder.encoder.bias_hh_l0: 0.005800630897283554 0.08289165794849396
encoder.encoder.weight_ih_l0_reverse: 0.00043046666542068124 0.08249027281999588
encoder.encoder.weight_hh_l0_reverse: 0.0005445716669782996 0.08157812803983688
encoder.encoder.bias_ih_l0_reverse: 0.006623738911002874 0.07978484779596329
encoder.encoder.bias_hh_l0_reverse: 0.006918389815837145 0.08499293029308319
decider.lstm.weight_ih_l0: -0.0015025490429252386 0.14477789402008057
decider.lstm.weight_hh_l0: 0.001984373666346073 0.14418873190879822
decider.lstm.bias_ih_l0: -0.03140687197446823 0.14057792723178864
decider.lstm.bias_hh_l0: 0.004413922317326069 0.15224511921405792
decider.linear1.weight: 0.003630188060924411 0.11737263202667236
decider.linear1.bias: -0.0032888767309486866 0.11455650627613068
decider.linear2.weight: -2.0529201719909906e-05 0.05122004449367523
decider.linear2.bias: -0.002413940615952015 0.0515812486410141
decider.linear3.weight: 7.384154014289379e-05 0.05103930085897446
decider.linear3.bias: -0.014091280288994312 0.025888942182064056

Rewards:
55.2827
55.2827
55.2827
objective = 74.78592681884766
==== episode 2200/75000 ====
action = 0
probs = 0.3029 0.3109 0.2280 0.1582

action = 2
probs = 0.3365 0.2452 0.2736 0.1447

action = 2
probs = 0.2438 0.2894 0.3489 0.1179

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000507826276589185 0.08075010031461716
encoder.encoder.weight_hh_l0: -0.00012654437159653753 0.08190213888883591
encoder.encoder.bias_ih_l0: -0.007294723764061928 0.0851057693362236
encoder.encoder.bias_hh_l0: 0.005777264479547739 0.08291544020175934
encoder.encoder.weight_ih_l0_reverse: 0.00042938379920087755 0.08251136541366577
encoder.encoder.weight_hh_l0_reverse: 0.0005520123522728682 0.08159928768873215
encoder.encoder.bias_ih_l0_reverse: 0.006582137197256088 0.07973489165306091
encoder.encoder.bias_hh_l0_reverse: 0.006876785773783922 0.08502764999866486
decider.lstm.weight_ih_l0: -0.00150236114859581 0.14478886127471924
decider.lstm.weight_hh_l0: 0.0020147929899394512 0.14416784048080444
decider.lstm.bias_ih_l0: -0.03146335482597351 0.14070716500282288
decider.lstm.bias_hh_l0: 0.004357431083917618 0.15219251811504364
decider.linear1.weight: 0.0036302111111581326 0.1173514798283577
decider.linear1.bias: -0.0032899645157158375 0.11459832638502121
decider.linear2.weight: -4.3996493332087994e-05 0.05121143162250519
decider.linear2.bias: -0.0024616545997560024 0.051499973982572556
decider.linear3.weight: 5.153066013008356e-05 0.05100294202566147
decider.linear3.bias: -0.014161070808768272 0.026616329327225685

Rewards:
55.0778
55.0778
55.0778
objective = 65.05706024169922
==== episode 2300/75000 ====
action = 1
probs = 0.3725 0.3096 0.1907 0.1272

action = 2
probs = 0.4228 0.2424 0.2202 0.1146

action = 2
probs = 0.2997 0.2738 0.3254 0.1012

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004928719718009233 0.0807715356349945
encoder.encoder.weight_hh_l0: -0.0001391423138557002 0.08192380517721176
encoder.encoder.bias_ih_l0: -0.007245512213557959 0.08513743430376053
encoder.encoder.bias_hh_l0: 0.0058264825493097305 0.08289143443107605
encoder.encoder.weight_ih_l0_reverse: 0.00043918355368077755 0.08249092102050781
encoder.encoder.weight_hh_l0_reverse: 0.0005569321219809353 0.08160483837127686
encoder.encoder.bias_ih_l0_reverse: 0.006659546867012978 0.079647496342659
encoder.encoder.bias_hh_l0_reverse: 0.006954194977879524 0.08511782437562943
decider.lstm.weight_ih_l0: -0.0015012782532721758 0.14480766654014587
decider.lstm.weight_hh_l0: 0.0020608140621334314 0.14419011771678925
decider.lstm.bias_ih_l0: -0.03159356117248535 0.1406390368938446
decider.lstm.bias_hh_l0: 0.004227227531373501 0.15223994851112366
decider.linear1.weight: 0.0035884669050574303 0.11737177520990372
decider.linear1.bias: -0.002882225438952446 0.11454837024211884
decider.linear2.weight: 1.470145070925355e-05 0.05123462900519371
decider.linear2.bias: -0.002364938147366047 0.05149867385625839
decider.linear3.weight: 5.193287506699562e-06 0.051088158041238785
decider.linear3.bias: -0.014274893328547478 0.02795473113656044

Rewards:
52.0855
52.0855
52.0855
objective = 66.12300872802734
==== episode 2400/75000 ====
action = 1
probs = 0.3871 0.3368 0.1590 0.1171

action = 1
probs = 0.4882 0.2382 0.1722 0.1014

action = 0
probs = 0.3386 0.2821 0.2820 0.0973

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00048338226042687893 0.08080673217773438
encoder.encoder.weight_hh_l0: -0.00016178726218640804 0.0819445326924324
encoder.encoder.bias_ih_l0: -0.007070725783705711 0.0851856991648674
encoder.encoder.bias_hh_l0: 0.006001270841807127 0.08294884860515594
encoder.encoder.weight_ih_l0_reverse: 0.00045570507063530385 0.08247054368257523
encoder.encoder.weight_hh_l0_reverse: 0.0005593497771769762 0.08161687850952148
encoder.encoder.bias_ih_l0_reverse: 0.00681231077760458 0.0796782448887825
encoder.encoder.bias_hh_l0_reverse: 0.007106957957148552 0.08513391762971878
decider.lstm.weight_ih_l0: -0.0015115595888346434 0.14481551945209503
decider.lstm.weight_hh_l0: 0.002004236914217472 0.14423024654388428
decider.lstm.bias_ih_l0: -0.031449392437934875 0.14044980704784393
decider.lstm.bias_hh_l0: 0.004371390677988529 0.15241293609142303
decider.linear1.weight: 0.0035643610171973705 0.11740376800298691
decider.linear1.bias: -0.002638128586113453 0.11461176723241806
decider.linear2.weight: 6.016265251673758e-05 0.05125625431537628
decider.linear2.bias: -0.0022686903830617666 0.05156930536031723
decider.linear3.weight: -1.579767558723688e-05 0.051178883761167526
decider.linear3.bias: -0.014322897419333458 0.02850673906505108

Rewards:
56.2092
56.2092
56.2092
objective = 67.56807708740234
==== episode 2500/75000 ====
action = 1
probs = 0.3507 0.3509 0.1680 0.1303

action = 0
probs = 0.4556 0.2537 0.1831 0.1076

action = 1
probs = 0.3558 0.2711 0.2758 0.0973

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005299586919136345 0.0808003693819046
encoder.encoder.weight_hh_l0: -0.0001394983264617622 0.08194569498300552
encoder.encoder.bias_ih_l0: -0.007211094722151756 0.08518762141466141
encoder.encoder.bias_hh_l0: 0.005860904231667519 0.08296310901641846
encoder.encoder.weight_ih_l0_reverse: 0.0004305249312892556 0.08248750865459442
encoder.encoder.weight_hh_l0_reverse: 0.0005502236890606582 0.08161655068397522
encoder.encoder.bias_ih_l0_reverse: 0.006741251330822706 0.07964223623275757
encoder.encoder.bias_hh_l0_reverse: 0.007035903166979551 0.08512742072343826
decider.lstm.weight_ih_l0: -0.0015135861467570066 0.1448049396276474
decider.lstm.weight_hh_l0: 0.00203540176153183 0.1442420333623886
decider.lstm.bias_ih_l0: -0.03152106702327728 0.14041291177272797
decider.lstm.bias_hh_l0: 0.004299717955291271 0.15234056115150452
decider.linear1.weight: 0.0035880301147699356 0.11737856268882751
decider.linear1.bias: -0.0028822878375649452 0.1145886778831482
decider.linear2.weight: 9.008304914459586e-06 0.0512433759868145
decider.linear2.bias: -0.0023623176384717226 0.05158042535185814
decider.linear3.weight: -3.1436793506145477e-06 0.051094576716423035
decider.linear3.bias: -0.014293007552623749 0.02817574515938759

Rewards:
53.7139
53.7139
53.7139
objective = 56.20201873779297
==== episode 2600/75000 ====
action = 0
probs = 0.3612 0.3573 0.1617 0.1197

action = 2
probs = 0.4698 0.2386 0.1873 0.1044

action = 0
probs = 0.3504 0.2507 0.2995 0.0994

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004964836407452822 0.08080176264047623
encoder.encoder.weight_hh_l0: -0.00017790589481592178 0.08199514448642731
encoder.encoder.bias_ih_l0: -0.0071354699321091175 0.08520021289587021
encoder.encoder.bias_hh_l0: 0.005936524830758572 0.08296690881252289
encoder.encoder.weight_ih_l0_reverse: 0.00042037025559693575 0.08251019567251205
encoder.encoder.weight_hh_l0_reverse: 0.0005316070164553821 0.08162063360214233
encoder.encoder.bias_ih_l0_reverse: 0.006709312554448843 0.07969106733798981
encoder.encoder.bias_hh_l0_reverse: 0.007003963924944401 0.08503006398677826
decider.lstm.weight_ih_l0: -0.0015206917887553573 0.1448211520910263
decider.lstm.weight_hh_l0: 0.0019775356631726027 0.14429154992103577
decider.lstm.bias_ih_l0: -0.03141298145055771 0.14055602252483368
decider.lstm.bias_hh_l0: 0.004407802596688271 0.15250171720981598
decider.linear1.weight: 0.003588148858398199 0.11740309000015259
decider.linear1.bias: -0.0028066840022802353 0.11451297253370285
decider.linear2.weight: 7.55408254917711e-05 0.05125827342271805
decider.linear2.bias: -0.002259001135826111 0.05160599946975708
decider.linear3.weight: -3.787933383136988e-05 0.051142364740371704
decider.linear3.bias: -0.01431543380022049 0.028386294841766357

Rewards:
55.2622
55.2622
55.2622
objective = 68.9341049194336
==== episode 2700/75000 ====
action = 3
probs = 0.3954 0.3490 0.1452 0.1104

action = 0
probs = 0.4774 0.2563 0.1582 0.1080

action = 2
probs = 0.3922 0.2510 0.2540 0.1029

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005444095004349947 0.08080074191093445
encoder.encoder.weight_hh_l0: -0.0001625149743631482 0.08199010044336319
encoder.encoder.bias_ih_l0: -0.007106173317879438 0.08528298139572144
encoder.encoder.bias_hh_l0: 0.005965821444988251 0.0829777717590332
encoder.encoder.weight_ih_l0_reverse: 0.000404296355554834 0.08252175152301788
encoder.encoder.weight_hh_l0_reverse: 0.0005268428940325975 0.08163223415613174
encoder.encoder.bias_ih_l0_reverse: 0.00665411027148366 0.07966992259025574
encoder.encoder.bias_hh_l0_reverse: 0.006948763970285654 0.08496364206075668
decider.lstm.weight_ih_l0: -0.0015218763146549463 0.14484745264053345
decider.lstm.weight_hh_l0: 0.0019885662477463484 0.14431540668010712
decider.lstm.bias_ih_l0: -0.03143768012523651 0.14051896333694458
decider.lstm.bias_hh_l0: 0.0043831076472997665 0.15266354382038116
decider.linear1.weight: 0.003642498282715678 0.11738042533397675
decider.linear1.bias: -0.0029577501118183136 0.11440712213516235
decider.linear2.weight: 8.844152034725994e-05 0.051253415644168854
decider.linear2.bias: -0.0022568628191947937 0.051602523773908615
decider.linear3.weight: -4.456518217921257e-05 0.05110674723982811
decider.linear3.bias: -0.014335928484797478 0.028550639748573303

Rewards:
54.2413
54.2413
54.2413
objective = 77.99077606201172
==== episode 2800/75000 ====
action = 1
probs = 0.4123 0.2882 0.1790 0.1204

action = 2
probs = 0.4689 0.2200 0.1933 0.1178

action = 2
probs = 0.3167 0.2179 0.3540 0.1113

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005294016445986927 0.08079386502504349
encoder.encoder.weight_hh_l0: -0.0001830940746003762 0.08202828466892242
encoder.encoder.bias_ih_l0: -0.00708036171272397 0.08518999814987183
encoder.encoder.bias_hh_l0: 0.00599162932485342 0.08296184986829758
encoder.encoder.weight_ih_l0_reverse: 0.0003866428160108626 0.08258140832185745
encoder.encoder.weight_hh_l0_reverse: 0.0005284585058689117 0.08163206279277802
encoder.encoder.bias_ih_l0_reverse: 0.006580458953976631 0.07966788858175278
encoder.encoder.bias_hh_l0_reverse: 0.006875111721456051 0.08496647328138351
decider.lstm.weight_ih_l0: -0.0015319469384849072 0.14486800134181976
decider.lstm.weight_hh_l0: 0.0018804807914420962 0.1443202793598175
decider.lstm.bias_ih_l0: -0.031197402626276016 0.14075304567813873
decider.lstm.bias_hh_l0: 0.004623375833034515 0.1526874452829361
decider.linear1.weight: 0.003643859177827835 0.11739352345466614
decider.linear1.bias: -0.0030373954214155674 0.11448143422603607
decider.linear2.weight: 9.360024705529213e-06 0.051254015415906906
decider.linear2.bias: -0.0023697849828749895 0.05136234313249588
decider.linear3.weight: -3.980821929872036e-05 0.051097650080919266
decider.linear3.bias: -0.014288019388914108 0.02791864238679409

Rewards:
52.0855
52.0855
52.0855
objective = 68.16284942626953
==== episode 2900/75000 ====
action = 1
probs = 0.3983 0.2980 0.1852 0.1185

action = 3
probs = 0.4561 0.2312 0.1923 0.1203

action = 2
probs = 0.3053 0.2430 0.3316 0.1201

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005272704875096679 0.08079556375741959
encoder.encoder.weight_hh_l0: -0.00017861851665657014 0.08202431350946426
encoder.encoder.bias_ih_l0: -0.007179982960224152 0.0851975679397583
encoder.encoder.bias_hh_l0: 0.0058920071460306644 0.08299089223146439
encoder.encoder.weight_ih_l0_reverse: 0.00038835479062981904 0.0825907364487648
encoder.encoder.weight_hh_l0_reverse: 0.0005313858273439109 0.08164460957050323
encoder.encoder.bias_ih_l0_reverse: 0.006523938849568367 0.07967564463615417
encoder.encoder.bias_hh_l0_reverse: 0.006818594876676798 0.08501849323511124
decider.lstm.weight_ih_l0: -0.001523724407888949 0.14486098289489746
decider.lstm.weight_hh_l0: 0.0019197722431272268 0.14430931210517883
decider.lstm.bias_ih_l0: -0.03129034861922264 0.14074720442295074
decider.lstm.bias_hh_l0: 0.004530434496700764 0.15273509919643402
decider.linear1.weight: 0.0037035986315459013 0.11737397313117981
decider.linear1.bias: -0.0032460978254675865 0.11452581733465195
decider.linear2.weight: -2.2516760509461164e-05 0.051247429102659225
decider.linear2.bias: -0.0024280715733766556 0.05137548968195915
decider.linear3.weight: -2.789509017020464e-05 0.05104406177997589
decider.linear3.bias: -0.01426984928548336 0.02780780754983425

Rewards:
55.2417
55.2417
55.2417
objective = 81.60735321044922
==== episode 3000/75000 ====
action = 2
probs = 0.3707 0.3007 0.1938 0.1347

action = 0
probs = 0.4423 0.2250 0.1978 0.1349

action = 1
probs = 0.2984 0.2389 0.3397 0.1230

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005344066885299981 0.08080586791038513
encoder.encoder.weight_hh_l0: -0.00017800259229261428 0.08203354477882385
encoder.encoder.bias_ih_l0: -0.0071674520149827 0.0851796343922615
encoder.encoder.bias_hh_l0: 0.005904538556933403 0.08298490196466446
encoder.encoder.weight_ih_l0_reverse: 0.0003855004906654358 0.08262335509061813
encoder.encoder.weight_hh_l0_reverse: 0.0005320553318597376 0.08164820820093155
encoder.encoder.bias_ih_l0_reverse: 0.006511280778795481 0.07973352074623108
encoder.encoder.bias_hh_l0_reverse: 0.006805936340242624 0.08499551564455032
decider.lstm.weight_ih_l0: -0.0015227139228954911 0.14486823976039886
decider.lstm.weight_hh_l0: 0.0019134007161483169 0.14430420100688934
decider.lstm.bias_ih_l0: -0.03129788115620613 0.14071179926395416
decider.lstm.bias_hh_l0: 0.00452289916574955 0.15276405215263367
decider.linear1.weight: 0.0037368922494351864 0.11735641211271286
decider.linear1.bias: -0.0034529566764831543 0.11457989364862442
decider.linear2.weight: -6.127638334874064e-05 0.05124247074127197
decider.linear2.bias: -0.002495268825441599 0.05137426778674126
decider.linear3.weight: -1.091999001801014e-05 0.051000695675611496
decider.linear3.bias: -0.014211039990186691 0.027209380641579628

Rewards:
55.0368
55.0368
55.0368
objective = 71.33247375488281
==== episode 3100/75000 ====
action = 3
probs = 0.3553 0.3256 0.1897 0.1294

action = 0
probs = 0.4446 0.2375 0.1888 0.1290

action = 2
probs = 0.3273 0.2378 0.3178 0.1171

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005248815286904573 0.08082807064056396
encoder.encoder.weight_hh_l0: -0.00019052281277254224 0.08204320818185806
encoder.encoder.bias_ih_l0: -0.007154806517064571 0.08520001173019409
encoder.encoder.bias_hh_l0: 0.005917187314480543 0.08302382379770279
encoder.encoder.weight_ih_l0_reverse: 0.00038827297976240516 0.08265142887830734
encoder.encoder.weight_hh_l0_reverse: 0.0005332233267836273 0.0816635712981224
encoder.encoder.bias_ih_l0_reverse: 0.006539147812873125 0.07974661886692047
encoder.encoder.bias_hh_l0_reverse: 0.0068338001146912575 0.08504651486873627
decider.lstm.weight_ih_l0: -0.0015171598643064499 0.14486278593540192
decider.lstm.weight_hh_l0: 0.0019357939017936587 0.144306018948555
decider.lstm.bias_ih_l0: -0.03137079253792763 0.1407620757818222
decider.lstm.bias_hh_l0: 0.004449980333447456 0.15275579690933228
decider.linear1.weight: 0.003737982362508774 0.11735496670007706
decider.linear1.bias: -0.0034527513198554516 0.11455483734607697
decider.linear2.weight: -3.651119186542928e-05 0.05124764144420624
decider.linear2.bias: -0.0024572983384132385 0.051432136446237564
decider.linear3.weight: -2.2716820240020752e-05 0.05100278928875923
decider.linear3.bias: -0.014241771772503853 0.02754312753677368

Rewards:
54.2413
54.2413
54.2413
objective = 72.35112762451172
==== episode 3200/75000 ====
action = 1
probs = 0.4060 0.2997 0.1735 0.1209

action = 1
probs = 0.5236 0.2019 0.1617 0.1127

action = 0
probs = 0.3800 0.2060 0.3034 0.1105

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005007720901630819 0.08086314052343369
encoder.encoder.weight_hh_l0: -0.00019580697698984295 0.0820629820227623
encoder.encoder.bias_ih_l0: -0.007088733837008476 0.08524380624294281
encoder.encoder.bias_hh_l0: 0.005983259063214064 0.08303989470005035
encoder.encoder.weight_ih_l0_reverse: 0.0004084946122020483 0.08263696730136871
encoder.encoder.weight_hh_l0_reverse: 0.0005353815504349768 0.08166933804750443
encoder.encoder.bias_ih_l0_reverse: 0.0066216448321938515 0.07971828430891037
encoder.encoder.bias_hh_l0_reverse: 0.006916297134011984 0.08506594598293304
decider.lstm.weight_ih_l0: -0.001520578283816576 0.14486204087734222
decider.lstm.weight_hh_l0: 0.0019232586491852999 0.1443341076374054
decider.lstm.bias_ih_l0: -0.03139158710837364 0.14068607985973358
decider.lstm.bias_hh_l0: 0.004429186694324017 0.15265749394893646
decider.linear1.weight: 0.003673408180475235 0.11737571656703949
decider.linear1.bias: -0.0031576482579112053 0.11457829177379608
decider.linear2.weight: 2.0863342797383666e-05 0.051267169415950775
decider.linear2.bias: -0.002347645116969943 0.051410067826509476
decider.linear3.weight: -5.487864837050438e-05 0.05108776316046715
decider.linear3.bias: -0.014316478744149208 0.02805418334901333

Rewards:
56.2092
56.2092
56.2092
objective = 70.68063354492188
==== episode 3300/75000 ====
action = 3
probs = 0.3901 0.3065 0.1864 0.1170

action = 3
probs = 0.5043 0.2113 0.1740 0.1104

action = 1
probs = 0.3891 0.2302 0.2805 0.1003

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005182402674108744 0.08087527751922607
encoder.encoder.weight_hh_l0: -0.00018275498587172478 0.08205797523260117
encoder.encoder.bias_ih_l0: -0.007101456169039011 0.085275799036026
encoder.encoder.bias_hh_l0: 0.005970541853457689 0.08308370411396027
encoder.encoder.weight_ih_l0_reverse: 0.00038395149749703705 0.08267060667276382
encoder.encoder.weight_hh_l0_reverse: 0.0005365572869777679 0.08168859779834747
encoder.encoder.bias_ih_l0_reverse: 0.006645938381552696 0.07976362109184265
encoder.encoder.bias_hh_l0_reverse: 0.0069405934773385525 0.08506106585264206
decider.lstm.weight_ih_l0: -0.001519417972303927 0.14486970007419586
decider.lstm.weight_hh_l0: 0.001936181215569377 0.14431408047676086
decider.lstm.bias_ih_l0: -0.03141965717077255 0.14074181020259857
decider.lstm.bias_hh_l0: 0.004401109181344509 0.15272191166877747
decider.linear1.weight: 0.0036884627770632505 0.11737892031669617
decider.linear1.bias: -0.0032172324135899544 0.11462327092885971
decider.linear2.weight: -1.4636956620961428e-05 0.051267534494400024
decider.linear2.bias: -0.0024092805106192827 0.05145746096968651
decider.linear3.weight: -6.053142715245485e-05 0.05105621740221977
decider.linear3.bias: -0.014339623972773552 0.028357530012726784

Rewards:
54.6486
54.6486
54.6486
objective = 105.97392272949219
==== episode 3400/75000 ====
action = 1
probs = 0.3450 0.3200 0.2009 0.1341

action = 0
probs = 0.4319 0.2353 0.2003 0.1324

action = 1
probs = 0.2783 0.2471 0.3567 0.1179

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0005568471970036626 0.08084994554519653
encoder.encoder.weight_hh_l0: -0.0001959041110239923 0.08207639306783676
encoder.encoder.bias_ih_l0: -0.0071055409498512745 0.08520618826150894
encoder.encoder.bias_hh_l0: 0.005966457538306713 0.08307933062314987
encoder.encoder.weight_ih_l0_reverse: 0.0003621955111157149 0.08270743489265442
encoder.encoder.weight_hh_l0_reverse: 0.000530544260982424 0.08171103149652481
encoder.encoder.bias_ih_l0_reverse: 0.006562664173543453 0.07986140251159668
encoder.encoder.bias_hh_l0_reverse: 0.00685731740668416 0.08505981415510178
decider.lstm.weight_ih_l0: -0.001530996523797512 0.14488814771175385
decider.lstm.weight_hh_l0: 0.001845258055254817 0.14431017637252808
decider.lstm.bias_ih_l0: -0.03123445436358452 0.14091835916042328
decider.lstm.bias_hh_l0: 0.004586315713822842 0.15293683111667633
decider.linear1.weight: 0.003761639818549156 0.11736798286437988
decider.linear1.bias: -0.0035757655277848244 0.11462052911520004
decider.linear2.weight: -9.685852273833007e-05 0.05125501751899719
decider.linear2.bias: -0.0025531318970024586 0.05140390619635582
decider.linear3.weight: -1.7073354683816433e-05 0.05097370222210884
decider.linear3.bias: -0.014210090041160583 0.027397874742746353

Rewards:
53.7139
53.7139
53.7139
objective = 60.463043212890625
==== episode 3500/75000 ====
action = 0
probs = 0.3411 0.3520 0.1913 0.1157

action = 2
probs = 0.4698 0.2287 0.1947 0.1068

action = 1
probs = 0.2810 0.2403 0.3769 0.1017

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.000503421644680202 0.08087936043739319
encoder.encoder.weight_hh_l0: -0.00021858810214325786 0.08211398124694824
encoder.encoder.bias_ih_l0: -0.006956731900572777 0.0851508378982544
encoder.encoder.bias_hh_l0: 0.006115267053246498 0.08310475945472717
encoder.encoder.weight_ih_l0_reverse: 0.0003885593905579299 0.08271397650241852
encoder.encoder.weight_hh_l0_reverse: 0.0005315892049111426 0.08171968162059784
encoder.encoder.bias_ih_l0_reverse: 0.006684975698590279 0.07990401983261108
encoder.encoder.bias_hh_l0_reverse: 0.006979627069085836 0.08511538058519363
decider.lstm.weight_ih_l0: -0.001537043834105134 0.1448853313922882
decider.lstm.weight_hh_l0: 0.0018187088426202536 0.1443144977092743
decider.lstm.bias_ih_l0: -0.031207213178277016 0.1410241276025772
decider.lstm.bias_hh_l0: 0.004613557830452919 0.1528785675764084
decider.linear1.weight: 0.0036460577975958586 0.11742747575044632
decider.linear1.bias: -0.0030419277027249336 0.11468907445669174
decider.linear2.weight: -5.677153239957988e-06 0.05129372701048851
decider.linear2.bias: -0.002364513697102666 0.051466863602399826
decider.linear3.weight: -6.551819387823343e-05 0.05113033950328827
decider.linear3.bias: -0.014311157166957855 0.028416726738214493

Rewards:
56.1885
56.1885
56.1885
objective = 77.49591064453125
==== episode 3600/75000 ====
action = 0
probs = 0.3365 0.3604 0.2007 0.1024

action = 2
probs = 0.4993 0.2294 0.1806 0.0907

action = 3
probs = 0.3242 0.2329 0.3467 0.0962

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00046300742542371154 0.0809510201215744
encoder.encoder.weight_hh_l0: -0.00022437948791775852 0.0821554958820343
encoder.encoder.bias_ih_l0: -0.006820971611887217 0.08520761132240295
encoder.encoder.bias_hh_l0: 0.006251026410609484 0.08321249485015869
encoder.encoder.weight_ih_l0_reverse: 0.00043082862976007164 0.08275344967842102
encoder.encoder.weight_hh_l0_reverse: 0.0005371528095565736 0.08176115155220032
encoder.encoder.bias_ih_l0_reverse: 0.006887153256684542 0.07985737919807434
encoder.encoder.bias_hh_l0_reverse: 0.007181802298873663 0.08521340787410736
decider.lstm.weight_ih_l0: -0.0015342938713729382 0.1448952555656433
decider.lstm.weight_hh_l0: 0.0017564082518219948 0.1443364918231964
decider.lstm.bias_ih_l0: -0.031045150011777878 0.14093999564647675
decider.lstm.bias_hh_l0: 0.004775630310177803 0.15277408063411713
decider.linear1.weight: 0.0036424945574253798 0.11745595932006836
decider.linear1.bias: -0.002871471457183361 0.11471240967512131
decider.linear2.weight: 7.666836609132588e-06 0.05130835995078087
decider.linear2.bias: -0.0023326720111072063 0.05148050934076309
decider.linear3.weight: -9.204610250890255e-05 0.05116460099816322
decider.linear3.bias: -0.01438878383487463 0.029068972915410995

Rewards:
58.1477
58.1477
58.1477
objective = 99.67443084716797
==== episode 3700/75000 ====
action = 0
probs = 0.3116 0.3799 0.2054 0.1031

action = 1
probs = 0.4919 0.2431 0.1779 0.0871

action = 0
probs = 0.3174 0.2382 0.3502 0.0942

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00045605385093949735 0.08095167577266693
encoder.encoder.weight_hh_l0: -0.00022083925432525575 0.08214858919382095
encoder.encoder.bias_ih_l0: -0.00692566717043519 0.08514435589313507
encoder.encoder.bias_hh_l0: 0.0061463359743356705 0.08318042010068893
encoder.encoder.weight_ih_l0_reverse: 0.0004339186707511544 0.0827251672744751
encoder.encoder.weight_hh_l0_reverse: 0.0005373467574827373 0.08174419403076172
encoder.encoder.bias_ih_l0_reverse: 0.006858208682388067 0.07980652898550034
encoder.encoder.bias_hh_l0_reverse: 0.007152856327593327 0.08527979254722595
decider.lstm.weight_ih_l0: -0.001535689807496965 0.1448822170495987
decider.lstm.weight_hh_l0: 0.0017914833733811975 0.144330233335495
decider.lstm.bias_ih_l0: -0.031140046194195747 0.14083024859428406
decider.lstm.bias_hh_l0: 0.0046807341277599335 0.15269245207309723
decider.linear1.weight: 0.0036197665613144636 0.11745568364858627
decider.linear1.bias: -0.002806512638926506 0.11476992815732956
decider.linear2.weight: -2.151980879716575e-06 0.05131745710968971
decider.linear2.bias: -0.0023335411678999662 0.051525913178920746
decider.linear3.weight: -9.681785013526678e-05 0.051178231835365295
decider.linear3.bias: -0.014395054429769516 0.02918170392513275

Rewards:
55.6524
55.6524
55.6524
objective = 69.14940643310547
==== episode 3800/75000 ====
action = 2
probs = 0.3110 0.3821 0.2071 0.0998

action = 1
probs = 0.4385 0.2761 0.1956 0.0898

action = 0
probs = 0.2957 0.2202 0.3903 0.0939

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004748432547785342 0.0809250995516777
encoder.encoder.weight_hh_l0: -0.0002407134452369064 0.08217737823724747
encoder.encoder.bias_ih_l0: -0.006883101537823677 0.08511578291654587
encoder.encoder.bias_hh_l0: 0.006188900209963322 0.0831969752907753
encoder.encoder.weight_ih_l0_reverse: 0.00041422396316193044 0.08276194334030151
encoder.encoder.weight_hh_l0_reverse: 0.0005283394712023437 0.08176011592149734
encoder.encoder.bias_ih_l0_reverse: 0.006776727735996246 0.07986663281917572
encoder.encoder.bias_hh_l0_reverse: 0.007071374449878931 0.08527456969022751
decider.lstm.weight_ih_l0: -0.0015449392376467586 0.14489442110061646
decider.lstm.weight_hh_l0: 0.001761666382662952 0.14434176683425903
decider.lstm.bias_ih_l0: -0.03110538423061371 0.14112792909145355
decider.lstm.bias_hh_l0: 0.004715394228696823 0.15277588367462158
decider.linear1.weight: 0.0035952560137957335 0.1174735575914383
decider.linear1.bias: -0.0027520693838596344 0.11472776532173157
decider.linear2.weight: -1.4045363059267402e-06 0.051324617117643356
decider.linear2.bias: -0.0023317390587180853 0.05148071050643921
decider.linear3.weight: -0.00010514631867408752 0.05121009424328804
decider.linear3.bias: -0.014391629956662655 0.029191235080361366

Rewards:
53.1687
53.1687
53.1687
objective = 72.31155395507812
==== episode 3900/75000 ====
action = 1
probs = 0.3259 0.3993 0.1944 0.0804

action = 0
probs = 0.4697 0.2912 0.1729 0.0661

action = 2
probs = 0.3123 0.2259 0.3867 0.0751

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0003993302525486797 0.08099658042192459
encoder.encoder.weight_hh_l0: -0.0002931137860286981 0.08222010731697083
encoder.encoder.bias_ih_l0: -0.006636639591306448 0.08513768762350082
encoder.encoder.bias_hh_l0: 0.0064353602938354015 0.0832635909318924
encoder.encoder.weight_ih_l0_reverse: 0.000452435459010303 0.08277027308940887
encoder.encoder.weight_hh_l0_reverse: 0.0005344533710740507 0.08179192245006561
encoder.encoder.bias_ih_l0_reverse: 0.0070024095475673676 0.0798465684056282
encoder.encoder.bias_hh_l0_reverse: 0.007297056261450052 0.08535074442625046
decider.lstm.weight_ih_l0: -0.0015576061559841037 0.1448948234319687
decider.lstm.weight_hh_l0: 0.00164649891667068 0.14438585937023163
decider.lstm.bias_ih_l0: -0.030869994312524796 0.14100034534931183
decider.lstm.bias_hh_l0: 0.0049507832154631615 0.15280650556087494
decider.linear1.weight: 0.0035171392373740673 0.11752945929765701
decider.linear1.bias: -0.002270856872200966 0.11471933871507645
decider.linear2.weight: 7.775696576572955e-05 0.05135771632194519
decider.linear2.bias: -0.0021855952218174934 0.0515616312623024
decider.linear3.weight: -0.00017143762670457363 0.051326777786016464
decider.linear3.bias: -0.014553507789969444 0.030486129224300385

Rewards:
63.5281
63.5281
63.5281
objective = 55.56484603881836
==== episode 4000/75000 ====
action = 1
probs = 0.4031 0.3420 0.1769 0.0780

action = 3
probs = 0.5519 0.2461 0.1406 0.0615

action = 0
probs = 0.3922 0.2323 0.3033 0.0722

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0004014808509964496 0.08100554347038269
encoder.encoder.weight_hh_l0: -0.00027103046886622906 0.08218071609735489
encoder.encoder.bias_ih_l0: -0.006629501935094595 0.08523175120353699
encoder.encoder.bias_hh_l0: 0.006442496553063393 0.08327197283506393
encoder.encoder.weight_ih_l0_reverse: 0.000433803943451494 0.08275528252124786
encoder.encoder.weight_hh_l0_reverse: 0.0005429915036074817 0.08177391439676285
encoder.encoder.bias_ih_l0_reverse: 0.006997017655521631 0.07984787225723267
encoder.encoder.bias_hh_l0_reverse: 0.00729166017845273 0.08530838787555695
decider.lstm.weight_ih_l0: -0.0015603016363456845 0.14488127827644348
decider.lstm.weight_hh_l0: 0.0016605384880676866 0.14438600838184357
decider.lstm.bias_ih_l0: -0.031000852584838867 0.140761598944664
decider.lstm.bias_hh_l0: 0.004819931462407112 0.15285708010196686
decider.linear1.weight: 0.003499086946249008 0.11749845743179321
decider.linear1.bias: -0.0022956710308790207 0.11475998163223267
decider.linear2.weight: 5.949223123025149e-05 0.05135316774249077
decider.linear2.bias: -0.0022056340239942074 0.051497019827365875
decider.linear3.weight: -0.00018291152082383633 0.0513027086853981
decider.linear3.bias: -0.014598345384001732 0.03063022345304489

Rewards:
55.0573
55.0573
55.0573
objective = 88.04878997802734
==== episode 4100/75000 ====
action = 2
probs = 0.4292 0.3182 0.1808 0.0718

action = 0
probs = 0.5687 0.2231 0.1489 0.0592

action = 0
probs = 0.3715 0.2117 0.3460 0.0708

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00032934811315499246 0.08107049763202667
encoder.encoder.weight_hh_l0: -0.00032378672040067613 0.08226016163825989
encoder.encoder.bias_ih_l0: -0.0062491754069924355 0.0853060856461525
encoder.encoder.bias_hh_l0: 0.006822824478149414 0.08338107913732529
encoder.encoder.weight_ih_l0_reverse: 0.0004947498091496527 0.08283499628305435
encoder.encoder.weight_hh_l0_reverse: 0.0005426078569144011 0.08184617757797241
encoder.encoder.bias_ih_l0_reverse: 0.007198108360171318 0.07998540997505188
encoder.encoder.bias_hh_l0_reverse: 0.007492753677070141 0.08533558994531631
decider.lstm.weight_ih_l0: -0.0015625073574483395 0.14492292702198029
decider.lstm.weight_hh_l0: 0.0015221299836412072 0.14441442489624023
decider.lstm.bias_ih_l0: -0.030629437416791916 0.14088183641433716
decider.lstm.bias_hh_l0: 0.005191346630454063 0.15294350683689117
decider.linear1.weight: 0.0034880368039011955 0.11755281686782837
decider.linear1.bias: -0.002114584669470787 0.11478611826896667
decider.linear2.weight: 8.901940600480884e-05 0.051366452127695084
decider.linear2.bias: -0.0021671783179044724 0.051456816494464874
decider.linear3.weight: -0.000202054507099092 0.05134674161672592
decider.linear3.bias: -0.014639819972217083 0.030875567346811295

Rewards:
52.8870
52.8870
52.8870
objective = 57.555908203125
==== episode 4200/75000 ====
action = 2
probs = 0.4644 0.2878 0.1805 0.0673

action = 0
probs = 0.5956 0.1953 0.1509 0.0582

action = 1
probs = 0.3335 0.1992 0.3952 0.0721

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0002792415616568178 0.0810900628566742
encoder.encoder.weight_hh_l0: -0.00036036959500052035 0.08230627328157425
encoder.encoder.bias_ih_l0: -0.005983646493405104 0.08533445000648499
encoder.encoder.bias_hh_l0: 0.007088354788720608 0.08342519402503967
encoder.encoder.weight_ih_l0_reverse: 0.0005186094203963876 0.08286305516958237
encoder.encoder.weight_hh_l0_reverse: 0.0005388549761846662 0.08186838775873184
encoder.encoder.bias_ih_l0_reverse: 0.007292130030691624 0.08011674135923386
encoder.encoder.bias_hh_l0_reverse: 0.007586774881929159 0.08529096096754074
decider.lstm.weight_ih_l0: -0.0015632217982783914 0.14495794475078583
decider.lstm.weight_hh_l0: 0.0014662942849099636 0.14445878565311432
decider.lstm.bias_ih_l0: -0.03044426627457142 0.14095599949359894
decider.lstm.bias_hh_l0: 0.005376521497964859 0.153044193983078
decider.linear1.weight: 0.0034637029748409986 0.11759696155786514
decider.linear1.bias: -0.0018808254972100258 0.11482512950897217
decider.linear2.weight: 0.00013378687435761094 0.0513831302523613
decider.linear2.bias: -0.00208158977329731 0.051421284675598145
decider.linear3.weight: -0.00021490990184247494 0.051425445824861526
decider.linear3.bias: -0.014664076268672943 0.03095889836549759

Rewards:
55.0368
55.0368
55.0368
objective = 70.51066589355469
==== episode 4300/75000 ====
action = 0
probs = 0.4365 0.2982 0.1967 0.0686

action = 2
probs = 0.5913 0.1746 0.1782 0.0559

action = 3
probs = 0.3198 0.1649 0.4403 0.0749

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0002727458195295185 0.08111221343278885
encoder.encoder.weight_hh_l0: -0.00040747583261691034 0.08235574513673782
encoder.encoder.bias_ih_l0: -0.005881503690034151 0.08527825027704239
encoder.encoder.bias_hh_l0: 0.0071905008517205715 0.08346851170063019
encoder.encoder.weight_ih_l0_reverse: 0.0005213214317336679 0.08288923650979996
encoder.encoder.weight_hh_l0_reverse: 0.0005350076826289296 0.08187845349311829
encoder.encoder.bias_ih_l0_reverse: 0.0072138309478759766 0.08006731420755386
encoder.encoder.bias_hh_l0_reverse: 0.007508474867790937 0.08532112091779709
decider.lstm.weight_ih_l0: -0.0015670590801164508 0.14495866000652313
decider.lstm.weight_hh_l0: 0.0013877786695957184 0.1444791555404663
decider.lstm.bias_ih_l0: -0.03027970902621746 0.14121319353580475
decider.lstm.bias_hh_l0: 0.005541070364415646 0.15307937562465668
decider.linear1.weight: 0.0034597485791891813 0.11761406064033508
decider.linear1.bias: -0.0018523577600717545 0.11488308012485504
decider.linear2.weight: 0.00014919911336619407 0.05139293894171715
decider.linear2.bias: -0.002048342954367399 0.051418740302324295
decider.linear3.weight: -0.00021514063701033592 0.05146156623959541
decider.linear3.bias: -0.014644508250057697 0.030783139169216156

Rewards:
58.1477
58.1477
58.1477
objective = 99.72234344482422
==== episode 4400/75000 ====
action = 0
probs = 0.5139 0.2541 0.1670 0.0650

action = 1
probs = 0.6842 0.1182 0.1463 0.0512

action = 0
probs = 0.3710 0.1140 0.4389 0.0762

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00016322240117006004 0.08118599653244019
encoder.encoder.weight_hh_l0: -0.0004957440542057157 0.08246481418609619
encoder.encoder.bias_ih_l0: -0.0051942369900643826 0.08545294404029846
encoder.encoder.bias_hh_l0: 0.007877767086029053 0.08360849320888519
encoder.encoder.weight_ih_l0_reverse: 0.0005959065165370703 0.08291935920715332
encoder.encoder.weight_hh_l0_reverse: 0.0005265395739115775 0.08193562924861908
encoder.encoder.bias_ih_l0_reverse: 0.007587507367134094 0.08015038818120956
encoder.encoder.bias_hh_l0_reverse: 0.007882148027420044 0.08534662425518036
decider.lstm.weight_ih_l0: -0.0015667220577597618 0.1450245976448059
decider.lstm.weight_hh_l0: 0.0011494329664856195 0.1446034014225006
decider.lstm.bias_ih_l0: -0.029638223350048065 0.14130283892154694
decider.lstm.bias_hh_l0: 0.006182558834552765 0.15320971608161926
decider.linear1.weight: 0.003411209210753441 0.11768773943185806
decider.linear1.bias: -0.001463836058974266 0.11491475254297256
decider.linear2.weight: 0.00022133882157504559 0.051423314958810806
decider.linear2.bias: -0.0019133244641125202 0.05137033388018608
decider.linear3.weight: -0.00026851287111639977 0.051588624715805054
decider.linear3.bias: -0.014659762382507324 0.030674822628498077

Rewards:
55.6524
55.6524
55.6524
objective = 70.36238098144531
==== episode 4500/75000 ====
action = 0
probs = 0.5145 0.2550 0.1669 0.0636

action = 2
probs = 0.6582 0.1212 0.1697 0.0508

action = 2
probs = 0.3388 0.1144 0.4772 0.0696

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00015923831961117685 0.08116903156042099
encoder.encoder.weight_hh_l0: -0.0004964547697454691 0.08247695118188858
encoder.encoder.bias_ih_l0: -0.005148063879460096 0.08546256273984909
encoder.encoder.bias_hh_l0: 0.007923939265310764 0.08362646400928497
encoder.encoder.weight_ih_l0_reverse: 0.000592287047766149 0.08293420076370239
encoder.encoder.weight_hh_l0_reverse: 0.0005237174918875098 0.0819350928068161
encoder.encoder.bias_ih_l0_reverse: 0.007553961127996445 0.08017684519290924
encoder.encoder.bias_hh_l0_reverse: 0.007848602719604969 0.08538611233234406
decider.lstm.weight_ih_l0: -0.0015685864491388202 0.14502987265586853
decider.lstm.weight_hh_l0: 0.001181052066385746 0.14457803964614868
decider.lstm.bias_ih_l0: -0.02971220761537552 0.14150582253932953
decider.lstm.bias_hh_l0: 0.006108577363193035 0.1532004177570343
decider.linear1.weight: 0.0034010731615126133 0.11769986152648926
decider.linear1.bias: -0.0013845348730683327 0.11490395665168762
decider.linear2.weight: 0.00024252364528365433 0.051428038626909256
decider.linear2.bias: -0.0018836181843653321 0.05137797072529793
decider.linear3.weight: -0.00029438070487231016 0.05160176753997803
decider.linear3.bias: -0.014700504019856453 0.03094152733683586

Rewards:
55.0778
55.0778
55.0778
objective = 58.34375
==== episode 4600/75000 ====
action = 0
probs = 0.4978 0.2918 0.1518 0.0586

action = 0
probs = 0.6600 0.1283 0.1645 0.0473

action = 2
probs = 0.2479 0.1114 0.5689 0.0718

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.0001350633829133585 0.08119223266839981
encoder.encoder.weight_hh_l0: -0.0005149594508111477 0.08249801397323608
encoder.encoder.bias_ih_l0: -0.005168929696083069 0.08544576168060303
encoder.encoder.bias_hh_l0: 0.007903073914349079 0.0836290791630745
encoder.encoder.weight_ih_l0_reverse: 0.0006284913397394121 0.08294010162353516
encoder.encoder.weight_hh_l0_reverse: 0.0005225601489655674 0.08196312189102173
encoder.encoder.bias_ih_l0_reverse: 0.007591197732836008 0.08020399510860443
encoder.encoder.bias_hh_l0_reverse: 0.00788583792746067 0.08542027324438095
decider.lstm.weight_ih_l0: -0.0015674879541620612 0.14502781629562378
decider.lstm.weight_hh_l0: 0.0011874375632032752 0.14458969235420227
decider.lstm.bias_ih_l0: -0.029754316434264183 0.1414823979139328
decider.lstm.bias_hh_l0: 0.006066465750336647 0.15320312976837158
decider.linear1.weight: 0.0033956184051930904 0.11772724241018295
decider.linear1.bias: -0.0012079556472599506 0.11489997804164886
decider.linear2.weight: 0.0002891471958719194 0.05145193636417389
decider.linear2.bias: -0.00179012818261981 0.051469795405864716
decider.linear3.weight: -0.00031339237466454506 0.051696229726076126
decider.linear3.bias: -0.014725100249052048 0.031231006607413292

Rewards:
65.8452
65.8452
65.8452
objective = 36.812530517578125
==== episode 4700/75000 ====
action = 0
probs = 0.4904 0.3164 0.1330 0.0602

action = 1
probs = 0.6494 0.1514 0.1498 0.0494

action = 2
probs = 0.3250 0.1248 0.4750 0.0753

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -0.00016573361062910408 0.081183522939682
encoder.encoder.weight_hh_l0: -0.0004915324971079826 0.08246450871229172
encoder.encoder.bias_ih_l0: -0.005401013419032097 0.08542602509260178
encoder.encoder.bias_hh_l0: 0.007670991122722626 0.08352819830179214
encoder.encoder.weight_ih_l0_reverse: 0.0006211313302628696 0.08293548226356506
encoder.encoder.weight_hh_l0_reverse: 0.000524237984791398 0.08195886015892029
encoder.encoder.bias_ih_l0_reverse: 0.0074484157375991344 0.08019950985908508
encoder.encoder.bias_hh_l0_reverse: 0.007743055000901222 0.08537086099386215
decider.lstm.weight_ih_l0: -0.0015707688871771097 0.14501073956489563
decider.lstm.weight_hh_l0: 0.0012886244803667068 0.14456813037395477
decider.lstm.bias_ih_l0: -0.030063334852457047 0.14135871827602386
decider.lstm.bias_hh_l0: 0.005757443606853485 0.15316466987133026
decider.linear1.weight: 0.00342256180010736 0.1176903247833252
decider.linear1.bias: -0.0014157602563500404 0.11484377086162567
decider.linear2.weight: 0.0002503331925254315 0.051447972655296326
decider.linear2.bias: -0.001858302392065525 0.051497042179107666
decider.linear3.weight: -0.0003013727255165577 0.051656730473041534
decider.linear3.bias: -0.014688536524772644 0.03109721653163433

Rewards:
54.6078
54.6078
54.6078
objective = 60.888885498046875
==== episode 4800/75000 ====
action = 0
probs = 0.5307 0.2960 0.1236 0.0497

action = 0
probs = 0.6877 0.1240 0.1458 0.0425

action = 3
probs = 0.2283 0.1031 0.5945 0.0741

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: -9.065508493222296e-05 0.08125216513872147
encoder.encoder.weight_hh_l0: -0.00053559266962111 0.08255527913570404
encoder.encoder.bias_ih_l0: -0.004857822321355343 0.08547678589820862
encoder.encoder.bias_hh_l0: 0.008214181289076805 0.08370480686426163
encoder.encoder.weight_ih_l0_reverse: 0.0006801972631365061 0.0829927921295166
encoder.encoder.weight_hh_l0_reverse: 0.0005237928708083928 0.08201878517866135
encoder.encoder.bias_ih_l0_reverse: 0.007768540643155575 0.0803234726190567
encoder.encoder.bias_hh_l0_reverse: 0.008063179440796375 0.08544357120990753
decider.lstm.weight_ih_l0: -0.0015660119242966175 0.1450655460357666
decider.lstm.weight_hh_l0: 0.0011299921898171306 0.1446533054113388
decider.lstm.bias_ih_l0: -0.029597140848636627 0.1415565013885498
decider.lstm.bias_hh_l0: 0.006223628297448158 0.1532793641090393
decider.linear1.weight: 0.0033552125096321106 0.11779285222291946
decider.linear1.bias: -0.0008270055986940861 0.11489767581224442
decider.linear2.weight: 0.0003674495383165777 0.05149265378713608
decider.linear2.bias: -0.0016277190297842026 0.05149544030427933
decider.linear3.weight: -0.0003515270072966814 0.05185507610440254
decider.linear3.bias: -0.014774029143154621 0.03152597323060036

Rewards:
55.1187
55.1187
55.1187
objective = 66.3331069946289
==== episode 4900/75000 ====
action = 0
probs = 0.6281 0.2207 0.1082 0.0430

action = 0
probs = 0.7657 0.0885 0.1127 0.0331

action = 2
probs = 0.3160 0.1045 0.5120 0.0675

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 4.012360932392767e-06 0.08129972964525223
encoder.encoder.weight_hh_l0: -0.0005559541750699282 0.0825754851102829
encoder.encoder.bias_ih_l0: -0.004642630461603403 0.08568152785301208
encoder.encoder.bias_hh_l0: 0.008429371751844883 0.08379002660512924
encoder.encoder.weight_ih_l0_reverse: 0.0007230591727420688 0.08297169208526611
encoder.encoder.weight_hh_l0_reverse: 0.0005270881811156869 0.08203422278165817
encoder.encoder.bias_ih_l0_reverse: 0.008074110373854637 0.08034945279359818
encoder.encoder.bias_hh_l0_reverse: 0.008368750102818012 0.08544651418924332
decider.lstm.weight_ih_l0: -0.0015577295562252402 0.14509077370166779
decider.lstm.weight_hh_l0: 0.0010284923482686281 0.14472001791000366
decider.lstm.bias_ih_l0: -0.0292639322578907 0.14142119884490967
decider.lstm.bias_hh_l0: 0.006556844338774681 0.15325571596622467
decider.linear1.weight: 0.0033474918454885483 0.11781376600265503
decider.linear1.bias: -0.0006867288611829281 0.1148509830236435
decider.linear2.weight: 0.00043724491843022406 0.051489103585481644
decider.linear2.bias: -0.0015545974019914865 0.05149494856595993
decider.linear3.weight: -0.0003848344786092639 0.051839809864759445
decider.linear3.bias: -0.014892447739839554 0.03205931931734085

Rewards:
65.8452
65.8452
65.8452
objective = 30.75973892211914
==== episode 5000/75000 ====
action = 0
probs = 0.7647 0.1405 0.0673 0.0275

action = 2
probs = 0.8710 0.0493 0.0603 0.0194

action = 3
probs = 0.5749 0.0797 0.2925 0.0529

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.000253783306106925 0.08150072395801544
encoder.encoder.weight_hh_l0: -0.0006282468093559146 0.082789845764637
encoder.encoder.bias_ih_l0: -0.003174496116116643 0.08616220206022263
encoder.encoder.bias_hh_l0: 0.009897503070533276 0.08423789590597153
encoder.encoder.weight_ih_l0_reverse: 0.0009044050239026546 0.08308742195367813
encoder.encoder.weight_hh_l0_reverse: 0.0005389605066739023 0.08223732560873032
encoder.encoder.bias_ih_l0_reverse: 0.00930926762521267 0.08062049001455307
encoder.encoder.bias_hh_l0_reverse: 0.009603909216821194 0.08558084070682526
decider.lstm.weight_ih_l0: -0.0015104800695553422 0.14527428150177002
decider.lstm.weight_hh_l0: 0.0006895503029227257 0.145022913813591
decider.lstm.bias_ih_l0: -0.027893375605344772 0.14130069315433502
decider.lstm.bias_hh_l0: 0.00792739074677229 0.15340910851955414
decider.linear1.weight: 0.003316546557471156 0.11797699332237244
decider.linear1.bias: 6.2300823628902435e-06 0.11488737910985947
decider.linear2.weight: 0.0006435569375753403 0.05153762921690941
decider.linear2.bias: -0.0012470390647649765 0.05150885134935379
decider.linear3.weight: -0.00044748676009476185 0.0520583800971508
decider.linear3.bias: -0.015017949044704437 0.03270752355456352

Rewards:
58.1477
58.1477
58.1477
objective = 116.6180419921875
==== episode 5100/75000 ====
action = 0
probs = 0.7574 0.1461 0.0677 0.0288

action = 0
probs = 0.8539 0.0585 0.0665 0.0211

action = 2
probs = 0.3839 0.1007 0.4548 0.0606

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00021823971474077553 0.08147174119949341
encoder.encoder.weight_hh_l0: -0.0006229865248315036 0.08273053914308548
encoder.encoder.bias_ih_l0: -0.003609561827033758 0.08602097630500793
encoder.encoder.bias_hh_l0: 0.009462433867156506 0.08408845216035843
encoder.encoder.weight_ih_l0_reverse: 0.0008798058261163533 0.0830739215016365
encoder.encoder.weight_hh_l0_reverse: 0.0005337889888323843 0.0821966901421547
encoder.encoder.bias_ih_l0_reverse: 0.008984899148344994 0.08061018586158752
encoder.encoder.bias_hh_l0_reverse: 0.009279538877308369 0.08554260432720184
decider.lstm.weight_ih_l0: -0.0015335327479988337 0.14523033797740936
decider.lstm.weight_hh_l0: 0.0007734261453151703 0.14494654536247253
decider.lstm.bias_ih_l0: -0.028367996215820312 0.14137864112854004
decider.lstm.bias_hh_l0: 0.007452770136296749 0.15339119732379913
decider.linear1.weight: 0.0033172117546200752 0.11794095486402512
decider.linear1.bias: -3.4456606954336166e-05 0.11492214351892471
decider.linear2.weight: 0.0006074446719139814 0.05154087394475937
decider.linear2.bias: -0.0012853068765252829 0.05150724574923515
decider.linear3.weight: -0.00045496365055441856 0.05203556641936302
decider.linear3.bias: -0.01503184624016285 0.03279085457324982

Rewards:
65.8452
65.8452
65.8452
objective = 26.8596248626709
==== episode 5200/75000 ====
action = 0
probs = 0.8746 0.0731 0.0374 0.0148

action = 0
probs = 0.9253 0.0271 0.0370 0.0106

action = 0
probs = 0.4479 0.0761 0.4255 0.0505

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005227086367085576 0.08172105997800827
encoder.encoder.weight_hh_l0: -0.000666544830892235 0.08304847031831741
encoder.encoder.bias_ih_l0: -0.0016940014902502298 0.0865156501531601
encoder.encoder.bias_hh_l0: 0.011377994902431965 0.08470319956541061
encoder.encoder.weight_ih_l0_reverse: 0.0011331508867442608 0.08330246806144714
encoder.encoder.weight_hh_l0_reverse: 0.0005552220973186195 0.08252183347940445
encoder.encoder.bias_ih_l0_reverse: 0.010487213730812073 0.08098530769348145
encoder.encoder.bias_hh_l0_reverse: 0.010781851597130299 0.08582354336977005
decider.lstm.weight_ih_l0: -0.0014476964715868235 0.1454622596502304
decider.lstm.weight_hh_l0: 0.0005471155745908618 0.1452551931142807
decider.lstm.bias_ih_l0: -0.02685949206352234 0.14150960743427277
decider.lstm.bias_hh_l0: 0.00896129198372364 0.15358807146549225
decider.linear1.weight: 0.0033212359994649887 0.11819283664226532
decider.linear1.bias: 0.0009364881552755833 0.11499179899692535
decider.linear2.weight: 0.0008411261369474232 0.051619913429021835
decider.linear2.bias: -0.0009397724061273038 0.05154622346162796
decider.linear3.weight: -0.0005591697990894318 0.0523437038064003
decider.linear3.bias: -0.015187045559287071 0.03344456106424332

Rewards:
56.1059
56.1059
56.1059
objective = 18.979297637939453
==== episode 5300/75000 ====
action = 0
probs = 0.8401 0.0947 0.0462 0.0190

action = 0
probs = 0.9129 0.0318 0.0423 0.0130

action = 2
probs = 0.4038 0.0850 0.4517 0.0596

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0003851979272440076 0.08161989599466324
encoder.encoder.weight_hh_l0: -0.0006598698673769832 0.08290617167949677
encoder.encoder.bias_ih_l0: -0.0025861423928290606 0.08632662892341614
encoder.encoder.bias_hh_l0: 0.01048585120588541 0.08442788571119308
encoder.encoder.weight_ih_l0_reverse: 0.0010240827687084675 0.08320176601409912
encoder.encoder.weight_hh_l0_reverse: 0.0005438023945316672 0.08237888664007187
encoder.encoder.bias_ih_l0_reverse: 0.009781746193766594 0.0808359757065773
encoder.encoder.bias_hh_l0_reverse: 0.01007638406008482 0.08568378537893295
decider.lstm.weight_ih_l0: -0.0014971868367865682 0.14535729587078094
decider.lstm.weight_hh_l0: 0.0005902426782995462 0.14514979720115662
decider.lstm.bias_ih_l0: -0.02757023274898529 0.14142905175685883
decider.lstm.bias_hh_l0: 0.008250562474131584 0.15356101095676422
decider.linear1.weight: 0.003301592543721199 0.11809751391410828
decider.linear1.bias: 0.0005858391523361206 0.11505990475416183
decider.linear2.weight: 0.0007647059974260628 0.05160021409392357
decider.linear2.bias: -0.0010262145660817623 0.051527876406908035
decider.linear3.weight: -0.0005138297565281391 0.05227944627404213
decider.linear3.bias: -0.015102878212928772 0.03304607793688774

Rewards:
65.8452
65.8452
65.8452
objective = 23.269851684570312
==== episode 5400/75000 ====
action = 0
probs = 0.8947 0.0581 0.0343 0.0128

action = 0
probs = 0.9373 0.0205 0.0329 0.0093

action = 0
probs = 0.3640 0.0765 0.4984 0.0611

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0005259396275505424 0.08172645419836044
encoder.encoder.weight_hh_l0: -0.0006820218404754996 0.08305487036705017
encoder.encoder.bias_ih_l0: -0.0017086222069337964 0.08649124205112457
encoder.encoder.bias_hh_l0: 0.011363372206687927 0.0846906453371048
encoder.encoder.weight_ih_l0_reverse: 0.0011487777810543776 0.08334551006555557
encoder.encoder.weight_hh_l0_reverse: 0.0005482396227307618 0.08254263550043106
encoder.encoder.bias_ih_l0_reverse: 0.010462033562362194 0.0810190886259079
encoder.encoder.bias_hh_l0_reverse: 0.01075667142868042 0.08584379404783249
decider.lstm.weight_ih_l0: -0.001459436141885817 0.14546214044094086
decider.lstm.weight_hh_l0: 0.00048432929906994104 0.14527921378612518
decider.lstm.bias_ih_l0: -0.026951864361763 0.14154435694217682
decider.lstm.bias_hh_l0: 0.008868931792676449 0.1536756455898285
decider.linear1.weight: 0.003311761422082782 0.11822961270809174
decider.linear1.bias: 0.0011193519458174706 0.115145742893219
decider.linear2.weight: 0.0008746031089685857 0.051652830094099045
decider.linear2.bias: -0.0008454214548692107 0.05150902643799782
decider.linear3.weight: -0.0005685230134986341 0.052489690482616425
decider.linear3.bias: -0.01515058521181345 0.03312545269727707

Rewards:
56.1059
56.1059
56.1059
objective = 22.190959930419922
==== episode 5500/75000 ====
action = 2
probs = 0.9047 0.0525 0.0323 0.0104

action = 0
probs = 0.9419 0.0204 0.0302 0.0075

action = 2
probs = 0.3928 0.0632 0.5010 0.0429

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.000602542539127171 0.08179628103971481
encoder.encoder.weight_hh_l0: -0.0006845626048743725 0.0831822007894516
encoder.encoder.bias_ih_l0: -0.0011672511463984847 0.08644845336675644
encoder.encoder.bias_hh_l0: 0.011904741637408733 0.08484769612550735
encoder.encoder.weight_ih_l0_reverse: 0.0012407007161527872 0.08346536010503769
encoder.encoder.weight_hh_l0_reverse: 0.0005442379042506218 0.08267788589000702
encoder.encoder.bias_ih_l0_reverse: 0.010897067375481129 0.08107185363769531
encoder.encoder.bias_hh_l0_reverse: 0.011191708035767078 0.08603242039680481
decider.lstm.weight_ih_l0: -0.0014335339656099677 0.14553667604923248
decider.lstm.weight_hh_l0: 0.000449982937425375 0.1452922821044922
decider.lstm.bias_ih_l0: -0.026656582951545715 0.14170992374420166
decider.lstm.bias_hh_l0: 0.009164215065538883 0.15364809334278107
decider.linear1.weight: 0.0033279769122600555 0.1183730736374855
decider.linear1.bias: 0.001686655916273594 0.11517604440450668
decider.linear2.weight: 0.0009649765561334789 0.051725439727306366
decider.linear2.bias: -0.0006649114657193422 0.051524460315704346
decider.linear3.weight: -0.0006589963450096548 0.052738651633262634
decider.linear3.bias: -0.015239316038787365 0.033430397510528564

Rewards:
52.5056
52.5056
52.5056
objective = 73.2265396118164
==== episode 5600/75000 ====
action = 0
probs = 0.9027 0.0576 0.0300 0.0096

action = 0
probs = 0.9194 0.0279 0.0436 0.0092

action = 2
probs = 0.1994 0.0687 0.6870 0.0449

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0006201108335517347 0.08179832249879837
encoder.encoder.weight_hh_l0: -0.0007006858941167593 0.08316913992166519
encoder.encoder.bias_ih_l0: -0.0012693989556282759 0.08640813827514648
encoder.encoder.bias_hh_l0: 0.011802596040070057 0.084847092628479
encoder.encoder.weight_ih_l0_reverse: 0.0012549255043268204 0.08347952365875244
encoder.encoder.weight_hh_l0_reverse: 0.000550628814380616 0.08268821239471436
encoder.encoder.bias_ih_l0_reverse: 0.010927594266831875 0.08106003701686859
encoder.encoder.bias_hh_l0_reverse: 0.011222234927117825 0.08604510873556137
decider.lstm.weight_ih_l0: -0.0014322259230539203 0.14554184675216675
decider.lstm.weight_hh_l0: 0.0004320242442190647 0.14527997374534607
decider.lstm.bias_ih_l0: -0.02671106718480587 0.14173230528831482
decider.lstm.bias_hh_l0: 0.009109734557569027 0.15359307825565338
decider.linear1.weight: 0.0033338251523673534 0.11837565153837204
decider.linear1.bias: 0.0017169145867228508 0.11508558690547943
decider.linear2.weight: 0.0009997959714382887 0.051724858582019806
decider.linear2.bias: -0.0006500507006421685 0.05154939740896225
decider.linear3.weight: -0.0006815498345531523 0.052719660103321075
decider.linear3.bias: -0.015268907882273197 0.03367430716753006

Rewards:
65.8452
65.8452
65.8452
objective = 12.330965042114258
==== episode 5700/75000 ====
action = 0
probs = 0.9219 0.0465 0.0230 0.0085

action = 0
probs = 0.9265 0.0248 0.0390 0.0097

action = 0
probs = 0.1792 0.0661 0.7064 0.0484

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0006924610352143645 0.08186715841293335
encoder.encoder.weight_hh_l0: -0.0007216127123683691 0.08325323462486267
encoder.encoder.bias_ih_l0: -0.0008414274198003113 0.0865175798535347
encoder.encoder.bias_hh_l0: 0.012230567634105682 0.08498765528202057
encoder.encoder.weight_ih_l0_reverse: 0.0013131480664014816 0.08355055004358292
encoder.encoder.weight_hh_l0_reverse: 0.0005338265909813344 0.08276956528425217
encoder.encoder.bias_ih_l0_reverse: 0.011254665441811085 0.08114328235387802
encoder.encoder.bias_hh_l0_reverse: 0.01154930330812931 0.08606754243373871
decider.lstm.weight_ih_l0: -0.00143392663449049 0.14559362828731537
decider.lstm.weight_hh_l0: 0.0003801734419539571 0.1453656405210495
decider.lstm.bias_ih_l0: -0.026443148031830788 0.14169959723949432
decider.lstm.bias_hh_l0: 0.009377654641866684 0.15363511443138123
decider.linear1.weight: 0.0033569205552339554 0.11844179034233093
decider.linear1.bias: 0.0019552288576960564 0.11500640213489532
decider.linear2.weight: 0.0010825367644429207 0.05174761638045311
decider.linear2.bias: -0.0005351661238819361 0.0515303760766983
decider.linear3.weight: -0.000667026499286294 0.052815817296504974
decider.linear3.bias: -0.015225631184875965 0.033418066799640656

Rewards:
56.1059
56.1059
56.1059
objective = 35.104923248291016
==== episode 5800/75000 ====
action = 0
probs = 0.9531 0.0263 0.0151 0.0055

action = 0
probs = 0.9510 0.0145 0.0280 0.0065

action = 0
probs = 0.1481 0.0465 0.7676 0.0378

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008472658228129148 0.08204182982444763
encoder.encoder.weight_hh_l0: -0.0007116785855032504 0.08351005613803864
encoder.encoder.bias_ih_l0: 0.00036149114021100104 0.08674792945384979
encoder.encoder.bias_hh_l0: 0.0134334871545434 0.08533657342195511
encoder.encoder.weight_ih_l0_reverse: 0.0014760908670723438 0.08373261988162994
encoder.encoder.weight_hh_l0_reverse: 0.0004934436874464154 0.08303070068359375
encoder.encoder.bias_ih_l0_reverse: 0.012202706187963486 0.0813518762588501
encoder.encoder.bias_hh_l0_reverse: 0.012497344985604286 0.0863032191991806
decider.lstm.weight_ih_l0: -0.0014079045504331589 0.14573992788791656
decider.lstm.weight_hh_l0: 0.00038018019404262304 0.14550885558128357
decider.lstm.bias_ih_l0: -0.025569196790456772 0.14170385897159576
decider.lstm.bias_hh_l0: 0.01025161799043417 0.153659850358963
decider.linear1.weight: 0.00342700257897377 0.11863840371370316
decider.linear1.bias: 0.0026716962456703186 0.11506388336420059
decider.linear2.weight: 0.0012081703171133995 0.051830489188432693
decider.linear2.bias: -0.00031270686304196715 0.051529932767152786
decider.linear3.weight: -0.0007600260432809591 0.053100503981113434
decider.linear3.bias: -0.015316469594836235 0.033633895218372345

Rewards:
56.1059
56.1059
56.1059
objective = 37.56005859375
==== episode 5900/75000 ====
action = 0
probs = 0.9558 0.0265 0.0132 0.0045

action = 3
probs = 0.9575 0.0145 0.0230 0.0049

action = 2
probs = 0.3058 0.0516 0.6113 0.0313

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0008847896824590862 0.0820867046713829
encoder.encoder.weight_hh_l0: -0.0007039725896902382 0.08358155190944672
encoder.encoder.bias_ih_l0: 0.0006501385360024869 0.08680368959903717
encoder.encoder.bias_hh_l0: 0.013722131960093975 0.08537807315587997
encoder.encoder.weight_ih_l0_reverse: 0.001523481565527618 0.08378811180591583
encoder.encoder.weight_hh_l0_reverse: 0.0004843846254516393 0.08312039822340012
encoder.encoder.bias_ih_l0_reverse: 0.012476791627705097 0.08140520006418228
encoder.encoder.bias_hh_l0_reverse: 0.012771428562700748 0.08634515851736069
decider.lstm.weight_ih_l0: -0.0014010810991749167 0.14577695727348328
decider.lstm.weight_hh_l0: 0.00038521981332451105 0.14555329084396362
decider.lstm.bias_ih_l0: -0.02542155422270298 0.14163194596767426
decider.lstm.bias_hh_l0: 0.010399268940091133 0.15368443727493286
decider.linear1.weight: 0.003454828169196844 0.11870481073856354
decider.linear1.bias: 0.0028983186930418015 0.11509612202644348
decider.linear2.weight: 0.0012495712144300342 0.05186408758163452
decider.linear2.bias: -0.0002422367106191814 0.05158168449997902
decider.linear3.weight: -0.0008263566414825618 0.05320847034454346
decider.linear3.bias: -0.015391194261610508 0.034047286957502365

Rewards:
53.7747
53.7747
53.7747
objective = 104.80367279052734
==== episode 6000/75000 ====
action = 0
probs = 0.9589 0.0232 0.0136 0.0043

action = 0
probs = 0.9542 0.0132 0.0277 0.0049

action = 2
probs = 0.0807 0.0321 0.8660 0.0213

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009442364680580795 0.08219292014837265
encoder.encoder.weight_hh_l0: -0.0006724680424667895 0.08380074799060822
encoder.encoder.bias_ih_l0: 0.0014795964816585183 0.08688151091337204
encoder.encoder.bias_hh_l0: 0.014551589265465736 0.08553263545036316
encoder.encoder.weight_ih_l0_reverse: 0.001585736288689077 0.0838882327079773
encoder.encoder.weight_hh_l0_reverse: 0.00045736940228380263 0.08326304703950882
encoder.encoder.bias_ih_l0_reverse: 0.012906515039503574 0.0815000906586647
encoder.encoder.bias_hh_l0_reverse: 0.013201151043176651 0.08650580793619156
decider.lstm.weight_ih_l0: -0.0013868060195818543 0.14586158096790314
decider.lstm.weight_hh_l0: 0.00045240181498229504 0.14558303356170654
decider.lstm.bias_ih_l0: -0.02488240972161293 0.14161895215511322
decider.lstm.bias_hh_l0: 0.010938421823084354 0.1535583883523941
decider.linear1.weight: 0.003497556783258915 0.11883489787578583
decider.linear1.bias: 0.0033008409664034843 0.1151369959115982
decider.linear2.weight: 0.0013570525916293263 0.05190889537334442
decider.linear2.bias: -4.206167068332434e-05 0.051527075469493866
decider.linear3.weight: -0.0009838247206062078 0.05347970500588417
decider.linear3.bias: -0.015453587286174297 0.03419511392712593

Rewards:
65.8452
65.8452
65.8452
objective = 5.109354019165039
==== episode 6100/75000 ====
action = 0
probs = 0.9671 0.0198 0.0100 0.0031

action = 0
probs = 0.9666 0.0106 0.0195 0.0033

action = 2
probs = 0.0858 0.0327 0.8641 0.0174

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001002014148980379 0.0822671428322792
encoder.encoder.weight_hh_l0: -0.0006672469899058342 0.08393194526433945
encoder.encoder.bias_ih_l0: 0.0019692485220730305 0.08697204291820526
encoder.encoder.bias_hh_l0: 0.01504124142229557 0.08561855554580688
encoder.encoder.weight_ih_l0_reverse: 0.0016509698471054435 0.08395401388406754
encoder.encoder.weight_hh_l0_reverse: 0.00042795343324542046 0.08339107781648636
encoder.encoder.bias_ih_l0_reverse: 0.01330137625336647 0.08159614354372025
encoder.encoder.bias_hh_l0_reverse: 0.013596011325716972 0.08658785372972488
decider.lstm.weight_ih_l0: -0.0013885305961593986 0.14591151475906372
decider.lstm.weight_hh_l0: 0.0005070616025477648 0.14567214250564575
decider.lstm.bias_ih_l0: -0.02460118755698204 0.14156943559646606
decider.lstm.bias_hh_l0: 0.01121965330094099 0.1536458283662796
decider.linear1.weight: 0.003544330131262541 0.11890728026628494
decider.linear1.bias: 0.003542414866387844 0.1152288094162941
decider.linear2.weight: 0.0014204408507794142 0.05194641277194023
decider.linear2.bias: 5.0868489779531956e-05 0.05158397555351257
decider.linear3.weight: -0.0011017033830285072 0.053634777665138245
decider.linear3.bias: -0.015539810992777348 0.034670982509851456

Rewards:
65.8452
65.8452
65.8452
objective = 4.685275077819824
==== episode 6200/75000 ====
action = 0
probs = 0.9561 0.0264 0.0129 0.0047

action = 0
probs = 0.9467 0.0170 0.0304 0.0059

action = 2
probs = 0.0562 0.0357 0.8861 0.0220

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.000940163794439286 0.0821676030755043
encoder.encoder.weight_hh_l0: -0.0006855250103399158 0.08374762535095215
encoder.encoder.bias_ih_l0: 0.0011602526064962149 0.08683547377586365
encoder.encoder.bias_hh_l0: 0.014232245273888111 0.08542117476463318
encoder.encoder.weight_ih_l0_reverse: 0.0015785673167556524 0.0838722214102745
encoder.encoder.weight_hh_l0_reverse: 0.000462963042082265 0.08322444558143616
encoder.encoder.bias_ih_l0_reverse: 0.012729428708553314 0.08149199932813644
encoder.encoder.bias_hh_l0_reverse: 0.013024067506194115 0.08644362539052963
decider.lstm.weight_ih_l0: -0.0013959474163129926 0.14584366977214813
decider.lstm.weight_hh_l0: 0.00039281731005758047 0.14555136859416962
decider.lstm.bias_ih_l0: -0.02516227960586548 0.14161843061447144
decider.lstm.bias_hh_l0: 0.01065856870263815 0.153481125831604
decider.linear1.weight: 0.0034887250512838364 0.11884535104036331
decider.linear1.bias: 0.00322573259472847 0.11519145965576172
decider.linear2.weight: 0.0013295779936015606 0.051938675343990326
decider.linear2.bias: -6.606627721339464e-05 0.05151408538222313
decider.linear3.weight: -0.0009987936355173588 0.05358484014868736
decider.linear3.bias: -0.01537275779992342 0.033917661756277084

Rewards:
65.8452
65.8452
65.8452
objective = 4.843008041381836
==== episode 6300/75000 ====
action = 0
probs = 0.9671 0.0208 0.0085 0.0035

action = 2
probs = 0.9678 0.0121 0.0159 0.0042

action = 0
probs = 0.2051 0.0564 0.7045 0.0340

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009453127277083695 0.0821455866098404
encoder.encoder.weight_hh_l0: -0.0007057455368340015 0.08365695178508759
encoder.encoder.bias_ih_l0: 0.0007948061684146523 0.08684254437685013
encoder.encoder.bias_hh_l0: 0.013866796158254147 0.08535230904817581
encoder.encoder.weight_ih_l0_reverse: 0.0016032549319788814 0.08387040346860886
encoder.encoder.weight_hh_l0_reverse: 0.0004618608800228685 0.08324592560529709
encoder.encoder.bias_ih_l0_reverse: 0.012770073488354683 0.08152981102466583
encoder.encoder.bias_hh_l0_reverse: 0.013064713217318058 0.08637627214193344
decider.lstm.weight_ih_l0: -0.0014094654470682144 0.14582520723342896
decider.lstm.weight_hh_l0: 0.0003336961381137371 0.14558251202106476
decider.lstm.bias_ih_l0: -0.025474360212683678 0.14159786701202393
decider.lstm.bias_hh_l0: 0.01034648809581995 0.15369150042533875
decider.linear1.weight: 0.0035080253146588802 0.1188172996044159
decider.linear1.bias: 0.0031839068979024887 0.11521704494953156
decider.linear2.weight: 0.0013090912252664566 0.05195505544543266
decider.linear2.bias: -0.00010731018846854568 0.05151817202568054
decider.linear3.weight: -0.0009926555212587118 0.053592123091220856
decider.linear3.bias: -0.015342707745730877 0.03390203416347504

Rewards:
55.2622
55.2622
55.2622
objective = 106.04115295410156
==== episode 6400/75000 ====
action = 0
probs = 0.9733 0.0162 0.0079 0.0027

action = 0
probs = 0.9701 0.0100 0.0167 0.0032

action = 2
probs = 0.0849 0.0370 0.8558 0.0224

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0010121356463059783 0.08224217593669891
encoder.encoder.weight_hh_l0: -0.0006967891240492463 0.08378787338733673
encoder.encoder.bias_ih_l0: 0.0014016693457961082 0.08698666840791702
encoder.encoder.bias_hh_l0: 0.014473664574325085 0.0855691134929657
encoder.encoder.weight_ih_l0_reverse: 0.0016721382271498442 0.08396199345588684
encoder.encoder.weight_hh_l0_reverse: 0.00044893950689584017 0.08336570858955383
encoder.encoder.bias_ih_l0_reverse: 0.013177324086427689 0.081623874604702
encoder.encoder.bias_hh_l0_reverse: 0.013471962884068489 0.0865052193403244
decider.lstm.weight_ih_l0: -0.001391951460391283 0.14589807391166687
decider.lstm.weight_hh_l0: 0.00038119079545140266 0.14566448330879211
decider.lstm.bias_ih_l0: -0.024979615584015846 0.14162449538707733
decider.lstm.bias_hh_l0: 0.010841235518455505 0.1537197232246399
decider.linear1.weight: 0.0035572629421949387 0.11890292167663574
decider.linear1.bias: 0.0035236431285738945 0.11519976705312729
decider.linear2.weight: 0.001421425142325461 0.05196979269385338
decider.linear2.bias: 4.630564944818616e-05 0.05155450478196144
decider.linear3.weight: -0.0010752888629212976 0.0536455437541008
decider.linear3.bias: -0.015496150590479374 0.034455977380275726

Rewards:
65.8452
65.8452
65.8452
objective = 4.678815841674805
==== episode 6500/75000 ====
action = 0
probs = 0.9589 0.0251 0.0123 0.0037

action = 0
probs = 0.9527 0.0156 0.0270 0.0047

action = 2
probs = 0.0912 0.0398 0.8423 0.0267

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009069021325558424 0.08211320638656616
encoder.encoder.weight_hh_l0: -0.000703599420376122 0.08362232148647308
encoder.encoder.bias_ih_l0: 0.0006139528704807162 0.08683210611343384
encoder.encoder.bias_hh_l0: 0.013685946352779865 0.08539564907550812
encoder.encoder.weight_ih_l0_reverse: 0.0015607550740242004 0.08383488655090332
encoder.encoder.weight_hh_l0_reverse: 0.0004629209288395941 0.08317804336547852
encoder.encoder.bias_ih_l0_reverse: 0.012516970746219158 0.08146876841783524
encoder.encoder.bias_hh_l0_reverse: 0.01281160768121481 0.08632642030715942
decider.lstm.weight_ih_l0: -0.0014132672222331166 0.1458168625831604
decider.lstm.weight_hh_l0: 0.00031317200046032667 0.14555315673351288
decider.lstm.bias_ih_l0: -0.02559977024793625 0.14166444540023804
decider.lstm.bias_hh_l0: 0.010221092030405998 0.15365195274353027
decider.linear1.weight: 0.003476800862699747 0.11877162009477615
decider.linear1.bias: 0.00307281780987978 0.11511886119842529
decider.linear2.weight: 0.0013348194770514965 0.05191565304994583
decider.linear2.bias: -0.00011457246728241444 0.05153833329677582
decider.linear3.weight: -0.001035217777825892 0.053447041660547256
decider.linear3.bias: -0.01543903723359108 0.03420190140604973

Rewards:
65.8452
65.8452
65.8452
objective = 5.75238561630249
==== episode 6600/75000 ====
action = 0
probs = 0.9686 0.0183 0.0103 0.0027

action = 0
probs = 0.9579 0.0127 0.0256 0.0038

action = 2
probs = 0.1161 0.0424 0.8153 0.0262

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0009551240364089608 0.08216115087270737
encoder.encoder.weight_hh_l0: -0.0007136842468753457 0.08365831524133682
encoder.encoder.bias_ih_l0: 0.00085736985784024 0.08693757653236389
encoder.encoder.bias_hh_l0: 0.01392935961484909 0.08552194386720657
encoder.encoder.weight_ih_l0_reverse: 0.0016036710003390908 0.08387713134288788
encoder.encoder.weight_hh_l0_reverse: 0.00045546540059149265 0.08322698622941971
encoder.encoder.bias_ih_l0_reverse: 0.012733864597976208 0.08152074366807938
encoder.encoder.bias_hh_l0_reverse: 0.01302849967032671 0.08637333661317825
decider.lstm.weight_ih_l0: -0.00141158327460289 0.1458560824394226
decider.lstm.weight_hh_l0: 0.00030465039890259504 0.14562708139419556
decider.lstm.bias_ih_l0: -0.025387626141309738 0.14166893064975739
decider.lstm.bias_hh_l0: 0.010433245450258255 0.15372833609580994
decider.linear1.weight: 0.0035060103982686996 0.11880212277173996
decider.linear1.bias: 0.0032058991491794586 0.11506541818380356
decider.linear2.weight: 0.0013933053705841303 0.05191794037818909
decider.linear2.bias: -6.702844984829426e-05 0.0515567809343338
decider.linear3.weight: -0.0010693040676414967 0.05343072861433029
decider.linear3.bias: -0.01551838032901287 0.034556400030851364

Rewards:
65.8452
65.8452
65.8452
objective = 6.125267028808594
==== episode 6700/75000 ====
action = 0
probs = 0.9794 0.0120 0.0068 0.0019

action = 0
probs = 0.9686 0.0091 0.0194 0.0029

action = 2
probs = 0.0838 0.0317 0.8601 0.0243

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0010606355499476194 0.08229757845401764
encoder.encoder.weight_hh_l0: -0.000718137074727565 0.08383964747190475
encoder.encoder.bias_ih_l0: 0.0016874911962077022 0.08710436522960663
encoder.encoder.bias_hh_l0: 0.014759480953216553 0.08570209890604019
encoder.encoder.weight_ih_l0_reverse: 0.001699764863587916 0.08402159810066223
encoder.encoder.weight_hh_l0_reverse: 0.00044668829650618136 0.083401158452034
encoder.encoder.bias_ih_l0_reverse: 0.01331371534615755 0.08167548477649689
encoder.encoder.bias_hh_l0_reverse: 0.013608349487185478 0.08653946220874786
decider.lstm.weight_ih_l0: -0.0013971080770716071 0.1459406465291977
decider.lstm.weight_hh_l0: 0.00036532164085656404 0.14572836458683014
decider.lstm.bias_ih_l0: -0.02477380633354187 0.14164161682128906
decider.lstm.bias_hh_l0: 0.011047061532735825 0.15376214683055878
decider.linear1.weight: 0.0035970835015177727 0.11895708739757538
decider.linear1.bias: 0.0037333108484745026 0.11511562019586563
decider.linear2.weight: 0.0014784856466576457 0.051990244537591934
decider.linear2.bias: 9.076177957467735e-05 0.05153278633952141
decider.linear3.weight: -0.0011232607066631317 0.05365994572639465
decider.linear3.bias: -0.015520970337092876 0.03435632586479187

Rewards:
65.8452
65.8452
65.8452
objective = 4.465944290161133
==== episode 6800/75000 ====
action = 0
probs = 0.9751 0.0146 0.0083 0.0020

action = 0
probs = 0.9573 0.0107 0.0285 0.0034

action = 2
probs = 0.0550 0.0222 0.9032 0.0197

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0010749244829639792 0.08234123885631561
encoder.encoder.weight_hh_l0: -0.0007027985411696136 0.08393324166536331
encoder.encoder.bias_ih_l0: 0.0020224391482770443 0.0871223509311676
encoder.encoder.bias_hh_l0: 0.015094427391886711 0.08576321601867676
encoder.encoder.weight_ih_l0_reverse: 0.0017096158117055893 0.08404798805713654
encoder.encoder.weight_hh_l0_reverse: 0.00044383658678270876 0.08342395722866058
encoder.encoder.bias_ih_l0_reverse: 0.013360300101339817 0.08167913556098938
encoder.encoder.bias_hh_l0_reverse: 0.013654932379722595 0.08660698682069778
decider.lstm.weight_ih_l0: -0.001388008240610361 0.14596155285835266
decider.lstm.weight_hh_l0: 0.00044514460023492575 0.14572082459926605
decider.lstm.bias_ih_l0: -0.024506675079464912 0.14163275063037872
decider.lstm.bias_hh_l0: 0.011314187198877335 0.15365271270275116
decider.linear1.weight: 0.0036219824105501175 0.1190173551440239
decider.linear1.bias: 0.003926414065063 0.11512140184640884
decider.linear2.weight: 0.00151862355414778 0.05201113224029541
decider.linear2.bias: 0.00017461151583120227 0.05153368413448334
decider.linear3.weight: -0.001161946333013475 0.05374321714043617
decider.linear3.bias: -0.015537533909082413 0.03424263373017311

Rewards:
65.8452
65.8452
65.8452
objective = 3.7467658519744873
==== episode 6900/75000 ====
action = 0
probs = 0.9772 0.0139 0.0073 0.0017

action = 0
probs = 0.9560 0.0125 0.0284 0.0031

action = 2
probs = 0.0504 0.0257 0.9059 0.0180

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0010886695235967636 0.08236661553382874
encoder.encoder.weight_hh_l0: -0.0007093725726008415 0.08395544439554214
encoder.encoder.bias_ih_l0: 0.0021306436974555254 0.08714597672224045
encoder.encoder.bias_hh_l0: 0.015202634036540985 0.08578991889953613
encoder.encoder.weight_ih_l0_reverse: 0.0017248083604499698 0.0840863585472107
encoder.encoder.weight_hh_l0_reverse: 0.0004344648332335055 0.08347208052873611
encoder.encoder.bias_ih_l0_reverse: 0.013505708426237106 0.08171048015356064
encoder.encoder.bias_hh_l0_reverse: 0.013800340704619884 0.0866411104798317
decider.lstm.weight_ih_l0: -0.0013922331854701042 0.14597788453102112
decider.lstm.weight_hh_l0: 0.0004294032696634531 0.14574941992759705
decider.lstm.bias_ih_l0: -0.02444734051823616 0.14160726964473724
decider.lstm.bias_hh_l0: 0.011373532004654408 0.15368768572807312
decider.linear1.weight: 0.003642396070063114 0.11904323101043701
decider.linear1.bias: 0.004018887411803007 0.11510483920574188
decider.linear2.weight: 0.0015469302888959646 0.052022483199834824
decider.linear2.bias: 0.00020831302390433848 0.05157465115189552
decider.linear3.weight: -0.0011893576011061668 0.053770512342453
decider.linear3.bias: -0.015582295134663582 0.03458993509411812

Rewards:
65.8452
65.8452
65.8452
objective = 3.663750410079956
==== episode 7000/75000 ====
action = 0
probs = 0.9803 0.0122 0.0062 0.0014

action = 0
probs = 0.9597 0.0117 0.0258 0.0028

action = 2
probs = 0.0372 0.0229 0.9234 0.0165

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001127280411310494 0.08243834972381592
encoder.encoder.weight_hh_l0: -0.0007014427683316171 0.08406431972980499
encoder.encoder.bias_ih_l0: 0.002553971717134118 0.08721920847892761
encoder.encoder.bias_hh_l0: 0.015625961124897003 0.08585630357265472
encoder.encoder.weight_ih_l0_reverse: 0.001762908068485558 0.08415364474058151
encoder.encoder.weight_hh_l0_reverse: 0.00041702750604599714 0.08356896787881851
encoder.encoder.bias_ih_l0_reverse: 0.013789047487080097 0.08179005235433578
encoder.encoder.bias_hh_l0_reverse: 0.0140836788341403 0.08672021329402924
decider.lstm.weight_ih_l0: -0.0013914600713178515 0.1460164487361908
decider.lstm.weight_hh_l0: 0.00048816227354109287 0.1457895040512085
decider.lstm.bias_ih_l0: -0.02419065684080124 0.14155398309230804
decider.lstm.bias_hh_l0: 0.011630214750766754 0.15368995070457458
decider.linear1.weight: 0.0036991331726312637 0.11912216246128082
decider.linear1.bias: 0.004278871230781078 0.11515023559331894
decider.linear2.weight: 0.0015902642626315355 0.05206484720110893
decider.linear2.bias: 0.00029612850630655885 0.05159137770533562
decider.linear3.weight: -0.0012239344650879502 0.05390273034572601
decider.linear3.bias: -0.015585056506097317 0.034555502235889435

Rewards:
65.8452
65.8452
65.8452
objective = 3.086768627166748
==== episode 7100/75000 ====
action = 0
probs = 0.9885 0.0070 0.0036 0.0009

action = 0
probs = 0.9754 0.0071 0.0155 0.0020

action = 2
probs = 0.0303 0.0197 0.9315 0.0185

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012072455137968063 0.08254680037498474
encoder.encoder.weight_hh_l0: -0.0007037704344838858 0.08420383185148239
encoder.encoder.bias_ih_l0: 0.0031254219356924295 0.08735311776399612
encoder.encoder.bias_hh_l0: 0.016197409480810165 0.08597134053707123
encoder.encoder.weight_ih_l0_reverse: 0.0018393016653135419 0.08426135033369064
encoder.encoder.weight_hh_l0_reverse: 0.00039697959437035024 0.0837353765964508
encoder.encoder.bias_ih_l0_reverse: 0.014301581308245659 0.08192387968301773
encoder.encoder.bias_hh_l0_reverse: 0.014596213586628437 0.08683940023183823
decider.lstm.weight_ih_l0: -0.0013883077772334218 0.14608046412467957
decider.lstm.weight_hh_l0: 0.0005620057927444577 0.14587292075157166
decider.lstm.bias_ih_l0: -0.023800350725650787 0.14152005314826965
decider.lstm.bias_hh_l0: 0.012020516209304333 0.15375496447086334
decider.linear1.weight: 0.003798662219196558 0.11924723535776138
decider.linear1.bias: 0.004657802637666464 0.11519251018762589
decider.linear2.weight: 0.0016642969567328691 0.052127230912446976
decider.linear2.bias: 0.00042036033119075 0.05156736448407173
decider.linear3.weight: -0.0012687604175880551 0.054081305861473083
decider.linear3.bias: -0.01551879197359085 0.03410686179995537

Rewards:
65.8452
65.8452
65.8452
objective = 2.3563129901885986
==== episode 7200/75000 ====
action = 0
probs = 0.9926 0.0044 0.0025 0.0006

action = 0
probs = 0.9819 0.0050 0.0117 0.0014

action = 2
probs = 0.0320 0.0159 0.9365 0.0156

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012762584956362844 0.08263196051120758
encoder.encoder.weight_hh_l0: -0.0007038296316750348 0.08434929698705673
encoder.encoder.bias_ih_l0: 0.0037106263916939497 0.0874563604593277
encoder.encoder.bias_hh_l0: 0.0167826097458601 0.08608409762382507
encoder.encoder.weight_ih_l0_reverse: 0.0018991905963048339 0.08434587717056274
encoder.encoder.weight_hh_l0_reverse: 0.0003813221410382539 0.08387958258390427
encoder.encoder.bias_ih_l0_reverse: 0.014742761850357056 0.08201055973768234
encoder.encoder.bias_hh_l0_reverse: 0.015037390403449535 0.08697202056646347
decider.lstm.weight_ih_l0: -0.0013857927406206727 0.14613793790340424
decider.lstm.weight_hh_l0: 0.0006792186759412289 0.1459561139345169
decider.lstm.bias_ih_l0: -0.023386474698781967 0.14149494469165802
decider.lstm.bias_hh_l0: 0.012434384785592556 0.15383538603782654
decider.linear1.weight: 0.003926862496882677 0.11936505883932114
decider.linear1.bias: 0.005131064914166927 0.11535746604204178
decider.linear2.weight: 0.0018070918740704656 0.05220375210046768
decider.linear2.bias: 0.0005325023666955531 0.05158631131052971
decider.linear3.weight: -0.001331530511379242 0.05418279767036438
decider.linear3.bias: -0.015602435916662216 0.03436095640063286

Rewards:
65.8452
65.8452
65.8452
objective = 2.006028652191162
==== episode 7300/75000 ====
action = 0
probs = 0.9886 0.0074 0.0032 0.0008

action = 0
probs = 0.9733 0.0083 0.0163 0.0020

action = 2
probs = 0.0257 0.0164 0.9399 0.0180

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001231673057191074 0.08256209641695023
encoder.encoder.weight_hh_l0: -0.0007006880478002131 0.08422548323869705
encoder.encoder.bias_ih_l0: 0.0031819783616811037 0.08735009282827377
encoder.encoder.bias_hh_l0: 0.016253957524895668 0.0859866663813591
encoder.encoder.weight_ih_l0_reverse: 0.0018488599453121424 0.08427569270133972
encoder.encoder.weight_hh_l0_reverse: 0.0004014121077489108 0.08374117314815521
encoder.encoder.bias_ih_l0_reverse: 0.01430539321154356 0.08190969377756119
encoder.encoder.bias_hh_l0_reverse: 0.014600023627281189 0.08684002608060837
decider.lstm.weight_ih_l0: -0.0013794016558676958 0.14608614146709442
decider.lstm.weight_hh_l0: 0.0005780134815722704 0.14587193727493286
decider.lstm.bias_ih_l0: -0.023737793788313866 0.14148499071598053
decider.lstm.bias_hh_l0: 0.01208307035267353 0.15373080968856812
decider.linear1.weight: 0.0038596163503825665 0.11929492652416229
decider.linear1.bias: 0.00486326776444912 0.11531208455562592
decider.linear2.weight: 0.0017674638656899333 0.05218179151415825
decider.linear2.bias: 0.00047098289360292256 0.051575981080532074
decider.linear3.weight: -0.0013056239113211632 0.05412790924310684
decider.linear3.bias: -0.01549897063523531 0.033965304493904114

Rewards:
65.8452
65.8452
65.8452
objective = 2.205617904663086
==== episode 7400/75000 ====
action = 0
probs = 0.9908 0.0059 0.0026 0.0006

action = 0
probs = 0.9789 0.0063 0.0133 0.0016

action = 2
probs = 0.0232 0.0125 0.9499 0.0144

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012857371475547552 0.08264604955911636
encoder.encoder.weight_hh_l0: -0.0006945495260879397 0.08437364548444748
encoder.encoder.bias_ih_l0: 0.0037319352850317955 0.08743628859519958
encoder.encoder.bias_hh_l0: 0.016803914681077003 0.08608459681272507
encoder.encoder.weight_ih_l0_reverse: 0.0018990751123055816 0.08434481918811798
encoder.encoder.weight_hh_l0_reverse: 0.0003864038153551519 0.0838601291179657
encoder.encoder.bias_ih_l0_reverse: 0.014666921459138393 0.08198860287666321
encoder.encoder.bias_hh_l0_reverse: 0.014961551874876022 0.086967334151268
decider.lstm.weight_ih_l0: -0.0013745861360803246 0.1461361050605774
decider.lstm.weight_hh_l0: 0.0006963016930967569 0.14593404531478882
decider.lstm.bias_ih_l0: -0.023332176730036736 0.14144235849380493
decider.lstm.bias_hh_l0: 0.012488692998886108 0.15375863015651703
decider.linear1.weight: 0.003932689316570759 0.11939089000225067
decider.linear1.bias: 0.005177116021513939 0.11535651981830597
decider.linear2.weight: 0.0018336555222049356 0.05222061648964882
decider.linear2.bias: 0.000589828472584486 0.051586247980594635
decider.linear3.weight: -0.0013563961256295443 0.05424794927239418
decider.linear3.bias: -0.015572639182209969 0.03415491804480553

Rewards:
65.8452
65.8452
65.8452
objective = 1.7987329959869385
==== episode 7500/75000 ====
action = 0
probs = 0.9861 0.0084 0.0044 0.0010

action = 0
probs = 0.9490 0.0108 0.0367 0.0036

action = 2
probs = 0.0137 0.0091 0.9655 0.0116

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012769510503858328 0.0826491117477417
encoder.encoder.weight_hh_l0: -0.00068786705378443 0.08441220223903656
encoder.encoder.bias_ih_l0: 0.00383982271887362 0.08736773580312729
encoder.encoder.bias_hh_l0: 0.016911806538701057 0.08612389862537384
encoder.encoder.weight_ih_l0_reverse: 0.0018649748526513577 0.08432242274284363
encoder.encoder.weight_hh_l0_reverse: 0.0003869493375532329 0.08378702402114868
encoder.encoder.bias_ih_l0_reverse: 0.014439859427511692 0.0819166973233223
encoder.encoder.bias_hh_l0_reverse: 0.014734489843249321 0.08700673282146454
decider.lstm.weight_ih_l0: -0.001368316705338657 0.14613579213619232
decider.lstm.weight_hh_l0: 0.0008454050403088331 0.14590582251548767
decider.lstm.bias_ih_l0: -0.022954612970352173 0.14139410853385925
decider.lstm.bias_hh_l0: 0.012866266071796417 0.15351741015911102
decider.linear1.weight: 0.003924062009900808 0.11940906196832657
decider.linear1.bias: 0.005162043496966362 0.11525221914052963
decider.linear2.weight: 0.0018070987425744534 0.05220312625169754
decider.linear2.bias: 0.0005611310480162501 0.05155353620648384
decider.linear3.weight: -0.0013080285862088203 0.054194360971450806
decider.linear3.bias: -0.015546859242022038 0.03383353725075722

Rewards:
65.8452
65.8452
65.8452
objective = 2.225464344024658
==== episode 7600/75000 ====
action = 0
probs = 0.9890 0.0072 0.0030 0.0009

action = 0
probs = 0.9730 0.0075 0.0173 0.0022

action = 2
probs = 0.0191 0.0094 0.9604 0.0111

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0012618806213140488 0.0826473981142044
encoder.encoder.weight_hh_l0: -0.0006720664096064866 0.08441077917814255
encoder.encoder.bias_ih_l0: 0.003782978281378746 0.08739160746335983
encoder.encoder.bias_hh_l0: 0.01685495860874653 0.08607999235391617
encoder.encoder.weight_ih_l0_reverse: 0.001882562879472971 0.08433321118354797
encoder.encoder.weight_hh_l0_reverse: 0.0003743486013263464 0.08384092897176743
encoder.encoder.bias_ih_l0_reverse: 0.014565842226147652 0.08195360004901886
encoder.encoder.bias_hh_l0_reverse: 0.01486047450453043 0.08697586506605148
decider.lstm.weight_ih_l0: -0.0013740839203819633 0.14613188803195953
decider.lstm.weight_hh_l0: 0.0007612187182530761 0.14591677486896515
decider.lstm.bias_ih_l0: -0.02326928824186325 0.14136727154254913
decider.lstm.bias_hh_l0: 0.012551589868962765 0.153683140873909
decider.linear1.weight: 0.003941586706787348 0.1194068193435669
decider.linear1.bias: 0.005198915489017963 0.11531005054712296
decider.linear2.weight: 0.0018000801792368293 0.052224788814783096
decider.linear2.bias: 0.0005976960528641939 0.051580991595983505
decider.linear3.weight: -0.0013354797847568989 0.05424732714891434
decider.linear3.bias: -0.015600020065903664 0.034157413989305496

Rewards:
65.8452
65.8452
65.8452
objective = 1.7311317920684814
==== episode 7700/75000 ====
action = 0
probs = 0.9906 0.0059 0.0028 0.0007

action = 0
probs = 0.9765 0.0059 0.0158 0.0018

action = 2
probs = 0.0139 0.0066 0.9709 0.0085

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013056591851636767 0.08273295313119888
encoder.encoder.weight_hh_l0: -0.0006634039455093443 0.08457394689321518
encoder.encoder.bias_ih_l0: 0.004298052284866571 0.08744438737630844
encoder.encoder.bias_hh_l0: 0.017370034009218216 0.0861576721072197
encoder.encoder.weight_ih_l0_reverse: 0.0019204834243282676 0.08439043909311295
encoder.encoder.weight_hh_l0_reverse: 0.00035752265830524266 0.08394694328308105
encoder.encoder.bias_ih_l0_reverse: 0.01487515214830637 0.08201766014099121
encoder.encoder.bias_hh_l0_reverse: 0.015169787220656872 0.0871087908744812
decider.lstm.weight_ih_l0: -0.0013709997292608023 0.1461738646030426
decider.lstm.weight_hh_l0: 0.0009323286358267069 0.14596372842788696
decider.lstm.bias_ih_l0: -0.022844310849905014 0.14130422472953796
decider.lstm.bias_hh_l0: 0.012976572848856449 0.15366224944591522
decider.linear1.weight: 0.004022040870040655 0.1195107027888298
decider.linear1.bias: 0.005494984798133373 0.11538197100162506
decider.linear2.weight: 0.0018514516996219754 0.0522618442773819
decider.linear2.bias: 0.0007164563285186887 0.05158130079507828
decider.linear3.weight: -0.0013892876449972391 0.0543852336704731
decider.linear3.bias: -0.015662813559174538 0.03424166515469551

Rewards:
65.8452
65.8452
65.8452
objective = 1.377187967300415
==== episode 7800/75000 ====
action = 0
probs = 0.9918 0.0051 0.0025 0.0006

action = 0
probs = 0.9841 0.0045 0.0101 0.0012

action = 2
probs = 0.0182 0.0075 0.9659 0.0084

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013009123504161835 0.08274070173501968
encoder.encoder.weight_hh_l0: -0.0006576188025064766 0.08458569645881653
encoder.encoder.bias_ih_l0: 0.004314439371228218 0.08747343719005585
encoder.encoder.bias_hh_l0: 0.01738642156124115 0.08614186942577362
encoder.encoder.weight_ih_l0_reverse: 0.0019292893121019006 0.0844026580452919
encoder.encoder.weight_hh_l0_reverse: 0.000354596326360479 0.08398176729679108
encoder.encoder.bias_ih_l0_reverse: 0.014971473254263401 0.08204571902751923
encoder.encoder.bias_hh_l0_reverse: 0.015266108326613903 0.08710256963968277
decider.lstm.weight_ih_l0: -0.001374144572764635 0.14617319405078888
decider.lstm.weight_hh_l0: 0.0008765162201598287 0.14598096907138824
decider.lstm.bias_ih_l0: -0.02298073098063469 0.1413000524044037
decider.lstm.bias_hh_l0: 0.01284013781696558 0.15376806259155273
decider.linear1.weight: 0.0040167877450585365 0.11950641870498657
decider.linear1.bias: 0.005500664468854666 0.11544882506132126
decider.linear2.weight: 0.001836727955378592 0.05227259173989296
decider.linear2.bias: 0.0007126105483621359 0.051597531884908676
decider.linear3.weight: -0.0014196560950949788 0.05440239980816841
decider.linear3.bias: -0.015728604048490524 0.034583140164613724

Rewards:
65.8452
65.8452
65.8452
objective = 1.2950892448425293
==== episode 7900/75000 ====
action = 0
probs = 0.9930 0.0043 0.0022 0.0005

action = 0
probs = 0.9842 0.0040 0.0107 0.0011

action = 2
probs = 0.0125 0.0053 0.9754 0.0068

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013483371585607529 0.08281418681144714
encoder.encoder.weight_hh_l0: -0.0006624383968301117 0.08472780138254166
encoder.encoder.bias_ih_l0: 0.004782455042004585 0.08750981092453003
encoder.encoder.bias_hh_l0: 0.01785443350672722 0.0862196683883667
encoder.encoder.weight_ih_l0_reverse: 0.001959571847692132 0.08445466309785843
encoder.encoder.weight_hh_l0_reverse: 0.0003494803386274725 0.08406320214271545
encoder.encoder.bias_ih_l0_reverse: 0.015222721733152866 0.08209020644426346
encoder.encoder.bias_hh_l0_reverse: 0.015517359599471092 0.08722854405641556
decider.lstm.weight_ih_l0: -0.0013667447492480278 0.14621245861053467
decider.lstm.weight_hh_l0: 0.001028333674184978 0.14602790772914886
decider.lstm.bias_ih_l0: -0.022522281855344772 0.14125236868858337
decider.lstm.bias_hh_l0: 0.013298574835062027 0.15372171998023987
decider.linear1.weight: 0.004097107797861099 0.11961474269628525
decider.linear1.bias: 0.00579582154750824 0.11546015739440918
decider.linear2.weight: 0.0018922861199826002 0.0523117370903492
decider.linear2.bias: 0.0008145894971676171 0.05159444361925125
decider.linear3.weight: -0.0014599061105400324 0.05453115701675415
decider.linear3.bias: -0.01575835794210434 0.03455782309174538

Rewards:
65.8452
65.8452
65.8452
objective = 1.0519394874572754
==== episode 8000/75000 ====
action = 0
probs = 0.9922 0.0045 0.0026 0.0007

action = 0
probs = 0.9850 0.0035 0.0103 0.0011

action = 2
probs = 0.0098 0.0040 0.9810 0.0053

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013389834202826023 0.08283280581235886
encoder.encoder.weight_hh_l0: -0.0006453010719269514 0.08480610698461533
encoder.encoder.bias_ih_l0: 0.004927349742501974 0.08748549968004227
encoder.encoder.bias_hh_l0: 0.017999332398176193 0.08619004487991333
encoder.encoder.weight_ih_l0_reverse: 0.0019405294442549348 0.08443377912044525
encoder.encoder.weight_hh_l0_reverse: 0.00034572643926367164 0.08405177295207977
encoder.encoder.bias_ih_l0_reverse: 0.015176241286098957 0.08208449184894562
encoder.encoder.bias_hh_l0_reverse: 0.015470877289772034 0.08724474906921387
decider.lstm.weight_ih_l0: -0.0013595729833468795 0.14621448516845703
decider.lstm.weight_hh_l0: 0.0011340812779963017 0.14601971209049225
decider.lstm.bias_ih_l0: -0.02241957001388073 0.14120051264762878
decider.lstm.bias_hh_l0: 0.013401282951235771 0.15366880595684052
decider.linear1.weight: 0.004110395908355713 0.11965563148260117
decider.linear1.bias: 0.005848758853971958 0.11553036421537399
decider.linear2.weight: 0.0018906581681221724 0.05232052505016327
decider.linear2.bias: 0.0008687605150043964 0.05158569663763046
decider.linear3.weight: -0.001463047112338245 0.05459369346499443
decider.linear3.bias: -0.01577519066631794 0.03447560593485832

Rewards:
65.8452
65.8452
65.8452
objective = 0.9239650964736938
==== episode 8100/75000 ====
action = 0
probs = 0.9899 0.0053 0.0040 0.0008

action = 0
probs = 0.9718 0.0048 0.0219 0.0016

action = 2
probs = 0.0082 0.0033 0.9842 0.0043

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001354749663732946 0.08282624185085297
encoder.encoder.weight_hh_l0: -0.0006495448178611696 0.08479990810155869
encoder.encoder.bias_ih_l0: 0.004915514029562473 0.0874539315700531
encoder.encoder.bias_hh_l0: 0.01798749342560768 0.08622429519891739
encoder.encoder.weight_ih_l0_reverse: 0.0019320137798786163 0.08441023528575897
encoder.encoder.weight_hh_l0_reverse: 0.00034686404978856444 0.08400221168994904
encoder.encoder.bias_ih_l0_reverse: 0.01501061487942934 0.0820758044719696
encoder.encoder.bias_hh_l0_reverse: 0.015305252745747566 0.08727014809846878
decider.lstm.weight_ih_l0: -0.0013488427503034472 0.14621976017951965
decider.lstm.weight_hh_l0: 0.0012283152900636196 0.14602196216583252
decider.lstm.bias_ih_l0: -0.022180095314979553 0.14123067259788513
decider.lstm.bias_hh_l0: 0.013640763238072395 0.15352097153663635
decider.linear1.weight: 0.004099398851394653 0.1196458488702774
decider.linear1.bias: 0.005799493286758661 0.11548323184251785
decider.linear2.weight: 0.0019008847884833813 0.05229096859693527
decider.linear2.bias: 0.0008580415742471814 0.051581427454948425
decider.linear3.weight: -0.0014770354609936476 0.05451790988445282
decider.linear3.bias: -0.015832193195819855 0.034611430019140244

Rewards:
65.8452
65.8452
65.8452
objective = 1.2008682489395142
==== episode 8200/75000 ====
action = 0
probs = 0.9939 0.0034 0.0022 0.0005

action = 0
probs = 0.9881 0.0027 0.0083 0.0009

action = 2
probs = 0.0180 0.0051 0.9706 0.0063

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013549545546993613 0.0828268826007843
encoder.encoder.weight_hh_l0: -0.0006569828256033361 0.08474865555763245
encoder.encoder.bias_ih_l0: 0.004824419505894184 0.0875505656003952
encoder.encoder.bias_hh_l0: 0.01789640262722969 0.08624573796987534
encoder.encoder.weight_ih_l0_reverse: 0.0019633304327726364 0.08444719016551971
encoder.encoder.weight_hh_l0_reverse: 0.000344493193551898 0.08406750857830048
encoder.encoder.bias_ih_l0_reverse: 0.015220386907458305 0.08211828768253326
encoder.encoder.bias_hh_l0_reverse: 0.015515024773776531 0.08723533898591995
decider.lstm.weight_ih_l0: -0.0013571796007454395 0.14623026549816132
decider.lstm.weight_hh_l0: 0.0010647198650985956 0.1460503190755844
decider.lstm.bias_ih_l0: -0.022527378052473068 0.14126946032047272
decider.lstm.bias_hh_l0: 0.013293485157191753 0.1537216454744339
decider.linear1.weight: 0.004112315364181995 0.11961731314659119
decider.linear1.bias: 0.005806758068501949 0.11550871282815933
decider.linear2.weight: 0.0019216033397242427 0.052304841578006744
decider.linear2.bias: 0.0008717666496522725 0.05159762501716614
decider.linear3.weight: -0.001489152666181326 0.054525043815374374
decider.linear3.bias: -0.01584498956799507 0.03479496389627457

Rewards:
65.8452
65.8452
65.8452
objective = 1.051093339920044
==== episode 8300/75000 ====
action = 0
probs = 0.9940 0.0034 0.0021 0.0005

action = 0
probs = 0.9896 0.0024 0.0072 0.0008

action = 0
probs = 0.0223 0.0051 0.9659 0.0067

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013450986007228494 0.08282379060983658
encoder.encoder.weight_hh_l0: -0.0006548232631757855 0.08474697917699814
encoder.encoder.bias_ih_l0: 0.004802504554390907 0.08755699545145035
encoder.encoder.bias_hh_l0: 0.017874490469694138 0.08624351769685745
encoder.encoder.weight_ih_l0_reverse: 0.0019582295790314674 0.08444329351186752
encoder.encoder.weight_hh_l0_reverse: 0.000343886116752401 0.08406829088926315
encoder.encoder.bias_ih_l0_reverse: 0.015210224315524101 0.08211267739534378
encoder.encoder.bias_hh_l0_reverse: 0.015504863113164902 0.08722153306007385
decider.lstm.weight_ih_l0: -0.0013589009176939726 0.14622974395751953
decider.lstm.weight_hh_l0: 0.0010390582028776407 0.14605045318603516
decider.lstm.bias_ih_l0: -0.022601202130317688 0.14126934111118317
decider.lstm.bias_hh_l0: 0.013219664804637432 0.15375494956970215
decider.linear1.weight: 0.004104636609554291 0.11960579454898834
decider.linear1.bias: 0.005801118910312653 0.11552352458238602
decider.linear2.weight: 0.0019328915514051914 0.0523030124604702
decider.linear2.bias: 0.0008888658485375345 0.05160736292600632
decider.linear3.weight: -0.001503043225966394 0.05452432855963707
decider.linear3.bias: -0.015851296484470367 0.03482760861515999

Rewards:
56.1059
56.1059
56.1059
objective = 71.43096923828125
==== episode 8400/75000 ====
action = 0
probs = 0.9912 0.0051 0.0029 0.0007

action = 0
probs = 0.9849 0.0034 0.0107 0.0011

action = 2
probs = 0.0186 0.0045 0.9705 0.0064

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013331457739695907 0.08277180790901184
encoder.encoder.weight_hh_l0: -0.0006435693358071148 0.08466137945652008
encoder.encoder.bias_ih_l0: 0.0044324323534965515 0.08744031935930252
encoder.encoder.bias_hh_l0: 0.01750442013144493 0.08614467829465866
encoder.encoder.weight_ih_l0_reverse: 0.0019300490384921432 0.08438723534345627
encoder.encoder.weight_hh_l0_reverse: 0.00035522101097740233 0.08397036790847778
encoder.encoder.bias_ih_l0_reverse: 0.014875384978950024 0.08204159140586853
encoder.encoder.bias_hh_l0_reverse: 0.01517002284526825 0.0871284008026123
decider.lstm.weight_ih_l0: -0.0013486567186191678 0.1461898684501648
decider.lstm.weight_hh_l0: 0.001025502453558147 0.14598599076271057
decider.lstm.bias_ih_l0: -0.02277194708585739 0.1412866711616516
decider.lstm.bias_hh_l0: 0.01304893009364605 0.15367206931114197
decider.linear1.weight: 0.0040772841311991215 0.11956026405096054
decider.linear1.bias: 0.005640826188027859 0.11549456417560577
decider.linear2.weight: 0.0018955741543322802 0.05228268727660179
decider.linear2.bias: 0.0008362613734789193 0.05160228908061981
decider.linear3.weight: -0.0014946951996535063 0.05447390675544739
decider.linear3.bias: -0.015828296542167664 0.03473951667547226

Rewards:
65.8452
65.8452
65.8452
objective = 1.1834964752197266
==== episode 8500/75000 ====
action = 0
probs = 0.9932 0.0040 0.0023 0.0005

action = 0
probs = 0.9877 0.0027 0.0087 0.0009

action = 2
probs = 0.0169 0.0043 0.9725 0.0062

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0013673545327037573 0.08282013237476349
encoder.encoder.weight_hh_l0: -0.000655443815048784 0.08472444117069244
encoder.encoder.bias_ih_l0: 0.004671874456107616 0.08750608563423157
encoder.encoder.bias_hh_l0: 0.01774386316537857 0.08621109277009964
encoder.encoder.weight_ih_l0_reverse: 0.001964229391887784 0.08443763852119446
encoder.encoder.weight_hh_l0_reverse: 0.000352875649696216 0.08403905481100082
encoder.encoder.bias_ih_l0_reverse: 0.015092643909156322 0.08209593594074249
encoder.encoder.bias_hh_l0_reverse: 0.015387279912829399 0.08719735592603683
decider.lstm.weight_ih_l0: -0.0013484425144270062 0.14621929824352264
decider.lstm.weight_hh_l0: 0.001047420664690435 0.14602553844451904
decider.lstm.bias_ih_l0: -0.022609679028391838 0.14128831028938293
decider.lstm.bias_hh_l0: 0.013211194425821304 0.15369825065135956
decider.linear1.weight: 0.004119255114346743 0.1196112260222435
decider.linear1.bias: 0.005799552425742149 0.11551262438297272
decider.linear2.weight: 0.0019218053203076124 0.05231286212801933
decider.linear2.bias: 0.0008782852673903108 0.05160439386963844
decider.linear3.weight: -0.0015152236446738243 0.05455061420798302
decider.linear3.bias: -0.015841063112020493 0.03476853668689728

Rewards:
65.8452
65.8452
65.8452
objective = 1.0341318845748901
==== episode 8600/75000 ====
action = 0
probs = 0.9909 0.0044 0.0039 0.0007

action = 0
probs = 0.9633 0.0042 0.0306 0.0018

action = 2
probs = 0.0080 0.0028 0.9845 0.0047

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014425262343138456 0.08285921812057495
encoder.encoder.weight_hh_l0: -0.000674401584547013 0.08478172868490219
encoder.encoder.bias_ih_l0: 0.004873158875852823 0.08745209872722626
encoder.encoder.bias_hh_l0: 0.017945148050785065 0.08628211915493011
encoder.encoder.weight_ih_l0_reverse: 0.0019826553761959076 0.08445730060338974
encoder.encoder.weight_hh_l0_reverse: 0.0003656961489468813 0.08401697874069214
encoder.encoder.bias_ih_l0_reverse: 0.015027961693704128 0.08208546042442322
encoder.encoder.bias_hh_l0_reverse: 0.015322600491344929 0.08730103075504303
decider.lstm.weight_ih_l0: -0.0013261416461318731 0.14624467492103577
decider.lstm.weight_hh_l0: 0.0012106808135285974 0.1460203379392624
decider.lstm.bias_ih_l0: -0.022041257470846176 0.14137305319309235
decider.lstm.bias_hh_l0: 0.013779617846012115 0.15348097681999207
decider.linear1.weight: 0.00415231566876173 0.11965806037187576
decider.linear1.bias: 0.005886404775083065 0.11543898284435272
decider.linear2.weight: 0.001924054929986596 0.05230608582496643
decider.linear2.bias: 0.0008749954868108034 0.051563411951065063
decider.linear3.weight: -0.001519021112471819 0.05452838912606239
decider.linear3.bias: -0.01584572158753872 0.034453947097063065

Rewards:
65.8452
65.8452
65.8452
objective = 1.3639219999313354
==== episode 8700/75000 ====
action = 0
probs = 0.9939 0.0029 0.0027 0.0005

action = 0
probs = 0.9743 0.0028 0.0217 0.0012

action = 2
probs = 0.0081 0.0024 0.9856 0.0040

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015007492620497942 0.08294945955276489
encoder.encoder.weight_hh_l0: -0.0006860282737761736 0.08493190258741379
encoder.encoder.bias_ih_l0: 0.005406350828707218 0.08755214512348175
encoder.encoder.bias_hh_l0: 0.01847834326326847 0.08640201389789581
encoder.encoder.weight_ih_l0_reverse: 0.002036797348409891 0.08454322069883347
encoder.encoder.weight_hh_l0_reverse: 0.00035247771302238107 0.0841514840722084
encoder.encoder.bias_ih_l0_reverse: 0.015429438091814518 0.08215544372797012
encoder.encoder.bias_hh_l0_reverse: 0.015724074095487595 0.08744168281555176
decider.lstm.weight_ih_l0: -0.0013257244136184454 0.1463032364845276
decider.lstm.weight_hh_l0: 0.001370340003632009 0.14608873426914215
decider.lstm.bias_ih_l0: -0.021687673404812813 0.14132189750671387
decider.lstm.bias_hh_l0: 0.014133203774690628 0.15355606377124786
decider.linear1.weight: 0.004273824393749237 0.11975589394569397
decider.linear1.bias: 0.006222114898264408 0.11546730250120163
decider.linear2.weight: 0.002010494004935026 0.052357204258441925
decider.linear2.bias: 0.0010142181999981403 0.05159440264105797
decider.linear3.weight: -0.0015831936616450548 0.0546472892165184
decider.linear3.bias: -0.01594598963856697 0.034762192517519

Rewards:
65.8452
65.8452
65.8452
objective = 1.021876335144043
==== episode 8800/75000 ====
action = 0
probs = 0.9958 0.0020 0.0019 0.0003

action = 0
probs = 0.9844 0.0017 0.0131 0.0007

action = 2
probs = 0.0123 0.0025 0.9812 0.0041

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001525940839201212 0.0829915925860405
encoder.encoder.weight_hh_l0: -0.0006953631527721882 0.08499754965305328
encoder.encoder.bias_ih_l0: 0.00567697174847126 0.08762718737125397
encoder.encoder.bias_hh_l0: 0.018748965114355087 0.08647597581148148
encoder.encoder.weight_ih_l0_reverse: 0.0020696597639471292 0.08459413796663284
encoder.encoder.weight_hh_l0_reverse: 0.0003457366256043315 0.08423533290624619
encoder.encoder.bias_ih_l0_reverse: 0.01568332314491272 0.08218418061733246
encoder.encoder.bias_hh_l0_reverse: 0.015977958217263222 0.08750651031732559
decider.lstm.weight_ih_l0: -0.0013284455053508282 0.14633896946907043
decider.lstm.weight_hh_l0: 0.0014216514537110925 0.14613081514835358
decider.lstm.bias_ih_l0: -0.021577749401330948 0.14129577577114105
decider.lstm.bias_hh_l0: 0.01424312312155962 0.1536450833082199
decider.linear1.weight: 0.00433739647269249 0.11979354172945023
decider.linear1.bias: 0.006379480008035898 0.11549481004476547
decider.linear2.weight: 0.0020705326460301876 0.052377160638570786
decider.linear2.bias: 0.0010921333450824022 0.05162828415632248
decider.linear3.weight: -0.0016351358499377966 0.054690323770046234
decider.linear3.bias: -0.016039766371250153 0.03512899577617645

Rewards:
65.8452
65.8452
65.8452
objective = 0.8542183637619019
==== episode 8900/75000 ====
action = 0
probs = 0.9952 0.0022 0.0023 0.0004

action = 0
probs = 0.9864 0.0017 0.0113 0.0007

action = 2
probs = 0.0121 0.0028 0.9805 0.0045

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014764305669814348 0.08294615894556046
encoder.encoder.weight_hh_l0: -0.0006830602651461959 0.0849141776561737
encoder.encoder.bias_ih_l0: 0.005317517556250095 0.0875808447599411
encoder.encoder.bias_hh_l0: 0.018389509990811348 0.08636397123336792
encoder.encoder.weight_ih_l0_reverse: 0.0020379831548780203 0.08454721421003342
encoder.encoder.weight_hh_l0_reverse: 0.0003471330273896456 0.08416803926229477
encoder.encoder.bias_ih_l0_reverse: 0.015462979674339294 0.08216511458158493
encoder.encoder.bias_hh_l0_reverse: 0.015757614746689796 0.08738354593515396
decider.lstm.weight_ih_l0: -0.001336198067292571 0.1462954580783844
decider.lstm.weight_hh_l0: 0.0012828063918277621 0.14608921110630035
decider.lstm.bias_ih_l0: -0.021989375352859497 0.14128455519676208
decider.lstm.bias_hh_l0: 0.01383149717003107 0.15364202857017517
decider.linear1.weight: 0.00426805904135108 0.11973866820335388
decider.linear1.bias: 0.006174136884510517 0.11555340141057968
decider.linear2.weight: 0.0019949781708419323 0.05237136781215668
decider.linear2.bias: 0.0010129346046596766 0.05160713568329811
decider.linear3.weight: -0.0016268726903945208 0.05468055233359337
decider.linear3.bias: -0.016012202948331833 0.03502848371863365

Rewards:
65.8452
65.8452
65.8452
objective = 0.8381540775299072
==== episode 9000/75000 ====
action = 0
probs = 0.9968 0.0015 0.0015 0.0002

action = 0
probs = 0.9921 0.0010 0.0064 0.0004

action = 2
probs = 0.0167 0.0028 0.9760 0.0045

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015102680772542953 0.08300311863422394
encoder.encoder.weight_hh_l0: -0.0006910038646310568 0.08500257879495621
encoder.encoder.bias_ih_l0: 0.00565553642809391 0.08766603469848633
encoder.encoder.bias_hh_l0: 0.01872752606868744 0.08644264936447144
encoder.encoder.weight_ih_l0_reverse: 0.0020713210105895996 0.08460459858179092
encoder.encoder.weight_hh_l0_reverse: 0.0003438266576267779 0.08425857126712799
encoder.encoder.bias_ih_l0_reverse: 0.01575358584523201 0.08219926804304123
encoder.encoder.bias_hh_l0_reverse: 0.016048220917582512 0.08745882660150528
decider.lstm.weight_ih_l0: -0.00133498664945364 0.14633440971374512
decider.lstm.weight_hh_l0: 0.0013279528357088566 0.14614377915859222
decider.lstm.bias_ih_l0: -0.02182915061712265 0.14122885465621948
decider.lstm.bias_hh_l0: 0.013991722837090492 0.153723806142807
decider.linear1.weight: 0.00432027829810977 0.11979486048221588
decider.linear1.bias: 0.006367932073771954 0.1155906617641449
decider.linear2.weight: 0.0020541255362331867 0.0524030365049839
decider.linear2.bias: 0.0011018066434189677 0.051644496619701385
decider.linear3.weight: -0.001674850471317768 0.054764408618211746
decider.linear3.bias: -0.016090741381049156 0.035333629697561264

Rewards:
65.8452
65.8452
65.8452
objective = 0.778436541557312
==== episode 9100/75000 ====
action = 0
probs = 0.9974 0.0012 0.0012 0.0002

action = 0
probs = 0.9937 0.0009 0.0050 0.0003

action = 2
probs = 0.0145 0.0029 0.9787 0.0039

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015416222158819437 0.08305417001247406
encoder.encoder.weight_hh_l0: -0.0006977472803555429 0.085081085562706
encoder.encoder.bias_ih_l0: 0.0059228441677987576 0.08771894127130508
encoder.encoder.bias_hh_l0: 0.018994834274053574 0.08649557828903198
encoder.encoder.weight_ih_l0_reverse: 0.0020986045710742474 0.0846494659781456
encoder.encoder.weight_hh_l0_reverse: 0.0003431066870689392 0.08432433754205704
encoder.encoder.bias_ih_l0_reverse: 0.015974750742316246 0.0822356566786766
encoder.encoder.bias_hh_l0_reverse: 0.016269385814666748 0.08753382414579391
decider.lstm.weight_ih_l0: -0.0013318753335624933 0.14636196196079254
decider.lstm.weight_hh_l0: 0.0013836933067068458 0.14617976546287537
decider.lstm.bias_ih_l0: -0.02164299041032791 0.1412029266357422
decider.lstm.bias_hh_l0: 0.014177875593304634 0.15374356508255005
decider.linear1.weight: 0.0043680607341229916 0.11985556036233902
decider.linear1.bias: 0.0065439920872449875 0.11561769992113113
decider.linear2.weight: 0.0020886745769530535 0.052437517791986465
decider.linear2.bias: 0.0011660187738016248 0.051671963185071945
decider.linear3.weight: -0.0016993768513202667 0.05485973507165909
decider.linear3.bias: -0.016127265989780426 0.035559024661779404

Rewards:
65.8452
65.8452
65.8452
objective = 0.6660050749778748
==== episode 9200/75000 ====
action = 0
probs = 0.9980 0.0009 0.0009 0.0001

action = 0
probs = 0.9950 0.0007 0.0041 0.0003

action = 2
probs = 0.0139 0.0024 0.9804 0.0033

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015805428847670555 0.0831139013171196
encoder.encoder.weight_hh_l0: -0.0007016993477009237 0.08519265800714493
encoder.encoder.bias_ih_l0: 0.00629978533834219 0.08777479827404022
encoder.encoder.bias_hh_l0: 0.019371777772903442 0.08656208217144012
encoder.encoder.weight_ih_l0_reverse: 0.002119797980412841 0.08469577878713608
encoder.encoder.weight_hh_l0_reverse: 0.0003421837172936648 0.08439310640096664
encoder.encoder.bias_ih_l0_reverse: 0.016201991587877274 0.08225885778665543
encoder.encoder.bias_hh_l0_reverse: 0.016496628522872925 0.08762288838624954
decider.lstm.weight_ih_l0: -0.0013265532907098532 0.14639846980571747
decider.lstm.weight_hh_l0: 0.0014699442544952035 0.14622332155704498
decider.lstm.bias_ih_l0: -0.021393656730651855 0.14114908874034882
decider.lstm.bias_hh_l0: 0.014427213929593563 0.15376460552215576
decider.linear1.weight: 0.004430751316249371 0.11993224173784256
decider.linear1.bias: 0.006774389185011387 0.11564552038908005
decider.linear2.weight: 0.002149995882064104 0.052475955337285995
decider.linear2.bias: 0.0012459727004170418 0.05169684812426567
decider.linear3.weight: -0.0017483639530837536 0.054962724447250366
decider.linear3.bias: -0.016206596046686172 0.03579510375857353

Rewards:
65.8452
65.8452
65.8452
objective = 0.5875108242034912
==== episode 9300/75000 ====
action = 0
probs = 0.9980 0.0009 0.0009 0.0001

action = 0
probs = 0.9974 0.0005 0.0020 0.0002

action = 2
probs = 0.0386 0.0041 0.9526 0.0047

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015280770603567362 0.08304343372583389
encoder.encoder.weight_hh_l0: -0.000695343769621104 0.08507292717695236
encoder.encoder.bias_ih_l0: 0.0059536355547606945 0.0877641811966896
encoder.encoder.bias_hh_l0: 0.01902562566101551 0.08647780865430832
encoder.encoder.weight_ih_l0_reverse: 0.002094576833769679 0.08464279770851135
encoder.encoder.weight_hh_l0_reverse: 0.0003403744485694915 0.08432920277118683
encoder.encoder.bias_ih_l0_reverse: 0.015993088483810425 0.08220379799604416
encoder.encoder.bias_hh_l0_reverse: 0.016287729144096375 0.0874776616692543
decider.lstm.weight_ih_l0: -0.0013393182307481766 0.1463625729084015
decider.lstm.weight_hh_l0: 0.0013228568714112043 0.14619918167591095
decider.lstm.bias_ih_l0: -0.021861586719751358 0.14112766087055206
decider.lstm.bias_hh_l0: 0.013959286734461784 0.1538667231798172
decider.linear1.weight: 0.004399711731821299 0.11990838497877121
decider.linear1.bias: 0.006673417054116726 0.11540060490369797
decider.linear2.weight: 0.002132549649104476 0.05253693461418152
decider.linear2.bias: 0.0011186636984348297 0.05172665789723396
decider.linear3.weight: -0.001751320669427514 0.054824672639369965
decider.linear3.bias: -0.0162445530295372 0.03624969348311424

Rewards:
65.8452
65.8452
65.8452
objective = 1.1678003072738647
==== episode 9400/75000 ====
action = 0
probs = 0.9984 0.0007 0.0007 0.0001

action = 0
probs = 0.9981 0.0004 0.0014 0.0001

action = 2
probs = 0.0396 0.0048 0.9501 0.0055

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001523136510513723 0.08303628116846085
encoder.encoder.weight_hh_l0: -0.0007016526651568711 0.08503623306751251
encoder.encoder.bias_ih_l0: 0.005842938087880611 0.08777138590812683
encoder.encoder.bias_hh_l0: 0.018914928659796715 0.08648177236318588
encoder.encoder.weight_ih_l0_reverse: 0.0021038660779595375 0.08464685827493668
encoder.encoder.weight_hh_l0_reverse: 0.00034258721279911697 0.08433341979980469
encoder.encoder.bias_ih_l0_reverse: 0.016003785654902458 0.082211434841156
encoder.encoder.bias_hh_l0_reverse: 0.01629842258989811 0.08745308965444565
decider.lstm.weight_ih_l0: -0.0013419152237474918 0.14635689556598663
decider.lstm.weight_hh_l0: 0.0012812769273295999 0.14619778096675873
decider.lstm.bias_ih_l0: -0.021948982030153275 0.14113958179950714
decider.lstm.bias_hh_l0: 0.013871898874640465 0.1538771688938141
decider.linear1.weight: 0.004401512444019318 0.11993186920881271
decider.linear1.bias: 0.006679086945950985 0.11528442054986954
decider.linear2.weight: 0.002160341013222933 0.052660465240478516
decider.linear2.bias: 0.0010792880784720182 0.051725104451179504
decider.linear3.weight: -0.0017296599689871073 0.054824378341436386
decider.linear3.bias: -0.01617988757789135 0.03611709922552109

Rewards:
65.8452
65.8452
65.8452
objective = 1.1987667083740234
==== episode 9500/75000 ====
action = 0
probs = 0.9987 0.0006 0.0006 0.0001

action = 0
probs = 0.9984 0.0003 0.0012 0.0001

action = 2
probs = 0.0256 0.0037 0.9660 0.0048

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015447669429704547 0.08307480067014694
encoder.encoder.weight_hh_l0: -0.0007059871568344533 0.08508818596601486
encoder.encoder.bias_ih_l0: 0.005978678818792105 0.08778820186853409
encoder.encoder.bias_hh_l0: 0.01905066892504692 0.08652912080287933
encoder.encoder.weight_ih_l0_reverse: 0.0021190668921917677 0.08467508852481842
encoder.encoder.weight_hh_l0_reverse: 0.0003441136213950813 0.08436555415391922
encoder.encoder.bias_ih_l0_reverse: 0.016103610396385193 0.08224359899759293
encoder.encoder.bias_hh_l0_reverse: 0.016398251056671143 0.08751820027828217
decider.lstm.weight_ih_l0: -0.001336918561719358 0.1463734209537506
decider.lstm.weight_hh_l0: 0.0013204626739025116 0.14620764553546906
decider.lstm.bias_ih_l0: -0.021762199699878693 0.1411585956811905
decider.lstm.bias_hh_l0: 0.014058680273592472 0.15381985902786255
decider.linear1.weight: 0.004431949462741613 0.1200108453631401
decider.linear1.bias: 0.006854684092104435 0.11521651595830917
decider.linear2.weight: 0.0022336081601679325 0.05278914049267769
decider.linear2.bias: 0.001144643290899694 0.051701392978429794
decider.linear3.weight: -0.0017454051412642002 0.054909005761146545
decider.linear3.bias: -0.01618172414600849 0.03584275022149086

Rewards:
65.8452
65.8452
65.8452
objective = 0.8246707320213318
==== episode 9600/75000 ====
action = 0
probs = 0.9986 0.0006 0.0007 0.0001

action = 0
probs = 0.9977 0.0003 0.0018 0.0001

action = 2
probs = 0.0170 0.0027 0.9768 0.0035

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015558602754026651 0.0830853208899498
encoder.encoder.weight_hh_l0: -0.0007034780574031174 0.08510899543762207
encoder.encoder.bias_ih_l0: 0.006012053228914738 0.08776687830686569
encoder.encoder.bias_hh_l0: 0.01908404380083084 0.08653342723846436
encoder.encoder.weight_ih_l0_reverse: 0.0021175220608711243 0.08468379825353622
encoder.encoder.weight_hh_l0_reverse: 0.00034500000765547156 0.08435378223657608
encoder.encoder.bias_ih_l0_reverse: 0.01603403128683567 0.08226540684700012
encoder.encoder.bias_hh_l0_reverse: 0.01632867380976677 0.08752679824829102
decider.lstm.weight_ih_l0: -0.001334065804257989 0.14638322591781616
decider.lstm.weight_hh_l0: 0.0013351795496419072 0.1462019830942154
decider.lstm.bias_ih_l0: -0.02168930135667324 0.14118976891040802
decider.lstm.bias_hh_l0: 0.014131576754152775 0.15374895930290222
decider.linear1.weight: 0.004449279513210058 0.12005306035280228
decider.linear1.bias: 0.006966216489672661 0.11519407480955124
decider.linear2.weight: 0.002266919706016779 0.05285927280783653
decider.linear2.bias: 0.0011735110310837626 0.051697514951229095
decider.linear3.weight: -0.0017886403948068619 0.05492950603365898
decider.linear3.bias: -0.016275491565465927 0.03593339025974274

Rewards:
65.8452
65.8452
65.8452
objective = 0.5972634553909302
==== episode 9700/75000 ====
action = 0
probs = 0.9987 0.0005 0.0007 0.0001

action = 0
probs = 0.9976 0.0003 0.0020 0.0001

action = 2
probs = 0.0114 0.0022 0.9832 0.0033

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015830803895369172 0.08313137292861938
encoder.encoder.weight_hh_l0: -0.0007054779562167823 0.08517300337553024
encoder.encoder.bias_ih_l0: 0.006199939642101526 0.0877976343035698
encoder.encoder.bias_hh_l0: 0.019271928817033768 0.08658895641565323
encoder.encoder.weight_ih_l0_reverse: 0.0021337741054594517 0.08471370488405228
encoder.encoder.weight_hh_l0_reverse: 0.00034533784491941333 0.08439525216817856
encoder.encoder.bias_ih_l0_reverse: 0.01617301255464554 0.08229144662618637
encoder.encoder.bias_hh_l0_reverse: 0.016467656940221786 0.08760621398687363
decider.lstm.weight_ih_l0: -0.001326745841652155 0.14640139043331146
decider.lstm.weight_hh_l0: 0.0013985377736389637 0.1462184190750122
decider.lstm.bias_ih_l0: -0.02146740071475506 0.14119790494441986
decider.lstm.bias_hh_l0: 0.014353489503264427 0.15370908379554749
decider.linear1.weight: 0.004480371251702309 0.12010512501001358
decider.linear1.bias: 0.007096205372363329 0.11518105864524841
decider.linear2.weight: 0.0022967003751546144 0.05289130657911301
decider.linear2.bias: 0.0012256298214197159 0.05167682468891144
decider.linear3.weight: -0.001795392483472824 0.05500897765159607
decider.linear3.bias: -0.016246138140559196 0.03560057654976845

Rewards:
65.8452
65.8452
65.8452
objective = 0.45326969027519226
==== episode 9800/75000 ====
action = 0
probs = 0.9989 0.0004 0.0006 0.0001

action = 0
probs = 0.9979 0.0003 0.0017 0.0001

action = 2
probs = 0.0098 0.0018 0.9858 0.0027

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016221209662035108 0.08319395035505295
encoder.encoder.weight_hh_l0: -0.0007049238192848861 0.08528520911931992
encoder.encoder.bias_ih_l0: 0.0065714833326637745 0.08784136921167374
encoder.encoder.bias_hh_l0: 0.019643470644950867 0.08666595816612244
encoder.encoder.weight_ih_l0_reverse: 0.002151052001863718 0.08475564420223236
encoder.encoder.weight_hh_l0_reverse: 0.00034393873647786677 0.08445984125137329
encoder.encoder.bias_ih_l0_reverse: 0.016387997195124626 0.08230587095022202
encoder.encoder.bias_hh_l0_reverse: 0.016682637855410576 0.08772111684083939
decider.lstm.weight_ih_l0: -0.0013167932629585266 0.14643454551696777
decider.lstm.weight_hh_l0: 0.0015178227331489325 0.1462586522102356
decider.lstm.bias_ih_l0: -0.02113162912428379 0.1411563754081726
decider.lstm.bias_hh_l0: 0.014689254574477673 0.15371198952198029
decider.linear1.weight: 0.004535790998488665 0.12017557770013809
decider.linear1.bias: 0.007308466825634241 0.11519598960876465
decider.linear2.weight: 0.002350240247324109 0.05292629823088646
decider.linear2.bias: 0.0013147006975486875 0.051697440445423126
decider.linear3.weight: -0.001836778363212943 0.05509502440690994
decider.linear3.bias: -0.016319189220666885 0.03576517850160599

Rewards:
65.8452
65.8452
65.8452
objective = 0.3832370638847351
==== episode 9900/75000 ====
action = 0
probs = 0.9991 0.0004 0.0005 0.0001

action = 0
probs = 0.9985 0.0002 0.0011 0.0001

action = 0
probs = 0.0181 0.0027 0.9738 0.0054

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015739258378744125 0.08312227576971054
encoder.encoder.weight_hh_l0: -0.0007147185388021171 0.08512415736913681
encoder.encoder.bias_ih_l0: 0.006079919170588255 0.0878470316529274
encoder.encoder.bias_hh_l0: 0.01915190927684307 0.08661499619483948
encoder.encoder.weight_ih_l0_reverse: 0.002150308107957244 0.08472053706645966
encoder.encoder.weight_hh_l0_reverse: 0.0003469346556812525 0.08442143350839615
encoder.encoder.bias_ih_l0_reverse: 0.016254587098956108 0.08228541165590286
encoder.encoder.bias_hh_l0_reverse: 0.016549227759242058 0.08756989985704422
decider.lstm.weight_ih_l0: -0.0013324965257197618 0.14640019834041595
decider.lstm.weight_hh_l0: 0.0013139896327629685 0.14622192084789276
decider.lstm.bias_ih_l0: -0.02166876569390297 0.1412164717912674
decider.lstm.bias_hh_l0: 0.014152119867503643 0.15378376841545105
decider.linear1.weight: 0.0044630905613303185 0.12006298452615738
decider.linear1.bias: 0.006973079405725002 0.11515583097934723
decider.linear2.weight: 0.0022772077936679125 0.05290435254573822
decider.linear2.bias: 0.001167863723821938 0.0516553558409214
decider.linear3.weight: -0.0017815602477639914 0.05499332398176193
decider.linear3.bias: -0.01612766832113266 0.03506850823760033

Rewards:
56.1059
56.1059
56.1059
objective = 75.04753112792969
==== episode 10000/75000 ====
action = 0
probs = 0.9992 0.0003 0.0004 0.0001

action = 0
probs = 0.9987 0.0002 0.0010 0.0001

action = 2
probs = 0.0170 0.0023 0.9756 0.0050

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015999984461814165 0.08316576480865479
encoder.encoder.weight_hh_l0: -0.0007170577882789075 0.08519420027732849
encoder.encoder.bias_ih_l0: 0.00631233723834157 0.08788617700338364
encoder.encoder.bias_hh_l0: 0.019384324550628662 0.08667474240064621
encoder.encoder.weight_ih_l0_reverse: 0.002164067467674613 0.08475137501955032
encoder.encoder.weight_hh_l0_reverse: 0.0003475975536275655 0.08446678519248962
encoder.encoder.bias_ih_l0_reverse: 0.016402969136834145 0.08229992538690567
encoder.encoder.bias_hh_l0_reverse: 0.016697611659765244 0.08764740824699402
decider.lstm.weight_ih_l0: -0.0013262407155707479 0.14642341434955597
decider.lstm.weight_hh_l0: 0.0013700677081942558 0.1462486982345581
decider.lstm.bias_ih_l0: -0.021458875387907028 0.14120317995548248
decider.lstm.bias_hh_l0: 0.014362020418047905 0.15378157794475555
decider.linear1.weight: 0.004492582753300667 0.12010925263166428
decider.linear1.bias: 0.007116908207535744 0.11516112834215164
decider.linear2.weight: 0.002317892387509346 0.052927564829587936
decider.linear2.bias: 0.0012330980971455574 0.05166483297944069
decider.linear3.weight: -0.0018146589864045382 0.05505456030368805
decider.linear3.bias: -0.016180358827114105 0.03512412682175636

Rewards:
65.8452
65.8452
65.8452
objective = 0.5873388051986694
==== episode 10100/75000 ====
action = 0
probs = 0.9992 0.0003 0.0004 0.0001

action = 0
probs = 0.9988 0.0002 0.0009 0.0001

action = 2
probs = 0.0188 0.0030 0.9723 0.0059

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015860780840739608 0.08314725011587143
encoder.encoder.weight_hh_l0: -0.000721028249245137 0.08514153957366943
encoder.encoder.bias_ih_l0: 0.006146288476884365 0.08789073675870895
encoder.encoder.bias_hh_l0: 0.01921827718615532 0.08665980398654938
encoder.encoder.weight_ih_l0_reverse: 0.0021714731119573116 0.08474379032850266
encoder.encoder.weight_hh_l0_reverse: 0.0003501999017316848 0.0844595804810524
encoder.encoder.bias_ih_l0_reverse: 0.016381485387682915 0.08230066299438477
encoder.encoder.bias_hh_l0_reverse: 0.016676129773259163 0.08760911226272583
decider.lstm.weight_ih_l0: -0.001329484861344099 0.14640983939170837
decider.lstm.weight_hh_l0: 0.0013125278055667877 0.1462389975786209
decider.lstm.bias_ih_l0: -0.021599125117063522 0.14123253524303436
decider.lstm.bias_hh_l0: 0.014221771620213985 0.1537976711988449
decider.linear1.weight: 0.00447180587798357 0.12007733434438705
decider.linear1.bias: 0.00700712576508522 0.11514190584421158
decider.linear2.weight: 0.0022942260839045048 0.05292763561010361
decider.linear2.bias: 0.0011781378416344523 0.05165513977408409
decider.linear3.weight: -0.0017833646852523088 0.05502941831946373
decider.linear3.bias: -0.01609686203300953 0.035036757588386536

Rewards:
65.8452
65.8452
65.8452
objective = 0.6592679023742676
==== episode 10200/75000 ====
action = 0
probs = 0.9993 0.0003 0.0004 0.0001

action = 0
probs = 0.9987 0.0002 0.0010 0.0001

action = 2
probs = 0.0117 0.0022 0.9810 0.0051

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016146558336913586 0.08319669961929321
encoder.encoder.weight_hh_l0: -0.0007236573728732765 0.08521481603384018
encoder.encoder.bias_ih_l0: 0.006358837243169546 0.08791543543338776
encoder.encoder.bias_hh_l0: 0.019430825486779213 0.08671624213457108
encoder.encoder.weight_ih_l0_reverse: 0.0021843702998012304 0.08477352559566498
encoder.encoder.weight_hh_l0_reverse: 0.0003524608910083771 0.0844963863492012
encoder.encoder.bias_ih_l0_reverse: 0.016505001112818718 0.08232855796813965
encoder.encoder.bias_hh_l0_reverse: 0.016799641773104668 0.08769878000020981
decider.lstm.weight_ih_l0: -0.0013204347342252731 0.146429181098938
decider.lstm.weight_hh_l0: 0.001384264905937016 0.14625297486782074
decider.lstm.bias_ih_l0: -0.021332411095499992 0.14124852418899536
decider.lstm.bias_hh_l0: 0.014488481916487217 0.1537415236234665
decider.linear1.weight: 0.004501380957663059 0.12013843655586243
decider.linear1.bias: 0.007160784676671028 0.11513371765613556
decider.linear2.weight: 0.002332191215828061 0.05295785516500473
decider.linear2.bias: 0.0012443533632904291 0.051637452095746994
decider.linear3.weight: -0.0018059485591948032 0.055118970572948456
decider.linear3.bias: -0.01611359976232052 0.03475615382194519

Rewards:
65.8452
65.8452
65.8452
objective = 0.4652724266052246
==== episode 10300/75000 ====
action = 0
probs = 0.9988 0.0005 0.0006 0.0001

action = 0
probs = 0.9982 0.0003 0.0014 0.0001

action = 2
probs = 0.0129 0.0030 0.9778 0.0063

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015244235983118415 0.0830700546503067
encoder.encoder.weight_hh_l0: -0.0007151979953050613 0.08501583337783813
encoder.encoder.bias_ih_l0: 0.00561000918969512 0.087774857878685
encoder.encoder.bias_hh_l0: 0.018681997433304787 0.08650065213441849
encoder.encoder.weight_ih_l0_reverse: 0.0021359508391469717 0.08467361330986023
encoder.encoder.weight_hh_l0_reverse: 0.0003470660012681037 0.08434678614139557
encoder.encoder.bias_ih_l0_reverse: 0.01600617915391922 0.08229084312915802
encoder.encoder.bias_hh_l0_reverse: 0.016300823539495468 0.08745713531970978
decider.lstm.weight_ih_l0: -0.0013405841309577227 0.14635244011878967
decider.lstm.weight_hh_l0: 0.0011845298577100039 0.14615827798843384
decider.lstm.bias_ih_l0: -0.02201954647898674 0.14129824936389923
decider.lstm.bias_hh_l0: 0.013801351189613342 0.15371526777744293
decider.linear1.weight: 0.0043905084021389484 0.12001016736030579
decider.linear1.bias: 0.0067070601508021355 0.11515464633703232
decider.linear2.weight: 0.002209632657468319 0.05291217938065529
decider.linear2.bias: 0.001065243617631495 0.051600344479084015
decider.linear3.weight: -0.001771625131368637 0.05498874559998512
decider.linear3.bias: -0.016021257266402245 0.03456706553697586

Rewards:
65.8452
65.8452
65.8452
objective = 0.5562463998794556
==== episode 10400/75000 ====
action = 0
probs = 0.9991 0.0004 0.0005 0.0001

action = 0
probs = 0.9986 0.0002 0.0010 0.0001

action = 2
probs = 0.0162 0.0030 0.9739 0.0068

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015340077225118876 0.08309026807546616
encoder.encoder.weight_hh_l0: -0.0007198635139502585 0.08503402024507523
encoder.encoder.bias_ih_l0: 0.0056958929635584354 0.08781395852565765
encoder.encoder.bias_hh_l0: 0.01876787655055523 0.08654769510030746
encoder.encoder.weight_ih_l0_reverse: 0.002148723229765892 0.08469414710998535
encoder.encoder.weight_hh_l0_reverse: 0.0003489101363811642 0.08438405394554138
encoder.encoder.bias_ih_l0_reverse: 0.016118956729769707 0.08229617029428482
encoder.encoder.bias_hh_l0_reverse: 0.016413597390055656 0.08748946338891983
decider.lstm.weight_ih_l0: -0.001339090638794005 0.14636953175067902
decider.lstm.weight_hh_l0: 0.0011883482802659273 0.14617827534675598
decider.lstm.bias_ih_l0: -0.021963492035865784 0.14129744470119476
decider.lstm.bias_hh_l0: 0.013857399113476276 0.15374094247817993
decider.linear1.weight: 0.004402009770274162 0.12002130597829819
decider.linear1.bias: 0.006760371848940849 0.11516010761260986
decider.linear2.weight: 0.0022366358898580074 0.0529252253472805
decider.linear2.bias: 0.0011001310776919127 0.05161197856068611
decider.linear3.weight: -0.0017953430069610476 0.05501344054937363
decider.linear3.bias: -0.01605008915066719 0.03462834656238556

Rewards:
65.8452
65.8452
65.8452
objective = 0.6315655708312988
==== episode 10500/75000 ====
action = 0
probs = 0.9992 0.0003 0.0004 0.0001

action = 0
probs = 0.9989 0.0002 0.0009 0.0001

action = 2
probs = 0.0168 0.0026 0.9749 0.0057

Learning rate: 8.0973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001567466533742845 0.08315098285675049
encoder.encoder.weight_hh_l0: -0.000721245538443327 0.08512906730175018
encoder.encoder.bias_ih_l0: 0.00603951420634985 0.08788108080625534
encoder.encoder.bias_hh_l0: 0.019111504778265953 0.08663826435804367
encoder.encoder.weight_ih_l0_reverse: 0.002166857710108161 0.08473888039588928
encoder.encoder.weight_hh_l0_reverse: 0.0003493123222142458 0.0844523087143898
encoder.encoder.bias_ih_l0_reverse: 0.01633501425385475 0.08231297880411148
encoder.encoder.bias_hh_l0_reverse: 0.01662965677678585 0.08759038150310516
decider.lstm.weight_ih_l0: -0.0013296828838065267 0.14640773832798004
decider.lstm.weight_hh_l0: 0.0012593651190400124 0.14622452855110168
decider.lstm.bias_ih_l0: -0.021699246019124985 0.14126503467559814
decider.lstm.bias_hh_l0: 0.014121648855507374 0.15376591682434082
decider.linear1.weight: 0.004443040117621422 0.12007806450128555
decider.linear1.bias: 0.006970677059143782 0.11518576741218567
decider.linear2.weight: 0.002293618395924568 0.05295127257704735
decider.linear2.bias: 0.0011973341461271048 0.05164795741438866
decider.linear3.weight: -0.0018456445541232824 0.05507902428507805
decider.linear3.bias: -0.016164928674697876 0.035008639097213745

Rewards:
65.8452
65.8452
65.8452
objective = 0.5986224412918091
==== episode 10600/75000 ====
action = 0
probs = 0.9993 0.0003 0.0004 0.0001

action = 0
probs = 0.9990 0.0001 0.0008 0.0001

action = 2
probs = 0.0148 0.0023 0.9775 0.0054

Learning rate: 8.0973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001588423503562808 0.08318527042865753
encoder.encoder.weight_hh_l0: -0.0007248028996400535 0.08517856895923615
encoder.encoder.bias_ih_l0: 0.006196756847202778 0.0879121944308281
encoder.encoder.bias_hh_l0: 0.019268745556473732 0.08668863773345947
encoder.encoder.weight_ih_l0_reverse: 0.002176860347390175 0.08476261049509048
encoder.encoder.weight_hh_l0_reverse: 0.0003510761889629066 0.0844813659787178
encoder.encoder.bias_ih_l0_reverse: 0.016428619623184204 0.0823294147849083
encoder.encoder.bias_hh_l0_reverse: 0.016723260283470154 0.08764868229627609
decider.lstm.weight_ih_l0: -0.0013243049615994096 0.14642325043678284
decider.lstm.weight_hh_l0: 0.001296461676247418 0.14624281227588654
decider.lstm.bias_ih_l0: -0.021530069410800934 0.14126835763454437
decider.lstm.bias_hh_l0: 0.014290816150605679 0.15374970436096191
decider.linear1.weight: 0.004460587166249752 0.12011285871267319
decider.linear1.bias: 0.007067876402288675 0.11518161743879318
decider.linear2.weight: 0.002323536667972803 0.052970219403505325
decider.linear2.bias: 0.001244512153789401 0.051643870770931244
decider.linear3.weight: -0.0018686545081436634 0.055132362991571426
decider.linear3.bias: -0.016196224838495255 0.03487483784556389

Rewards:
65.8452
65.8452
65.8452
objective = 0.5383586287498474
==== episode 10700/75000 ====
action = 0
probs = 0.9994 0.0002 0.0003 0.0001

action = 0
probs = 0.9992 0.0001 0.0006 0.0001

action = 0
probs = 0.0342 0.0040 0.9483 0.0135

Learning rate: 8.0973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015025150496512651 0.08305316418409348
encoder.encoder.weight_hh_l0: -0.0007279987912625074 0.08492784947156906
encoder.encoder.bias_ih_l0: 0.005375808570533991 0.08784518390893936
encoder.encoder.bias_hh_l0: 0.018447794020175934 0.0865463986992836
encoder.encoder.weight_ih_l0_reverse: 0.0021620241459459066 0.08468594402074814
encoder.encoder.weight_hh_l0_reverse: 0.000352837989339605 0.08440442383289337
encoder.encoder.bias_ih_l0_reverse: 0.016146263107657433 0.0822686031460762
encoder.encoder.bias_hh_l0_reverse: 0.016440901905298233 0.08740203082561493
decider.lstm.weight_ih_l0: -0.0013495173770934343 0.1463625580072403
decider.lstm.weight_hh_l0: 0.001057206653058529 0.14616626501083374
decider.lstm.bias_ih_l0: -0.02233494445681572 0.14134258031845093
decider.lstm.bias_hh_l0: 0.013485930860042572 0.15381363034248352
decider.linear1.weight: 0.004375412128865719 0.11995840817689896
decider.linear1.bias: 0.006547065451741219 0.11512826383113861
decider.linear2.weight: 0.002229715697467327 0.05293458327651024
decider.linear2.bias: 0.0010411018738523126 0.05159146338701248
decider.linear3.weight: -0.001794313662685454 0.05502020940184593
decider.linear3.bias: -0.01593431830406189 0.03392990678548813

Rewards:
56.1059
56.1059
56.1059
objective = 63.17174530029297
==== episode 10800/75000 ====
action = 0
probs = 0.9995 0.0002 0.0003 0.0001

action = 0
probs = 0.9994 0.0001 0.0005 0.0001

action = 2
probs = 0.0434 0.0040 0.9378 0.0149

Learning rate: 8.0973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015096289571374655 0.08306793123483658
encoder.encoder.weight_hh_l0: -0.0007317351410165429 0.08494146913290024
encoder.encoder.bias_ih_l0: 0.0054392218589782715 0.08787967264652252
encoder.encoder.bias_hh_l0: 0.0185112114995718 0.0865849182009697
encoder.encoder.weight_ih_l0_reverse: 0.002168867038562894 0.08470162749290466
encoder.encoder.weight_hh_l0_reverse: 0.00035499196383170784 0.08443266898393631
encoder.encoder.bias_ih_l0_reverse: 0.016227371990680695 0.08227039873600006
encoder.encoder.bias_hh_l0_reverse: 0.016522014513611794 0.08742045611143112
decider.lstm.weight_ih_l0: -0.0013488754630088806 0.14637760818004608
decider.lstm.weight_hh_l0: 0.0010539294453337789 0.1461811661720276
decider.lstm.bias_ih_l0: -0.022306520491838455 0.14134320616722107
decider.lstm.bias_hh_l0: 0.013514352031052113 0.1538366973400116
decider.linear1.weight: 0.0043809376657009125 0.11996547132730484
decider.linear1.bias: 0.006585145369172096 0.115132637321949
decider.linear2.weight: 0.0022472012788057327 0.05294465646147728
decider.linear2.bias: 0.001063243136741221 0.05159889534115791
decider.linear3.weight: -0.0018226762767881155 0.05504801869392395
decider.linear3.bias: -0.015978513285517693 0.03392583876848221

Rewards:
65.8452
65.8452
65.8452
objective = 1.4361624717712402
==== episode 10900/75000 ====
action = 0
probs = 0.9995 0.0002 0.0002 0.0001

action = 0
probs = 0.9994 0.0001 0.0003 0.0001

action = 2
probs = 0.0855 0.0076 0.8811 0.0257

Learning rate: 8.0973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014274362474679947 0.0829387679696083
encoder.encoder.weight_hh_l0: -0.0007156435749493539 0.08471643179655075
encoder.encoder.bias_ih_l0: 0.004673216957598925 0.0877547636628151
encoder.encoder.bias_hh_l0: 0.017745207995176315 0.08640438318252563
encoder.encoder.weight_ih_l0_reverse: 0.0021397569216787815 0.08462105691432953
encoder.encoder.weight_hh_l0_reverse: 0.00035091768950223923 0.08435051143169403
encoder.encoder.bias_ih_l0_reverse: 0.015932712703943253 0.08217793703079224
encoder.encoder.bias_hh_l0_reverse: 0.016227353364229202 0.08720022439956665
decider.lstm.weight_ih_l0: -0.0013656651135534048 0.14631356298923492
decider.lstm.weight_hh_l0: 0.0009137453744187951 0.14611126482486725
decider.lstm.bias_ih_l0: -0.0229814276099205 0.14132679998874664
decider.lstm.bias_hh_l0: 0.01283944956958294 0.15389342606067657
decider.linear1.weight: 0.004331539385020733 0.11984628438949585
decider.linear1.bias: 0.0061443643644452095 0.11509517580270767
decider.linear2.weight: 0.0021382421255111694 0.052916985005140305
decider.linear2.bias: 0.0008352638105861843 0.05160030722618103
decider.linear3.weight: -0.0017168899066746235 0.054920751601457596
decider.linear3.bias: -0.015665259212255478 0.03375421464443207

Rewards:
65.8452
65.8452
65.8452
objective = 2.800079345703125
==== episode 11000/75000 ====
action = 0
probs = 0.9995 0.0002 0.0002 0.0001

action = 0
probs = 0.9994 0.0001 0.0004 0.0001

action = 2
probs = 0.0597 0.0058 0.9118 0.0227

Learning rate: 8.0163e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014554514782503247 0.0829831063747406
encoder.encoder.weight_hh_l0: -0.0007225944427773356 0.08478076010942459
encoder.encoder.bias_ih_l0: 0.0048718941397964954 0.08780159801244736
encoder.encoder.bias_hh_l0: 0.017943887040019035 0.08646788448095322
encoder.encoder.weight_ih_l0_reverse: 0.002156704431399703 0.08464904129505157
encoder.encoder.weight_hh_l0_reverse: 0.0003538607561495155 0.08436974138021469
encoder.encoder.bias_ih_l0_reverse: 0.015976019203662872 0.08221880346536636
encoder.encoder.bias_hh_l0_reverse: 0.016270658001303673 0.08725573122501373
decider.lstm.weight_ih_l0: -0.0013600861420854926 0.1463267058134079
decider.lstm.weight_hh_l0: 0.0009381872368976474 0.14612653851509094
decider.lstm.bias_ih_l0: -0.02278667688369751 0.14135847985744476
decider.lstm.bias_hh_l0: 0.013034197501838207 0.15386082231998444
decider.linear1.weight: 0.0043425895273685455 0.11988333612680435
decider.linear1.bias: 0.006262300070375204 0.1150941327214241
decider.linear2.weight: 0.002176336944103241 0.05293720215559006
decider.linear2.bias: 0.0008980741258710623 0.05157357454299927
decider.linear3.weight: -0.0017709142994135618 0.054988037794828415
decider.linear3.bias: -0.015802500769495964 0.03349822014570236

Rewards:
65.8452
65.8452
65.8452
objective = 2.051421642303467
==== episode 11100/75000 ====
action = 0
probs = 0.9995 0.0002 0.0002 0.0001

action = 0
probs = 0.9994 0.0001 0.0005 0.0001

action = 2
probs = 0.0403 0.0043 0.9374 0.0180

Learning rate: 8.0163e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0014982852153480053 0.08305772393941879
encoder.encoder.weight_hh_l0: -0.0007309732027351856 0.08488883823156357
encoder.encoder.bias_ih_l0: 0.005232591647654772 0.08787574619054794
encoder.encoder.bias_hh_l0: 0.01830458641052246 0.08657209575176239
encoder.encoder.weight_ih_l0_reverse: 0.002181882271543145 0.08469881117343903
encoder.encoder.weight_hh_l0_reverse: 0.00035658321576192975 0.0844201073050499
encoder.encoder.bias_ih_l0_reverse: 0.01613156683743 0.08227625489234924
encoder.encoder.bias_hh_l0_reverse: 0.0164262056350708 0.08737095445394516
decider.lstm.weight_ih_l0: -0.001350043574348092 0.1463581770658493
decider.lstm.weight_hh_l0: 0.0009983436902984977 0.14616315066814423
decider.lstm.bias_ih_l0: -0.02244127169251442 0.1413814276456833
decider.lstm.bias_hh_l0: 0.013379600830376148 0.1538357436656952
decider.linear1.weight: 0.004365887492895126 0.11994535475969315
decider.linear1.bias: 0.006467037368565798 0.11510177701711655
decider.linear2.weight: 0.0022336882539093494 0.05296375975012779
decider.linear2.bias: 0.0009989689569920301 0.051561567932367325
decider.linear3.weight: -0.0018329429440200329 0.05507311224937439
decider.linear3.bias: -0.0159644465893507 0.03344374895095825

Rewards:
65.8452
65.8452
65.8452
objective = 1.4434598684310913
==== episode 11200/75000 ====
action = 0
probs = 0.9996 0.0002 0.0002 0.0000

action = 0
probs = 0.9994 0.0001 0.0004 0.0001

action = 2
probs = 0.0350 0.0039 0.9478 0.0133

Learning rate: 8.0163e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001528450520709157 0.08311858028173447
encoder.encoder.weight_hh_l0: -0.0007369285449385643 0.08497409522533417
encoder.encoder.bias_ih_l0: 0.005526835564523935 0.08793188631534576
encoder.encoder.bias_hh_l0: 0.018598824739456177 0.08666029572486877
encoder.encoder.weight_ih_l0_reverse: 0.0022055027075111866 0.08474351465702057
encoder.encoder.weight_hh_l0_reverse: 0.000358960940502584 0.08447731286287308
encoder.encoder.bias_ih_l0_reverse: 0.016314871609210968 0.0823129341006279
encoder.encoder.bias_hh_l0_reverse: 0.01660950854420662 0.08748140931129456
decider.lstm.weight_ih_l0: -0.0013419719180092216 0.1463901400566101
decider.lstm.weight_hh_l0: 0.001056787557899952 0.1462029665708542
decider.lstm.bias_ih_l0: -0.02215462177991867 0.14138594269752502
decider.lstm.bias_hh_l0: 0.01366625539958477 0.1538357436656952
decider.linear1.weight: 0.004389426205307245 0.11999489367008209
decider.linear1.bias: 0.006643312051892281 0.11512713134288788
decider.linear2.weight: 0.0022807898931205273 0.0529850535094738
decider.linear2.bias: 0.0010789392981678247 0.05160342901945114
decider.linear3.weight: -0.001866726204752922 0.055110301822423935
decider.linear3.bias: -0.01604892499744892 0.03407394886016846

Rewards:
65.8452
65.8452
65.8452
objective = 1.1992501020431519
==== episode 11300/75000 ====
action = 0
probs = 0.9996 0.0002 0.0002 0.0000

action = 0
probs = 0.9993 0.0001 0.0005 0.0001

action = 2
probs = 0.0230 0.0036 0.9624 0.0110

Learning rate: 8.0163e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015513062244281173 0.08315472304821014
encoder.encoder.weight_hh_l0: -0.0007410983671434224 0.0850241631269455
encoder.encoder.bias_ih_l0: 0.00567588210105896 0.08795179426670074
encoder.encoder.bias_hh_l0: 0.018747873604297638 0.08669426292181015
encoder.encoder.weight_ih_l0_reverse: 0.0022216185461729765 0.08476199209690094
encoder.encoder.weight_hh_l0_reverse: 0.00036138310679234564 0.08448732644319534
encoder.encoder.bias_ih_l0_reverse: 0.01636168733239174 0.08234450966119766
encoder.encoder.bias_hh_l0_reverse: 0.01665632613003254 0.08754453808069229
decider.lstm.weight_ih_l0: -0.0013357737334445119 0.14639250934123993
decider.lstm.weight_hh_l0: 0.0010984953260049224 0.14621417224407196
decider.lstm.bias_ih_l0: -0.021940384060144424 0.14139670133590698
decider.lstm.bias_hh_l0: 0.013880494982004166 0.1538030058145523
decider.linear1.weight: 0.004400609992444515 0.12003126740455627
decider.linear1.bias: 0.006731010507792234 0.11512210220098495
decider.linear2.weight: 0.002302178181707859 0.053002387285232544
decider.linear2.bias: 0.0011055683717131615 0.05159584432840347
decider.linear3.weight: -0.0018720270600169897 0.05515167489647865
decider.linear3.bias: -0.016044674441218376 0.034057457000017166

Rewards:
65.8452
65.8452
65.8452
objective = 0.8655564188957214
==== episode 11400/75000 ====
action = 0
probs = 0.9996 0.0002 0.0002 0.0000

action = 0
probs = 0.9993 0.0001 0.0005 0.0001

action = 2
probs = 0.0164 0.0028 0.9717 0.0091

Learning rate: 8.0163e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0015897927805781364 0.0832177996635437
encoder.encoder.weight_hh_l0: -0.0007441906491294503 0.08511829376220703
encoder.encoder.bias_ih_l0: 0.005987093318253756 0.08800522983074188
encoder.encoder.bias_hh_l0: 0.019059082493185997 0.0867755338549614
encoder.encoder.weight_ih_l0_reverse: 0.002238044748082757 0.0848030224442482
encoder.encoder.weight_hh_l0_reverse: 0.0003628215636126697 0.08453020453453064
encoder.encoder.bias_ih_l0_reverse: 0.016505012288689613 0.08238761872053146
encoder.encoder.bias_hh_l0_reverse: 0.016799645498394966 0.08764750510454178
decider.lstm.weight_ih_l0: -0.0013255623634904623 0.14641833305358887
decider.lstm.weight_hh_l0: 0.00117949815467 0.14624550938606262
decider.lstm.bias_ih_l0: -0.021616406738758087 0.1413903385400772
decider.lstm.bias_hh_l0: 0.014204474166035652 0.15378084778785706
decider.linear1.weight: 0.004432290326803923 0.12009240686893463
decider.linear1.bias: 0.006929374299943447 0.11512589454650879
decider.linear2.weight: 0.0023503093980252743 0.05302640050649643
decider.linear2.bias: 0.001184183405712247 0.05158858746290207
decider.linear3.weight: -0.0019096864853054285 0.05522987246513367
decider.linear3.bias: -0.016134852543473244 0.033987175673246384

Rewards:
65.8452
65.8452
65.8452
objective = 0.6545016765594482
==== episode 11500/75000 ====
action = 0
probs = 0.9997 0.0001 0.0002 0.0000

action = 0
probs = 0.9995 0.0001 0.0004 0.0000

action = 2
probs = 0.0246 0.0028 0.9641 0.0085

Learning rate: 7.9361e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001597558381035924 0.08324107527732849
encoder.encoder.weight_hh_l0: -0.0007468339754268527 0.0851512998342514
encoder.encoder.bias_ih_l0: 0.006131542380899191 0.08804845064878464
encoder.encoder.bias_hh_l0: 0.019203534349799156 0.08683820068836212
encoder.encoder.weight_ih_l0_reverse: 0.002247503260150552 0.08483581244945526
encoder.encoder.weight_hh_l0_reverse: 0.00036326987901702523 0.08459053933620453
encoder.encoder.bias_ih_l0_reverse: 0.016676276922225952 0.08238532394170761
encoder.encoder.bias_hh_l0_reverse: 0.016970911994576454 0.08769522607326508
decider.lstm.weight_ih_l0: -0.0013247861061245203 0.14645522832870483
decider.lstm.weight_hh_l0: 0.001192638766951859 0.14628006517887115
decider.lstm.bias_ih_l0: -0.02157340571284294 0.14138035476207733
decider.lstm.bias_hh_l0: 0.014247467741370201 0.15382972359657288
decider.linear1.weight: 0.004450615029782057 0.12011127173900604
decider.linear1.bias: 0.007025083526968956 0.11517229676246643
decider.linear2.weight: 0.0023930822499096394 0.05304130166769028
decider.linear2.bias: 0.001253324095159769 0.051643408834934235
decider.linear3.weight: -0.001958378590643406 0.055258456617593765
decider.linear3.bias: -0.016260482370853424 0.0345928855240345

Rewards:
65.8452
65.8452
65.8452
objective = 0.820084810256958
==== episode 11600/75000 ====
action = 0
probs = 0.9997 0.0001 0.0002 0.0000

action = 0
probs = 0.9995 0.0001 0.0004 0.0000

action = 2
probs = 0.0252 0.0026 0.9639 0.0083

Learning rate: 7.9361e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016083589289337397 0.08325949311256409
encoder.encoder.weight_hh_l0: -0.0007485870155505836 0.08517783880233765
encoder.encoder.bias_ih_l0: 0.006227533798664808 0.08807843178510666
encoder.encoder.bias_hh_l0: 0.019299525767564774 0.08686959743499756
encoder.encoder.weight_ih_l0_reverse: 0.0022534148301929235 0.08485394716262817
encoder.encoder.weight_hh_l0_reverse: 0.0003640522772911936 0.08461461961269379
encoder.encoder.bias_ih_l0_reverse: 0.01674429140985012 0.08239671587944031
encoder.encoder.bias_hh_l0_reverse: 0.017038926482200623 0.08771572262048721
decider.lstm.weight_ih_l0: -0.001324162119999528 0.14647063612937927
decider.lstm.weight_hh_l0: 0.0011975191300734878 0.14629489183425903
decider.lstm.bias_ih_l0: -0.02154129184782505 0.1413772702217102
decider.lstm.bias_hh_l0: 0.014279582537710667 0.153843492269516
decider.linear1.weight: 0.0044622356072068214 0.12012918293476105
decider.linear1.bias: 0.007090145722031593 0.11518669128417969
decider.linear2.weight: 0.0024176957085728645 0.053054727613925934
decider.linear2.bias: 0.0012879534624516964 0.051649995148181915
decider.linear3.weight: -0.0019851522520184517 0.05529430881142616
decider.linear3.bias: -0.016319314017891884 0.034620501101017

Rewards:
65.8452
65.8452
65.8452
objective = 0.8230141997337341
==== episode 11700/75000 ====
action = 0
probs = 0.9997 0.0001 0.0002 0.0000

action = 0
probs = 0.9995 0.0001 0.0004 0.0000

action = 2
probs = 0.0185 0.0019 0.9734 0.0061

Learning rate: 7.9361e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016498708864673972 0.08332522213459015
encoder.encoder.weight_hh_l0: -0.0007507521077059209 0.08528482168912888
encoder.encoder.bias_ih_l0: 0.006573885679244995 0.08812115341424942
encoder.encoder.bias_hh_l0: 0.01964588090777397 0.08695516735315323
encoder.encoder.weight_ih_l0_reverse: 0.002265999326482415 0.0848982110619545
encoder.encoder.weight_hh_l0_reverse: 0.0003645247488748282 0.0846632868051529
encoder.encoder.bias_ih_l0_reverse: 0.016910403966903687 0.0824316218495369
encoder.encoder.bias_hh_l0_reverse: 0.017205040901899338 0.08783988654613495
decider.lstm.weight_ih_l0: -0.001314196502789855 0.14650395512580872
decider.lstm.weight_hh_l0: 0.0013041123747825623 0.14632996916770935
decider.lstm.bias_ih_l0: -0.021167699247598648 0.14135673642158508
decider.lstm.bias_hh_l0: 0.014653172343969345 0.15381290018558502
decider.linear1.weight: 0.004506578668951988 0.12020298093557358
decider.linear1.bias: 0.007332174107432365 0.11520589143037796
decider.linear2.weight: 0.002473668660968542 0.053082339465618134
decider.linear2.bias: 0.0013834889978170395 0.05167112872004509
decider.linear3.weight: -0.002038391772657633 0.05537662282586098
decider.linear3.bias: -0.016460487619042397 0.03481544181704521

Rewards:
65.8452
65.8452
65.8452
objective = 0.6083574295043945
==== episode 11800/75000 ====
action = 0
probs = 0.9997 0.0001 0.0001 0.0000

action = 0
probs = 0.9996 0.0001 0.0003 0.0000

action = 2
probs = 0.0221 0.0022 0.9678 0.0080

Learning rate: 7.9361e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016273112269118428 0.08329543471336365
encoder.encoder.weight_hh_l0: -0.0007534357137046754 0.08522408455610275
encoder.encoder.bias_ih_l0: 0.00636938726529479 0.0881166085600853
encoder.encoder.bias_hh_l0: 0.019441382959485054 0.086925208568573
encoder.encoder.weight_ih_l0_reverse: 0.0022661180701106787 0.08488094806671143
encoder.encoder.weight_hh_l0_reverse: 0.0003665699914563447 0.0846497043967247
encoder.encoder.bias_ih_l0_reverse: 0.01684553176164627 0.08242152631282806
encoder.encoder.bias_hh_l0_reverse: 0.017140168696641922 0.08777374774217606
decider.lstm.weight_ih_l0: -0.0013200812973082066 0.1464885175228119
decider.lstm.weight_hh_l0: 0.0012228133855387568 0.14631164073944092
decider.lstm.bias_ih_l0: -0.02139420062303543 0.14139460027217865
decider.lstm.bias_hh_l0: 0.014426681213080883 0.15382863581180573
decider.linear1.weight: 0.004481243900954723 0.1201665922999382
decider.linear1.bias: 0.0072122784331440926 0.11518850177526474
decider.linear2.weight: 0.002455801237374544 0.0530807264149189
decider.linear2.bias: 0.0013355228584259748 0.0516580231487751
decider.linear3.weight: -0.0020316436421126127 0.05536861717700958
decider.linear3.bias: -0.016414126381278038 0.03445516526699066

Rewards:
65.8452
65.8452
65.8452
objective = 0.7337237596511841
==== episode 11900/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9996 0.0001 0.0003 0.0000

action = 2
probs = 0.0180 0.0018 0.9730 0.0072

Learning rate: 7.9361e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0016528409905731678 0.08333498984575272
encoder.encoder.weight_hh_l0: -0.0007552350289188325 0.08528488874435425
encoder.encoder.bias_ih_l0: 0.006563441827893257 0.08814707398414612
encoder.encoder.bias_hh_l0: 0.019635435193777084 0.08697595447301865
encoder.encoder.weight_ih_l0_reverse: 0.0022736042737960815 0.08490508049726486
encoder.encoder.weight_hh_l0_reverse: 0.0003675325424410403 0.08467409759759903
encoder.encoder.bias_ih_l0_reverse: 0.016930850222706795 0.08244413882493973
encoder.encoder.bias_hh_l0_reverse: 0.017225485295057297 0.08784128725528717
decider.lstm.weight_ih_l0: -0.0013141032541170716 0.1465047299861908
decider.lstm.weight_hh_l0: 0.0012810924090445042 0.14633074402809143
decider.lstm.bias_ih_l0: -0.021179955452680588 0.1413865089416504
decider.lstm.bias_hh_l0: 0.014640933834016323 0.15381105244159698
decider.linear1.weight: 0.00450440589338541 0.12020690739154816
decider.linear1.bias: 0.007339589297771454 0.11518853157758713
decider.linear2.weight: 0.002488641534000635 0.05309850350022316
decider.linear2.bias: 0.0013862632913514972 0.05164935067296028
decider.linear3.weight: -0.002061958657577634 0.055423248559236526
decider.linear3.bias: -0.016484994441270828 0.03435986116528511

Rewards:
65.8452
65.8452
65.8452
objective = 0.615242600440979
==== episode 12000/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9995 0.0000 0.0004 0.0000

action = 2
probs = 0.0104 0.0012 0.9836 0.0048

Learning rate: 7.8568e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0017128381878137589 0.08342111110687256
encoder.encoder.weight_hh_l0: -0.0007547161658294499 0.0854317843914032
encoder.encoder.bias_ih_l0: 0.007031893357634544 0.08819574862718582
encoder.encoder.bias_hh_l0: 0.02010389044880867 0.08707418292760849
encoder.encoder.weight_ih_l0_reverse: 0.0022831398528069258 0.0849587619304657
encoder.encoder.weight_hh_l0_reverse: 0.0003673451719805598 0.08472266048192978
encoder.encoder.bias_ih_l0_reverse: 0.01711161620914936 0.08249226957559586
encoder.encoder.bias_hh_l0_reverse: 0.017406253144145012 0.08799225836992264
decider.lstm.weight_ih_l0: -0.0013012035051360726 0.1465446650981903
decider.lstm.weight_hh_l0: 0.0014433959731832147 0.14637599885463715
decider.lstm.bias_ih_l0: -0.020674772560596466 0.14133058488368988
decider.lstm.bias_hh_l0: 0.015146116726100445 0.15376617014408112
decider.linear1.weight: 0.004569387994706631 0.1203065812587738
decider.linear1.bias: 0.007649685256183147 0.11521264165639877
decider.linear2.weight: 0.0025525998789817095 0.05313346907496452
decider.linear2.bias: 0.0015030649956315756 0.051652565598487854
decider.linear3.weight: -0.0021141362376511097 0.05552799627184868
decider.linear3.bias: -0.016623524948954582 0.03446124866604805

Rewards:
65.8452
65.8452
65.8452
objective = 0.37885457277297974
==== episode 12100/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9995 0.0000 0.0005 0.0000

action = 2
probs = 0.0063 0.0008 0.9897 0.0033

Learning rate: 7.8568e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0017611621879041195 0.08348657935857773
encoder.encoder.weight_hh_l0: -0.0007524187676608562 0.08554976433515549
encoder.encoder.bias_ih_l0: 0.007410909980535507 0.08822862058877945
encoder.encoder.bias_hh_l0: 0.02048291079699993 0.08714908361434937
encoder.encoder.weight_ih_l0_reverse: 0.002288107294589281 0.08500178903341293
encoder.encoder.weight_hh_l0_reverse: 0.00036642656777985394 0.08476495742797852
encoder.encoder.bias_ih_l0_reverse: 0.01727454364299774 0.08251779526472092
encoder.encoder.bias_hh_l0_reverse: 0.017569180577993393 0.08811682462692261
decider.lstm.weight_ih_l0: -0.0012910437071695924 0.14658015966415405
decider.lstm.weight_hh_l0: 0.0015996645670384169 0.1464146375656128
decider.lstm.bias_ih_l0: -0.020253513008356094 0.14126959443092346
decider.lstm.bias_hh_l0: 0.015567371621727943 0.15373577177524567
decider.linear1.weight: 0.004632233642041683 0.12039096653461456
decider.linear1.bias: 0.007896391674876213 0.11524178087711334
decider.linear2.weight: 0.0026358524337410927 0.05317828059196472
decider.linear2.bias: 0.0016842924524098635 0.05171457678079605
decider.linear3.weight: -0.002241790760308504 0.05566396936774254
decider.linear3.bias: -0.016721203923225403 0.034560542553663254

Rewards:
65.8452
65.8452
65.8452
objective = 0.2450079321861267
==== episode 12200/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9995 0.0000 0.0004 0.0000

action = 2
probs = 0.0052 0.0005 0.9921 0.0023

Learning rate: 7.8568e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0017780321650207043 0.08351141959428787
encoder.encoder.weight_hh_l0: -0.0007528465357609093 0.08559325337409973
encoder.encoder.bias_ih_l0: 0.007567221764475107 0.08824607729911804
encoder.encoder.bias_hh_l0: 0.020639223977923393 0.08718983829021454
encoder.encoder.weight_ih_l0_reverse: 0.00228984490968287 0.08501823991537094
encoder.encoder.weight_hh_l0_reverse: 0.0003656285407487303 0.08479229360818863
encoder.encoder.bias_ih_l0_reverse: 0.017386419698596 0.08250216394662857
encoder.encoder.bias_hh_l0_reverse: 0.017681054770946503 0.0881887897849083
decider.lstm.weight_ih_l0: -0.0012863323790952563 0.1465974748134613
decider.lstm.weight_hh_l0: 0.0016850843094289303 0.14643190801143646
decider.lstm.bias_ih_l0: -0.02005169726908207 0.14124460518360138
decider.lstm.bias_hh_l0: 0.015769192948937416 0.15375889837741852
decider.linear1.weight: 0.00465620681643486 0.12041500210762024
decider.linear1.bias: 0.00797490868717432 0.11525110900402069
decider.linear2.weight: 0.002676878124475479 0.05326763540506363
decider.linear2.bias: 0.0018501314334571362 0.05183979868888855
decider.linear3.weight: -0.002396784955635667 0.05589340999722481
decider.linear3.bias: -0.016767071560025215 0.03473712503910065

Rewards:
65.8452
65.8452
65.8452
objective = 0.18799549341201782
==== episode 12300/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9996 0.0000 0.0004 0.0000

action = 2
probs = 0.0040 0.0004 0.9939 0.0017

Learning rate: 7.8568e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018048968631774187 0.08354321122169495
encoder.encoder.weight_hh_l0: -0.0007517411140725017 0.08565700054168701
encoder.encoder.bias_ih_l0: 0.007772109471261501 0.0882669985294342
encoder.encoder.bias_hh_l0: 0.0208441112190485 0.08722511678934097
encoder.encoder.weight_ih_l0_reverse: 0.002293471246957779 0.08504385501146317
encoder.encoder.weight_hh_l0_reverse: 0.0003655598557088524 0.08481568843126297
encoder.encoder.bias_ih_l0_reverse: 0.017473572865128517 0.08251824975013733
encoder.encoder.bias_hh_l0_reverse: 0.01776820980012417 0.08824480324983597
decider.lstm.weight_ih_l0: -0.0012830639025196433 0.14661915600299835
decider.lstm.weight_hh_l0: 0.0017584338784217834 0.14645355939865112
decider.lstm.bias_ih_l0: -0.019870758056640625 0.14121092855930328
decider.lstm.bias_hh_l0: 0.015950117260217667 0.1537453830242157
decider.linear1.weight: 0.004699780605733395 0.12046761810779572
decider.linear1.bias: 0.008129362016916275 0.115275539457798
decider.linear2.weight: 0.002692851470783353 0.053321950137615204
decider.linear2.bias: 0.0019099724013358355 0.051855627447366714
decider.linear3.weight: -0.0025048248935490847 0.05604763701558113
decider.linear3.bias: -0.01681700348854065 0.03479966148734093

Rewards:
65.8452
65.8452
65.8452
objective = 0.1471204310655594
==== episode 12400/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9996 0.0000 0.0004 0.0000

action = 2
probs = 0.0037 0.0004 0.9938 0.0021

Learning rate: 7.8568e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0017878535436466336 0.0835290253162384
encoder.encoder.weight_hh_l0: -0.0007555213524028659 0.08561583608388901
encoder.encoder.bias_ih_l0: 0.007618842180818319 0.0882653295993805
encoder.encoder.bias_hh_l0: 0.02069084160029888 0.08720879256725311
encoder.encoder.weight_ih_l0_reverse: 0.002299272920936346 0.0850336104631424
encoder.encoder.weight_hh_l0_reverse: 0.00036778778303414583 0.08480687439441681
encoder.encoder.bias_ih_l0_reverse: 0.01741849072277546 0.08253350853919983
encoder.encoder.bias_hh_l0_reverse: 0.017713133245706558 0.08819354325532913
decider.lstm.weight_ih_l0: -0.001286081038415432 0.14660190045833588
decider.lstm.weight_hh_l0: 0.0016786691267043352 0.14643782377243042
decider.lstm.bias_ih_l0: -0.020038597285747528 0.14125068485736847
decider.lstm.bias_hh_l0: 0.01578226312994957 0.15373757481575012
decider.linear1.weight: 0.004678589757531881 0.12044905126094818
decider.linear1.bias: 0.00806129164993763 0.11526257544755936
decider.linear2.weight: 0.002674561459571123 0.053334109485149384
decider.linear2.bias: 0.0018774952040985227 0.05182671546936035
decider.linear3.weight: -0.0025264746509492397 0.056119393557310104
decider.linear3.bias: -0.016768421977758408 0.03442566096782684

Rewards:
65.8452
65.8452
65.8452
objective = 0.14922736585140228
==== episode 12500/75000 ====
action = 0
probs = 0.9998 0.0000 0.0001 0.0000

action = 0
probs = 0.9996 0.0000 0.0004 0.0000

action = 2
probs = 0.0030 0.0003 0.9950 0.0017

Learning rate: 7.7782e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018176566809415817 0.08356638997793198
encoder.encoder.weight_hh_l0: -0.0007534364704042673 0.08568713814020157
encoder.encoder.bias_ih_l0: 0.00785018689930439 0.08828583359718323
encoder.encoder.bias_hh_l0: 0.020922185853123665 0.08725368231534958
encoder.encoder.weight_ih_l0_reverse: 0.0023015595506876707 0.08506015688180923
encoder.encoder.weight_hh_l0_reverse: 0.00036737570189870894 0.08483361452817917
encoder.encoder.bias_ih_l0_reverse: 0.017526719719171524 0.08254173398017883
encoder.encoder.bias_hh_l0_reverse: 0.017821362242102623 0.08826892822980881
decider.lstm.weight_ih_l0: -0.0012802672572433949 0.14662593603134155
decider.lstm.weight_hh_l0: 0.0017772839637473226 0.14646226167678833
decider.lstm.bias_ih_l0: -0.019787676632404327 0.1412123441696167
decider.lstm.bias_hh_l0: 0.01603318750858307 0.153724804520607
decider.linear1.weight: 0.004722608253359795 0.1205042377114296
decider.linear1.bias: 0.008220639079809189 0.11528493463993073
decider.linear2.weight: 0.002702185418456793 0.053370390087366104
decider.linear2.bias: 0.0019372296519577503 0.051842235028743744
decider.linear3.weight: -0.0025728726759552956 0.05623706057667732
decider.linear3.bias: -0.016815239563584328 0.034491054713726044

Rewards:
65.8452
65.8452
65.8452
objective = 0.12164293229579926
==== episode 12600/75000 ====
action = 0
probs = 0.9995 0.0002 0.0002 0.0000

action = 0
probs = 0.9991 0.0001 0.0007 0.0001

action = 2
probs = 0.0024 0.0003 0.9958 0.0015

Learning rate: 7.7782e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001719916588626802 0.08342524617910385
encoder.encoder.weight_hh_l0: -0.0007232411880977452 0.08550243824720383
encoder.encoder.bias_ih_l0: 0.007125751581043005 0.08804739266633987
encoder.encoder.bias_hh_l0: 0.020197751000523567 0.08695480227470398
encoder.encoder.weight_ih_l0_reverse: 0.0022230781614780426 0.0849246010184288
encoder.encoder.weight_hh_l0_reverse: 0.00035392030258663 0.08462849259376526
encoder.encoder.bias_ih_l0_reverse: 0.016886232420802116 0.08249135315418243
encoder.encoder.bias_hh_l0_reverse: 0.017180876806378365 0.0879998728632927
decider.lstm.weight_ih_l0: -0.0012919905129820108 0.14651603996753693
decider.lstm.weight_hh_l0: 0.0015766560100018978 0.14634092152118683
decider.lstm.bias_ih_l0: -0.02048950456082821 0.14119254052639008
decider.lstm.bias_hh_l0: 0.015331361442804337 0.1536594033241272
decider.linear1.weight: 0.0045891618356108665 0.12037745118141174
decider.linear1.bias: 0.007741805166006088 0.11527490615844727
decider.linear2.weight: 0.0025129630230367184 0.05332234129309654
decider.linear2.bias: 0.0017643363680690527 0.05182913318276405
decider.linear3.weight: -0.0025898509193211794 0.05615333840250969
decider.linear3.bias: -0.016627486795186996 0.034470334649086

Rewards:
65.8452
65.8452
65.8452
objective = 0.12204167246818542
==== episode 12700/75000 ====
action = 0
probs = 0.9996 0.0002 0.0002 0.0000

action = 0
probs = 0.9993 0.0001 0.0006 0.0000

action = 2
probs = 0.0021 0.0002 0.9964 0.0013

Learning rate: 7.7782e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001745440298691392 0.08347047120332718
encoder.encoder.weight_hh_l0: -0.0007197762606665492 0.08557923138141632
encoder.encoder.bias_ih_l0: 0.007370461244136095 0.08807583153247833
encoder.encoder.bias_hh_l0: 0.02044246345758438 0.08701176941394806
encoder.encoder.weight_ih_l0_reverse: 0.002225683769211173 0.08495493233203888
encoder.encoder.weight_hh_l0_reverse: 0.0003513714764267206 0.08466815203428268
encoder.encoder.bias_ih_l0_reverse: 0.01701892726123333 0.08249393105506897
encoder.encoder.bias_hh_l0_reverse: 0.017313571646809578 0.08808749169111252
decider.lstm.weight_ih_l0: -0.0012838842812925577 0.14654241502285004
decider.lstm.weight_hh_l0: 0.0016752483788877726 0.14637719094753265
decider.lstm.bias_ih_l0: -0.02020188793540001 0.1411430984735489
decider.lstm.bias_hh_l0: 0.015618985518813133 0.1536555290222168
decider.linear1.weight: 0.004631100222468376 0.12043170630931854
decider.linear1.bias: 0.007907452061772346 0.11529508233070374
decider.linear2.weight: 0.002542177913710475 0.053363773971796036
decider.linear2.bias: 0.0018355150241404772 0.05185156688094139
decider.linear3.weight: -0.0026353506837040186 0.056266285479068756
decider.linear3.bias: -0.01666562631726265 0.034547045826911926

Rewards:
65.8452
65.8452
65.8452
objective = 0.10428042709827423
==== episode 12800/75000 ====
action = 0
probs = 0.9997 0.0001 0.0002 0.0000

action = 0
probs = 0.9993 0.0001 0.0005 0.0000

action = 2
probs = 0.0018 0.0002 0.9969 0.0011

Learning rate: 7.7782e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0017688098596408963 0.08350922167301178
encoder.encoder.weight_hh_l0: -0.0007166878785938025 0.08564794808626175
encoder.encoder.bias_ih_l0: 0.007589181885123253 0.08810059726238251
encoder.encoder.bias_hh_l0: 0.020661186426877975 0.08705899119377136
encoder.encoder.weight_ih_l0_reverse: 0.0022270632907748222 0.08498100191354752
encoder.encoder.weight_hh_l0_reverse: 0.0003493742842692882 0.08470156043767929
encoder.encoder.bias_ih_l0_reverse: 0.017131708562374115 0.08249623328447342
encoder.encoder.bias_hh_l0_reverse: 0.017426354810595512 0.08816434442996979
decider.lstm.weight_ih_l0: -0.001277609495446086 0.14656712114810944
decider.lstm.weight_hh_l0: 0.0017649403307586908 0.14640872180461884
decider.lstm.bias_ih_l0: -0.01995200291275978 0.1411042958498001
decider.lstm.bias_hh_l0: 0.01586887240409851 0.1536535918712616
decider.linear1.weight: 0.004670594818890095 0.12048192322254181
decider.linear1.bias: 0.008056387305259705 0.11531224846839905
decider.linear2.weight: 0.0025706570595502853 0.05339990183711052
decider.linear2.bias: 0.0019007278606295586 0.05187239125370979
decider.linear3.weight: -0.0026756511069834232 0.0563693605363369
decider.linear3.bias: -0.016699781641364098 0.034616630524396896

Rewards:
65.8452
65.8452
65.8452
objective = 0.09024371206760406
==== episode 12900/75000 ====
action = 0
probs = 0.9997 0.0001 0.0002 0.0000

action = 0
probs = 0.9994 0.0001 0.0005 0.0000

action = 2
probs = 0.0008 0.0001 0.9984 0.0007

Learning rate: 7.7782e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0017875927733257413 0.0835389792919159
encoder.encoder.weight_hh_l0: -0.0007146349526010454 0.08570168912410736
encoder.encoder.bias_ih_l0: 0.007760514970868826 0.08812172710895538
encoder.encoder.bias_hh_l0: 0.020832519978284836 0.08709453791379929
encoder.encoder.weight_ih_l0_reverse: 0.0022285631857812405 0.08500207960605621
encoder.encoder.weight_hh_l0_reverse: 0.00034796513500623405 0.08472835272550583
encoder.encoder.bias_ih_l0_reverse: 0.01722189411520958 0.08249876648187637
encoder.encoder.bias_hh_l0_reverse: 0.017516538500785828 0.08822162449359894
decider.lstm.weight_ih_l0: -0.0012734641786664724 0.14658765494823456
decider.lstm.weight_hh_l0: 0.0018326377030462027 0.14643260836601257
decider.lstm.bias_ih_l0: -0.01976967602968216 0.14107710123062134
decider.lstm.bias_hh_l0: 0.01605120860040188 0.15365161001682281
decider.linear1.weight: 0.00470469705760479 0.12052354961633682
decider.linear1.bias: 0.00817771628499031 0.11532826721668243
decider.linear2.weight: 0.0026595613453537226 0.0534728467464447
decider.linear2.bias: 0.0021900092251598835 0.051599569618701935
decider.linear3.weight: -0.002866049762815237 0.05678509920835495
decider.linear3.bias: -0.016726914793252945 0.03467762470245361

Rewards:
65.8452
65.8452
65.8452
objective = 0.054970111697912216
==== episode 13000/75000 ====
action = 0
probs = 0.9997 0.0001 0.0001 0.0000

action = 0
probs = 0.9995 0.0001 0.0004 0.0000

action = 2
probs = 0.0005 0.0000 0.9991 0.0004

Learning rate: 7.7004e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018003841396421194 0.08355875313282013
encoder.encoder.weight_hh_l0: -0.0007138485088944435 0.08573739975690842
encoder.encoder.bias_ih_l0: 0.007876780815422535 0.0881391316652298
encoder.encoder.bias_hh_l0: 0.020948784425854683 0.08711958676576614
encoder.encoder.weight_ih_l0_reverse: 0.002231233986094594 0.08501745760440826
encoder.encoder.weight_hh_l0_reverse: 0.0003471562231425196 0.08474850654602051
encoder.encoder.bias_ih_l0_reverse: 0.017290350049734116 0.08250029385089874
encoder.encoder.bias_hh_l0_reverse: 0.017584994435310364 0.08826033771038055
decider.lstm.weight_ih_l0: -0.0012709848815575242 0.14660170674324036
decider.lstm.weight_hh_l0: 0.0018759125377982855 0.146449476480484
decider.lstm.bias_ih_l0: -0.019654367119073868 0.1410597711801529
decider.lstm.bias_hh_l0: 0.01616651564836502 0.15365564823150635
decider.linear1.weight: 0.004730151500552893 0.12055335193872452
decider.linear1.bias: 0.008264679461717606 0.11533935368061066
decider.linear2.weight: 0.0026807007379829884 0.05356329306960106
decider.linear2.bias: 0.0023371903225779533 0.05152175575494766
decider.linear3.weight: -0.002981856931000948 0.05714278668165207
decider.linear3.bias: -0.01674417220056057 0.03472289443016052

Rewards:
65.8452
65.8452
65.8452
objective = 0.037233177572488785
==== episode 13100/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9996 0.0001 0.0004 0.0000

action = 2
probs = 0.0003 0.0000 0.9994 0.0003

Learning rate: 7.7004e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018104094779118896 0.08357405662536621
encoder.encoder.weight_hh_l0: -0.0007135877385735512 0.08576497435569763
encoder.encoder.bias_ih_l0: 0.007967229932546616 0.0881538987159729
encoder.encoder.bias_hh_l0: 0.021039238199591637 0.08713987469673157
encoder.encoder.weight_ih_l0_reverse: 0.0022338153794407845 0.08502976596355438
encoder.encoder.weight_hh_l0_reverse: 0.00034667839645408094 0.08476480841636658
encoder.encoder.bias_ih_l0_reverse: 0.017346184700727463 0.08250156044960022
encoder.encoder.bias_hh_l0_reverse: 0.017640825361013412 0.08829072117805481
decider.lstm.weight_ih_l0: -0.0012691318988800049 0.14661243557929993
decider.lstm.weight_hh_l0: 0.0019096744945272803 0.14646296203136444
decider.lstm.bias_ih_l0: -0.01956479623913765 0.14104591310024261
decider.lstm.bias_hh_l0: 0.016256099566817284 0.15366129577159882
decider.linear1.weight: 0.004750564228743315 0.12057696282863617
decider.linear1.bias: 0.008333031088113785 0.11534824967384338
decider.linear2.weight: 0.002702977042645216 0.05363836511969566
decider.linear2.bias: 0.0024411447811871767 0.051486268639564514
decider.linear3.weight: -0.0030561613384634256 0.05741151422262192
decider.linear3.bias: -0.01675686426460743 0.03475723788142204

Rewards:
65.8452
65.8452
65.8452
objective = 0.02808775007724762
==== episode 13200/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9996 0.0001 0.0003 0.0000

action = 2
probs = 0.0002 0.0000 0.9996 0.0002

Learning rate: 7.7004e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018188586691394448 0.08358702808618546
encoder.encoder.weight_hh_l0: -0.0007136531639844179 0.08578818291425705
encoder.encoder.bias_ih_l0: 0.008043567650020123 0.08816710114479065
encoder.encoder.bias_hh_l0: 0.02111557498574257 0.08715745806694031
encoder.encoder.weight_ih_l0_reverse: 0.0022363464813679457 0.08504042774438858
encoder.encoder.weight_hh_l0_reverse: 0.0003463734174147248 0.08477915823459625
encoder.encoder.bias_ih_l0_reverse: 0.0173957459628582 0.0825025662779808
encoder.encoder.bias_hh_l0_reverse: 0.017690390348434448 0.08831658959388733
decider.lstm.weight_ih_l0: -0.0012675923062488437 0.14662133157253265
decider.lstm.weight_hh_l0: 0.001938372734002769 0.14647462964057922
decider.lstm.bias_ih_l0: -0.019488822668790817 0.14103305339813232
decider.lstm.bias_hh_l0: 0.016332067549228668 0.15366768836975098
decider.linear1.weight: 0.004768240265548229 0.12059720605611801
decider.linear1.bias: 0.00839168205857277 0.1153559684753418
decider.linear2.weight: 0.002725576516240835 0.0537000447511673
decider.linear2.bias: 0.0025204105768352747 0.051470283418893814
decider.linear3.weight: -0.003112031612545252 0.05762751027941704
decider.linear3.bias: -0.016767069697380066 0.034785427153110504

Rewards:
65.8452
65.8452
65.8452
objective = 0.022636473178863525
==== episode 13300/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9996 0.0000 0.0003 0.0000

action = 2
probs = 0.0001 0.0000 0.9997 0.0001

Learning rate: 7.7004e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018264997052028775 0.08359870314598083
encoder.encoder.weight_hh_l0: -0.0007138406508602202 0.08580909669399261
encoder.encoder.bias_ih_l0: 0.008112797513604164 0.0881793424487114
encoder.encoder.bias_hh_l0: 0.021184802055358887 0.08717351406812668
encoder.encoder.weight_ih_l0_reverse: 0.002238631248474121 0.0850500538945198
encoder.encoder.weight_hh_l0_reverse: 0.0003461657324805856 0.08479215949773788
encoder.encoder.bias_ih_l0_reverse: 0.01744111441075802 0.08250310271978378
encoder.encoder.bias_hh_l0_reverse: 0.017735756933689117 0.08833980560302734
decider.lstm.weight_ih_l0: -0.0012662475928664207 0.14662936329841614
decider.lstm.weight_hh_l0: 0.0019639190286397934 0.1464851051568985
decider.lstm.bias_ih_l0: -0.019421113654971123 0.14102119207382202
decider.lstm.bias_hh_l0: 0.016399795189499855 0.15367399156093597
decider.linear1.weight: 0.004784171469509602 0.12061529606580734
decider.linear1.bias: 0.008444659411907196 0.11536294966936111
decider.linear2.weight: 0.0027458555996418 0.05375393480062485
decider.linear2.bias: 0.0025841486640274525 0.05146363750100136
decider.linear3.weight: -0.003157238243147731 0.05780933424830437
decider.linear3.bias: -0.01677577570080757 0.034809622913599014

Rewards:
65.8452
65.8452
65.8452
objective = 0.01894991844892502
==== episode 13400/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9997 0.0000 0.0003 0.0000

action = 2
probs = 0.0001 0.0000 0.9998 0.0001

Learning rate: 7.7004e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018335762433707714 0.08360941708087921
encoder.encoder.weight_hh_l0: -0.0007141056121326983 0.0858282819390297
encoder.encoder.bias_ih_l0: 0.008176760748028755 0.08819098025560379
encoder.encoder.bias_hh_l0: 0.021248767152428627 0.08718828856945038
encoder.encoder.weight_ih_l0_reverse: 0.0022408156655728817 0.08505890518426895
encoder.encoder.weight_hh_l0_reverse: 0.0003460400621406734 0.08480408042669296
encoder.encoder.bias_ih_l0_reverse: 0.017483007162809372 0.08250352740287781
encoder.encoder.bias_hh_l0_reverse: 0.01777765527367592 0.08836082369089127
decider.lstm.weight_ih_l0: -0.0012650748249143362 0.1466367393732071
decider.lstm.weight_hh_l0: 0.0019866893999278545 0.14649471640586853
decider.lstm.bias_ih_l0: -0.019360588863492012 0.1410101056098938
decider.lstm.bias_hh_l0: 0.01646031066775322 0.15368027985095978
decider.linear1.weight: 0.004798843991011381 0.12063172459602356
decider.linear1.bias: 0.008493166416883469 0.115369513630867
decider.linear2.weight: 0.002764189150184393 0.053801849484443665
decider.linear2.bias: 0.002637740457430482 0.05146162956953049
decider.linear3.weight: -0.003195519559085369 0.05796745792031288
decider.linear3.bias: -0.016783498227596283 0.03483101353049278

Rewards:
65.8452
65.8452
65.8452
objective = 0.01626860722899437
==== episode 13500/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9997 0.0000 0.0002 0.0000

action = 2
probs = 0.0001 0.0000 0.9998 0.0001

Learning rate: 7.6234e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018402445130050182 0.0836193785071373
encoder.encoder.weight_hh_l0: -0.0007144081173464656 0.08584632724523544
encoder.encoder.bias_ih_l0: 0.008237120695412159 0.08820212632417679
encoder.encoder.bias_hh_l0: 0.021309124305844307 0.0872020423412323
encoder.encoder.weight_ih_l0_reverse: 0.0022429467644542456 0.0850672498345375
encoder.encoder.weight_hh_l0_reverse: 0.0003459701547399163 0.08481524139642715
encoder.encoder.bias_ih_l0_reverse: 0.017522640526294708 0.0825038030743599
encoder.encoder.bias_hh_l0_reverse: 0.017817286774516106 0.08838046342134476
decider.lstm.weight_ih_l0: -0.0012639955384656787 0.14664360880851746
decider.lstm.weight_hh_l0: 0.0020079801324754953 0.14650388062000275
decider.lstm.bias_ih_l0: -0.019304094836115837 0.14099891483783722
decider.lstm.bias_hh_l0: 0.016516799107193947 0.15368697047233582
decider.linear1.weight: 0.004812698811292648 0.12064724415540695
decider.linear1.bias: 0.008538966067135334 0.11537554860115051
decider.linear2.weight: 0.0027815871872007847 0.05384514108300209
decider.linear2.bias: 0.002684822306036949 0.051462411880493164
decider.linear3.weight: -0.003228951944038272 0.05810819938778877
decider.linear3.bias: -0.016790518537163734 0.03485032543540001

Rewards:
65.8452
65.8452
65.8452
objective = 0.014203732833266258
==== episode 13600/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9997 0.0000 0.0002 0.0000

action = 2
probs = 0.0001 0.0000 0.9998 0.0001

Learning rate: 7.6234e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018465433968231082 0.08362866938114166
encoder.encoder.weight_hh_l0: -0.0007147282012738287 0.08586332947015762
encoder.encoder.bias_ih_l0: 0.00829404592514038 0.08821269124746323
encoder.encoder.bias_hh_l0: 0.021366050466895103 0.0872148796916008
encoder.encoder.weight_ih_l0_reverse: 0.002244971226900816 0.08507507294416428
encoder.encoder.weight_hh_l0_reverse: 0.00034594611497595906 0.08482568711042404
encoder.encoder.bias_ih_l0_reverse: 0.017560049891471863 0.08250394463539124
encoder.encoder.bias_hh_l0_reverse: 0.01785469986498356 0.08839895576238632
decider.lstm.weight_ih_l0: -0.0012629866832867265 0.14664998650550842
decider.lstm.weight_hh_l0: 0.0020281358156353235 0.14651256799697876
decider.lstm.bias_ih_l0: -0.019250674173235893 0.140987828373909
decider.lstm.bias_hh_l0: 0.016570232808589935 0.1536937952041626
decider.linear1.weight: 0.004825751297175884 0.1206618994474411
decider.linear1.bias: 0.008582178503274918 0.11538121104240417
decider.linear2.weight: 0.002797964494675398 0.053884357213974
decider.linear2.bias: 0.0027265886310487986 0.05146503821015358
decider.linear3.weight: -0.0032585200387984514 0.058234453201293945
decider.linear3.bias: -0.01679696887731552 0.03486787527799606

Rewards:
65.8452
65.8452
65.8452
objective = 0.01255895011126995
==== episode 13700/75000 ====
action = 0
probs = 0.9996 0.0001 0.0002 0.0000

action = 0
probs = 0.9994 0.0001 0.0005 0.0000

action = 2
probs = 0.0001 0.0000 0.9999 0.0001

Learning rate: 7.6234e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0017660502344369888 0.08349950611591339
encoder.encoder.weight_hh_l0: -0.0006981943151913583 0.0856686607003212
encoder.encoder.bias_ih_l0: 0.007599635049700737 0.08802660554647446
encoder.encoder.bias_hh_l0: 0.02067163959145546 0.08698130398988724
encoder.encoder.weight_ih_l0_reverse: 0.002186187542974949 0.0849541649222374
encoder.encoder.weight_hh_l0_reverse: 0.00033940261346288025 0.08464771509170532
encoder.encoder.bias_ih_l0_reverse: 0.016987403854727745 0.08247735351324081
encoder.encoder.bias_hh_l0_reverse: 0.01728205569088459 0.08813583850860596
decider.lstm.weight_ih_l0: -0.001277605420909822 0.14654971659183502
decider.lstm.weight_hh_l0: 0.0018418243853375316 0.14638561010360718
decider.lstm.bias_ih_l0: -0.019902091473340988 0.14103582501411438
decider.lstm.bias_hh_l0: 0.015918804332613945 0.15358136594295502
decider.linear1.weight: 0.004699062556028366 0.12052491307258606
decider.linear1.bias: 0.008110939525067806 0.11539192497730255
decider.linear2.weight: 0.0026609371416270733 0.053852446377277374
decider.linear2.bias: 0.0025421087630093098 0.0514250285923481
decider.linear3.weight: -0.003273808164522052 0.05819186940789223
decider.linear3.bias: -0.016821933910250664 0.034750647842884064

Rewards:
65.8452
65.8452
65.8452
objective = 0.023531153798103333
==== episode 13800/75000 ====
action = 0
probs = 0.9996 0.0002 0.0002 0.0000

action = 0
probs = 0.9994 0.0001 0.0005 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0001

Learning rate: 7.6234e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001755405217409134 0.08349033445119858
encoder.encoder.weight_hh_l0: -0.0006945569184608757 0.08565226197242737
encoder.encoder.bias_ih_l0: 0.00752920052036643 0.08800540864467621
encoder.encoder.bias_hh_l0: 0.020601199939846992 0.08695566654205322
encoder.encoder.weight_ih_l0_reverse: 0.0021786666475236416 0.08494382351636887
encoder.encoder.weight_hh_l0_reverse: 0.0003361932758707553 0.08463402092456818
encoder.encoder.bias_ih_l0_reverse: 0.016932480037212372 0.08247555047273636
encoder.encoder.bias_hh_l0_reverse: 0.017227131873369217 0.0881119966506958
decider.lstm.weight_ih_l0: -0.0012788629392161965 0.1465393602848053
decider.lstm.weight_hh_l0: 0.0018207497196272016 0.1463746875524521
decider.lstm.bias_ih_l0: -0.01997816003859043 0.14103977382183075
decider.lstm.bias_hh_l0: 0.01584273763000965 0.15357884764671326
decider.linear1.weight: 0.0046844384633004665 0.12051086872816086
decider.linear1.bias: 0.008058628998696804 0.1154043972492218
decider.linear2.weight: 0.0026431819424033165 0.05387992784380913
decider.linear2.bias: 0.002541932975873351 0.05142246186733246
decider.linear3.weight: -0.0032982423435896635 0.05826796218752861
decider.linear3.bias: -0.01683725416660309 0.03475228697061539

Rewards:
65.8452
65.8452
65.8452
objective = 0.024473629891872406
==== episode 13900/75000 ====
action = 0
probs = 0.9996 0.0001 0.0002 0.0000

action = 0
probs = 0.9995 0.0001 0.0004 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 7.6234e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0017644492909312248 0.08350981026887894
encoder.encoder.weight_hh_l0: -0.0006949577364139259 0.08568129688501358
encoder.encoder.bias_ih_l0: 0.007626662030816078 0.08802703768014908
encoder.encoder.bias_hh_l0: 0.0206986665725708 0.08698394149541855
encoder.encoder.weight_ih_l0_reverse: 0.0021845675073564053 0.08496023714542389
encoder.encoder.weight_hh_l0_reverse: 0.0003348098252899945 0.08465941995382309
encoder.encoder.bias_ih_l0_reverse: 0.017011623829603195 0.08247823268175125
encoder.encoder.bias_hh_l0_reverse: 0.01730627566576004 0.08814887702465057
decider.lstm.weight_ih_l0: -0.0012766530271619558 0.14655201137065887
decider.lstm.weight_hh_l0: 0.0018456804100424051 0.1463928520679474
decider.lstm.bias_ih_l0: -0.01989554613828659 0.14102981984615326
decider.lstm.bias_hh_l0: 0.01592535898089409 0.1536002904176712
decider.linear1.weight: 0.004701181314885616 0.12052995711565018
decider.linear1.bias: 0.008122269995510578 0.11541452258825302
decider.linear2.weight: 0.0026645660400390625 0.05391383916139603
decider.linear2.bias: 0.002590023446828127 0.05143014341592789
decider.linear3.weight: -0.0033234134316444397 0.05837270990014076
decider.linear3.bias: -0.01684785820543766 0.034781839698553085

Rewards:
65.8452
65.8452
65.8452
objective = 0.02097252570092678
==== episode 14000/75000 ====
action = 0
probs = 0.9997 0.0001 0.0002 0.0000

action = 0
probs = 0.9996 0.0000 0.0004 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 7.5472e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001773083582520485 0.08352784812450409
encoder.encoder.weight_hh_l0: -0.0006954855052754283 0.0857086256146431
encoder.encoder.bias_ih_l0: 0.007717623375356197 0.08804680407047272
encoder.encoder.bias_hh_l0: 0.020789626985788345 0.0870097205042839
encoder.encoder.weight_ih_l0_reverse: 0.0021897575352340937 0.08497527986764908
encoder.encoder.weight_hh_l0_reverse: 0.0003337966336403042 0.08468218147754669
encoder.encoder.bias_ih_l0_reverse: 0.0170827005058527 0.08248117566108704
encoder.encoder.bias_hh_l0_reverse: 0.017377348616719246 0.08818252384662628
decider.lstm.weight_ih_l0: -0.0012745825806632638 0.14656411111354828
decider.lstm.weight_hh_l0: 0.001869799685664475 0.14640949666500092
decider.lstm.bias_ih_l0: -0.01981576532125473 0.1410200297832489
decider.lstm.bias_hh_l0: 0.016005128622055054 0.15361672639846802
decider.linear1.weight: 0.0047164782881736755 0.12054816633462906
decider.linear1.bias: 0.008180856704711914 0.1154237687587738
decider.linear2.weight: 0.0026858518831431866 0.05394453927874565
decider.linear2.bias: 0.0026345746591687202 0.05143827572464943
decider.linear3.weight: -0.0033467006869614124 0.058470942080020905
decider.linear3.bias: -0.016857773065567017 0.03480881452560425

Rewards:
65.8452
65.8452
65.8452
objective = 0.018293552100658417
==== episode 14100/75000 ====
action = 0
probs = 0.9997 0.0001 0.0002 0.0000

action = 0
probs = 0.9996 0.0000 0.0003 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 7.5472e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001781158265657723 0.08354431390762329
encoder.encoder.weight_hh_l0: -0.0006960496539250016 0.08573386818170547
encoder.encoder.bias_ih_l0: 0.007801656611263752 0.08806502819061279
encoder.encoder.bias_hh_l0: 0.02087366208434105 0.08703307807445526
encoder.encoder.weight_ih_l0_reverse: 0.0021942793391644955 0.08498891443014145
encoder.encoder.weight_hh_l0_reverse: 0.000333068281179294 0.08470242470502853
encoder.encoder.bias_ih_l0_reverse: 0.017146330326795578 0.08248409628868103
encoder.encoder.bias_hh_l0_reverse: 0.017440976575016975 0.08821303397417068
decider.lstm.weight_ih_l0: -0.0012727526482194662 0.14657534658908844
decider.lstm.weight_hh_l0: 0.0018918601563200355 0.14642444252967834
decider.lstm.bias_ih_l0: -0.019742710515856743 0.14101140201091766
decider.lstm.bias_hh_l0: 0.016078175976872444 0.153630793094635
decider.linear1.weight: 0.004730750806629658 0.12056516110897064
decider.linear1.bias: 0.008235670626163483 0.11543207615613937
decider.linear2.weight: 0.0027061891742050648 0.05397270247340202
decider.linear2.bias: 0.002675382187590003 0.05144656077027321
decider.linear3.weight: -0.003368234261870384 0.05856284126639366
decider.linear3.bias: -0.01686701737344265 0.03483351320028305

Rewards:
65.8452
65.8452
65.8452
objective = 0.016169589012861252
==== episode 14200/75000 ====
action = 0
probs = 0.9997 0.0001 0.0001 0.0000

action = 0
probs = 0.9997 0.0000 0.0003 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 7.5472e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001788864377886057 0.08355961740016937
encoder.encoder.weight_hh_l0: -0.0006966512301005423 0.08575763553380966
encoder.encoder.bias_ih_l0: 0.00788047257810831 0.0880819633603096
encoder.encoder.bias_hh_l0: 0.02095247246325016 0.08705495297908783
encoder.encoder.weight_ih_l0_reverse: 0.002198240254074335 0.0850013941526413
encoder.encoder.weight_hh_l0_reverse: 0.00033256440656259656 0.08472081273794174
encoder.encoder.bias_ih_l0_reverse: 0.01720423623919487 0.08248674124479294
encoder.encoder.bias_hh_l0_reverse: 0.017498884350061417 0.08824169635772705
decider.lstm.weight_ih_l0: -0.0012710471637547016 0.14658606052398682
decider.lstm.weight_hh_l0: 0.0019132912857457995 0.1464381068944931
decider.lstm.bias_ih_l0: -0.019672097638249397 0.14100417494773865
decider.lstm.bias_hh_l0: 0.016148779541254044 0.15364214777946472
decider.linear1.weight: 0.004744339734315872 0.1205814927816391
decider.linear1.bias: 0.008287936449050903 0.11543931812047958
decider.linear2.weight: 0.0027263446245342493 0.053998734802007675
decider.linear2.bias: 0.0027137945871800184 0.051454249769449234
decider.linear3.weight: -0.0033885191660374403 0.058650340884923935
decider.linear3.bias: -0.016875773668289185 0.03485659882426262

Rewards:
65.8452
65.8452
65.8452
objective = 0.014444833621382713
==== episode 14300/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9997 0.0000 0.0002 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 7.5472e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0017962330020964146 0.08357395231723785
encoder.encoder.weight_hh_l0: -0.0006972896517254412 0.08578012883663177
encoder.encoder.bias_ih_l0: 0.00795474462211132 0.0880977138876915
encoder.encoder.bias_hh_l0: 0.021026743575930595 0.08707544207572937
encoder.encoder.weight_ih_l0_reverse: 0.002201744355261326 0.08501289039850235
encoder.encoder.weight_hh_l0_reverse: 0.00033223157515749335 0.0847376212477684
encoder.encoder.bias_ih_l0_reverse: 0.0172575693577528 0.08248911798000336
encoder.encoder.bias_hh_l0_reverse: 0.017552215605974197 0.08826872706413269
decider.lstm.weight_ih_l0: -0.001269437838345766 0.14659617841243744
decider.lstm.weight_hh_l0: 0.0019341371953487396 0.14645077288150787
decider.lstm.bias_ih_l0: -0.01960386335849762 0.14099755883216858
decider.lstm.bias_hh_l0: 0.016217026859521866 0.15365181863307953
decider.linear1.weight: 0.004757288843393326 0.12059720605611801
decider.linear1.bias: 0.008337639272212982 0.11544623970985413
decider.linear2.weight: 0.0027453401125967503 0.05402356758713722
decider.linear2.bias: 0.0027496791444718838 0.05146162211894989
decider.linear3.weight: -0.0034077847376465797 0.05873433127999306
decider.linear3.bias: -0.01688414067029953 0.034878406673669815

Rewards:
65.8452
65.8452
65.8452
objective = 0.012998859398066998
==== episode 14400/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9997 0.0000 0.0002 0.0000

action = 2
probs = 0.0000 0.0000 0.9999 0.0000

Learning rate: 7.5472e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018033052328974009 0.08358742296695709
encoder.encoder.weight_hh_l0: -0.0006979316822253168 0.08580152690410614
encoder.encoder.bias_ih_l0: 0.00802534818649292 0.08811254054307938
encoder.encoder.bias_hh_l0: 0.021097347140312195 0.08709462732076645
encoder.encoder.weight_ih_l0_reverse: 0.0022049571853131056 0.0850236713886261
encoder.encoder.weight_hh_l0_reverse: 0.0003320170217193663 0.08475319296121597
encoder.encoder.bias_ih_l0_reverse: 0.017307523638010025 0.0824911892414093
encoder.encoder.bias_hh_l0_reverse: 0.017602162435650826 0.08829418569803238
decider.lstm.weight_ih_l0: -0.0012679224601015449 0.1466057449579239
decider.lstm.weight_hh_l0: 0.0019540158100426197 0.14646273851394653
decider.lstm.bias_ih_l0: -0.0195390023291111 0.14099086821079254
decider.lstm.bias_hh_l0: 0.016281895339488983 0.15366089344024658
decider.linear1.weight: 0.0047697024419903755 0.12061231583356857
decider.linear1.bias: 0.008385146968066692 0.11545303463935852
decider.linear2.weight: 0.002762984950095415 0.05404767766594887
decider.linear2.bias: 0.0027831317856907845 0.05146884173154831
decider.linear3.weight: -0.0034261937253177166 0.05881543830037117
decider.linear3.bias: -0.01689213700592518 0.03489905595779419

Rewards:
65.8452
65.8452
65.8452
objective = 0.011751821264624596
==== episode 14500/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9998 0.0000 0.0002 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.4717e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018101409077644348 0.08360018581151962
encoder.encoder.weight_hh_l0: -0.0006985687068663538 0.08582209050655365
encoder.encoder.bias_ih_l0: 0.00809305626899004 0.08812657743692398
encoder.encoder.bias_hh_l0: 0.02116505615413189 0.08711270242929459
encoder.encoder.weight_ih_l0_reverse: 0.0022079071495682 0.0850338488817215
encoder.encoder.weight_hh_l0_reverse: 0.000331894465489313 0.08476775884628296
encoder.encoder.bias_ih_l0_reverse: 0.017354680225253105 0.08249300718307495
encoder.encoder.bias_hh_l0_reverse: 0.017649322748184204 0.08831843733787537
decider.lstm.weight_ih_l0: -0.0012664789101108909 0.14661484956741333
decider.lstm.weight_hh_l0: 0.0019732252694666386 0.14647409319877625
decider.lstm.bias_ih_l0: -0.019476626068353653 0.14098404347896576
decider.lstm.bias_hh_l0: 0.01634427160024643 0.15366940200328827
decider.linear1.weight: 0.00478168111294508 0.12062694132328033
decider.linear1.bias: 0.008430931717157364 0.11545959860086441
decider.linear2.weight: 0.0027803536504507065 0.05407078191637993
decider.linear2.bias: 0.002815786749124527 0.05147619917988777
decider.linear3.weight: -0.003443850204348564 0.05889401212334633
decider.linear3.bias: -0.016899820417165756 0.034918732941150665

Rewards:
65.8452
65.8452
65.8452
objective = 0.01066445093601942
==== episode 14600/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9998 0.0000 0.0002 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.4717e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001816695905290544 0.08361220359802246
encoder.encoder.weight_hh_l0: -0.0006991936825215816 0.08584170788526535
encoder.encoder.bias_ih_l0: 0.00815751776099205 0.08813979476690292
encoder.encoder.bias_hh_l0: 0.021229518577456474 0.0871296152472496
encoder.encoder.weight_ih_l0_reverse: 0.002210614737123251 0.08504342287778854
encoder.encoder.weight_hh_l0_reverse: 0.0003318479866720736 0.08478131145238876
encoder.encoder.bias_ih_l0_reverse: 0.017399001866579056 0.0824945792555809
encoder.encoder.bias_hh_l0_reverse: 0.017693646252155304 0.0883413776755333
decider.lstm.weight_ih_l0: -0.00126511394046247 0.14662349224090576
decider.lstm.weight_hh_l0: 0.0019916226156055927 0.1464848667383194
decider.lstm.bias_ih_l0: -0.019417140632867813 0.1409771591424942
decider.lstm.bias_hh_l0: 0.01640378311276436 0.15367746353149414
decider.linear1.weight: 0.00479315547272563 0.12064099311828613
decider.linear1.bias: 0.008474742993712425 0.1154659241437912
decider.linear2.weight: 0.002796646673232317 0.05409310385584831
decider.linear2.bias: 0.002846253802999854 0.051483284682035446
decider.linear3.weight: -0.0034606666304171085 0.05896952003240585
decider.linear3.bias: -0.016907161101698875 0.03493736684322357

Rewards:
65.8452
65.8452
65.8452
objective = 0.009715799242258072
==== episode 14700/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9998 0.0000 0.0002 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.4717e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018230709247291088 0.08362369239330292
encoder.encoder.weight_hh_l0: -0.0006998128956183791 0.08586069941520691
encoder.encoder.bias_ih_l0: 0.008219767361879349 0.08815242350101471
encoder.encoder.bias_hh_l0: 0.021291768178343773 0.08714568614959717
encoder.encoder.weight_ih_l0_reverse: 0.0022131367586553097 0.08505254983901978
encoder.encoder.weight_hh_l0_reverse: 0.0003318643430247903 0.08479411154985428
encoder.encoder.bias_ih_l0_reverse: 0.017441248521208763 0.08249597251415253
encoder.encoder.bias_hh_l0_reverse: 0.01773589290678501 0.0883634090423584
decider.lstm.weight_ih_l0: -0.0012638051994144917 0.14663179218769073
decider.lstm.weight_hh_l0: 0.0020095002837479115 0.14649520814418793
decider.lstm.bias_ih_l0: -0.01935957372188568 0.14097018539905548
decider.lstm.bias_hh_l0: 0.01646132953464985 0.1536850929260254
decider.linear1.weight: 0.004804297350347042 0.12065467238426208
decider.linear1.bias: 0.008517200127243996 0.11547207087278366
decider.linear2.weight: 0.002812449587509036 0.054114773869514465
decider.linear2.bias: 0.0028756214305758476 0.05149034038186073
decider.linear3.weight: -0.0034768893383443356 0.05904296040534973
decider.linear3.bias: -0.016914263367652893 0.03495525196194649

Rewards:
65.8452
65.8452
65.8452
objective = 0.008877076208591461
==== episode 14800/75000 ====
action = 0
probs = 0.9998 0.0001 0.0001 0.0000

action = 0
probs = 0.9998 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.4717e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001829285523854196 0.08363470435142517
encoder.encoder.weight_hh_l0: -0.0007004269282333553 0.08587910979986191
encoder.encoder.bias_ih_l0: 0.008280039764940739 0.08816453069448471
encoder.encoder.bias_hh_l0: 0.021352039650082588 0.08716098964214325
encoder.encoder.weight_ih_l0_reverse: 0.00221549766138196 0.08506128191947937
encoder.encoder.weight_hh_l0_reverse: 0.00033193526905961335 0.08480624109506607
encoder.encoder.bias_ih_l0_reverse: 0.017481666058301926 0.08249718695878983
encoder.encoder.bias_hh_l0_reverse: 0.017776308581233025 0.08838462084531784
decider.lstm.weight_ih_l0: -0.0012625467497855425 0.14663977921009064
decider.lstm.weight_hh_l0: 0.0020269150845706463 0.14650516211986542
decider.lstm.bias_ih_l0: -0.019303733482956886 0.14096315205097198
decider.lstm.bias_hh_l0: 0.016517166048288345 0.15369242429733276
decider.linear1.weight: 0.004815139342099428 0.12066803872585297
decider.linear1.bias: 0.008558466099202633 0.11547808349132538
decider.linear2.weight: 0.0028278266545385122 0.05413590744137764
decider.linear2.bias: 0.002903972752392292 0.05149737000465393
decider.linear3.weight: -0.0034925704821944237 0.059114500880241394
decider.linear3.bias: -0.016921110451221466 0.03497239574790001

Rewards:
65.8452
65.8452
65.8452
objective = 0.00813257321715355
==== episode 14900/75000 ====
action = 0
probs = 0.9999 0.0001 0.0001 0.0000

action = 0
probs = 0.9998 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.4717e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001835355767980218 0.08364526182413101
encoder.encoder.weight_hh_l0: -0.0007010356639511883 0.08589700609445572
encoder.encoder.bias_ih_l0: 0.008338510990142822 0.0881761759519577
encoder.encoder.bias_hh_l0: 0.021410508081316948 0.08717560768127441
encoder.encoder.weight_ih_l0_reverse: 0.002217720728367567 0.08506966382265091
encoder.encoder.weight_hh_l0_reverse: 0.0003320523537695408 0.08481777459383011
encoder.encoder.bias_ih_l0_reverse: 0.017520448192954063 0.08249825984239578
encoder.encoder.bias_hh_l0_reverse: 0.017815088853240013 0.088405080139637
decider.lstm.weight_ih_l0: -0.0012613360304385424 0.14664749801158905
decider.lstm.weight_hh_l0: 0.0020438875071704388 0.14651475846767426
decider.lstm.bias_ih_l0: -0.019249524921178818 0.14095599949359894
decider.lstm.bias_hh_l0: 0.016571391373872757 0.15369953215122223
decider.linear1.weight: 0.0048257093876600266 0.12068107724189758
decider.linear1.bias: 0.008598631247878075 0.11548396199941635
decider.linear2.weight: 0.0028426756616681814 0.05415680631995201
decider.linear2.bias: 0.0029309969395399094 0.05150419473648071
decider.linear3.weight: -0.0035077587235718966 0.059184301644563675
decider.linear3.bias: -0.01692778244614601 0.03498896211385727

Rewards:
65.8452
65.8452
65.8452
objective = 0.007470511831343174
==== episode 15000/75000 ====
action = 0
probs = 0.9999 0.0001 0.0001 0.0000

action = 0
probs = 0.9998 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.3970e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018412999343127012 0.08365543186664581
encoder.encoder.weight_hh_l0: -0.0007016413728706539 0.08591444045305252
encoder.encoder.bias_ih_l0: 0.008395370095968246 0.08818741887807846
encoder.encoder.bias_hh_l0: 0.02146737091243267 0.08718959242105484
encoder.encoder.weight_ih_l0_reverse: 0.0022198124788701534 0.08507774025201797
encoder.encoder.weight_hh_l0_reverse: 0.00033220771001651883 0.08482877165079117
encoder.encoder.bias_ih_l0_reverse: 0.01755770668387413 0.0824991911649704
encoder.encoder.bias_hh_l0_reverse: 0.01785234361886978 0.08842482417821884
decider.lstm.weight_ih_l0: -0.0012601715279743075 0.14665497839450836
decider.lstm.weight_hh_l0: 0.002060433616861701 0.14652405679225922
decider.lstm.bias_ih_l0: -0.019196856766939163 0.14094871282577515
decider.lstm.bias_hh_l0: 0.01662403903901577 0.15370632708072662
decider.linear1.weight: 0.004836022853851318 0.12069384753704071
decider.linear1.bias: 0.008637730032205582 0.115489661693573
decider.linear2.weight: 0.0028573963791131973 0.05417731776833534
decider.linear2.bias: 0.0029574776999652386 0.051511067897081375
decider.linear3.weight: -0.0035225022584199905 0.05925252288579941
decider.linear3.bias: -0.016934290528297424 0.03500501066446304

Rewards:
65.8452
65.8452
65.8452
objective = 0.00687387865036726
==== episode 15100/75000 ====
action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.3970e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018470732029527426 0.0836651548743248
encoder.encoder.weight_hh_l0: -0.0007022350328043103 0.08593130111694336
encoder.encoder.bias_ih_l0: 0.008450248278677464 0.08819818496704102
encoder.encoder.bias_hh_l0: 0.021522250026464462 0.08720289170742035
encoder.encoder.weight_ih_l0_reverse: 0.0022217766381800175 0.08508545905351639
encoder.encoder.weight_hh_l0_reverse: 0.00033239598269574344 0.08483919501304626
encoder.encoder.bias_ih_l0_reverse: 0.017593305557966232 0.08250001072883606
encoder.encoder.bias_hh_l0_reverse: 0.017887940630316734 0.08844377845525742
decider.lstm.weight_ih_l0: -0.0012590588303282857 0.1466621458530426
decider.lstm.weight_hh_l0: 0.0020764851942658424 0.14653295278549194
decider.lstm.bias_ih_l0: -0.01914597488939762 0.14094139635562897
decider.lstm.bias_hh_l0: 0.016674943268299103 0.15371280908584595
decider.linear1.weight: 0.004846015013754368 0.12070625275373459
decider.linear1.bias: 0.008675577118992805 0.1154952123761177
decider.linear2.weight: 0.002871610689908266 0.05419744551181793
decider.linear2.bias: 0.0029827463440597057 0.051517777144908905
decider.linear3.weight: -0.0035366970114409924 0.059318654239177704
decider.linear3.bias: -0.016940519213676453 0.03502029925584793

Rewards:
65.8452
65.8452
65.8452
objective = 0.006342670880258083
==== episode 15200/75000 ====
action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.3970e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001852750196121633 0.08367455750703812
encoder.encoder.weight_hh_l0: -0.0007028217078186572 0.08594781160354614
encoder.encoder.bias_ih_l0: 0.008503880351781845 0.08820861577987671
encoder.encoder.bias_hh_l0: 0.02157587930560112 0.08721567690372467
encoder.encoder.weight_ih_l0_reverse: 0.0022236458025872707 0.0850929245352745
encoder.encoder.weight_hh_l0_reverse: 0.00033261359203606844 0.08484920859336853
encoder.encoder.bias_ih_l0_reverse: 0.01762775331735611 0.08250072598457336
encoder.encoder.bias_hh_l0_reverse: 0.01792239025235176 0.0884622260928154
decider.lstm.weight_ih_l0: -0.0012579753529280424 0.14666911959648132
decider.lstm.weight_hh_l0: 0.002092252019792795 0.14654164016246796
decider.lstm.bias_ih_l0: -0.019096164032816887 0.140934020280838
decider.lstm.bias_hh_l0: 0.016724765300750732 0.15371912717819214
decider.linear1.weight: 0.004855816252529621 0.12071844935417175
decider.linear1.bias: 0.008712638169527054 0.11550062894821167
decider.linear2.weight: 0.00288559403270483 0.05421736463904381
decider.linear2.bias: 0.003007318824529648 0.05152444168925285
decider.linear3.weight: -0.003550529247149825 0.05938350036740303
decider.linear3.bias: -0.01694667339324951 0.035035282373428345

Rewards:
65.8452
65.8452
65.8452
objective = 0.005861186888068914
==== episode 15300/75000 ====
action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.3970e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018583410419523716 0.08368368446826935
encoder.encoder.weight_hh_l0: -0.0007034020381979644 0.08596400916576385
encoder.encoder.bias_ih_l0: 0.008556378073990345 0.08821876347064972
encoder.encoder.bias_hh_l0: 0.021628374233841896 0.08722800761461258
encoder.encoder.weight_ih_l0_reverse: 0.0022254299838095903 0.08510015904903412
encoder.encoder.weight_hh_l0_reverse: 0.00033285774406977 0.08485882729291916
encoder.encoder.bias_ih_l0_reverse: 0.01766115240752697 0.0825013518333435
encoder.encoder.bias_hh_l0_reverse: 0.01795579306781292 0.08848019689321518
decider.lstm.weight_ih_l0: -0.001256926916539669 0.1466759294271469
decider.lstm.weight_hh_l0: 0.0021077722776681185 0.14655007421970367
decider.lstm.bias_ih_l0: -0.01904732547700405 0.14092659950256348
decider.lstm.bias_hh_l0: 0.01677362620830536 0.1537252962589264
decider.linear1.weight: 0.004865444265305996 0.1207304373383522
decider.linear1.bias: 0.008748967200517654 0.11550597101449966
decider.linear2.weight: 0.002899354323744774 0.05423709750175476
decider.linear2.bias: 0.0030312538146972656 0.05153108015656471
decider.linear3.weight: -0.0035640245769172907 0.059447143226861954
decider.linear3.bias: -0.01695261150598526 0.035049695521593094

Rewards:
65.8452
65.8452
65.8452
objective = 0.005424192175269127
==== episode 15400/75000 ====
action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.3970e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018638548208400607 0.08369255065917969
encoder.encoder.weight_hh_l0: -0.0007039750926196575 0.08597990870475769
encoder.encoder.bias_ih_l0: 0.008607834577560425 0.08822865039110184
encoder.encoder.bias_hh_l0: 0.02167983539402485 0.08723991364240646
encoder.encoder.weight_ih_l0_reverse: 0.0022271391935646534 0.08510719239711761
encoder.encoder.weight_hh_l0_reverse: 0.00033312555751763284 0.08486809581518173
encoder.encoder.bias_ih_l0_reverse: 0.01769358664751053 0.08250189572572708
encoder.encoder.bias_hh_l0_reverse: 0.017988231033086777 0.08849772810935974
decider.lstm.weight_ih_l0: -0.0012559023452922702 0.14668259024620056
decider.lstm.weight_hh_l0: 0.002123060170561075 0.14655831456184387
decider.lstm.bias_ih_l0: -0.018999356776475906 0.14091911911964417
decider.lstm.bias_hh_l0: 0.016821585595607758 0.1537313312292099
decider.linear1.weight: 0.004874910693615675 0.12074224650859833
decider.linear1.bias: 0.008784622885286808 0.11551123112440109
decider.linear2.weight: 0.0029128766618669033 0.05425667762756348
decider.linear2.bias: 0.0030545564368367195 0.051537662744522095
decider.linear3.weight: -0.003577199764549732 0.059509653598070145
decider.linear3.bias: -0.016958504915237427 0.03506387770175934

Rewards:
65.8452
65.8452
65.8452
objective = 0.005027759820222855
==== episode 15500/75000 ====
action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.3230e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018692993326112628 0.08370117098093033
encoder.encoder.weight_hh_l0: -0.000704541802406311 0.08599556237459183
encoder.encoder.bias_ih_l0: 0.008658348582684994 0.08823829144239426
encoder.encoder.bias_hh_l0: 0.021730350330471992 0.08725141733884811
encoder.encoder.weight_ih_l0_reverse: 0.0022287783212959766 0.08511403948068619
encoder.encoder.weight_hh_l0_reverse: 0.00033341458765789866 0.08487704396247864
encoder.encoder.bias_ih_l0_reverse: 0.01772514171898365 0.08250237256288528
encoder.encoder.bias_hh_l0_reverse: 0.0180197861045599 0.08851485699415207
decider.lstm.weight_ih_l0: -0.0012549057137221098 0.14668908715248108
decider.lstm.weight_hh_l0: 0.0021381541155278683 0.14656637609004974
decider.lstm.bias_ih_l0: -0.01895221695303917 0.1409115195274353
decider.lstm.bias_hh_l0: 0.016868717968463898 0.1537371575832367
decider.linear1.weight: 0.00488422904163599 0.12075390666723251
decider.linear1.bias: 0.00881968718022108 0.11551642417907715
decider.linear2.weight: 0.0029261955060064793 0.05427609756588936
decider.linear2.bias: 0.0030773133039474487 0.051544226706027985
decider.linear3.weight: -0.0035900825168937445 0.05957109481096268
decider.linear3.bias: -0.01696421578526497 0.03507758304476738

Rewards:
65.8452
65.8452
65.8452
objective = 0.004665347281843424
==== episode 15600/75000 ====
action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.3230e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018746311543509364 0.0837094858288765
encoder.encoder.weight_hh_l0: -0.0007050958229228854 0.08601082861423492
encoder.encoder.bias_ih_l0: 0.008707518689334393 0.0882476195693016
encoder.encoder.bias_hh_l0: 0.02177952229976654 0.08726246654987335
encoder.encoder.weight_ih_l0_reverse: 0.0022303408477455378 0.08512063324451447
encoder.encoder.weight_hh_l0_reverse: 0.0003337207599543035 0.0848855972290039
encoder.encoder.bias_ih_l0_reverse: 0.01775558665394783 0.08250276744365692
encoder.encoder.bias_hh_l0_reverse: 0.01805022917687893 0.08853144943714142
decider.lstm.weight_ih_l0: -0.0012539445888251066 0.14669539034366608
decider.lstm.weight_hh_l0: 0.0021529127843677998 0.14657418429851532
decider.lstm.bias_ih_l0: -0.01890629157423973 0.14090396463871002
decider.lstm.bias_hh_l0: 0.016914639621973038 0.15374280512332916
decider.linear1.weight: 0.004893322940915823 0.12076529115438461
decider.linear1.bias: 0.008853846229612827 0.11552151292562485
decider.linear2.weight: 0.0029392093420028687 0.05429515987634659
decider.linear2.bias: 0.003099378664046526 0.05155070871114731
decider.linear3.weight: -0.0036025673616677523 0.059630949050188065
decider.linear3.bias: -0.01696980744600296 0.035090915858745575

Rewards:
65.8452
65.8452
65.8452
objective = 0.004338262137025595
==== episode 15700/75000 ====
action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.3230e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00187993876170367 0.08371764421463013
encoder.encoder.weight_hh_l0: -0.0007056519389152527 0.08602598309516907
encoder.encoder.bias_ih_l0: 0.00875608716160059 0.08825670927762985
encoder.encoder.bias_hh_l0: 0.02182808890938759 0.08727318048477173
encoder.encoder.weight_ih_l0_reverse: 0.002231875667348504 0.08512711524963379
encoder.encoder.weight_hh_l0_reverse: 0.00033404078567400575 0.08489394187927246
encoder.encoder.bias_ih_l0_reverse: 0.017785344272851944 0.08250314742326736
encoder.encoder.bias_hh_l0_reverse: 0.018079986795783043 0.08854766935110092
decider.lstm.weight_ih_l0: -0.0012529907980933785 0.1467016041278839
decider.lstm.weight_hh_l0: 0.002167687751352787 0.14658190310001373
decider.lstm.bias_ih_l0: -0.01886051520705223 0.14089614152908325
decider.lstm.bias_hh_l0: 0.01696041412651539 0.15374799072742462
decider.linear1.weight: 0.004902317188680172 0.12077660858631134
decider.linear1.bias: 0.008887588046491146 0.11552688479423523
decider.linear2.weight: 0.0029521374963223934 0.05431407317519188
decider.linear2.bias: 0.0031210537999868393 0.05155722796916962
decider.linear3.weight: -0.0036148023791611195 0.05968990549445152
decider.linear3.bias: -0.016975320875644684 0.03510398417711258

Rewards:
65.8452
65.8452
65.8452
objective = 0.004039962776005268
==== episode 15800/75000 ====
action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.3230e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001885205158032477 0.08372561633586884
encoder.encoder.weight_hh_l0: -0.0007062008953653276 0.08604095876216888
encoder.encoder.bias_ih_l0: 0.008803988806903362 0.08826562762260437
encoder.encoder.bias_hh_l0: 0.021875988692045212 0.08728359639644623
encoder.encoder.weight_ih_l0_reverse: 0.002233360894024372 0.08513346314430237
encoder.encoder.weight_hh_l0_reverse: 0.00033437536330893636 0.08490204811096191
encoder.encoder.bias_ih_l0_reverse: 0.01781444251537323 0.08250346034765244
encoder.encoder.bias_hh_l0_reverse: 0.01810908131301403 0.08856360614299774
decider.lstm.weight_ih_l0: -0.0012520537711679935 0.1467077136039734
decider.lstm.weight_hh_l0: 0.0021823355928063393 0.1465894728899002
decider.lstm.bias_ih_l0: -0.018815290182828903 0.1408882588148117
decider.lstm.bias_hh_l0: 0.017005659639835358 0.1537531167268753
decider.linear1.weight: 0.004911205731332302 0.12078779935836792
decider.linear1.bias: 0.008920884691178799 0.11553222686052322
decider.linear2.weight: 0.0029649240896105766 0.05433283746242523
decider.linear2.bias: 0.003142346628010273 0.05156373605132103
decider.linear3.weight: -0.0036268073599785566 0.05974800884723663
decider.linear3.bias: -0.016980662941932678 0.035116635262966156

Rewards:
65.8452
65.8452
65.8452
objective = 0.003763906192034483
==== episode 15900/75000 ====
action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.3230e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018904305761680007 0.08373341709375381
encoder.encoder.weight_hh_l0: -0.0007067401893436909 0.08605577796697617
encoder.encoder.bias_ih_l0: 0.008851257152855396 0.08827437460422516
encoder.encoder.bias_hh_l0: 0.021923255175352097 0.08729370683431625
encoder.encoder.weight_ih_l0_reverse: 0.0022348000202327967 0.08513966202735901
encoder.encoder.weight_hh_l0_reverse: 0.0003347245219629258 0.08490990847349167
encoder.encoder.bias_ih_l0_reverse: 0.01784292608499527 0.08250372856855392
encoder.encoder.bias_hh_l0_reverse: 0.01813756674528122 0.08857925981283188
decider.lstm.weight_ih_l0: -0.0012511307140812278 0.1467137187719345
decider.lstm.weight_hh_l0: 0.0021968651562929153 0.14659690856933594
decider.lstm.bias_ih_l0: -0.01877061277627945 0.140880286693573
decider.lstm.bias_hh_l0: 0.017050286754965782 0.15375809371471405
decider.linear1.weight: 0.004920001607388258 0.12079887837171555
decider.linear1.bias: 0.008953748270869255 0.11553750187158585
decider.linear2.weight: 0.00297751696780324 0.054351482540369034
decider.linear2.bias: 0.0031631984747946262 0.05157020315527916
decider.linear3.weight: -0.0036385932471603155 0.05980530381202698
decider.linear3.bias: -0.016985975205898285 0.0351291298866272

Rewards:
65.8452
65.8452
65.8452
objective = 0.0035087838768959045
==== episode 16000/75000 ====
action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.2498e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0018956197891384363 0.08374105393886566
encoder.encoder.weight_hh_l0: -0.0007072696462273598 0.08607044070959091
encoder.encoder.bias_ih_l0: 0.00889794435352087 0.0882829800248146
encoder.encoder.bias_hh_l0: 0.021969947963953018 0.0873035341501236
encoder.encoder.weight_ih_l0_reverse: 0.00223619700409472 0.0851457417011261
encoder.encoder.weight_hh_l0_reverse: 0.00033508538035675883 0.08491755276918411
encoder.encoder.bias_ih_l0_reverse: 0.0178708303719759 0.08250394463539124
encoder.encoder.bias_hh_l0_reverse: 0.0181654691696167 0.08859465271234512
decider.lstm.weight_ih_l0: -0.001250223140232265 0.14671963453292847
decider.lstm.weight_hh_l0: 0.0022112871520221233 0.1466042399406433
decider.lstm.bias_ih_l0: -0.018726438283920288 0.14087225496768951
decider.lstm.bias_hh_l0: 0.01709446683526039 0.15376310050487518
decider.linear1.weight: 0.004928705282509327 0.1208098754286766
decider.linear1.bias: 0.008986216969788074 0.1155427098274231
decider.linear2.weight: 0.002989940345287323 0.05436999723315239
decider.linear2.bias: 0.0031836465932428837 0.05157662555575371
decider.linear3.weight: -0.0036501737777143717 0.059861816465854645
decider.linear3.bias: -0.016991261392831802 0.035141490399837494

Rewards:
65.8452
65.8452
65.8452
objective = 0.0032745960634201765
==== episode 16100/75000 ====
action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0000 0.0001 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.2498e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0019007264636456966 0.0837484747171402
encoder.encoder.weight_hh_l0: -0.0007077822228893638 0.08608486503362656
encoder.encoder.bias_ih_l0: 0.00894363783299923 0.08829137682914734
encoder.encoder.bias_hh_l0: 0.022015638649463654 0.08731310069561005
encoder.encoder.weight_ih_l0_reverse: 0.002237509237602353 0.08515165001153946
encoder.encoder.weight_hh_l0_reverse: 0.0003354549698997289 0.08492488414049149
encoder.encoder.bias_ih_l0_reverse: 0.017897702753543854 0.08250422030687332
encoder.encoder.bias_hh_l0_reverse: 0.018192337825894356 0.08860966563224792
decider.lstm.weight_ih_l0: -0.0012493532849475741 0.14672541618347168
decider.lstm.weight_hh_l0: 0.0022256344091147184 0.14661137759685516
decider.lstm.bias_ih_l0: -0.01868276484310627 0.14086443185806274
decider.lstm.bias_hh_l0: 0.017138158902525902 0.15376785397529602
decider.linear1.weight: 0.004937285091727972 0.12082073837518692
decider.linear1.bias: 0.009018182754516602 0.11554787307977676
decider.linear2.weight: 0.003002454061061144 0.0543879009783268
decider.linear2.bias: 0.0032036746852099895 0.05158298462629318
decider.linear3.weight: -0.00366144347935915 0.059917062520980835
decider.linear3.bias: -0.01699630171060562 0.03515328839421272

Rewards:
65.8452
65.8452
65.8452
objective = 0.0030639588367193937
==== episode 16200/75000 ====
action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.2498e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0019058057805523276 0.08375576138496399
encoder.encoder.weight_hh_l0: -0.0007082863594405353 0.08609917014837265
encoder.encoder.bias_ih_l0: 0.008988884277641773 0.08829966932535172
encoder.encoder.bias_hh_l0: 0.022060874849557877 0.0873224288225174
encoder.encoder.weight_ih_l0_reverse: 0.0022387879434973 0.08515744656324387
encoder.encoder.weight_hh_l0_reverse: 0.0003358334070071578 0.08493202924728394
encoder.encoder.bias_ih_l0_reverse: 0.01792409084737301 0.08250445127487183
encoder.encoder.bias_hh_l0_reverse: 0.01821872405707836 0.08862446248531342
decider.lstm.weight_ih_l0: -0.001248496351763606 0.1467311531305313
decider.lstm.weight_hh_l0: 0.002239919500425458 0.14661842584609985
decider.lstm.bias_ih_l0: -0.018639419227838516 0.14085653424263
decider.lstm.bias_hh_l0: 0.017181526869535446 0.1537725180387497
decider.linear1.weight: 0.004945801105350256 0.12083151936531067
decider.linear1.bias: 0.009049816988408566 0.11555300652980804
decider.linear2.weight: 0.0030148448422551155 0.054405685514211655
decider.linear2.bias: 0.003223382867872715 0.05158931761980057
decider.linear3.weight: -0.0036725387908518314 0.0599716454744339
decider.linear3.bias: -0.01700131967663765 0.035164974629879

Rewards:
65.8452
65.8452
65.8452
objective = 0.0028677135705947876
==== episode 16300/75000 ====
action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.2498e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0019108654232695699 0.08376292139291763
encoder.encoder.weight_hh_l0: -0.0007087814155966043 0.08611339330673218
encoder.encoder.bias_ih_l0: 0.009033715352416039 0.08830785006284714
encoder.encoder.bias_hh_l0: 0.022105710580945015 0.08733153343200684
encoder.encoder.weight_ih_l0_reverse: 0.002240036614239216 0.08516314625740051
encoder.encoder.weight_hh_l0_reverse: 0.0003362216812092811 0.08493900299072266
encoder.encoder.bias_ih_l0_reverse: 0.01795005612075329 0.08250463753938675
encoder.encoder.bias_hh_l0_reverse: 0.018244676291942596 0.08863908052444458
decider.lstm.weight_ih_l0: -0.001247650245204568 0.14673678576946259
decider.lstm.weight_hh_l0: 0.002254137769341469 0.14662538468837738
decider.lstm.bias_ih_l0: -0.01859646663069725 0.14084848761558533
decider.lstm.bias_hh_l0: 0.01722443848848343 0.15377706289291382
decider.linear1.weight: 0.004954256117343903 0.12084223330020905
decider.linear1.bias: 0.009081150405108929 0.11555808782577515
decider.linear2.weight: 0.0030270968563854694 0.05442335829138756
decider.linear2.bias: 0.0032427823171019554 0.05159561708569527
decider.linear3.weight: -0.0036834673956036568 0.06002560630440712
decider.linear3.bias: -0.017006313428282738 0.035176560282707214

Rewards:
65.8452
65.8452
65.8452
objective = 0.002684551989659667
==== episode 16400/75000 ====
action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.2498e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001915904227644205 0.08376994729042053
encoder.encoder.weight_hh_l0: -0.0007092645391821861 0.08612751960754395
encoder.encoder.bias_ih_l0: 0.00907816644757986 0.08831591159105301
encoder.encoder.bias_hh_l0: 0.022150155156850815 0.08734039217233658
encoder.encoder.weight_ih_l0_reverse: 0.0022412578109651804 0.0851687639951706
encoder.encoder.weight_hh_l0_reverse: 0.0003366182208992541 0.08494580537080765
encoder.encoder.bias_ih_l0_reverse: 0.01797560416162014 0.08250477910041809
encoder.encoder.bias_hh_l0_reverse: 0.018270233646035194 0.08865351974964142
decider.lstm.weight_ih_l0: -0.001246815430931747 0.14674237370491028
decider.lstm.weight_hh_l0: 0.002268306678161025 0.14663225412368774
decider.lstm.bias_ih_l0: -0.01855379343032837 0.14084041118621826
decider.lstm.bias_hh_l0: 0.017267048358917236 0.15378162264823914
decider.linear1.weight: 0.004962658043950796 0.12085288017988205
decider.linear1.bias: 0.009112218394875526 0.11556313186883926
decider.linear2.weight: 0.0030392317567020655 0.054440926760435104
decider.linear2.bias: 0.0032619107514619827 0.05160190910100937
decider.linear3.weight: -0.0036942267324775457 0.06007895618677139
decider.linear3.bias: -0.017011284828186035 0.035188037902116776

Rewards:
65.8452
65.8452
65.8452
objective = 0.0025157821364700794
==== episode 16500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.1773e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001920926384627819 0.08377687633037567
encoder.encoder.weight_hh_l0: -0.0007097366033121943 0.08614157140254974
encoder.encoder.bias_ih_l0: 0.009122248739004135 0.08832389116287231
encoder.encoder.bias_hh_l0: 0.022194236516952515 0.0873490571975708
encoder.encoder.weight_ih_l0_reverse: 0.0022424545604735613 0.08517428487539291
encoder.encoder.weight_hh_l0_reverse: 0.0003370226768311113 0.0849524587392807
encoder.encoder.bias_ih_l0_reverse: 0.0180007703602314 0.08250488340854645
encoder.encoder.bias_hh_l0_reverse: 0.0182954054325819 0.08866775780916214
decider.lstm.weight_ih_l0: -0.0012459906283766031 0.146747887134552
decider.lstm.weight_hh_l0: 0.0022824332118034363 0.14663903415203094
decider.lstm.bias_ih_l0: -0.01851145550608635 0.14083221554756165
decider.lstm.bias_hh_l0: 0.017309391871094704 0.15378618240356445
decider.linear1.weight: 0.004971003159880638 0.12086346745491028
decider.linear1.bias: 0.009143001399934292 0.11556816101074219
decider.linear2.weight: 0.00305048655718565 0.05445874482393265
decider.linear2.bias: 0.003280415665358305 0.05160822346806526
decider.linear3.weight: -0.0037048370577394962 0.06013173609972
decider.linear3.bias: -0.01701609417796135 0.03519916534423828

Rewards:
65.8452
65.8452
65.8452
objective = 0.0023574791848659515
==== episode 16600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.1773e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0019258975517004728 0.08378364890813828
encoder.encoder.weight_hh_l0: -0.0007101891096681356 0.08615544438362122
encoder.encoder.bias_ih_l0: 0.009165680035948753 0.08833176642656326
encoder.encoder.bias_hh_l0: 0.022237665951251984 0.08735745400190353
encoder.encoder.weight_ih_l0_reverse: 0.0022436080034822226 0.08517967909574509
encoder.encoder.weight_hh_l0_reverse: 0.00033743184758350253 0.08495889604091644
encoder.encoder.bias_ih_l0_reverse: 0.018025314435362816 0.08250496536493301
encoder.encoder.bias_hh_l0_reverse: 0.01831994764506817 0.08868168294429779
decider.lstm.weight_ih_l0: -0.0012451900402083993 0.14675331115722656
decider.lstm.weight_hh_l0: 0.0022963439114391804 0.1466457098722458
decider.lstm.bias_ih_l0: -0.018469911068677902 0.1408241242170334
decider.lstm.bias_hh_l0: 0.01735089346766472 0.1537906527519226
decider.linear1.weight: 0.004979191347956657 0.12087389826774597
decider.linear1.bias: 0.009173154830932617 0.11557316780090332
decider.linear2.weight: 0.0030623762868344784 0.05447588488459587
decider.linear2.bias: 0.0032990367617458105 0.05161454901099205
decider.linear3.weight: -0.0037152059376239777 0.06018346920609474
decider.linear3.bias: -0.017020808532834053 0.035210028290748596

Rewards:
65.8452
65.8452
65.8452
objective = 0.0022148764692246914
==== episode 16700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.1773e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001930861035361886 0.08379031717777252
encoder.encoder.weight_hh_l0: -0.0007106303819455206 0.08616925776004791
encoder.encoder.bias_ih_l0: 0.009208833798766136 0.08833954483270645
encoder.encoder.bias_hh_l0: 0.022280823439359665 0.08736567944288254
encoder.encoder.weight_ih_l0_reverse: 0.0022447416558861732 0.08518499881029129
encoder.encoder.weight_hh_l0_reverse: 0.0003378478577360511 0.08496519923210144
encoder.encoder.bias_ih_l0_reverse: 0.018049530684947968 0.0825050100684166
encoder.encoder.bias_hh_l0_reverse: 0.01834416389465332 0.0886954516172409
decider.lstm.weight_ih_l0: -0.0012444009771570563 0.14675867557525635
decider.lstm.weight_hh_l0: 0.002310179639607668 0.14665226638317108
decider.lstm.bias_ih_l0: -0.01842869259417057 0.14081595838069916
decider.lstm.bias_hh_l0: 0.017392102628946304 0.15379521250724792
decider.linear1.weight: 0.004987318068742752 0.12088428437709808
decider.linear1.bias: 0.009203021414577961 0.11557814478874207
decider.linear2.weight: 0.003074055537581444 0.0544930025935173
decider.linear2.bias: 0.0033172271214425564 0.0516207255423069
decider.linear3.weight: -0.0037254435010254383 0.060234732925891876
decider.linear3.bias: -0.017025504261255264 0.03522081673145294

Rewards:
65.8452
65.8452
65.8452
objective = 0.002076198346912861
==== episode 16800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.1773e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0019358167191967368 0.0837968960404396
encoder.encoder.weight_hh_l0: -0.0007110568112693727 0.08618303388357162
encoder.encoder.bias_ih_l0: 0.00925171934068203 0.08834727108478546
encoder.encoder.bias_hh_l0: 0.022323710843920708 0.08737371116876602
encoder.encoder.weight_ih_l0_reverse: 0.002245858544483781 0.08519025146961212
encoder.encoder.weight_hh_l0_reverse: 0.0003382695431355387 0.0849713608622551
encoder.encoder.bias_ih_l0_reverse: 0.018073447048664093 0.08250503242015839
encoder.encoder.bias_hh_l0_reverse: 0.018368082121014595 0.08870909363031387
decider.lstm.weight_ih_l0: -0.001243616221472621 0.14676399528980255
decider.lstm.weight_hh_l0: 0.002323990222066641 0.14665882289409637
decider.lstm.bias_ih_l0: -0.018387680873274803 0.14080765843391418
decider.lstm.bias_hh_l0: 0.017433082684874535 0.15379974246025085
decider.linear1.weight: 0.004995367489755154 0.12089459598064423
decider.linear1.bias: 0.009232636541128159 0.11558303982019424
decider.linear2.weight: 0.0030856060329824686 0.05451005697250366
decider.linear2.bias: 0.0033351427409797907 0.051626864820718765
decider.linear3.weight: -0.0037355555687099695 0.060285534709692
decider.linear3.bias: -0.017030183225870132 0.03523152694106102

Rewards:
65.8452
65.8452
65.8452
objective = 0.0019492954015731812
==== episode 16900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.1773e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0019407706568017602 0.08380337804555893
encoder.encoder.weight_hh_l0: -0.0007114702020771801 0.08619675785303116
encoder.encoder.bias_ih_l0: 0.009294375777244568 0.0883549377322197
encoder.encoder.bias_hh_l0: 0.022366361692547798 0.08738154172897339
encoder.encoder.weight_ih_l0_reverse: 0.0022469577379524708 0.08519543707370758
encoder.encoder.weight_hh_l0_reverse: 0.0003387000469956547 0.0849774032831192
encoder.encoder.bias_ih_l0_reverse: 0.018097054213285446 0.0825050100684166
encoder.encoder.bias_hh_l0_reverse: 0.0183916874229908 0.08872257173061371
decider.lstm.weight_ih_l0: -0.0012428382178768516 0.14676928520202637
decider.lstm.weight_hh_l0: 0.002337800106033683 0.1466653198003769
decider.lstm.bias_ih_l0: -0.018346836790442467 0.14079920947551727
decider.lstm.bias_hh_l0: 0.017473913729190826 0.15380419790744781
decider.linear1.weight: 0.00500338152050972 0.12090486288070679
decider.linear1.bias: 0.009262037463486195 0.11558792740106583
decider.linear2.weight: 0.00309709832072258 0.05452701821923256
decider.linear2.bias: 0.00335290958173573 0.05163302272558212
decider.linear3.weight: -0.0037455467972904444 0.0603359080851078
decider.linear3.bias: -0.01703484356403351 0.03524215891957283

Rewards:
65.8452
65.8452
65.8452
objective = 0.0018315508496016264
==== episode 17000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.1055e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001945718890056014 0.08380978554487228
encoder.encoder.weight_hh_l0: -0.0007118688663467765 0.0862104594707489
encoder.encoder.bias_ih_l0: 0.009336804039776325 0.08836255222558975
encoder.encoder.bias_hh_l0: 0.02240879088640213 0.08738923817873001
encoder.encoder.weight_ih_l0_reverse: 0.002248041331768036 0.08520055562257767
encoder.encoder.weight_hh_l0_reverse: 0.0003391345962882042 0.08498332649469376
encoder.encoder.bias_ih_l0_reverse: 0.018120381981134415 0.08250495791435242
encoder.encoder.bias_hh_l0_reverse: 0.018415018916130066 0.08873595297336578
decider.lstm.weight_ih_l0: -0.001242065685801208 0.1467745006084442
decider.lstm.weight_hh_l0: 0.002351596252992749 0.14667174220085144
decider.lstm.bias_ih_l0: -0.01830616407096386 0.14079062640666962
decider.lstm.bias_hh_l0: 0.017514584586024284 0.15380871295928955
decider.linear1.weight: 0.005011357367038727 0.12091509997844696
decider.linear1.bias: 0.009291247464716434 0.11559276282787323
decider.linear2.weight: 0.003108487231656909 0.05454391613602638
decider.linear2.bias: 0.0033704517409205437 0.05163918435573578
decider.linear3.weight: -0.003755423938855529 0.06038586422801018
decider.linear3.bias: -0.017039399594068527 0.03525255247950554

Rewards:
65.8452
65.8452
65.8452
objective = 0.001717731123790145
==== episode 17100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.1055e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001950617996044457 0.0838160365819931
encoder.encoder.weight_hh_l0: -0.0007122502429410815 0.08622400462627411
encoder.encoder.bias_ih_l0: 0.009378615766763687 0.08837005496025085
encoder.encoder.bias_hh_l0: 0.02245059609413147 0.08739667385816574
encoder.encoder.weight_ih_l0_reverse: 0.0022491023410111666 0.0852055624127388
encoder.encoder.weight_hh_l0_reverse: 0.00033957214327529073 0.08498907089233398
encoder.encoder.bias_ih_l0_reverse: 0.01814320683479309 0.08250486850738525
encoder.encoder.bias_hh_l0_reverse: 0.018437856808304787 0.08874906599521637
decider.lstm.weight_ih_l0: -0.001241308986209333 0.14677965641021729
decider.lstm.weight_hh_l0: 0.002365251537412405 0.14667809009552002
decider.lstm.bias_ih_l0: -0.018266046419739723 0.14078202843666077
decider.lstm.bias_hh_l0: 0.017554711550474167 0.1538131833076477
decider.linear1.weight: 0.00501922145485878 0.1209251880645752
decider.linear1.bias: 0.009319971315562725 0.11559750139713287
decider.linear2.weight: 0.0031196563504636288 0.054560586810112
decider.linear2.bias: 0.003387587843462825 0.05164523422718048
decider.linear3.weight: -0.003765092696994543 0.06043492630124092
decider.linear3.bias: -0.017043815925717354 0.03526262193918228

Rewards:
65.8452
65.8452
65.8452
objective = 0.0016169942682608962
==== episode 17200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.1055e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001955521060153842 0.08382222056388855
encoder.encoder.weight_hh_l0: -0.000712615204975009 0.08623754233121872
encoder.encoder.bias_ih_l0: 0.009420257993042469 0.08837751299142838
encoder.encoder.bias_hh_l0: 0.022492241114377975 0.08740396797657013
encoder.encoder.weight_ih_l0_reverse: 0.0022501491475850344 0.08521052449941635
encoder.encoder.weight_hh_l0_reverse: 0.0003400127461645752 0.08499471843242645
encoder.encoder.bias_ih_l0_reverse: 0.018165798857808113 0.08250479400157928
encoder.encoder.bias_hh_l0_reverse: 0.018460458144545555 0.0887620821595192
decider.lstm.weight_ih_l0: -0.0012405505403876305 0.14678476750850677
decider.lstm.weight_hh_l0: 0.0023789163678884506 0.14668436348438263
decider.lstm.bias_ih_l0: -0.018225988373160362 0.14077335596084595
decider.lstm.bias_hh_l0: 0.01759474352002144 0.15381771326065063
decider.linear1.weight: 0.00502705667167902 0.12093525379896164
decider.linear1.bias: 0.009348541498184204 0.11560221761465073
decider.linear2.weight: 0.0031308031175285578 0.05457717180252075
decider.linear2.bias: 0.0034046454820781946 0.05165133997797966
decider.linear3.weight: -0.003774657379835844 0.06048363447189331
decider.linear3.bias: -0.017048219218850136 0.03527262434363365

Rewards:
65.8452
65.8452
65.8452
objective = 0.0015214908635243773
==== episode 17300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.1055e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0019604279659688473 0.08382833003997803
encoder.encoder.weight_hh_l0: -0.0007129640434868634 0.08625108003616333
encoder.encoder.bias_ih_l0: 0.009461742825806141 0.08838491886854172
encoder.encoder.bias_hh_l0: 0.022533748298883438 0.08741109073162079
encoder.encoder.weight_ih_l0_reverse: 0.0022511864081025124 0.08521542698144913
encoder.encoder.weight_hh_l0_reverse: 0.0003404608287382871 0.08500025421380997
encoder.encoder.bias_ih_l0_reverse: 0.01818816550076008 0.08250466734170914
encoder.encoder.bias_hh_l0_reverse: 0.018482817336916924 0.08877497911453247
decider.lstm.weight_ih_l0: -0.0012397962855175138 0.14678989350795746
decider.lstm.weight_hh_l0: 0.002392578637227416 0.14669063687324524
decider.lstm.bias_ih_l0: -0.018186114728450775 0.1407644897699356
decider.lstm.bias_hh_l0: 0.017634686082601547 0.15382219851016998
decider.linear1.weight: 0.005034863017499447 0.1209452897310257
decider.linear1.bias: 0.009376933798193932 0.11560693383216858
decider.linear2.weight: 0.003141800407320261 0.05459373816847801
decider.linear2.bias: 0.0034214071929454803 0.05165735259652138
decider.linear3.weight: -0.0037841310258954763 0.06053201109170914
decider.linear3.bias: -0.017052605748176575 0.03528256714344025

Rewards:
65.8452
65.8452
65.8452
objective = 0.0014299124013632536
==== episode 17400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.1055e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0019653423223644495 0.08383437991142273
encoder.encoder.weight_hh_l0: -0.0007132953614927828 0.08626461029052734
encoder.encoder.bias_ih_l0: 0.00950312614440918 0.08839232474565506
encoder.encoder.bias_hh_l0: 0.02257511392235756 0.08741804957389832
encoder.encoder.weight_ih_l0_reverse: 0.0022522180806845427 0.08522027730941772
encoder.encoder.weight_hh_l0_reverse: 0.0003409131895750761 0.08500569313764572
encoder.encoder.bias_ih_l0_reverse: 0.01821029558777809 0.082504503428936
encoder.encoder.bias_hh_l0_reverse: 0.018504947423934937 0.08878776431083679
decider.lstm.weight_ih_l0: -0.00123904540669173 0.14679498970508575
decider.lstm.weight_hh_l0: 0.00240626884624362 0.14669686555862427
decider.lstm.bias_ih_l0: -0.018146280199289322 0.14075559377670288
decider.lstm.bias_hh_l0: 0.0176745243370533 0.1538267284631729
decider.linear1.weight: 0.005042642820626497 0.12095531821250916
decider.linear1.bias: 0.009405180811882019 0.11561162024736404
decider.linear2.weight: 0.0031528016552329063 0.05461021140217781
decider.linear2.bias: 0.003438130486756563 0.051663435995578766
decider.linear3.weight: -0.0037935147993266582 0.060580044984817505
decider.linear3.bias: -0.017056981101632118 0.035292450338602066

Rewards:
65.8452
65.8452
65.8452
objective = 0.0013461837079375982
==== episode 17500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.0345e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0019702897407114506 0.08384039252996445
encoder.encoder.weight_hh_l0: -0.0007136104395613074 0.08627822250127792
encoder.encoder.bias_ih_l0: 0.009544523432850838 0.08839970827102661
encoder.encoder.bias_hh_l0: 0.02261650748550892 0.08742489665746689
encoder.encoder.weight_ih_l0_reverse: 0.002253240440040827 0.08522509783506393
encoder.encoder.weight_hh_l0_reverse: 0.00034136773319914937 0.08501104265451431
encoder.encoder.bias_ih_l0_reverse: 0.01823222078382969 0.08250435441732407
encoder.encoder.bias_hh_l0_reverse: 0.01852688007056713 0.08880051225423813
decider.lstm.weight_ih_l0: -0.0012382932472974062 0.14680005609989166
decider.lstm.weight_hh_l0: 0.002420014701783657 0.1467030644416809
decider.lstm.bias_ih_l0: -0.018106408417224884 0.14074663817882538
decider.lstm.bias_hh_l0: 0.017714418470859528 0.15383106470108032
decider.linear1.weight: 0.005050474777817726 0.12096534669399261
decider.linear1.bias: 0.009433472529053688 0.11561623215675354
decider.linear2.weight: 0.0031635798513889313 0.05462663993239403
decider.linear2.bias: 0.003454584162682295 0.051669441163539886
decider.linear3.weight: -0.0038028063718229532 0.06062775477766991
decider.linear3.bias: -0.017061343416571617 0.03530227765440941

Rewards:
65.8452
65.8452
65.8452
objective = 0.0012689961586147547
==== episode 17600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.0345e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0019752613734453917 0.08384637534618378
encoder.encoder.weight_hh_l0: -0.0007139061344787478 0.08629187196493149
encoder.encoder.bias_ih_l0: 0.00958581268787384 0.08840702474117279
encoder.encoder.bias_hh_l0: 0.02265779860317707 0.08743154257535934
encoder.encoder.weight_ih_l0_reverse: 0.002254239981994033 0.08522987365722656
encoder.encoder.weight_hh_l0_reverse: 0.00034182300441898406 0.08501628786325455
encoder.encoder.bias_ih_l0_reverse: 0.018253730610013008 0.08250419795513153
encoder.encoder.bias_hh_l0_reverse: 0.01854838617146015 0.08881303668022156
decider.lstm.weight_ih_l0: -0.0012375451624393463 0.14680515229701996
decider.lstm.weight_hh_l0: 0.0024337880313396454 0.14670917391777039
decider.lstm.bias_ih_l0: -0.0180666446685791 0.14073766767978668
decider.lstm.bias_hh_l0: 0.017754146829247475 0.15383505821228027
decider.linear1.weight: 0.00505838543176651 0.12097535282373428
decider.linear1.bias: 0.009461799636483192 0.1156207025051117
decider.linear2.weight: 0.0031738574616611004 0.05464271828532219
decider.linear2.bias: 0.003470870666205883 0.05167548730969429
decider.linear3.weight: -0.0038119209930300713 0.06067469343543053
decider.linear3.bias: -0.017065664753317833 0.035311974585056305

Rewards:
65.8452
65.8452
65.8452
objective = 0.0011970419436693192
==== episode 17700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.0345e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001980242319405079 0.08385228365659714
encoder.encoder.weight_hh_l0: -0.000714178488124162 0.08630555123090744
encoder.encoder.bias_ih_l0: 0.009627020917832851 0.08841434866189957
encoder.encoder.bias_hh_l0: 0.02269899472594261 0.08743804693222046
encoder.encoder.weight_ih_l0_reverse: 0.0022552357986569405 0.08523458987474442
encoder.encoder.weight_hh_l0_reverse: 0.00034228310687467456 0.08502144366502762
encoder.encoder.bias_ih_l0_reverse: 0.0182750653475523 0.0825040340423584
encoder.encoder.bias_hh_l0_reverse: 0.01856972463428974 0.08882550150156021
decider.lstm.weight_ih_l0: -0.0012367982417345047 0.14681021869182587
decider.lstm.weight_hh_l0: 0.0024475855752825737 0.14671528339385986
decider.lstm.bias_ih_l0: -0.018026992678642273 0.14072862267494202
decider.lstm.bias_hh_l0: 0.017793849110603333 0.153839111328125
decider.linear1.weight: 0.00506626395508647 0.12098532915115356
decider.linear1.bias: 0.00948996003717184 0.11562514305114746
decider.linear2.weight: 0.0031840880401432514 0.054658886045217514
decider.linear2.bias: 0.0034869019873440266 0.051681458950042725
decider.linear3.weight: -0.003820954356342554 0.060721345245838165
decider.linear3.bias: -0.01706979237496853 0.03532128036022186

Rewards:
65.8452
65.8452
65.8452
objective = 0.0011250878451392055
==== episode 17800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.0345e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0019852416589856148 0.08385815471410751
encoder.encoder.weight_hh_l0: -0.0007144265109673142 0.08631926774978638
encoder.encoder.bias_ih_l0: 0.009668173268437386 0.08842167258262634
encoder.encoder.bias_hh_l0: 0.022740159183740616 0.08744441717863083
encoder.encoder.weight_ih_l0_reverse: 0.002256225561723113 0.08523928374052048
encoder.encoder.weight_hh_l0_reverse: 0.0003427448100410402 0.08502651751041412
encoder.encoder.bias_ih_l0_reverse: 0.01829621195793152 0.08250384777784348
encoder.encoder.bias_hh_l0_reverse: 0.01859087496995926 0.0888378843665123
decider.lstm.weight_ih_l0: -0.0012360456166788936 0.14681528508663177
decider.lstm.weight_hh_l0: 0.002461459022015333 0.14672136306762695
decider.lstm.bias_ih_l0: -0.017987234517931938 0.14071941375732422
decider.lstm.bias_hh_l0: 0.017833607271313667 0.1538432091474533
decider.linear1.weight: 0.005074146203696728 0.12099532037973404
decider.linear1.bias: 0.00951804593205452 0.11562953889369965
decider.linear2.weight: 0.003194390330463648 0.05467505753040314
decider.linear2.bias: 0.003502876963466406 0.051687486469745636
decider.linear3.weight: -0.003829905530437827 0.060767725110054016
decider.linear3.bias: -0.01707390323281288 0.03533053398132324

Rewards:
65.8452
65.8452
65.8452
objective = 0.0010596751235425472
==== episode 17900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 7.0345e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0019902598578482866 0.08386395871639252
encoder.encoder.weight_hh_l0: -0.000714649329893291 0.08633304387331009
encoder.encoder.bias_ih_l0: 0.00970928929746151 0.08842898905277252
encoder.encoder.bias_hh_l0: 0.02278127148747444 0.08745063841342926
encoder.encoder.weight_ih_l0_reverse: 0.0022572081070393324 0.08524394035339355
encoder.encoder.weight_hh_l0_reverse: 0.00034321064595133066 0.08503150939941406
encoder.encoder.bias_ih_l0_reverse: 0.018317192792892456 0.08250364661216736
encoder.encoder.bias_hh_l0_reverse: 0.018611857667565346 0.08885018527507782
decider.lstm.weight_ih_l0: -0.0012352867051959038 0.14682035148143768
decider.lstm.weight_hh_l0: 0.0024753848556429148 0.14672744274139404
decider.lstm.bias_ih_l0: -0.017947334796190262 0.14071008563041687
decider.lstm.bias_hh_l0: 0.01787346787750721 0.1538473665714264
decider.linear1.weight: 0.0050820340402424335 0.12100531905889511
decider.linear1.bias: 0.009546086192131042 0.11563388258218765
decider.linear2.weight: 0.003204677253961563 0.054691240191459656
decider.linear2.bias: 0.0035186903551220894 0.05169348791241646
decider.linear3.weight: -0.0038387859240174294 0.060813840478658676
decider.linear3.bias: -0.017078010365366936 0.035339727997779846

Rewards:
65.8452
65.8452
65.8452
objective = 0.00099557067733258
==== episode 18000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.9641e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.001995294587686658 0.08386973291635513
encoder.encoder.weight_hh_l0: -0.0007148446748033166 0.08634687960147858
encoder.encoder.bias_ih_l0: 0.009750395081937313 0.0884363204240799
encoder.encoder.bias_hh_l0: 0.022822372615337372 0.08745674788951874
encoder.encoder.weight_ih_l0_reverse: 0.0022581894882023335 0.08524855226278305
encoder.encoder.weight_hh_l0_reverse: 0.0003436775295995176 0.08503641188144684
encoder.encoder.bias_ih_l0_reverse: 0.018337998539209366 0.08250347524881363
encoder.encoder.bias_hh_l0_reverse: 0.018632659688591957 0.08886242657899857
decider.lstm.weight_ih_l0: -0.0012345295399427414 0.14682537317276
decider.lstm.weight_hh_l0: 0.002489378210157156 0.14673353731632233
decider.lstm.bias_ih_l0: -0.01790744438767433 0.14070051908493042
decider.lstm.bias_hh_l0: 0.01791337877511978 0.15385153889656067
decider.linear1.weight: 0.0050900219939649105 0.12101535499095917
decider.linear1.bias: 0.00957406498491764 0.11563845723867416
decider.linear2.weight: 0.00321502098813653 0.05470740795135498
decider.linear2.bias: 0.0035344220232218504 0.05169936269521713
decider.linear3.weight: -0.0038475929759442806 0.060859691351652145
decider.linear3.bias: -0.017082098871469498 0.035348884761333466

Rewards:
65.8452
65.8452
65.8452
objective = 0.0009419323760084808
==== episode 18100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.9641e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0020003009121865034 0.08387541025876999
encoder.encoder.weight_hh_l0: -0.0007150089368224144 0.08636064827442169
encoder.encoder.bias_ih_l0: 0.009791089221835136 0.0884435772895813
encoder.encoder.bias_hh_l0: 0.02286306768655777 0.08746263384819031
encoder.encoder.weight_ih_l0_reverse: 0.0022591627202928066 0.08525309711694717
encoder.encoder.weight_hh_l0_reverse: 0.0003441428125370294 0.08504119515419006
encoder.encoder.bias_ih_l0_reverse: 0.01835843361914158 0.08250327408313751
encoder.encoder.bias_hh_l0_reverse: 0.018653089180588722 0.08887447416782379
decider.lstm.weight_ih_l0: -0.001233771094121039 0.14683037996292114
decider.lstm.weight_hh_l0: 0.002503293566405773 0.14673952758312225
decider.lstm.bias_ih_l0: -0.017867906019091606 0.14069083333015442
decider.lstm.bias_hh_l0: 0.017952844500541687 0.15385553240776062
decider.linear1.weight: 0.005097975023090839 0.12102533131837845
decider.linear1.bias: 0.00960168894380331 0.11564309149980545
decider.linear2.weight: 0.003225321415811777 0.05472337827086449
decider.linear2.bias: 0.0035499546211212873 0.051705170422792435
decider.linear3.weight: -0.003856239840388298 0.0609048493206501
decider.linear3.bias: -0.017086157575249672 0.035357922315597534

Rewards:
65.8452
65.8452
65.8452
objective = 0.0008869857992976904
==== episode 18200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.9641e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0020053288899362087 0.08388105034828186
encoder.encoder.weight_hh_l0: -0.0007151415920816362 0.08637447655200958
encoder.encoder.bias_ih_l0: 0.009831797331571579 0.08845087885856628
encoder.encoder.bias_hh_l0: 0.02290377952158451 0.08746841549873352
encoder.encoder.weight_ih_l0_reverse: 0.0022601373493671417 0.08525760471820831
encoder.encoder.weight_hh_l0_reverse: 0.0003446113842073828 0.08504589647054672
encoder.encoder.bias_ih_l0_reverse: 0.018378736451268196 0.0825030654668808
encoder.encoder.bias_hh_l0_reverse: 0.01867339015007019 0.08888646960258484
decider.lstm.weight_ih_l0: -0.0012330106692388654 0.14683537185192108
decider.lstm.weight_hh_l0: 0.002517260843887925 0.14674553275108337
decider.lstm.bias_ih_l0: -0.01782836951315403 0.14068107306957245
decider.lstm.bias_hh_l0: 0.017992403358221054 0.15385960042476654
decider.linear1.weight: 0.00510583259165287 0.12103529274463654
decider.linear1.bias: 0.00962912105023861 0.11564768850803375
decider.linear2.weight: 0.003235575743019581 0.05473936349153519
decider.linear2.bias: 0.003565295599400997 0.051710911095142365
decider.linear3.weight: -0.0038648229092359543 0.06094977259635925
decider.linear3.bias: -0.0170902032405138 0.03536692634224892

Rewards:
65.8452
65.8452
65.8452
objective = 0.0008346558315679431
==== episode 18300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.9641e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0020103822462260723 0.08388663828372955
encoder.encoder.weight_hh_l0: -0.0007152407197281718 0.08638839423656464
encoder.encoder.bias_ih_l0: 0.00987254362553358 0.08845821768045425
encoder.encoder.bias_hh_l0: 0.02294451743364334 0.08747407793998718
encoder.encoder.weight_ih_l0_reverse: 0.0022611157037317753 0.08526208996772766
encoder.encoder.weight_hh_l0_reverse: 0.00034508254611864686 0.0850505381822586
encoder.encoder.bias_ih_l0_reverse: 0.018398921936750412 0.08250286430120468
encoder.encoder.bias_hh_l0_reverse: 0.018693584948778152 0.08889839798212051
decider.lstm.weight_ih_l0: -0.0012322405818849802 0.14684034883975983
decider.lstm.weight_hh_l0: 0.002531292848289013 0.1467515528202057
decider.lstm.bias_ih_l0: -0.017788756638765335 0.14067114889621735
decider.lstm.bias_hh_l0: 0.018031984567642212 0.15386374294757843
decider.linear1.weight: 0.005113785155117512 0.12104526907205582
decider.linear1.bias: 0.009656550362706184 0.11565230786800385
decider.linear2.weight: 0.003245825180783868 0.05475534498691559
decider.linear2.bias: 0.003580526215955615 0.05171666294336319
decider.linear3.weight: -0.0038733389228582382 0.06099448353052139
decider.linear3.bias: -0.017094237729907036 0.03537588566541672

Rewards:
65.8452
65.8452
65.8452
objective = 0.0007901753997430205
==== episode 18400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.9641e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002015455160290003 0.08389220386743546
encoder.encoder.weight_hh_l0: -0.0007153057958930731 0.08640239387750626
encoder.encoder.bias_ih_l0: 0.00991331972181797 0.08846557140350342
encoder.encoder.bias_hh_l0: 0.02298528142273426 0.0874795913696289
encoder.encoder.weight_ih_l0_reverse: 0.0022620968520641327 0.08526653051376343
encoder.encoder.weight_hh_l0_reverse: 0.00034555516322143376 0.08505510538816452
encoder.encoder.bias_ih_l0_reverse: 0.01841898076236248 0.08250264823436737
encoder.encoder.bias_hh_l0_reverse: 0.01871364563703537 0.08891027420759201
decider.lstm.weight_ih_l0: -0.0012314531486481428 0.14684535562992096
decider.lstm.weight_hh_l0: 0.0025453828275203705 0.1467575877904892
decider.lstm.bias_ih_l0: -0.017748994752764702 0.14066113531589508
decider.lstm.bias_hh_l0: 0.018071681261062622 0.15386798977851868
decider.linear1.weight: 0.005121647380292416 0.1210552528500557
decider.linear1.bias: 0.009683799929916859 0.11565690487623215
decider.linear2.weight: 0.0032561146654188633 0.05477127060294151
decider.linear2.bias: 0.0035957274958491325 0.05172247067093849
decider.linear3.weight: -0.0038817906752228737 0.06103898584842682
decider.linear3.bias: -0.01709826849400997 0.035384807735681534

Rewards:
65.8452
65.8452
65.8452
objective = 0.0007443868089467287
==== episode 18500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.8945e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002020555082708597 0.08389772474765778
encoder.encoder.weight_hh_l0: -0.0007153320475481451 0.08641650527715683
encoder.encoder.bias_ih_l0: 0.00995411816984415 0.08847296237945557
encoder.encoder.bias_hh_l0: 0.023026099428534508 0.08748500794172287
encoder.encoder.weight_ih_l0_reverse: 0.002263084053993225 0.085270956158638
encoder.encoder.weight_hh_l0_reverse: 0.00034603214589878917 0.08505962044000626
encoder.encoder.bias_ih_l0_reverse: 0.018438927829265594 0.08250241726636887
encoder.encoder.bias_hh_l0_reverse: 0.01873357966542244 0.08892208337783813
decider.lstm.weight_ih_l0: -0.0012306501157581806 0.1468503624200821
decider.lstm.weight_hh_l0: 0.0025595370680093765 0.1467636078596115
decider.lstm.bias_ih_l0: -0.01770925521850586 0.14065086841583252
decider.lstm.bias_hh_l0: 0.018111437559127808 0.1538722664117813
decider.linear1.weight: 0.005129508674144745 0.12106524407863617
decider.linear1.bias: 0.009710955433547497 0.11566151678562164
decider.linear2.weight: 0.003266382496803999 0.054787203669548035
decider.linear2.bias: 0.0036108021158725023 0.051728248596191406
decider.linear3.weight: -0.00389018002897501 0.06108328327536583
decider.linear3.bias: -0.01710228994488716 0.03539368882775307

Rewards:
65.8452
65.8452
65.8452
objective = 0.0007025228696875274
==== episode 18600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.8945e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002025643130764365 0.08390316367149353
encoder.encoder.weight_hh_l0: -0.0007153165061026812 0.08643057942390442
encoder.encoder.bias_ih_l0: 0.00999465398490429 0.08848036825656891
encoder.encoder.bias_hh_l0: 0.023066624999046326 0.08749020099639893
encoder.encoder.weight_ih_l0_reverse: 0.0022640617098659277 0.0852753072977066
encoder.encoder.weight_hh_l0_reverse: 0.0003465051995590329 0.08506402373313904
encoder.encoder.bias_ih_l0_reverse: 0.01845856010913849 0.08250215649604797
encoder.encoder.bias_hh_l0_reverse: 0.01875322498381138 0.08893372118473053
decider.lstm.weight_ih_l0: -0.0012298580259084702 0.14685532450675964
decider.lstm.weight_hh_l0: 0.002573559060692787 0.14676955342292786
decider.lstm.bias_ih_l0: -0.0176699161529541 0.14064057171344757
decider.lstm.bias_hh_l0: 0.01815074309706688 0.15387655794620514
decider.linear1.weight: 0.005137374624609947 0.12107513844966888
decider.linear1.bias: 0.009737826883792877 0.11566605418920517
decider.linear2.weight: 0.003276507370173931 0.05480298027396202
decider.linear2.bias: 0.003625548677518964 0.05173392593860626
decider.linear3.weight: -0.0038984231650829315 0.06112693250179291
decider.linear3.bias: -0.01710609160363674 0.03540211543440819

Rewards:
65.8452
65.8452
65.8452
objective = 0.000661967322230339
==== episode 18700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.8945e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0020307644736021757 0.0839085727930069
encoder.encoder.weight_hh_l0: -0.0007152573671191931 0.08644478023052216
encoder.encoder.bias_ih_l0: 0.010035298764705658 0.08848782628774643
encoder.encoder.bias_hh_l0: 0.023107264190912247 0.08749528229236603
encoder.encoder.weight_ih_l0_reverse: 0.0022650533355772495 0.08527964353561401
encoder.encoder.weight_hh_l0_reverse: 0.00034698116360232234 0.08506837487220764
encoder.encoder.bias_ih_l0_reverse: 0.01847810670733452 0.08250190317630768
encoder.encoder.bias_hh_l0_reverse: 0.01877276971936226 0.08894527703523636
decider.lstm.weight_ih_l0: -0.0012290498707443476 0.1468603014945984
decider.lstm.weight_hh_l0: 0.002587622031569481 0.1467755287885666
decider.lstm.bias_ih_l0: -0.01763049140572548 0.14063014090061188
decider.lstm.bias_hh_l0: 0.018190134316682816 0.15388092398643494
decider.linear1.weight: 0.005145150236785412 0.12108506262302399
decider.linear1.bias: 0.009764527902007103 0.11567053198814392
decider.linear2.weight: 0.0032866294495761395 0.05481874942779541
decider.linear2.bias: 0.0036401960533112288 0.05173960700631142
decider.linear3.weight: -0.003906611818820238 0.061170414090156555
decider.linear3.bias: -0.017109882086515427 0.035410504788160324

Rewards:
65.8452
65.8452
65.8452
objective = 0.000624028267338872
==== episode 18800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.8945e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002035907469689846 0.08391395956277847
encoder.encoder.weight_hh_l0: -0.0007151561439968646 0.08645913004875183
encoder.encoder.bias_ih_l0: 0.010076041333377361 0.08849532157182693
encoder.encoder.bias_hh_l0: 0.023148000240325928 0.08750025182962418
encoder.encoder.weight_ih_l0_reverse: 0.002266089664772153 0.08528397977352142
encoder.encoder.weight_hh_l0_reverse: 0.00034746210440061986 0.08507271856069565
encoder.encoder.bias_ih_l0_reverse: 0.018497612327337265 0.08250167965888977
encoder.encoder.bias_hh_l0_reverse: 0.01879228465259075 0.08895676583051682
decider.lstm.weight_ih_l0: -0.0012282122625038028 0.14686527848243713
decider.lstm.weight_hh_l0: 0.0026018135249614716 0.14678159356117249
decider.lstm.bias_ih_l0: -0.017590880393981934 0.14061933755874634
decider.lstm.bias_hh_l0: 0.018229763954877853 0.1538853645324707
decider.linear1.weight: 0.005153002217411995 0.12109500914812088
decider.linear1.bias: 0.009791269898414612 0.11567496508359909
decider.linear2.weight: 0.0032967713195830584 0.05483449995517731
decider.linear2.bias: 0.0036547884810715914 0.05174531415104866
decider.linear3.weight: -0.003914752043783665 0.06121372431516647
decider.linear3.bias: -0.017113665118813515 0.03541886433959007

Rewards:
65.8452
65.8452
65.8452
objective = 0.0005887057050131261
==== episode 18900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.8945e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002041089115664363 0.08391931653022766
encoder.encoder.weight_hh_l0: -0.0007150077726691961 0.08647362887859344
encoder.encoder.bias_ih_l0: 0.010116908699274063 0.088502898812294
encoder.encoder.bias_hh_l0: 0.023188866674900055 0.08750509470701218
encoder.encoder.weight_ih_l0_reverse: 0.0022671318147331476 0.08528830111026764
encoder.encoder.weight_hh_l0_reverse: 0.0003479441220406443 0.08507698774337769
encoder.encoder.bias_ih_l0_reverse: 0.018517030403017998 0.08250145614147186
encoder.encoder.bias_hh_l0_reverse: 0.018811697140336037 0.0889681950211525
decider.lstm.weight_ih_l0: -0.001227359171025455 0.14687030017375946
decider.lstm.weight_hh_l0: 0.002616093959659338 0.1467876434326172
decider.lstm.bias_ih_l0: -0.017551138997077942 0.14060835540294647
decider.lstm.bias_hh_l0: 0.018269477412104607 0.1538897156715393
decider.linear1.weight: 0.0051599955186247826 0.12110434472560883
decider.linear1.bias: 0.009816231206059456 0.1156824454665184
decider.linear2.weight: 0.0033070268109440804 0.05485019460320473
decider.linear2.bias: 0.0036693373695015907 0.0517510250210762
decider.linear3.weight: -0.003922839183360338 0.061256859451532364
decider.linear3.bias: -0.017117440700531006 0.035427190363407135

Rewards:
65.8452
65.8452
65.8452
objective = 0.0005559996934607625
==== episode 19000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.8255e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002046313602477312 0.08392465114593506
encoder.encoder.weight_hh_l0: -0.0007148116710595787 0.08648829907178879
encoder.encoder.bias_ih_l0: 0.01015792228281498 0.08851055055856705
encoder.encoder.bias_hh_l0: 0.02322988398373127 0.08750981092453003
encoder.encoder.weight_ih_l0_reverse: 0.0022681793197989464 0.08529260009527206
encoder.encoder.weight_hh_l0_reverse: 0.00034842791501432657 0.08508122712373734
encoder.encoder.bias_ih_l0_reverse: 0.01853634975850582 0.08250122517347336
encoder.encoder.bias_hh_l0_reverse: 0.018831003457307816 0.0889795646071434
decider.lstm.weight_ih_l0: -0.001226488035172224 0.14687533676624298
decider.lstm.weight_hh_l0: 0.002630452625453472 0.14679373800754547
decider.lstm.bias_ih_l0: -0.017511270940303802 0.14059720933437347
decider.lstm.bias_hh_l0: 0.018309317529201508 0.1538940817117691
decider.linear1.weight: 0.005167452618479729 0.12111406028270721
decider.linear1.bias: 0.0098420986905694 0.1156882494688034
decider.linear2.weight: 0.003317383350804448 0.05486585944890976
decider.linear2.bias: 0.0036838045343756676 0.05175667256116867
decider.linear3.weight: -0.003930873703211546 0.06129983067512512
decider.linear3.bias: -0.0171212051063776 0.03543548658490181

Rewards:
65.8452
65.8452
65.8452
objective = 0.0005272183334454894
==== episode 19100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.8255e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0020515203941613436 0.08392992615699768
encoder.encoder.weight_hh_l0: -0.0007145649287849665 0.08650298416614532
encoder.encoder.bias_ih_l0: 0.010198650881648064 0.08851820975542068
encoder.encoder.bias_hh_l0: 0.023270631209015846 0.08751435577869415
encoder.encoder.weight_ih_l0_reverse: 0.002269226359203458 0.08529683947563171
encoder.encoder.weight_hh_l0_reverse: 0.00034890815732069314 0.08508535474538803
encoder.encoder.bias_ih_l0_reverse: 0.018555402755737305 0.08250100910663605
encoder.encoder.bias_hh_l0_reverse: 0.01885005459189415 0.08899081498384476
decider.lstm.weight_ih_l0: -0.0012256101472303271 0.1468803584575653
decider.lstm.weight_hh_l0: 0.0026447377167642117 0.14679978787899017
decider.lstm.bias_ih_l0: -0.01747160777449608 0.1405859738588333
decider.lstm.bias_hh_l0: 0.01834888570010662 0.1538984775543213
decider.linear1.weight: 0.00517524778842926 0.12112400680780411
decider.linear1.bias: 0.009868450462818146 0.1156926229596138
decider.linear2.weight: 0.0033271287102252245 0.05488158017396927
decider.linear2.bias: 0.0036978949792683125 0.051762357354164124
decider.linear3.weight: -0.003938775043934584 0.061342205852270126
decider.linear3.bias: -0.01712493598461151 0.035443682223558426

Rewards:
65.8452
65.8452
65.8452
objective = 0.000497128814458847
==== episode 19200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.8255e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002056762343272567 0.08393518626689911
encoder.encoder.weight_hh_l0: -0.0007142623071558774 0.08651784807443619
encoder.encoder.bias_ih_l0: 0.010239547118544579 0.08852595090866089
encoder.encoder.bias_hh_l0: 0.02331152930855751 0.08751881122589111
encoder.encoder.weight_ih_l0_reverse: 0.0022702848073095083 0.08530104905366898
encoder.encoder.weight_hh_l0_reverse: 0.0003493904951028526 0.08508943766355515
encoder.encoder.bias_ih_l0_reverse: 0.01857437752187252 0.08250077813863754
encoder.encoder.bias_hh_l0_reverse: 0.018869027495384216 0.08900199830532074
decider.lstm.weight_ih_l0: -0.0012247039703652263 0.14688540995121002
decider.lstm.weight_hh_l0: 0.0026591152418404818 0.14680586755275726
decider.lstm.bias_ih_l0: -0.017431821674108505 0.14057457447052002
decider.lstm.bias_hh_l0: 0.018388645723462105 0.15390296280384064
decider.linear1.weight: 0.005183068104088306 0.12113399058580399
decider.linear1.bias: 0.009894768707454205 0.11569703370332718
decider.linear2.weight: 0.003337383270263672 0.05489707738161087
decider.linear2.bias: 0.0037120403721928596 0.051767926663160324
decider.linear3.weight: -0.003946628887206316 0.061384450644254684
decider.linear3.bias: -0.017128661274909973 0.03545185178518295

Rewards:
65.8452
65.8452
65.8452
objective = 0.0004696558171417564
==== episode 19300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.8255e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0020620406139642 0.08394043892621994
encoder.encoder.weight_hh_l0: -0.000713900662958622 0.08653290569782257
encoder.encoder.bias_ih_l0: 0.010280592367053032 0.08853378146886826
encoder.encoder.bias_hh_l0: 0.02335255593061447 0.08752312511205673
encoder.encoder.weight_ih_l0_reverse: 0.002271357923746109 0.08530525118112564
encoder.encoder.weight_hh_l0_reverse: 0.00034987268736585975 0.08509346842765808
encoder.encoder.bias_ih_l0_reverse: 0.01859329454600811 0.08250054717063904
encoder.encoder.bias_hh_l0_reverse: 0.01888793706893921 0.08901317417621613
decider.lstm.weight_ih_l0: -0.0012237734626978636 0.14689049124717712
decider.lstm.weight_hh_l0: 0.0026735852006822824 0.14681196212768555
decider.lstm.bias_ih_l0: -0.01739180088043213 0.14056296646595
decider.lstm.bias_hh_l0: 0.018428616225719452 0.15390758216381073
decider.linear1.weight: 0.005190980155020952 0.12114401906728745
decider.linear1.bias: 0.009921112097799778 0.11570151150226593
decider.linear2.weight: 0.0033476538956165314 0.05491256341338158
decider.linear2.bias: 0.00372611777856946 0.05177351459860802
decider.linear3.weight: -0.0039544361643493176 0.061426542699337006
decider.linear3.bias: -0.017132380977272987 0.035459987819194794

Rewards:
65.8452
65.8452
65.8452
objective = 0.0004434910078998655
==== episode 19400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.8255e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0020673798862844706 0.08394568413496017
encoder.encoder.weight_hh_l0: -0.0007134822080843151 0.08654821664094925
encoder.encoder.bias_ih_l0: 0.010321874171495438 0.08854172378778458
encoder.encoder.bias_hh_l0: 0.02339383028447628 0.0875273048877716
encoder.encoder.weight_ih_l0_reverse: 0.0022724485024809837 0.0853094533085823
encoder.encoder.weight_hh_l0_reverse: 0.0003503585758153349 0.08509746938943863
encoder.encoder.bias_ih_l0_reverse: 0.018612150102853775 0.08250031620264053
encoder.encoder.bias_hh_l0_reverse: 0.018906794488430023 0.08902433514595032
decider.lstm.weight_ih_l0: -0.0012228155974298716 0.146895632147789
decider.lstm.weight_hh_l0: 0.002688153414055705 0.1468181163072586
decider.lstm.bias_ih_l0: -0.017351564019918442 0.14055116474628448
decider.lstm.bias_hh_l0: 0.018468808382749557 0.15391220152378082
decider.linear1.weight: 0.005198846571147442 0.12115411460399628
decider.linear1.bias: 0.009947383776307106 0.11570589989423752
decider.linear2.weight: 0.0033580372110009193 0.05492796748876572
decider.linear2.bias: 0.003740152111276984 0.05177910625934601
decider.linear3.weight: -0.003962202463299036 0.061468496918678284
decider.linear3.bias: -0.017136091366410255 0.035468097776174545

Rewards:
65.8452
65.8452
65.8452
objective = 0.0004173261986579746
==== episode 19500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.7573e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002072783885523677 0.08395092934370041
encoder.encoder.weight_hh_l0: -0.0007129981531761587 0.08656381815671921
encoder.encoder.bias_ih_l0: 0.010363447479903698 0.08854981511831284
encoder.encoder.bias_hh_l0: 0.023435397073626518 0.08753136545419693
encoder.encoder.weight_ih_l0_reverse: 0.0022735579404979944 0.08531366288661957
encoder.encoder.weight_hh_l0_reverse: 0.0003508478694129735 0.08510143309831619
encoder.encoder.bias_ih_l0_reverse: 0.01863095909357071 0.08250007778406143
encoder.encoder.bias_hh_l0_reverse: 0.01892559975385666 0.08903547376394272
decider.lstm.weight_ih_l0: -0.0012218246702104807 0.14690083265304565
decider.lstm.weight_hh_l0: 0.002702816389501095 0.14682430028915405
decider.lstm.bias_ih_l0: -0.01731114648282528 0.14053919911384583
decider.lstm.bias_hh_l0: 0.018509212881326675 0.15391691029071808
decider.linear1.weight: 0.00520673394203186 0.12116430699825287
decider.linear1.bias: 0.009973633103072643 0.11571024358272552
decider.linear2.weight: 0.003368525533005595 0.0549432709813118
decider.linear2.bias: 0.003754126839339733 0.051784686744213104
decider.linear3.weight: -0.0039699142798781395 0.061510294675827026
decider.linear3.bias: -0.01713978871703148 0.03547617793083191

Rewards:
65.8452
65.8452
65.8452
objective = 0.0003963944036513567
==== episode 19600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.7573e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0020781776402145624 0.08395612239837646
encoder.encoder.weight_hh_l0: -0.0007124466937966645 0.08657950162887573
encoder.encoder.bias_ih_l0: 0.010404788888990879 0.0885578915476799
encoder.encoder.bias_hh_l0: 0.02347675710916519 0.08753526210784912
encoder.encoder.weight_ih_l0_reverse: 0.0022746750619262457 0.08531781286001205
encoder.encoder.weight_hh_l0_reverse: 0.00035133326309733093 0.08510531485080719
encoder.encoder.bias_ih_l0_reverse: 0.018649544566869736 0.08249986916780472
encoder.encoder.bias_hh_l0_reverse: 0.018944185227155685 0.08904653787612915
decider.lstm.weight_ih_l0: -0.001220816746354103 0.1469060182571411
decider.lstm.weight_hh_l0: 0.0027174302376806736 0.14683043956756592
decider.lstm.bias_ih_l0: -0.01727096177637577 0.14052709937095642
decider.lstm.bias_hh_l0: 0.018549475818872452 0.15392163395881653
decider.linear1.weight: 0.005214575678110123 0.12117443978786469
decider.linear1.bias: 0.00999959371984005 0.11571460217237473
decider.linear2.weight: 0.003378915600478649 0.05495842546224594
decider.linear2.bias: 0.003767869435250759 0.051790203899145126
decider.linear3.weight: -0.003977504093199968 0.0615515410900116
decider.linear3.bias: -0.017143459990620613 0.03548416867852211

Rewards:
65.8452
65.8452
65.8452
objective = 0.0003741543914657086
==== episode 19700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.7573e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0020836112089455128 0.08396132290363312
encoder.encoder.weight_hh_l0: -0.0007118178182281554 0.08659545332193375
encoder.encoder.bias_ih_l0: 0.010446356609463692 0.0885661169886589
encoder.encoder.bias_hh_l0: 0.023518333211541176 0.08753907680511475
encoder.encoder.weight_ih_l0_reverse: 0.002275809645652771 0.08532194793224335
encoder.encoder.weight_hh_l0_reverse: 0.00035181952989660203 0.08510913699865341
encoder.encoder.bias_ih_l0_reverse: 0.018668092787265778 0.0824996680021286
encoder.encoder.bias_hh_l0_reverse: 0.018962733447551727 0.0890575721859932
decider.lstm.weight_ih_l0: -0.0012197744799777865 0.14691124856472015
decider.lstm.weight_hh_l0: 0.002732135821133852 0.14683662354946136
decider.lstm.bias_ih_l0: -0.017230531200766563 0.1405147761106491
decider.lstm.bias_hh_l0: 0.018589993938803673 0.15392649173736572
decider.linear1.weight: 0.005222461652010679 0.12118463963270187
decider.linear1.bias: 0.010025551542639732 0.1157190129160881
decider.linear2.weight: 0.0033893014770001173 0.05497359484434128
decider.linear2.bias: 0.00378150912001729 0.05179569497704506
decider.linear3.weight: -0.003985052928328514 0.061592649668455124
decider.linear3.bias: -0.017147118225693703 0.03549214079976082

Rewards:
65.8452
65.8452
65.8452
objective = 0.00035453084274195135
==== episode 19800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.7573e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002089085290208459 0.08396653831005096
encoder.encoder.weight_hh_l0: -0.0007111106533557177 0.08661166578531265
encoder.encoder.bias_ih_l0: 0.010488145053386688 0.08857447654008865
encoder.encoder.bias_hh_l0: 0.023560117930173874 0.08754275739192963
encoder.encoder.weight_ih_l0_reverse: 0.0022769642528146505 0.08532607555389404
encoder.encoder.weight_hh_l0_reverse: 0.0003523080958984792 0.08511293679475784
encoder.encoder.bias_ih_l0_reverse: 0.018686601892113686 0.08249945938587189
encoder.encoder.bias_hh_l0_reverse: 0.01898123137652874 0.08906855434179306
decider.lstm.weight_ih_l0: -0.0012186935637146235 0.14691655337810516
decider.lstm.weight_hh_l0: 0.0027469529304653406 0.146842822432518
decider.lstm.bias_ih_l0: -0.017189864069223404 0.14050227403640747
decider.lstm.bias_hh_l0: 0.0186307355761528 0.1539313942193985
decider.linear1.weight: 0.005230373702943325 0.12119489908218384
decider.linear1.bias: 0.010051499120891094 0.11572348326444626
decider.linear2.weight: 0.0033997236751019955 0.054988760501146317
decider.linear2.bias: 0.0037951066624373198 0.051801230758428574
decider.linear3.weight: -0.003992559853941202 0.0616336390376091
decider.linear3.bias: -0.01715068705379963 0.0354999303817749

Rewards:
65.8452
65.8452
65.8452
objective = 0.00033359904773533344
==== episode 19900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.7573e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0020946022123098373 0.08397175371646881
encoder.encoder.weight_hh_l0: -0.0007103212992660701 0.08662816882133484
encoder.encoder.bias_ih_l0: 0.010530147701501846 0.08858297765254974
encoder.encoder.bias_hh_l0: 0.023602113127708435 0.08754635602235794
encoder.encoder.weight_ih_l0_reverse: 0.0022781400475651026 0.08533018827438354
encoder.encoder.weight_hh_l0_reverse: 0.00035279864096082747 0.08511670678853989
encoder.encoder.bias_ih_l0_reverse: 0.018705083057284355 0.08249924331903458
encoder.encoder.bias_hh_l0_reverse: 0.018999703228473663 0.08907953649759293
decider.lstm.weight_ih_l0: -0.0012175722513347864 0.14692190289497375
decider.lstm.weight_hh_l0: 0.0027618766762316227 0.14684909582138062
decider.lstm.bias_ih_l0: -0.017148949205875397 0.14048950374126434
decider.lstm.bias_hh_l0: 0.018671657890081406 0.15393629670143127
decider.linear1.weight: 0.005238131619989872 0.12120521813631058
decider.linear1.bias: 0.010077347978949547 0.11572819203138351
decider.linear2.weight: 0.003410162404179573 0.055003922432661057
decider.linear2.bias: 0.0038086259737610817 0.051806747913360596
decider.linear3.weight: -0.004000023007392883 0.06167449802160263
decider.linear3.bias: -0.017154140397906303 0.035507503896951675

Rewards:
65.8452
65.8452
65.8452
objective = 0.0003165920206811279
==== episode 20000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.6897e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0021001631394028664 0.08397698402404785
encoder.encoder.weight_hh_l0: -0.0007094462052918971 0.0866449847817421
encoder.encoder.bias_ih_l0: 0.010572352446615696 0.08859159052371979
encoder.encoder.bias_hh_l0: 0.02364431507885456 0.08754986524581909
encoder.encoder.weight_ih_l0_reverse: 0.0022793354000896215 0.08533428609371185
encoder.encoder.weight_hh_l0_reverse: 0.00035328941885381937 0.08512041717767715
encoder.encoder.bias_ih_l0_reverse: 0.018723534420132637 0.08249906450510025
encoder.encoder.bias_hh_l0_reverse: 0.01901816576719284 0.0890904888510704
decider.lstm.weight_ih_l0: -0.0012164065847173333 0.14692731201648712
decider.lstm.weight_hh_l0: 0.0027769124135375023 0.146855428814888
decider.lstm.bias_ih_l0: -0.01710774190723896 0.14047648012638092
decider.lstm.bias_hh_l0: 0.018712807446718216 0.15394136309623718
decider.linear1.weight: 0.005245858337730169 0.12121561914682388
decider.linear1.bias: 0.010103152133524418 0.11573302745819092
decider.linear2.weight: 0.003420619759708643 0.05501910299062729
decider.linear2.bias: 0.003822066355496645 0.05181225761771202
decider.linear3.weight: -0.00400743680074811 0.06171521544456482
decider.linear3.bias: -0.01715758815407753 0.03551504760980606

Rewards:
65.8452
65.8452
65.8452
objective = 0.00029958493541926146
==== episode 20100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.6897e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002105707535520196 0.0839821845293045
encoder.encoder.weight_hh_l0: -0.0007084892131388187 0.08666194975376129
encoder.encoder.bias_ih_l0: 0.010614326223731041 0.08860023319721222
encoder.encoder.bias_hh_l0: 0.023686299100518227 0.08755325525999069
encoder.encoder.weight_ih_l0_reverse: 0.0022805400658398867 0.08533832430839539
encoder.encoder.weight_hh_l0_reverse: 0.0003537782176863402 0.08512406796216965
encoder.encoder.bias_ih_l0_reverse: 0.018741782754659653 0.08249890804290771
encoder.encoder.bias_hh_l0_reverse: 0.01903642527759075 0.08910131454467773
decider.lstm.weight_ih_l0: -0.0012152115814387798 0.14693273603916168
decider.lstm.weight_hh_l0: 0.002791888080537319 0.146861732006073
decider.lstm.bias_ih_l0: -0.017066724598407745 0.14046330749988556
decider.lstm.bias_hh_l0: 0.01875380054116249 0.15394653379917145
decider.linear1.weight: 0.005253528710454702 0.1212259829044342
decider.linear1.bias: 0.010128684341907501 0.1157379001379013
decider.linear2.weight: 0.0034305592998862267 0.05503431335091591
decider.linear2.bias: 0.0038352017290890217 0.051817841827869415
decider.linear3.weight: -0.004014741629362106 0.06175542250275612
decider.linear3.bias: -0.017160998657345772 0.03552250936627388

Rewards:
65.8452
65.8452
65.8452
objective = 0.0002825779083650559
==== episode 20200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.6897e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0021112910471856594 0.08398740738630295
encoder.encoder.weight_hh_l0: -0.0007074389141052961 0.08667924255132675
encoder.encoder.bias_ih_l0: 0.010656540282070637 0.08860902488231659
encoder.encoder.bias_hh_l0: 0.023728514090180397 0.08755658566951752
encoder.encoder.weight_ih_l0_reverse: 0.0022817705757915974 0.08534236252307892
encoder.encoder.weight_hh_l0_reverse: 0.0003542665217537433 0.08512768894433975
encoder.encoder.bias_ih_l0_reverse: 0.018760016188025475 0.08249875158071518
encoder.encoder.bias_hh_l0_reverse: 0.01905466802418232 0.08911213278770447
decider.lstm.weight_ih_l0: -0.0012139668688178062 0.1469382345676422
decider.lstm.weight_hh_l0: 0.002806971315294504 0.14686810970306396
decider.lstm.bias_ih_l0: -0.017025453969836235 0.14044979214668274
decider.lstm.bias_hh_l0: 0.01879512146115303 0.15395183861255646
decider.linear1.weight: 0.005261249840259552 0.12123643606901169
decider.linear1.bias: 0.01015422772616148 0.11574284732341766
decider.linear2.weight: 0.00344089325517416 0.05504946410655975
decider.linear2.bias: 0.003848376916721463 0.05182329937815666
decider.linear3.weight: -0.004022004548460245 0.06179553270339966
decider.linear3.bias: -0.017164403572678566 0.03552994877099991

Rewards:
65.8452
65.8452
65.8452
objective = 0.00026557082310318947
==== episode 20300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.6897e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002116910880431533 0.08399266749620438
encoder.encoder.weight_hh_l0: -0.0007062918157316744 0.08669687807559967
encoder.encoder.bias_ih_l0: 0.010698980651795864 0.0886179581284523
encoder.encoder.bias_hh_l0: 0.023770947009325027 0.08755983412265778
encoder.encoder.weight_ih_l0_reverse: 0.0022830243688076735 0.08534638583660126
encoder.encoder.weight_hh_l0_reverse: 0.00035475759068503976 0.08513126522302628
encoder.encoder.bias_ih_l0_reverse: 0.01877824030816555 0.08249863237142563
encoder.encoder.bias_hh_l0_reverse: 0.019072894006967545 0.08912291377782822
decider.lstm.weight_ih_l0: -0.0012126711662858725 0.1469438225030899
decider.lstm.weight_hh_l0: 0.0028221707325428724 0.1468745321035385
decider.lstm.bias_ih_l0: -0.016983868554234505 0.1404360979795456
decider.lstm.bias_hh_l0: 0.01883676089346409 0.1539573073387146
decider.linear1.weight: 0.005268941633403301 0.12124697118997574
decider.linear1.bias: 0.010179713368415833 0.11574788391590118
decider.linear2.weight: 0.003451249562203884 0.05506463721394539
decider.linear2.bias: 0.0038614794611930847 0.05182874575257301
decider.linear3.weight: -0.004029234871268272 0.06183553487062454
decider.linear3.bias: -0.017167795449495316 0.035537365823984146

Rewards:
65.8452
65.8452
65.8452
objective = 0.0002524885057937354
==== episode 20400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.6897e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002122570527717471 0.0839979276061058
encoder.encoder.weight_hh_l0: -0.0007050478016026318 0.08671490103006363
encoder.encoder.bias_ih_l0: 0.010741638951003551 0.08862704783678055
encoder.encoder.bias_hh_l0: 0.023813597857952118 0.08756303042173386
encoder.encoder.weight_ih_l0_reverse: 0.0022843056358397007 0.0853503942489624
encoder.encoder.weight_hh_l0_reverse: 0.0003552497655618936 0.08513481914997101
encoder.encoder.bias_ih_l0_reverse: 0.01879645138978958 0.08249851316213608
encoder.encoder.bias_hh_l0_reverse: 0.01909109391272068 0.08913367986679077
decider.lstm.weight_ih_l0: -0.0012113250559195876 0.14694948494434357
decider.lstm.weight_hh_l0: 0.0028374698013067245 0.14688102900981903
decider.lstm.bias_ih_l0: -0.016941945999860764 0.14042215049266815
decider.lstm.bias_hh_l0: 0.018878694623708725 0.15396292507648468
decider.linear1.weight: 0.005275742616504431 0.12125690281391144
decider.linear1.bias: 0.010203048586845398 0.11575683206319809
decider.linear2.weight: 0.003461636370047927 0.05507982522249222
decider.linear2.bias: 0.003874504007399082 0.05183418095111847
decider.linear3.weight: -0.004036420490592718 0.06187543645501137
decider.linear3.bias: -0.017171181738376617 0.0355447456240654

Rewards:
65.8452
65.8452
65.8452
objective = 0.00023809794220142066
==== episode 20500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.6228e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002128265332430601 0.08400322496891022
encoder.encoder.weight_hh_l0: -0.0007037028553895652 0.08673328161239624
encoder.encoder.bias_ih_l0: 0.010784485377371311 0.08863625675439835
encoder.encoder.bias_hh_l0: 0.023856448009610176 0.08756615221500397
encoder.encoder.weight_ih_l0_reverse: 0.0022856106515973806 0.08535438776016235
encoder.encoder.weight_hh_l0_reverse: 0.00035574098001234233 0.08513833582401276
encoder.encoder.bias_ih_l0_reverse: 0.01881464570760727 0.08249840885400772
encoder.encoder.bias_hh_l0_reverse: 0.019109297543764114 0.08914446085691452
decider.lstm.weight_ih_l0: -0.0012099248124286532 0.1469552367925644
decider.lstm.weight_hh_l0: 0.002852876204997301 0.14688760042190552
decider.lstm.bias_ih_l0: -0.01689968816936016 0.14040793478488922
decider.lstm.bias_hh_l0: 0.01892095059156418 0.15396875143051147
decider.linear1.weight: 0.005283576902002096 0.1212676540017128
decider.linear1.bias: 0.010228550061583519 0.11576211452484131
decider.linear2.weight: 0.0034720515832304955 0.05509503558278084
decider.linear2.bias: 0.0038874552119523287 0.05183962732553482
decider.linear3.weight: -0.004043566063046455 0.06191523000597954
decider.linear3.bias: -0.017174560576677322 0.03555210679769516

Rewards:
65.8452
65.8452
65.8452
objective = 0.00022632384207099676
==== episode 20600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.6228e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002133934060111642 0.08400852233171463
encoder.encoder.weight_hh_l0: -0.0007022705976851285 0.08675188571214676
encoder.encoder.bias_ih_l0: 0.010827073827385902 0.08864548802375793
encoder.encoder.bias_hh_l0: 0.023899054154753685 0.08756918460130692
encoder.encoder.weight_ih_l0_reverse: 0.002286930102854967 0.08535835146903992
encoder.encoder.weight_hh_l0_reverse: 0.00035622852738015354 0.08514180034399033
encoder.encoder.bias_ih_l0_reverse: 0.018832681700587273 0.08249834179878235
encoder.encoder.bias_hh_l0_reverse: 0.01912732608616352 0.08915510028600693
decider.lstm.weight_ih_l0: -0.001208477420732379 0.1469610333442688
decider.lstm.weight_hh_l0: 0.0028682209085673094 0.1468941569328308
decider.lstm.bias_ih_l0: -0.016857530921697617 0.14039365947246552
decider.lstm.bias_hh_l0: 0.018963143229484558 0.15397460758686066
decider.linear1.weight: 0.00529129896312952 0.12127838283777237
decider.linear1.bias: 0.01025374699383974 0.11576737463474274
decider.linear2.weight: 0.0034823999740183353 0.055110104382038116
decider.linear2.bias: 0.003900211537256837 0.05184502154588699
decider.linear3.weight: -0.004050603602081537 0.061954524368047714
decider.linear3.bias: -0.017177900299429893 0.035559386014938354

Rewards:
65.8452
65.8452
65.8452
objective = 0.00021193327847868204
==== episode 20700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.6228e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002139637479558587 0.08401382714509964
encoder.encoder.weight_hh_l0: -0.0007007360691204667 0.08677088469266891
encoder.encoder.bias_ih_l0: 0.010869869962334633 0.08865483850240707
encoder.encoder.bias_hh_l0: 0.023941857740283012 0.08757220208644867
encoder.encoder.weight_ih_l0_reverse: 0.002288281684741378 0.08536229282617569
encoder.encoder.weight_hh_l0_reverse: 0.0003567189269233495 0.08514522016048431
encoder.encoder.bias_ih_l0_reverse: 0.018850727006793022 0.08249830454587936
encoder.encoder.bias_hh_l0_reverse: 0.01914537325501442 0.08916574716567993
decider.lstm.weight_ih_l0: -0.0012069765944033861 0.14696693420410156
decider.lstm.weight_hh_l0: 0.002883664797991514 0.14690078794956207
decider.lstm.bias_ih_l0: -0.01681504026055336 0.14037910103797913
decider.lstm.bias_hh_l0: 0.019005650654435158 0.1539805680513382
decider.linear1.weight: 0.0052991341799497604 0.12128923833370209
decider.linear1.bias: 0.010279010981321335 0.11577276140451431
decider.linear2.weight: 0.0034927898086607456 0.055125195533037186
decider.linear2.bias: 0.00391289871186018 0.05185042321681976
decider.linear3.weight: -0.004057604353874922 0.06199372932314873
decider.linear3.bias: -0.017181232571601868 0.03556663170456886

Rewards:
65.8452
65.8452
65.8452
objective = 0.00020146741007920355
==== episode 20800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.6228e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0021453704684972763 0.08401918411254883
encoder.encoder.weight_hh_l0: -0.0006990964757278562 0.0867902860045433
encoder.encoder.bias_ih_l0: 0.010912845842540264 0.08866432309150696
encoder.encoder.bias_hh_l0: 0.023984836414456367 0.08757521212100983
encoder.encoder.weight_ih_l0_reverse: 0.0022896593436598778 0.08536622673273087
encoder.encoder.weight_hh_l0_reverse: 0.0003572091809473932 0.08514862507581711
encoder.encoder.bias_ih_l0_reverse: 0.01886877976357937 0.08249828964471817
encoder.encoder.bias_hh_l0_reverse: 0.01916343718767166 0.08917637914419174
decider.lstm.weight_ih_l0: -0.0012054203543812037 0.14697298407554626
decider.lstm.weight_hh_l0: 0.002899194834753871 0.1469074934720993
decider.lstm.bias_ih_l0: -0.016772175207734108 0.14036425948143005
decider.lstm.bias_hh_l0: 0.019048474729061127 0.15398676693439484
decider.linear1.weight: 0.00530694704502821 0.12130022794008255
decider.linear1.bias: 0.010304209776222706 0.11577825993299484
decider.linear2.weight: 0.0035028173588216305 0.05514046922326088
decider.linear2.bias: 0.003925405442714691 0.0518559105694294
decider.linear3.weight: -0.004064568784087896 0.062032848596572876
decider.linear3.bias: -0.017184557393193245 0.03557385131716728

Rewards:
65.8452
65.8452
65.8452
objective = 0.0001910015707835555
==== episode 20900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.6228e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0021511262748390436 0.084024578332901
encoder.encoder.weight_hh_l0: -0.0006973522249609232 0.08681011199951172
encoder.encoder.bias_ih_l0: 0.010955965146422386 0.088673897087574
encoder.encoder.bias_hh_l0: 0.02402796968817711 0.0875781923532486
encoder.encoder.weight_ih_l0_reverse: 0.0022910695988684893 0.08537016063928604
encoder.encoder.weight_hh_l0_reverse: 0.0003577019670046866 0.08515201508998871
encoder.encoder.bias_ih_l0_reverse: 0.01888684555888176 0.08249829709529877
encoder.encoder.bias_hh_l0_reverse: 0.01918150670826435 0.08918699622154236
decider.lstm.weight_ih_l0: -0.0012038032291457057 0.14697913825511932
decider.lstm.weight_hh_l0: 0.0029148245230317116 0.1469143033027649
decider.lstm.bias_ih_l0: -0.016728930175304413 0.14034901559352875
decider.lstm.bias_hh_l0: 0.019091665744781494 0.15399323403835297
decider.linear1.weight: 0.005314874462783337 0.12131135165691376
decider.linear1.bias: 0.010329466313123703 0.11578390002250671
decider.linear2.weight: 0.0035132956691086292 0.05515559762716293
decider.linear2.bias: 0.003937943838536739 0.05186130106449127
decider.linear3.weight: -0.00407149875536561 0.06207186356186867
decider.linear3.bias: -0.017187871038913727 0.03558104857802391

Rewards:
65.8452
65.8452
65.8452
objective = 0.00017922748520504683
==== episode 21000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.5566e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0021569032687693834 0.08403000980615616
encoder.encoder.weight_hh_l0: -0.0006955071585252881 0.08683035522699356
encoder.encoder.bias_ih_l0: 0.010999185964465141 0.08868357539176941
encoder.encoder.bias_hh_l0: 0.024071184918284416 0.08758115768432617
encoder.encoder.weight_ih_l0_reverse: 0.00229252059943974 0.08537407219409943
encoder.encoder.weight_hh_l0_reverse: 0.0003581940254662186 0.08515538275241852
encoder.encoder.bias_ih_l0_reverse: 0.01890493556857109 0.08249833434820175
encoder.encoder.bias_hh_l0_reverse: 0.01919960416853428 0.08919760584831238
decider.lstm.weight_ih_l0: -0.0012021231232210994 0.14698544144630432
decider.lstm.weight_hh_l0: 0.0029305669013410807 0.14692120254039764
decider.lstm.bias_ih_l0: -0.01668533682823181 0.1403333693742752
decider.lstm.bias_hh_l0: 0.019135255366563797 0.15399989485740662
decider.linear1.weight: 0.005322761368006468 0.1213226243853569
decider.linear1.bias: 0.01035466231405735 0.11578965187072754
decider.linear2.weight: 0.0035238577984273434 0.0551706999540329
decider.linear2.bias: 0.003950406331568956 0.05186667665839195
decider.linear3.weight: -0.00407838961109519 0.062110785394907
decider.linear3.bias: -0.017191171646118164 0.03558821231126785

Rewards:
65.8452
65.8452
65.8452
objective = 0.00017006983398459852
==== episode 21100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.5566e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002162578050047159 0.08403535932302475
encoder.encoder.weight_hh_l0: -0.0006935909041203558 0.08685068041086197
encoder.encoder.bias_ih_l0: 0.011041657999157906 0.08869309723377228
encoder.encoder.bias_hh_l0: 0.024113668128848076 0.08758402615785599
encoder.encoder.weight_ih_l0_reverse: 0.0022940337657928467 0.08537795394659042
encoder.encoder.weight_hh_l0_reverse: 0.0003586788661777973 0.08515870571136475
encoder.encoder.bias_ih_l0_reverse: 0.01892281323671341 0.08249848335981369
encoder.encoder.bias_hh_l0_reverse: 0.01921747252345085 0.08920799940824509
decider.lstm.weight_ih_l0: -0.0012003870215266943 0.1469917893409729
decider.lstm.weight_hh_l0: 0.0029462745878845453 0.14692819118499756
decider.lstm.bias_ih_l0: -0.01664172299206257 0.14031720161437988
decider.lstm.bias_hh_l0: 0.01917891390621662 0.15400658547878265
decider.linear1.weight: 0.005330628715455532 0.12133394181728363
decider.linear1.bias: 0.01037958450615406 0.11579540371894836
decider.linear2.weight: 0.003525319043546915 0.05518630892038345
decider.linear2.bias: 0.003947244491428137 0.05189884826540947
decider.linear3.weight: -0.0040851766243577 0.06214921548962593
decider.linear3.bias: -0.017194438725709915 0.03559529408812523

Rewards:
65.8452
65.8452
65.8452
objective = 0.00016222044359892607
==== episode 21200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.5566e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0021682705264538527 0.08404074609279633
encoder.encoder.weight_hh_l0: -0.0006915809353813529 0.0868714228272438
encoder.encoder.bias_ih_l0: 0.011084230616688728 0.08870270103216171
encoder.encoder.bias_hh_l0: 0.024156251922249794 0.0875869020819664
encoder.encoder.weight_ih_l0_reverse: 0.00229558814316988 0.08538182079792023
encoder.encoder.weight_hh_l0_reverse: 0.0003591658896766603 0.08516202121973038
encoder.encoder.bias_ih_l0_reverse: 0.018940728157758713 0.08249866962432861
encoder.encoder.bias_hh_l0_reverse: 0.0192353967577219 0.08921840786933899
decider.lstm.weight_ih_l0: -0.0011985879391431808 0.1469983011484146
decider.lstm.weight_hh_l0: 0.002962078433483839 0.14693526923656464
decider.lstm.bias_ih_l0: -0.016597695648670197 0.1403006613254547
decider.lstm.bias_hh_l0: 0.01922304555773735 0.1540134847164154
decider.linear1.weight: 0.005338580813258886 0.12134543061256409
decider.linear1.bias: 0.010404542088508606 0.11580131947994232
decider.linear2.weight: 0.003535704454407096 0.05520142614841461
decider.linear2.bias: 0.003959288354963064 0.051904529333114624
decider.linear3.weight: -0.0040919240564107895 0.06218758597970009
decider.linear3.bias: -0.01719769276678562 0.035602349787950516

Rewards:
65.8452
65.8452
65.8452
objective = 0.00015306283603422344
==== episode 21300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.5566e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0021739830262959003 0.08404618501663208
encoder.encoder.weight_hh_l0: -0.0006894748657941818 0.08689258992671967
encoder.encoder.bias_ih_l0: 0.011126954108476639 0.08871239423751831
encoder.encoder.bias_hh_l0: 0.024198951199650764 0.0875898003578186
encoder.encoder.weight_ih_l0_reverse: 0.0022971704602241516 0.08538569509983063
encoder.encoder.weight_hh_l0_reverse: 0.00035965628921985626 0.08516532182693481
encoder.encoder.bias_ih_l0_reverse: 0.018958695232868195 0.08249890804290771
encoder.encoder.bias_hh_l0_reverse: 0.01925336942076683 0.0892288088798523
decider.lstm.weight_ih_l0: -0.0011967255268245935 0.14700499176979065
decider.lstm.weight_hh_l0: 0.0029779698234051466 0.14694245159626007
decider.lstm.bias_ih_l0: -0.016553208231925964 0.14028379321098328
decider.lstm.bias_hh_l0: 0.019267629832029343 0.15402057766914368
decider.linear1.weight: 0.0053464993834495544 0.12135710567235947
decider.linear1.bias: 0.01042945310473442 0.11580733954906464
decider.linear2.weight: 0.003545875195413828 0.0552167184650898
decider.linear2.bias: 0.00397135503590107 0.05190998688340187
decider.linear3.weight: -0.004098643083125353 0.062225889414548874
decider.linear3.bias: -0.017200937494635582 0.03560937941074371

Rewards:
65.8452
65.8452
65.8452
objective = 0.00014259698218666017
==== episode 21400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.5566e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0021797078661620617 0.08405166864395142
encoder.encoder.weight_hh_l0: -0.0006872758967801929 0.08691420406103134
encoder.encoder.bias_ih_l0: 0.01116976235061884 0.08872215449810028
encoder.encoder.bias_hh_l0: 0.02424175664782524 0.08759277313947678
encoder.encoder.weight_ih_l0_reverse: 0.0022987895645201206 0.08538955450057983
encoder.encoder.weight_hh_l0_reverse: 0.0003601506759878248 0.08516861498355865
encoder.encoder.bias_ih_l0_reverse: 0.01897672563791275 0.0824991911649704
encoder.encoder.bias_hh_l0_reverse: 0.01927139423787594 0.08923918753862381
decider.lstm.weight_ih_l0: -0.0011948035098612309 0.147011861205101
decider.lstm.weight_hh_l0: 0.002993930596858263 0.14694976806640625
decider.lstm.bias_ih_l0: -0.01650821417570114 0.1402665078639984
decider.lstm.bias_hh_l0: 0.019312620162963867 0.15402792394161224
decider.linear1.weight: 0.005353542976081371 0.12136831134557724
decider.linear1.bias: 0.010452024638652802 0.11581769585609436
decider.linear2.weight: 0.0035564680583775043 0.05523190274834633
decider.linear2.bias: 0.003983424045145512 0.05191531032323837
decider.linear3.weight: -0.004105322528630495 0.06226411461830139
decider.linear3.bias: -0.01720408722758293 0.03561623394489288

Rewards:
65.8452
65.8452
65.8452
objective = 0.00013343937462195754
==== episode 21500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.4910e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002185429912060499 0.08405717462301254
encoder.encoder.weight_hh_l0: -0.0006850003264844418 0.08693618327379227
encoder.encoder.bias_ih_l0: 0.011212555691599846 0.08873194456100464
encoder.encoder.bias_hh_l0: 0.024284545332193375 0.08759579807519913
encoder.encoder.weight_ih_l0_reverse: 0.0023004517424851656 0.08539340645074844
encoder.encoder.weight_hh_l0_reverse: 0.0003606456739362329 0.0851719006896019
encoder.encoder.bias_ih_l0_reverse: 0.01899479329586029 0.08249950408935547
encoder.encoder.bias_hh_l0_reverse: 0.019289454445242882 0.08924955129623413
decider.lstm.weight_ih_l0: -0.0011928309686481953 0.1470189392566681
decider.lstm.weight_hh_l0: 0.003009933978319168 0.1469571888446808
decider.lstm.bias_ih_l0: -0.01646280661225319 0.1402488499879837
decider.lstm.bias_hh_l0: 0.019357988610863686 0.1540355384349823
decider.linear1.weight: 0.005361579358577728 0.12138038873672485
decider.linear1.bias: 0.0104769766330719 0.11582406610250473
decider.linear2.weight: 0.0035671775694936514 0.05524706095457077
decider.linear2.bias: 0.003995439503341913 0.05192064866423607
decider.linear3.weight: -0.004111969377845526 0.062302250415086746
decider.linear3.bias: -0.01720711775124073 0.03562285378575325

Rewards:
65.8452
65.8452
65.8452
objective = 0.0001268982159672305
==== episode 21600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.4910e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0021910809446126223 0.08406265079975128
encoder.encoder.weight_hh_l0: -0.0006826870958320796 0.08695826679468155
encoder.encoder.bias_ih_l0: 0.011254806071519852 0.08874162286520004
encoder.encoder.bias_hh_l0: 0.024326805025339127 0.08759882301092148
encoder.encoder.weight_ih_l0_reverse: 0.0023021376691758633 0.08539720624685287
encoder.encoder.weight_hh_l0_reverse: 0.00036113851820118725 0.08517514914274216
encoder.encoder.bias_ih_l0_reverse: 0.019012700766324997 0.08249985426664352
encoder.encoder.bias_hh_l0_reverse: 0.019307374954223633 0.0892597883939743
decider.lstm.weight_ih_l0: -0.001190836075693369 0.14702612161636353
decider.lstm.weight_hh_l0: 0.0030258060432970524 0.1469646543264389
decider.lstm.bias_ih_l0: -0.016417579725384712 0.14023074507713318
decider.lstm.bias_hh_l0: 0.01940324530005455 0.15404334664344788
decider.linear1.weight: 0.005369554739445448 0.12139255553483963
decider.linear1.bias: 0.010501623153686523 0.11583060771226883
decider.linear2.weight: 0.003577497787773609 0.05526232719421387
decider.linear2.bias: 0.004007195588201284 0.05192602053284645
decider.linear3.weight: -0.004118514247238636 0.06233992427587509
decider.linear3.bias: -0.017210112884640694 0.03562939539551735

Rewards:
65.8452
65.8452
65.8452
objective = 0.00012297352077439427
==== episode 21700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.4910e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0021967380307614803 0.084068164229393
encoder.encoder.weight_hh_l0: -0.0006802980205975473 0.08698073774576187
encoder.encoder.bias_ih_l0: 0.011297095566987991 0.08875131607055664
encoder.encoder.bias_hh_l0: 0.024369103834033012 0.08760187774896622
encoder.encoder.weight_ih_l0_reverse: 0.002303858520463109 0.08540099859237671
encoder.encoder.weight_hh_l0_reverse: 0.0003616335161495954 0.08517839759588242
encoder.encoder.bias_ih_l0_reverse: 0.019030703231692314 0.08250027149915695
encoder.encoder.bias_hh_l0_reverse: 0.019325360655784607 0.08927005529403687
decider.lstm.weight_ih_l0: -0.0011887962464243174 0.14703354239463806
decider.lstm.weight_hh_l0: 0.0030417214147746563 0.14697226881980896
decider.lstm.bias_ih_l0: -0.016371896490454674 0.14021222293376923
decider.lstm.bias_hh_l0: 0.019448986276984215 0.15405145287513733
decider.linear1.weight: 0.005377577152103186 0.12140499800443649
decider.linear1.bias: 0.010526305995881557 0.11583731323480606
decider.linear2.weight: 0.0035881013609468937 0.055277589708566666
decider.linear2.bias: 0.0040189241990447044 0.05193130671977997
decider.linear3.weight: -0.004125020932406187 0.06237756460905075
decider.linear3.bias: -0.017213093116879463 0.03563590347766876

Rewards:
65.8452
65.8452
65.8452
objective = 0.00011512414494063705
==== episode 21800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.4910e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0022024032659828663 0.08407371491193771
encoder.encoder.weight_hh_l0: -0.000677835545502603 0.08700361847877502
encoder.encoder.bias_ih_l0: 0.01133943535387516 0.08876106142997742
encoder.encoder.bias_hh_l0: 0.024411436170339584 0.08760501444339752
encoder.encoder.weight_ih_l0_reverse: 0.0023056156933307648 0.08540479838848114
encoder.encoder.weight_hh_l0_reverse: 0.00036213273415341973 0.08518164604902267
encoder.encoder.bias_ih_l0_reverse: 0.019048774614930153 0.08250076323747635
encoder.encoder.bias_hh_l0_reverse: 0.019343428313732147 0.08928030729293823
decider.lstm.weight_ih_l0: -0.0011867065913975239 0.1470412015914917
decider.lstm.weight_hh_l0: 0.0030576635617762804 0.14698006212711334
decider.lstm.bias_ih_l0: -0.01632571592926979 0.14019329845905304
decider.lstm.bias_hh_l0: 0.01949523389339447 0.15405985713005066
decider.linear1.weight: 0.005385638680309057 0.12141771614551544
decider.linear1.bias: 0.010551027953624725 0.11584419757127762
decider.linear2.weight: 0.0035989144816994667 0.05529278889298439
decider.linear2.bias: 0.004030623473227024 0.05193660408258438
decider.linear3.weight: -0.004131504334509373 0.062415145337581635
decider.linear3.bias: -0.01721605844795704 0.03564238175749779

Rewards:
65.8452
65.8452
65.8452
objective = 0.0001059665228240192
==== episode 21900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.4910e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0022080717608332634 0.0840793028473854
encoder.encoder.weight_hh_l0: -0.0006753052002750337 0.08702689409255981
encoder.encoder.bias_ih_l0: 0.011381780728697777 0.08877084404230118
encoder.encoder.bias_hh_l0: 0.02445378340780735 0.08760825544595718
encoder.encoder.weight_ih_l0_reverse: 0.002307410119101405 0.08540859073400497
encoder.encoder.weight_hh_l0_reverse: 0.0003626365796662867 0.08518490195274353
encoder.encoder.bias_ih_l0_reverse: 0.01906692050397396 0.08250129967927933
encoder.encoder.bias_hh_l0_reverse: 0.019361581653356552 0.08929058164358139
decider.lstm.weight_ih_l0: -0.0011845722328871489 0.14704911410808563
decider.lstm.weight_hh_l0: 0.0030736224725842476 0.14698795974254608
decider.lstm.bias_ih_l0: -0.01627904362976551 0.14017395675182343
decider.lstm.bias_hh_l0: 0.0195419080555439 0.15406854450702667
decider.linear1.weight: 0.005393753759562969 0.12143071740865707
decider.linear1.bias: 0.010575786232948303 0.1158512756228447
decider.linear2.weight: 0.003609479870647192 0.055308274924755096
decider.linear2.bias: 0.004042148590087891 0.05194193869829178
decider.linear3.weight: -0.0041379486210644245 0.06245267018675804
decider.linear3.bias: -0.01721901074051857 0.03564882278442383

Rewards:
65.8452
65.8452
65.8452
objective = 0.0001007336177281104
==== episode 22000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.4261e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002213741187006235 0.08408492803573608
encoder.encoder.weight_hh_l0: -0.0006727167055942118 0.08705054968595505
encoder.encoder.bias_ih_l0: 0.011424122378230095 0.08878060430288315
encoder.encoder.bias_hh_l0: 0.02449614182114601 0.08761155605316162
encoder.encoder.weight_ih_l0_reverse: 0.0023092397022992373 0.0854123905301094
encoder.encoder.weight_hh_l0_reverse: 0.00036314420867711306 0.08518816530704498
encoder.encoder.bias_ih_l0_reverse: 0.01908513717353344 0.08250189572572708
encoder.encoder.bias_hh_l0_reverse: 0.019379805773496628 0.08930081874132156
decider.lstm.weight_ih_l0: -0.0011824084213003516 0.14705730974674225
decider.lstm.weight_hh_l0: 0.003089573932811618 0.14699605107307434
decider.lstm.bias_ih_l0: -0.016231931746006012 0.14015424251556396
decider.lstm.bias_hh_l0: 0.019589029252529144 0.15407754480838776
decider.linear1.weight: 0.005401862785220146 0.12144403159618378
decider.linear1.bias: 0.010600528679788113 0.1158585250377655
decider.linear2.weight: 0.00362023850902915 0.055323801934719086
decider.linear2.bias: 0.004053647629916668 0.05194723233580589
decider.linear3.weight: -0.004144355654716492 0.06249013543128967
decider.linear3.bias: -0.01722194440662861 0.03565523028373718

Rewards:
65.8452
65.8452
65.8452
objective = 9.680890798335895e-05
==== episode 22100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.4261e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0022193577606230974 0.08409052342176437
encoder.encoder.weight_hh_l0: -0.0006700993981212378 0.08707433193922043
encoder.encoder.bias_ih_l0: 0.011466026306152344 0.08879028260707855
encoder.encoder.bias_hh_l0: 0.02453804388642311 0.08761493116617203
encoder.encoder.weight_ih_l0_reverse: 0.002311078133061528 0.08541613817214966
encoder.encoder.weight_hh_l0_reverse: 0.0003636520414147526 0.08519140630960464
encoder.encoder.bias_ih_l0_reverse: 0.019103262573480606 0.08250253647565842
encoder.encoder.bias_hh_l0_reverse: 0.019397933036088943 0.08931095898151398
decider.lstm.weight_ih_l0: -0.0011802278459072113 0.14706571400165558
decider.lstm.weight_hh_l0: 0.0031053435523062944 0.14700421690940857
decider.lstm.bias_ih_l0: -0.016184838488698006 0.1401343196630478
decider.lstm.bias_hh_l0: 0.01963610015809536 0.15408672392368317
decider.linear1.weight: 0.005409973673522472 0.1214575543999672
decider.linear1.bias: 0.010625075548887253 0.11586593091487885
decider.linear2.weight: 0.003631132422015071 0.05533912777900696
decider.linear2.bias: 0.004064997658133507 0.05195245146751404
decider.linear3.weight: -0.004150667227804661 0.06252717226743698
decider.linear3.bias: -0.017224840819835663 0.03566155582666397

Rewards:
65.8452
65.8452
65.8452
objective = 9.026776388054714e-05
==== episode 22200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.4261e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002224971540272236 0.08409614115953445
encoder.encoder.weight_hh_l0: -0.0006674333126284182 0.08709848672151566
encoder.encoder.bias_ih_l0: 0.011507894843816757 0.08879993110895157
encoder.encoder.bias_hh_l0: 0.02457990124821663 0.08761836588382721
encoder.encoder.weight_ih_l0_reverse: 0.0023129500914365053 0.08541988581418991
encoder.encoder.weight_hh_l0_reverse: 0.0003641633375082165 0.0851946696639061
encoder.encoder.bias_ih_l0_reverse: 0.019121471792459488 0.08250325918197632
encoder.encoder.bias_hh_l0_reverse: 0.019416145980358124 0.0893210917711258
decider.lstm.weight_ih_l0: -0.0011780202621594071 0.14707441627979279
decider.lstm.weight_hh_l0: 0.0031210780143737793 0.14701254665851593
decider.lstm.bias_ih_l0: -0.016137294471263885 0.14011406898498535
decider.lstm.bias_hh_l0: 0.01968361996114254 0.15409614145755768
decider.linear1.weight: 0.005418124608695507 0.12147141993045807
decider.linear1.bias: 0.010649658739566803 0.1158735528588295
decider.linear2.weight: 0.0036417171359062195 0.0553547739982605
decider.linear2.bias: 0.0040761856362223625 0.05195779725909233
decider.linear3.weight: -0.004156944341957569 0.06256415694952011
decider.linear3.bias: -0.017227722331881523 0.03566784784197807

Rewards:
65.8452
65.8452
65.8452
objective = 8.503485878463835e-05
==== episode 22300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.4261e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002230587648227811 0.08410178869962692
encoder.encoder.weight_hh_l0: -0.0006647274130955338 0.08712299168109894
encoder.encoder.bias_ih_l0: 0.011549750342965126 0.08880956470966339
encoder.encoder.bias_hh_l0: 0.02462172880768776 0.08762187510728836
encoder.encoder.weight_ih_l0_reverse: 0.0023148551117628813 0.08542364090681076
encoder.encoder.weight_hh_l0_reverse: 0.0003646798140835017 0.08519794046878815
encoder.encoder.bias_ih_l0_reverse: 0.019139785319566727 0.08250405639410019
encoder.encoder.bias_hh_l0_reverse: 0.019434446468949318 0.08933122456073761
decider.lstm.weight_ih_l0: -0.0011757899774238467 0.14708343148231506
decider.lstm.weight_hh_l0: 0.0031367591582238674 0.1470210701227188
decider.lstm.bias_ih_l0: -0.01608935184776783 0.14009340107440948
decider.lstm.bias_hh_l0: 0.019731590524315834 0.1541057974100113
decider.linear1.weight: 0.005425549112260342 0.121485136449337
decider.linear1.bias: 0.01067216508090496 0.11588503420352936
decider.linear2.weight: 0.0036527097690850496 0.05537039041519165
decider.linear2.bias: 0.004087404347956181 0.051963042467832565
decider.linear3.weight: -0.004163178149610758 0.06260108202695847
decider.linear3.bias: -0.01723058521747589 0.03567410260438919

Rewards:
65.8452
65.8452
65.8452
objective = 7.849370740586892e-05
==== episode 22400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.4261e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0022361986339092255 0.08410745114088058
encoder.encoder.weight_hh_l0: -0.0006619874038733542 0.08714783936738968
encoder.encoder.bias_ih_l0: 0.011591550894081593 0.08881915360689163
encoder.encoder.bias_hh_l0: 0.024663517251610756 0.08762549608945847
encoder.encoder.weight_ih_l0_reverse: 0.002316787140443921 0.08542739599943161
encoder.encoder.weight_hh_l0_reverse: 0.00036520263529382646 0.08520124852657318
encoder.encoder.bias_ih_l0_reverse: 0.01915818080306053 0.08250491321086884
encoder.encoder.bias_hh_l0_reverse: 0.019452836364507675 0.08934134244918823
decider.lstm.weight_ih_l0: -0.0011735470034182072 0.1470927596092224
decider.lstm.weight_hh_l0: 0.0031523569487035275 0.14702972769737244
decider.lstm.bias_ih_l0: -0.016041094437241554 0.14007233083248138
decider.lstm.bias_hh_l0: 0.01977989636361599 0.154115691781044
decider.linear1.weight: 0.005433752201497555 0.12149979919195175
decider.linear1.bias: 0.010696780867874622 0.11589311063289642
decider.linear2.weight: 0.0036635161377489567 0.055386174470186234
decider.linear2.bias: 0.004098443314433098 0.05196834355592728
decider.linear3.weight: -0.004169378895312548 0.06263794749975204
decider.linear3.bias: -0.017233429476618767 0.035680320113897324

Rewards:
65.8452
65.8452
65.8452
objective = 7.456901221303269e-05
==== episode 22500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.3619e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0022417991422116756 0.08411314338445663
encoder.encoder.weight_hh_l0: -0.0006592173012904823 0.08717300742864609
encoder.encoder.bias_ih_l0: 0.011633248068392277 0.0888286828994751
encoder.encoder.bias_hh_l0: 0.024705231189727783 0.08762917667627335
encoder.encoder.weight_ih_l0_reverse: 0.0023187429178506136 0.08543115109205246
encoder.encoder.weight_hh_l0_reverse: 0.0003657317138276994 0.08520457148551941
encoder.encoder.bias_ih_l0_reverse: 0.019176648929715157 0.08250583708286285
encoder.encoder.bias_hh_l0_reverse: 0.019471311941742897 0.08935143053531647
decider.lstm.weight_ih_l0: -0.001171290990896523 0.14710243046283722
decider.lstm.weight_hh_l0: 0.003167860209941864 0.1470385491847992
decider.lstm.bias_ih_l0: -0.015992477536201477 0.1400509625673294
decider.lstm.bias_hh_l0: 0.019828541204333305 0.1541258543729782
decider.linear1.weight: 0.005442000459879637 0.12151488661766052
decider.linear1.bias: 0.010721437633037567 0.1159014031291008
decider.linear2.weight: 0.0036745998077094555 0.05540208891034126
decider.linear2.bias: 0.0041094631887972355 0.05197351798415184
decider.linear3.weight: -0.004175540991127491 0.06267474591732025
decider.linear3.bias: -0.017236253246665 0.03568649664521217

Rewards:
65.8452
65.8452
65.8452
objective = 7.195255602709949e-05
==== episode 22600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.3619e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0022473426070064306 0.0841187834739685
encoder.encoder.weight_hh_l0: -0.0006564522627741098 0.08719823509454727
encoder.encoder.bias_ih_l0: 0.011674459092319012 0.08883809298276901
encoder.encoder.bias_hh_l0: 0.024746447801589966 0.08763287961483002
encoder.encoder.weight_ih_l0_reverse: 0.002320698229596019 0.08543486893177032
encoder.encoder.weight_hh_l0_reverse: 0.0003662613162305206 0.08520789444446564
encoder.encoder.bias_ih_l0_reverse: 0.019195036962628365 0.08250683546066284
encoder.encoder.bias_hh_l0_reverse: 0.019489699974656105 0.08936142176389694
decider.lstm.weight_ih_l0: -0.0011690508108586073 0.14711232483386993
decider.lstm.weight_hh_l0: 0.003183086635544896 0.14704746007919312
decider.lstm.bias_ih_l0: -0.01594410091638565 0.1400296539068222
decider.lstm.bias_hh_l0: 0.01987697184085846 0.15413600206375122
decider.linear1.weight: 0.005450209602713585 0.12153027206659317
decider.linear1.bias: 0.010745881125330925 0.11590985953807831
decider.linear2.weight: 0.003685455769300461 0.05541796237230301
decider.linear2.bias: 0.004120229743421078 0.051978740841150284
decider.linear3.weight: -0.0041816034354269505 0.06271111220121384
decider.linear3.bias: -0.017239036038517952 0.03569258749485016

Rewards:
65.8452
65.8452
65.8452
objective = 6.671964365523309e-05
==== episode 22700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.3619e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0022528818808496 0.08412445336580276
encoder.encoder.weight_hh_l0: -0.00065367337083444 0.08722377568483353
encoder.encoder.bias_ih_l0: 0.01171558815985918 0.08884746581315994
encoder.encoder.bias_hh_l0: 0.024787582457065582 0.08763667196035385
encoder.encoder.weight_ih_l0_reverse: 0.002322671003639698 0.08543857932090759
encoder.encoder.weight_hh_l0_reverse: 0.00036679781624116004 0.08521124720573425
encoder.encoder.bias_ih_l0_reverse: 0.019213499501347542 0.0825079083442688
encoder.encoder.bias_hh_l0_reverse: 0.019508173689246178 0.08937139064073563
decider.lstm.weight_ih_l0: -0.0011668081860989332 0.1471225470304489
decider.lstm.weight_hh_l0: 0.0031981763895601034 0.14705654978752136
decider.lstm.bias_ih_l0: -0.015895452350378036 0.1400081217288971
decider.lstm.bias_hh_l0: 0.019925659522414207 0.15414634346961975
decider.linear1.weight: 0.005458460655063391 0.12154615670442581
decider.linear1.bias: 0.010770363733172417 0.11591857671737671
decider.linear2.weight: 0.003696585074067116 0.05543399229645729
decider.linear2.bias: 0.0041310107335448265 0.05198388919234276
decider.linear3.weight: -0.0041876258328557014 0.06274741888046265
decider.linear3.bias: -0.01724179834127426 0.03569864109158516

Rewards:
65.8452
65.8452
65.8452
objective = 6.279494846239686e-05
==== episode 22800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.3619e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0022584099788218737 0.08413012325763702
encoder.encoder.weight_hh_l0: -0.0006508829537779093 0.08724960684776306
encoder.encoder.bias_ih_l0: 0.011756637133657932 0.08885680884122849
encoder.encoder.bias_hh_l0: 0.024828625842928886 0.08764053881168365
encoder.encoder.weight_ih_l0_reverse: 0.0023246610071510077 0.08544231206178665
encoder.encoder.weight_hh_l0_reverse: 0.0003673396713566035 0.08521464467048645
encoder.encoder.bias_ih_l0_reverse: 0.019232038408517838 0.08250906318426132
encoder.encoder.bias_hh_l0_reverse: 0.01952672377228737 0.08938136696815491
decider.lstm.weight_ih_l0: -0.0011645704507827759 0.14713309705257416
decider.lstm.weight_hh_l0: 0.003213100600987673 0.14706578850746155
decider.lstm.bias_ih_l0: -0.015846598893404007 0.13998651504516602
decider.lstm.bias_hh_l0: 0.019974496215581894 0.15415681898593903
decider.linear1.weight: 0.0054667433723807335 0.12156253308057785
decider.linear1.bias: 0.010794850066304207 0.11592753231525421
decider.linear2.weight: 0.003707580268383026 0.05545017123222351
decider.linear2.bias: 0.004141619428992271 0.051989104598760605
decider.linear3.weight: -0.004193617030978203 0.06278366595506668
decider.linear3.bias: -0.01724453829228878 0.035704657435417175

Rewards:
65.8452
65.8452
65.8452
objective = 6.0178495914442465e-05
==== episode 22900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.3619e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0022639213129878044 0.08413580805063248
encoder.encoder.weight_hh_l0: -0.0006480900337919593 0.08727571368217468
encoder.encoder.bias_ih_l0: 0.011797552928328514 0.08886606246232986
encoder.encoder.bias_hh_l0: 0.02486955188214779 0.08764446526765823
encoder.encoder.weight_ih_l0_reverse: 0.0023266614880412817 0.08544602990150452
encoder.encoder.weight_hh_l0_reverse: 0.0003678867651615292 0.08521807193756104
encoder.encoder.bias_ih_l0_reverse: 0.019250651821494102 0.08251029253005981
encoder.encoder.bias_hh_l0_reverse: 0.019545340910553932 0.0893913060426712
decider.lstm.weight_ih_l0: -0.0011623427271842957 0.14714398980140686
decider.lstm.weight_hh_l0: 0.003227842040359974 0.14707520604133606
decider.lstm.bias_ih_l0: -0.015797648578882217 0.13996487855911255
decider.lstm.bias_hh_l0: 0.020023416727781296 0.15416733920574188
decider.linear1.weight: 0.005475065670907497 0.12157943844795227
decider.linear1.bias: 0.01081935316324234 0.11593671888113022
decider.linear2.weight: 0.003718872554600239 0.05546650290489197
decider.linear2.bias: 0.004152259323745966 0.051994264125823975
decider.linear3.weight: -0.00419955886900425 0.06281983852386475
decider.linear3.bias: -0.017247259616851807 0.03571062162518501

Rewards:
65.8452
65.8452
65.8452
objective = 5.756203245255165e-05
==== episode 23000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.2982e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002269431948661804 0.08414146304130554
encoder.encoder.weight_hh_l0: -0.0006453159148804843 0.08730204403400421
encoder.encoder.bias_ih_l0: 0.011838274076581001 0.08887523412704468
encoder.encoder.bias_hh_l0: 0.02491026557981968 0.08764845877885818
encoder.encoder.weight_ih_l0_reverse: 0.0023286561481654644 0.08544975519180298
encoder.encoder.weight_hh_l0_reverse: 0.0003684383991640061 0.0852215513586998
encoder.encoder.bias_ih_l0_reverse: 0.01926925592124462 0.0825115516781807
encoder.encoder.bias_hh_l0_reverse: 0.0195639505982399 0.08940118551254272
decider.lstm.weight_ih_l0: -0.0011601136066019535 0.14715507626533508
decider.lstm.weight_hh_l0: 0.003242245875298977 0.147084578871727
decider.lstm.bias_ih_l0: -0.01574902981519699 0.13994362950325012
decider.lstm.bias_hh_l0: 0.020072003826498985 0.15417732298374176
decider.linear1.weight: 0.005482797976583242 0.12159637361764908
decider.linear1.bias: 0.010841868817806244 0.11594920605421066
decider.linear2.weight: 0.0037299583200365305 0.05548310652375221
decider.linear2.bias: 0.004162711091339588 0.05199947953224182
decider.linear3.weight: -0.004205464385449886 0.06285595893859863
decider.linear3.bias: -0.017249956727027893 0.03571654483675957

Rewards:
65.8452
65.8452
65.8452
objective = 5.232912371866405e-05
==== episode 23100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.2982e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0022748466581106186 0.08414704352617264
encoder.encoder.weight_hh_l0: -0.0006425929605029523 0.08732818067073822
encoder.encoder.bias_ih_l0: 0.011878292076289654 0.08888429403305054
encoder.encoder.bias_hh_l0: 0.024950269609689713 0.08765245229005814
encoder.encoder.weight_ih_l0_reverse: 0.0023306256625801325 0.08545343577861786
encoder.encoder.weight_hh_l0_reverse: 0.00036898814141750336 0.08522502332925797
encoder.encoder.bias_ih_l0_reverse: 0.019287649542093277 0.08251286298036575
encoder.encoder.bias_hh_l0_reverse: 0.019582344219088554 0.08941088616847992
decider.lstm.weight_ih_l0: -0.001157953287474811 0.1471661925315857
decider.lstm.weight_hh_l0: 0.0032561069820076227 0.14709387719631195
decider.lstm.bias_ih_l0: -0.015701666474342346 0.13992291688919067
decider.lstm.bias_hh_l0: 0.020119452849030495 0.15418697893619537
decider.linear1.weight: 0.005491096526384354 0.12161408364772797
decider.linear1.bias: 0.010866000317037106 0.11595857888460159
decider.linear2.weight: 0.0037409921642392874 0.05549972131848335
decider.linear2.bias: 0.004172935150563717 0.05200457200407982
decider.linear3.weight: -0.004211270250380039 0.06289169937372208
decider.linear3.bias: -0.017252609133720398 0.03572237864136696

Rewards:
65.8452
65.8452
65.8452
objective = 5.232912371866405e-05
==== episode 23200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.2982e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00228022038936615 0.08415260165929794
encoder.encoder.weight_hh_l0: -0.0006398928235284984 0.0873543918132782
encoder.encoder.bias_ih_l0: 0.011918030679225922 0.08889326453208923
encoder.encoder.bias_hh_l0: 0.02498999983072281 0.08765651285648346
encoder.encoder.weight_ih_l0_reverse: 0.002332590986043215 0.08545709401369095
encoder.encoder.weight_hh_l0_reverse: 0.0003695413179229945 0.08522853255271912
encoder.encoder.bias_ih_l0_reverse: 0.01930599845945835 0.0825142115354538
encoder.encoder.bias_hh_l0_reverse: 0.019600696861743927 0.08942050486803055
decider.lstm.weight_ih_l0: -0.0011558288242667913 0.14717747271060944
decider.lstm.weight_hh_l0: 0.003269631415605545 0.1471032053232193
decider.lstm.bias_ih_l0: -0.015654798597097397 0.13990260660648346
decider.lstm.bias_hh_l0: 0.02016638219356537 0.15419647097587585
decider.linear1.weight: 0.005499451421201229 0.12163230031728745
decider.linear1.bias: 0.010890095494687557 0.115968257188797
decider.linear2.weight: 0.0037523279897868633 0.055516477674245834
decider.linear2.bias: 0.004183150827884674 0.05200957506895065
decider.linear3.weight: -0.00421704538166523 0.06292743235826492
decider.linear3.bias: -0.017255209386348724 0.035728126764297485

Rewards:
65.8452
65.8452
65.8452
objective = 4.840443580178544e-05
==== episode 23300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.2982e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002285576658323407 0.08415814489126205
encoder.encoder.weight_hh_l0: -0.0006372069474309683 0.08738081157207489
encoder.encoder.bias_ih_l0: 0.011957579292356968 0.08890216052532196
encoder.encoder.bias_hh_l0: 0.025029566138982773 0.08766062557697296
encoder.encoder.weight_ih_l0_reverse: 0.00233455840498209 0.08546075969934464
encoder.encoder.weight_hh_l0_reverse: 0.00037009644438512623 0.08523207902908325
encoder.encoder.bias_ih_l0_reverse: 0.019324390217661858 0.08251561224460602
encoder.encoder.bias_hh_l0_reverse: 0.019619083032011986 0.089430071413517
decider.lstm.weight_ih_l0: -0.001153716933913529 0.14718900620937347
decider.lstm.weight_hh_l0: 0.0032829968258738518 0.147112637758255
decider.lstm.bias_ih_l0: -0.015608041547238827 0.13988250494003296
decider.lstm.bias_hh_l0: 0.0202131699770689 0.15420587360858917
decider.linear1.weight: 0.005507824011147022 0.1216510757803917
decider.linear1.bias: 0.010914169251918793 0.1159781813621521
decider.linear2.weight: 0.0037633380852639675 0.0555335208773613
decider.linear2.bias: 0.004193221218883991 0.05201468616724014
decider.linear3.weight: -0.0042227813974022865 0.06296315789222717
decider.linear3.bias: -0.017257623374462128 0.035733528435230255

Rewards:
65.8452
65.8452
65.8452
objective = 4.709620770881884e-05
==== episode 23400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.2982e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002290911041200161 0.08416366577148438
encoder.encoder.weight_hh_l0: -0.0006345415022224188 0.0874074324965477
encoder.encoder.bias_ih_l0: 0.011996926739811897 0.08891096711158752
encoder.encoder.bias_hh_l0: 0.025068916380405426 0.08766478300094604
encoder.encoder.weight_ih_l0_reverse: 0.002336514415219426 0.08546441048383713
encoder.encoder.weight_hh_l0_reverse: 0.0003706543648149818 0.08523566275835037
encoder.encoder.bias_ih_l0_reverse: 0.019342800602316856 0.08251708000898361
encoder.encoder.bias_hh_l0_reverse: 0.019637487828731537 0.08943960070610046
decider.lstm.weight_ih_l0: -0.0011516236700117588 0.1472007781267166
decider.lstm.weight_hh_l0: 0.0032961913384497166 0.14712218940258026
decider.lstm.bias_ih_l0: -0.01556139811873436 0.13986258208751678
decider.lstm.bias_hh_l0: 0.02025982178747654 0.15421514213085175
decider.linear1.weight: 0.005516280420124531 0.1216704398393631
decider.linear1.bias: 0.010938270948827267 0.11598829180002213
decider.linear2.weight: 0.0037743691354990005 0.05555080622434616
decider.linear2.bias: 0.004203179385513067 0.05201974883675575
decider.linear3.weight: -0.004228480160236359 0.06299887597560883
decider.linear3.bias: -0.01726001314818859 0.03573888540267944

Rewards:
65.8452
65.8452
65.8452
objective = 4.1863291698973626e-05
==== episode 23500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.2353e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002296251943334937 0.08416920155286789
encoder.encoder.weight_hh_l0: -0.0006318923551589251 0.08743435889482498
encoder.encoder.bias_ih_l0: 0.012036172673106194 0.08891968429088593
encoder.encoder.bias_hh_l0: 0.02510816790163517 0.08766897022724152
encoder.encoder.weight_ih_l0_reverse: 0.0023384736850857735 0.08546806871891022
encoder.encoder.weight_hh_l0_reverse: 0.0003712122270371765 0.08523926883935928
encoder.encoder.bias_ih_l0_reverse: 0.019361203536391258 0.0825185775756836
encoder.encoder.bias_hh_l0_reverse: 0.019655892625451088 0.08944907784461975
decider.lstm.weight_ih_l0: -0.0011495244689285755 0.14721284806728363
decider.lstm.weight_hh_l0: 0.0033093043603003025 0.14713189005851746
decider.lstm.bias_ih_l0: -0.015514625236392021 0.13984276354312897
decider.lstm.bias_hh_l0: 0.020306603983044624 0.15422414243221283
decider.linear1.weight: 0.005525677464902401 0.12169226258993149
decider.linear1.bias: 0.010963310487568378 0.1159999892115593
decider.linear2.weight: 0.0037853922694921494 0.055568303912878036
decider.linear2.bias: 0.004213086329400539 0.05202484875917435
decider.linear3.weight: -0.004234142601490021 0.06303456425666809
decider.linear3.bias: -0.017262374982237816 0.03574419021606445

Rewards:
65.8452
65.8452
65.8452
objective = 4.0555063606007025e-05
==== episode 23600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.2353e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002301611937582493 0.08417470753192902
encoder.encoder.weight_hh_l0: -0.000629279064014554 0.0874616801738739
encoder.encoder.bias_ih_l0: 0.012075179256498814 0.08892816305160522
encoder.encoder.bias_hh_l0: 0.02514718286693096 0.08767315745353699
encoder.encoder.weight_ih_l0_reverse: 0.0023404418025165796 0.08547169715166092
encoder.encoder.weight_hh_l0_reverse: 0.00037176880869083107 0.08524288982152939
encoder.encoder.bias_ih_l0_reverse: 0.019379327073693275 0.08252006024122238
encoder.encoder.bias_hh_l0_reverse: 0.019674008712172508 0.08945843577384949
decider.lstm.weight_ih_l0: -0.0011473560007289052 0.14722518622875214
decider.lstm.weight_hh_l0: 0.0033224846702069044 0.14714182913303375
decider.lstm.bias_ih_l0: -0.015467346645891666 0.13982300460338593
decider.lstm.bias_hh_l0: 0.02035384252667427 0.15423224866390228
decider.linear1.weight: 0.005538232158869505 0.12172214686870575
decider.linear1.bias: 0.010990487411618233 0.11602075397968292
decider.linear2.weight: 0.0037957513704895973 0.055586475878953934
decider.linear2.bias: 0.004222871735692024 0.052030086517333984
decider.linear3.weight: -0.00423969142138958 0.06306982040405273
decider.linear3.bias: -0.017264679074287415 0.03574938327074051

Rewards:
65.8452
65.8452
65.8452
objective = 3.663037932710722e-05
==== episode 23700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.2353e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002306908369064331 0.08418014645576477
encoder.encoder.weight_hh_l0: -0.0006267191492952406 0.08748894184827805
encoder.encoder.bias_ih_l0: 0.012113657779991627 0.08893649280071259
encoder.encoder.bias_hh_l0: 0.025185655802488327 0.08767733722925186
encoder.encoder.weight_ih_l0_reverse: 0.0023423905950039625 0.08547528088092804
encoder.encoder.weight_hh_l0_reverse: 0.0003723211702890694 0.0852465108036995
encoder.encoder.bias_ih_l0_reverse: 0.019397305324673653 0.08252155780792236
encoder.encoder.bias_hh_l0_reverse: 0.01969199813902378 0.08946766704320908
decider.lstm.weight_ih_l0: -0.0011452259495854378 0.14723767340183258
decider.lstm.weight_hh_l0: 0.0033354810439050198 0.1471518576145172
decider.lstm.bias_ih_l0: -0.015420627780258656 0.1398036926984787
decider.lstm.bias_hh_l0: 0.02040047198534012 0.1542399376630783
decider.linear1.weight: 0.005550965666770935 0.12175296247005463
decider.linear1.bias: 0.01101919449865818 0.11603889614343643
decider.linear2.weight: 0.0038061984814703465 0.055605195462703705
decider.linear2.bias: 0.004232431761920452 0.05203546956181526
decider.linear3.weight: -0.0042451717890799046 0.06310492008924484
decider.linear3.bias: -0.017266932874917984 0.035754479467868805

Rewards:
65.8452
65.8452
65.8452
objective = 3.2705698686186224e-05
==== episode 23800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.2353e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002312148455530405 0.08418551832437515
encoder.encoder.weight_hh_l0: -0.0006242150557227433 0.08751614391803741
encoder.encoder.bias_ih_l0: 0.012151605449616909 0.08894465863704681
encoder.encoder.bias_hh_l0: 0.02522360533475876 0.08768153935670853
encoder.encoder.weight_ih_l0_reverse: 0.0023443135432899 0.08547881245613098
encoder.encoder.weight_hh_l0_reverse: 0.0003728662268258631 0.0852501317858696
encoder.encoder.bias_ih_l0_reverse: 0.0194151122123003 0.08252310007810593
encoder.encoder.bias_hh_l0_reverse: 0.01970980316400528 0.08947676420211792
decider.lstm.weight_ih_l0: -0.0011431275634095073 0.1472502499818802
decider.lstm.weight_hh_l0: 0.0033482923172414303 0.14716194570064545
decider.lstm.bias_ih_l0: -0.015374522656202316 0.13978472352027893
decider.lstm.bias_hh_l0: 0.02044658362865448 0.15424714982509613
decider.linear1.weight: 0.005563521292060614 0.12178459018468857
decider.linear1.bias: 0.011047855019569397 0.11605750024318695
decider.linear2.weight: 0.0038172085769474506 0.055624254047870636
decider.linear2.bias: 0.004241921007633209 0.05204092711210251
decider.linear3.weight: -0.004250578582286835 0.06313982605934143
decider.linear3.bias: -0.017269141972064972 0.03575947880744934

Rewards:
65.8452
65.8452
65.8452
objective = 3.2705698686186224e-05
==== episode 23900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.2353e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023173163644969463 0.08419081568717957
encoder.encoder.weight_hh_l0: -0.0006217709160409868 0.08754322677850723
encoder.encoder.bias_ih_l0: 0.012188969179987907 0.08895263820886612
encoder.encoder.bias_hh_l0: 0.025260958820581436 0.08768569678068161
encoder.encoder.weight_ih_l0_reverse: 0.002346205757930875 0.08548232167959213
encoder.encoder.weight_hh_l0_reverse: 0.000373402755940333 0.0852537602186203
encoder.encoder.bias_ih_l0_reverse: 0.019432706758379936 0.0825246274471283
encoder.encoder.bias_hh_l0_reverse: 0.019727395847439766 0.08948569744825363
decider.lstm.weight_ih_l0: -0.0011410635197535157 0.14726291596889496
decider.lstm.weight_hh_l0: 0.003360940143465996 0.14717212319374084
decider.lstm.bias_ih_l0: -0.015329014509916306 0.13976618647575378
decider.lstm.bias_hh_l0: 0.020492082461714745 0.15425387024879456
decider.linear1.weight: 0.005575970746576786 0.12181716412305832
decider.linear1.bias: 0.011076463386416435 0.11607667058706284
decider.linear2.weight: 0.0038234528619796038 0.05564381554722786
decider.linear2.bias: 0.004244028124958277 0.05204886570572853
decider.linear3.weight: -0.004255909472703934 0.0631745308637619
decider.linear3.bias: -0.017271293327212334 0.03576437756419182

Rewards:
65.8452
65.8452
65.8452
objective = 2.8781010769307613e-05
==== episode 24000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.1729e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002322377869859338 0.0841960459947586
encoder.encoder.weight_hh_l0: -0.0006194298039190471 0.08757023513317108
encoder.encoder.bias_ih_l0: 0.012225670740008354 0.08896050602197647
encoder.encoder.bias_hh_l0: 0.02529766783118248 0.0876898318529129
encoder.encoder.weight_ih_l0_reverse: 0.0023481131065636873 0.08548576384782791
encoder.encoder.weight_hh_l0_reverse: 0.00037393654929473996 0.08525742590427399
encoder.encoder.bias_ih_l0_reverse: 0.01945042423903942 0.08252620697021484
encoder.encoder.bias_hh_l0_reverse: 0.01974511332809925 0.08949463814496994
decider.lstm.weight_ih_l0: -0.0011391034349799156 0.14727595448493958
decider.lstm.weight_hh_l0: 0.0033736643381416798 0.14718236029148102
decider.lstm.bias_ih_l0: -0.015283770859241486 0.13974742591381073
decider.lstm.bias_hh_l0: 0.02053728513419628 0.15426136553287506
decider.linear1.weight: 0.005588167812675238 0.12185034155845642
decider.linear1.bias: 0.011104661040008068 0.11609628051519394
decider.linear2.weight: 0.0038345460779964924 0.05565774440765381
decider.linear2.bias: 0.004251738078892231 0.05205266550183296
decider.linear3.weight: -0.004259825684130192 0.06319418549537659
decider.linear3.bias: -0.01727328635752201 0.03576904907822609

Rewards:
65.8452
65.8452
65.8452
objective = 2.8781010769307613e-05
==== episode 24100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.1729e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023272978141903877 0.0842011347413063
encoder.encoder.weight_hh_l0: -0.0006171966670081019 0.08759677410125732
encoder.encoder.bias_ih_l0: 0.012261323630809784 0.08896809816360474
encoder.encoder.bias_hh_l0: 0.025333313271403313 0.08769389986991882
encoder.encoder.weight_ih_l0_reverse: 0.002349971793591976 0.08548910915851593
encoder.encoder.weight_hh_l0_reverse: 0.00037445774069055915 0.08526104688644409
encoder.encoder.bias_ih_l0_reverse: 0.019467761740088463 0.0825277790427208
encoder.encoder.bias_hh_l0_reverse: 0.019762450829148293 0.08950332552194595
decider.lstm.weight_ih_l0: -0.0011372264707461 0.14728890359401703
decider.lstm.weight_hh_l0: 0.003386090975254774 0.14719250798225403
decider.lstm.bias_ih_l0: -0.015239691361784935 0.1397293359041214
decider.lstm.bias_hh_l0: 0.020581331104040146 0.15426859259605408
decider.linear1.weight: 0.005599661730229855 0.12188359349966049
decider.linear1.bias: 0.011130992323160172 0.1161184087395668
decider.linear2.weight: 0.0038455745670944452 0.05567049980163574
decider.linear2.bias: 0.00425903731957078 0.052055999636650085
decider.linear3.weight: -0.004263290204107761 0.06320969015359879
decider.linear3.bias: -0.017275167629122734 0.03577352315187454

Rewards:
65.8452
65.8452
65.8452
objective = 2.6164552764385007e-05
==== episode 24200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.1729e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023321215994656086 0.08420611917972565
encoder.encoder.weight_hh_l0: -0.000615034019574523 0.08762292563915253
encoder.encoder.bias_ih_l0: 0.012296196073293686 0.08897548168897629
encoder.encoder.bias_hh_l0: 0.025368191301822662 0.08769794553518295
encoder.encoder.weight_ih_l0_reverse: 0.002351767849177122 0.08549237996339798
encoder.encoder.weight_hh_l0_reverse: 0.00037496016011573374 0.08526462316513062
encoder.encoder.bias_ih_l0_reverse: 0.019484663382172585 0.08252932876348495
encoder.encoder.bias_hh_l0_reverse: 0.019779350608587265 0.08951176702976227
decider.lstm.weight_ih_l0: -0.0011353864101693034 0.14730167388916016
decider.lstm.weight_hh_l0: 0.0033981483429670334 0.14720264077186584
decider.lstm.bias_ih_l0: -0.015196764841675758 0.1397121697664261
decider.lstm.bias_hh_l0: 0.02062423899769783 0.1542748212814331
decider.linear1.weight: 0.0056110406294465065 0.12191696465015411
decider.linear1.bias: 0.011158006265759468 0.11613811552524567
decider.linear2.weight: 0.0038576796650886536 0.055685751140117645
decider.linear2.bias: 0.004266622010618448 0.0520598366856575
decider.linear3.weight: -0.004267123993486166 0.06323004513978958
decider.linear3.bias: -0.017277009785175323 0.035777874290943146

Rewards:
65.8452
65.8452
65.8452
objective = 2.2239870304474607e-05
==== episode 24300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.1729e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023368485271930695 0.08421099931001663
encoder.encoder.weight_hh_l0: -0.000612948089838028 0.08764876425266266
encoder.encoder.bias_ih_l0: 0.012330321595072746 0.08898267149925232
encoder.encoder.bias_hh_l0: 0.025402309373021126 0.0877019390463829
encoder.encoder.weight_ih_l0_reverse: 0.0023535180371254683 0.08549559116363525
encoder.encoder.weight_hh_l0_reverse: 0.00037544823135249317 0.08526816964149475
encoder.encoder.bias_ih_l0_reverse: 0.019501226022839546 0.08253087103366852
encoder.encoder.bias_hh_l0_reverse: 0.01979590579867363 0.08951999247074127
decider.lstm.weight_ih_l0: -0.0011335945455357432 0.14731436967849731
decider.lstm.weight_hh_l0: 0.003410006407648325 0.14721281826496124
decider.lstm.bias_ih_l0: -0.015154741704463959 0.13969559967517853
decider.lstm.bias_hh_l0: 0.02066625840961933 0.154280424118042
decider.linear1.weight: 0.005622365977615118 0.12195103615522385
decider.linear1.bias: 0.011184856295585632 0.11615805327892303
decider.linear2.weight: 0.0038706082850694656 0.055701710283756256
decider.linear2.bias: 0.00427396921440959 0.05206359177827835
decider.linear3.weight: -0.004270915407687426 0.06325066089630127
decider.linear3.bias: -0.017278771847486496 0.035782065242528915

Rewards:
65.8452
65.8452
65.8452
objective = 2.2239870304474607e-05
==== episode 24400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.1729e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023414792958647013 0.08421576768159866
encoder.encoder.weight_hh_l0: -0.0006109382375143468 0.08767424523830414
encoder.encoder.bias_ih_l0: 0.012363663874566555 0.08898964524269104
encoder.encoder.bias_hh_l0: 0.025435661897063255 0.08770589530467987
encoder.encoder.weight_ih_l0_reverse: 0.0023552225902676582 0.08549873530864716
encoder.encoder.weight_hh_l0_reverse: 0.0003759209648706019 0.0852716863155365
encoder.encoder.bias_ih_l0_reverse: 0.0195174477994442 0.08253239095211029
encoder.encoder.bias_hh_l0_reverse: 0.01981213316321373 0.08952802419662476
decider.lstm.weight_ih_l0: -0.0011318530887365341 0.1473269909620285
decider.lstm.weight_hh_l0: 0.003421684494242072 0.14722304046154022
decider.lstm.bias_ih_l0: -0.015113569796085358 0.13967964053153992
decider.lstm.bias_hh_l0: 0.02070731669664383 0.15428534150123596
decider.linear1.weight: 0.005633550696074963 0.12198569625616074
decider.linear1.bias: 0.01121140643954277 0.11617843061685562
decider.linear2.weight: 0.003883885219693184 0.055718183517456055
decider.linear2.bias: 0.00428110221400857 0.05206732451915741
decider.linear3.weight: -0.004274617414921522 0.06327101588249207
decider.linear3.bias: -0.017280472442507744 0.035786110907793045

Rewards:
65.8452
65.8452
65.8452
objective = 2.0931640392518602e-05
==== episode 24500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.1112e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023460029624402523 0.08422043919563293
encoder.encoder.weight_hh_l0: -0.0006090055103413761 0.08769933134317398
encoder.encoder.bias_ih_l0: 0.012396218255162239 0.08899640291929245
encoder.encoder.bias_hh_l0: 0.025468207895755768 0.08770978450775146
encoder.encoder.weight_ih_l0_reverse: 0.0023568840697407722 0.08550181239843369
encoder.encoder.weight_hh_l0_reverse: 0.0003763775166589767 0.08527515828609467
encoder.encoder.bias_ih_l0_reverse: 0.01953330636024475 0.08253388851881027
encoder.encoder.bias_hh_l0_reverse: 0.019827987998723984 0.08953582495450974
decider.lstm.weight_ih_l0: -0.0011301622726023197 0.14733949303627014
decider.lstm.weight_hh_l0: 0.003433197271078825 0.1472332924604416
decider.lstm.bias_ih_l0: -0.01507331058382988 0.13966429233551025
decider.lstm.bias_hh_l0: 0.02074749954044819 0.15428970754146576
decider.linear1.weight: 0.00564454635605216 0.12202084809541702
decider.linear1.bias: 0.011237582191824913 0.11619917303323746
decider.linear2.weight: 0.003897210117429495 0.05573529750108719
decider.linear2.bias: 0.004288033116608858 0.052070993930101395
decider.linear3.weight: -0.004278242122381926 0.06329125165939331
decider.linear3.bias: -0.017282122746109962 0.035790037363767624

Rewards:
65.8452
65.8452
65.8452
objective = 1.9623414118541405e-05
==== episode 24600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.1112e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023503771517425776 0.08422493934631348
encoder.encoder.weight_hh_l0: -0.0006071706884540617 0.0877237543463707
encoder.encoder.bias_ih_l0: 0.01242762804031372 0.08900289237499237
encoder.encoder.bias_hh_l0: 0.02549961768090725 0.0877135843038559
encoder.encoder.weight_ih_l0_reverse: 0.0023584815207868814 0.08550477772951126
encoder.encoder.weight_hh_l0_reverse: 0.00037681107642129064 0.08527856320142746
encoder.encoder.bias_ih_l0_reverse: 0.01954864338040352 0.08253533393144608
encoder.encoder.bias_hh_l0_reverse: 0.019843323156237602 0.08954332023859024
decider.lstm.weight_ih_l0: -0.0011285404907539487 0.14735178649425507
decider.lstm.weight_hh_l0: 0.003444455564022064 0.14724352955818176
decider.lstm.bias_ih_l0: -0.015034327283501625 0.1396496295928955
decider.lstm.bias_hh_l0: 0.02078641764819622 0.15429352223873138
decider.linear1.weight: 0.005655087064951658 0.12205586582422256
decider.linear1.bias: 0.011262130923569202 0.11622177809476852
decider.linear2.weight: 0.003910342697054148 0.05575273558497429
decider.linear2.bias: 0.004294694401323795 0.05207456648349762
decider.linear3.weight: -0.004281741101294756 0.06331104040145874
decider.linear3.bias: -0.01728370599448681 0.035793814808130264

Rewards:
65.8452
65.8452
65.8452
objective = 1.56987298396416e-05
==== episode 24700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.1112e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023546398151665926 0.08422932773828506
encoder.encoder.weight_hh_l0: -0.0006054102559573948 0.0877477377653122
encoder.encoder.bias_ih_l0: 0.012458223849534988 0.08900915831327438
encoder.encoder.bias_hh_l0: 0.025530215352773666 0.08771731704473495
encoder.encoder.weight_ih_l0_reverse: 0.0023600314743816853 0.08550766110420227
encoder.encoder.weight_hh_l0_reverse: 0.0003772276686504483 0.08528191596269608
encoder.encoder.bias_ih_l0_reverse: 0.01956360414624214 0.0825367346405983
encoder.encoder.bias_hh_l0_reverse: 0.01985829509794712 0.08955062925815582
decider.lstm.weight_ih_l0: -0.0011269740061834455 0.14736391603946686
decider.lstm.weight_hh_l0: 0.0034555920865386724 0.1472538262605667
decider.lstm.bias_ih_l0: -0.014996349811553955 0.13963539898395538
decider.lstm.bias_hh_l0: 0.02082439512014389 0.15429671108722687
decider.linear1.weight: 0.005665759555995464 0.12209136039018631
decider.linear1.bias: 0.011287350207567215 0.1162426546216011
decider.linear2.weight: 0.003923799842596054 0.05577090010046959
decider.linear2.bias: 0.004301159642636776 0.052077993750572205
decider.linear3.weight: -0.004285179544240236 0.06333089619874954
decider.linear3.bias: -0.017285238951444626 0.03579746559262276

Rewards:
65.8452
65.8452
65.8452
objective = 1.56987298396416e-05
==== episode 24800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.1112e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023587807081639767 0.0842336043715477
encoder.encoder.weight_hh_l0: -0.0006037218845449388 0.08777118474245071
encoder.encoder.bias_ih_l0: 0.012487971223890781 0.08901522308588028
encoder.encoder.bias_hh_l0: 0.025559965521097183 0.08772099018096924
encoder.encoder.weight_ih_l0_reverse: 0.0023615264799445868 0.08551046997308731
encoder.encoder.weight_hh_l0_reverse: 0.0003776244120672345 0.08528521656990051
encoder.encoder.bias_ih_l0_reverse: 0.01957820914685726 0.08253812044858932
encoder.encoder.bias_hh_l0_reverse: 0.01987289823591709 0.08955767005681992
decider.lstm.weight_ih_l0: -0.001125466194935143 0.1473759263753891
decider.lstm.weight_hh_l0: 0.0034666252322494984 0.14726419746875763
decider.lstm.bias_ih_l0: -0.014959272928535938 0.1396217942237854
decider.lstm.bias_hh_l0: 0.0208614282310009 0.1542993187904358
decider.linear1.weight: 0.005676161497831345 0.12212681025266647
decider.linear1.bias: 0.01131199486553669 0.11626367270946503
decider.linear2.weight: 0.003947595600038767 0.05579129606485367
decider.linear2.bias: 0.004308540374040604 0.05208008736371994
decider.linear3.weight: -0.004288691096007824 0.06335105001926422
decider.linear3.bias: -0.017286721616983414 0.0358009971678257

Rewards:
65.8452
65.8452
65.8452
objective = 1.4390503565664403e-05
==== episode 24900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.1112e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023627816699445248 0.08423774689435959
encoder.encoder.weight_hh_l0: -0.0006021087756380439 0.08779402077198029
encoder.encoder.bias_ih_l0: 0.012516777962446213 0.08902107179164886
encoder.encoder.bias_hh_l0: 0.025588762015104294 0.08772457391023636
encoder.encoder.weight_ih_l0_reverse: 0.002362961182370782 0.085513174533844
encoder.encoder.weight_hh_l0_reverse: 0.00037799865822307765 0.08528846502304077
encoder.encoder.bias_ih_l0_reverse: 0.01959237828850746 0.08253948390483856
encoder.encoder.bias_hh_l0_reverse: 0.019887065514922142 0.08956446498632431
decider.lstm.weight_ih_l0: -0.0011240186868235469 0.14738771319389343
decider.lstm.weight_hh_l0: 0.003477505873888731 0.14727456867694855
decider.lstm.bias_ih_l0: -0.014923270791769028 0.13960877060890198
decider.lstm.bias_hh_l0: 0.02089744433760643 0.15430139005184174
decider.linear1.weight: 0.0056863515637815 0.12216198444366455
decider.linear1.bias: 0.011336022056639194 0.11628446727991104
decider.linear2.weight: 0.003973578102886677 0.05581378564238548
decider.linear2.bias: 0.004316902719438076 0.05208097770810127
decider.linear3.weight: -0.004292918369174004 0.06337360292673111
decider.linear3.bias: -0.017288153991103172 0.035804383456707

Rewards:
65.8452
65.8452
65.8452
objective = 1.4390503565664403e-05
==== episode 25000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.0501e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002366638043895364 0.08424174040555954
encoder.encoder.weight_hh_l0: -0.0006005809409543872 0.08781611174345016
encoder.encoder.bias_ih_l0: 0.012544491328299046 0.08902666717767715
encoder.encoder.bias_hh_l0: 0.0256164763122797 0.08772806823253632
encoder.encoder.weight_ih_l0_reverse: 0.0023643358144909143 0.08551576733589172
encoder.encoder.weight_hh_l0_reverse: 0.0003783583815675229 0.08529161661863327
encoder.encoder.bias_ih_l0_reverse: 0.019605981186032295 0.08254076540470123
encoder.encoder.bias_hh_l0_reverse: 0.019900666549801826 0.08957096189260483
decider.lstm.weight_ih_l0: -0.0011226388160139322 0.14739912748336792
decider.lstm.weight_hh_l0: 0.003488125279545784 0.1472848355770111
decider.lstm.bias_ih_l0: -0.014888664707541466 0.13959644734859467
decider.lstm.bias_hh_l0: 0.020932074636220932 0.1543029248714447
decider.linear1.weight: 0.0056959399953484535 0.12219630181789398
decider.linear1.bias: 0.011358419433236122 0.11630614101886749
decider.linear2.weight: 0.003993543796241283 0.05583788827061653
decider.linear2.bias: 0.004325016401708126 0.05208190903067589
decider.linear3.weight: -0.004298001062124968 0.06340042501688004
decider.linear3.bias: -0.017289532348513603 0.03580763190984726

Rewards:
65.8452
65.8452
65.8452
objective = 1.3082275472697802e-05
==== episode 25100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.0501e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002370301401242614 0.08424554020166397
encoder.encoder.weight_hh_l0: -0.0005991524667479098 0.08783720433712006
encoder.encoder.bias_ih_l0: 0.012570829130709171 0.08903198689222336
encoder.encoder.bias_hh_l0: 0.02564280480146408 0.08773142099380493
encoder.encoder.weight_ih_l0_reverse: 0.002365634310990572 0.0855182409286499
encoder.encoder.weight_hh_l0_reverse: 0.00037869191146455705 0.08529464900493622
encoder.encoder.bias_ih_l0_reverse: 0.019618898630142212 0.08254200965166092
encoder.encoder.bias_hh_l0_reverse: 0.01991358958184719 0.08957710862159729
decider.lstm.weight_ih_l0: -0.0011213290272280574 0.14741012454032898
decider.lstm.weight_hh_l0: 0.003498392179608345 0.14729495346546173
decider.lstm.bias_ih_l0: -0.014855703338980675 0.13958488404750824
decider.lstm.bias_hh_l0: 0.020965024828910828 0.1543038934469223
decider.linear1.weight: 0.00570534635335207 0.12222982197999954
decider.linear1.bias: 0.011380534619092941 0.11632584780454636
decider.linear2.weight: 0.004013471305370331 0.055863965302705765
decider.linear2.bias: 0.004333397839218378 0.052082229405641556
decider.linear3.weight: -0.004303891211748123 0.0634312853217125
decider.linear3.bias: -0.01729084923863411 0.035810694098472595

Rewards:
65.8452
65.8452
65.8452
objective = 1.17740473797312e-05
==== episode 25200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.0501e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023737912997603416 0.08424915373325348
encoder.encoder.weight_hh_l0: -0.0005978093249723315 0.08785740286111832
encoder.encoder.bias_ih_l0: 0.012595956213772297 0.08903702348470688
encoder.encoder.bias_hh_l0: 0.025667931884527206 0.08773466944694519
encoder.encoder.weight_ih_l0_reverse: 0.002366867382079363 0.08552058041095734
encoder.encoder.weight_hh_l0_reverse: 0.0003790048067457974 0.08529756963253021
encoder.encoder.bias_ih_l0_reverse: 0.019631223753094673 0.08254318684339523
encoder.encoder.bias_hh_l0_reverse: 0.019925910979509354 0.08958294242620468
decider.lstm.weight_ih_l0: -0.0011200947919860482 0.1474207192659378
decider.lstm.weight_hh_l0: 0.0035084092523902655 0.147304967045784
decider.lstm.bias_ih_l0: -0.014824137091636658 0.13957402110099792
decider.lstm.bias_hh_l0: 0.020996568724513054 0.15430434048175812
decider.linear1.weight: 0.005714391358196735 0.12226245552301407
decider.linear1.bias: 0.011401724070310593 0.11634502559900284
decider.linear2.weight: 0.004033519420772791 0.055891942232847214
decider.linear2.bias: 0.004342174157500267 0.05208193510770798
decider.linear3.weight: -0.004310786724090576 0.06346685439348221
decider.linear3.bias: -0.017292112112045288 0.035813603550195694

Rewards:
65.8452
65.8452
65.8452
objective = 1.17740473797312e-05
==== episode 25300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.0501e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023770881816744804 0.08425258845090866
encoder.encoder.weight_hh_l0: -0.0005965541349723935 0.0878765732049942
encoder.encoder.bias_ih_l0: 0.012619721703231335 0.08904177695512772
encoder.encoder.bias_hh_l0: 0.02569170854985714 0.08773776888847351
encoder.encoder.weight_ih_l0_reverse: 0.0023680285084992647 0.08552280813455582
encoder.encoder.weight_hh_l0_reverse: 0.000379295670427382 0.08530037105083466
encoder.encoder.bias_ih_l0_reverse: 0.019642872735857964 0.08254431933164597
encoder.encoder.bias_hh_l0_reverse: 0.019937556236982346 0.08958841860294342
decider.lstm.weight_ih_l0: -0.0011189383221790195 0.14743083715438843
decider.lstm.weight_hh_l0: 0.0035180719569325447 0.14731480181217194
decider.lstm.bias_ih_l0: -0.014794167131185532 0.13956387341022491
decider.lstm.bias_hh_l0: 0.02102646417915821 0.15430420637130737
decider.linear1.weight: 0.005722764879465103 0.12229374796152115
decider.linear1.bias: 0.011421042494475842 0.11636479198932648
decider.linear2.weight: 0.004053358919918537 0.055921658873558044
decider.linear2.bias: 0.004351217299699783 0.052080996334552765
decider.linear3.weight: -0.004318800754845142 0.06350749731063843
decider.linear3.bias: -0.01729332096874714 0.03581634536385536

Rewards:
65.8452
65.8452
65.8452
objective = 1.0465820196259301e-05
==== episode 25400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 6.0501e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002380184829235077 0.08425582200288773
encoder.encoder.weight_hh_l0: -0.0005953879444859922 0.08789464831352234
encoder.encoder.bias_ih_l0: 0.01264208648353815 0.08904624730348587
encoder.encoder.bias_hh_l0: 0.02571406587958336 0.0877407118678093
encoder.encoder.weight_ih_l0_reverse: 0.0023691144306212664 0.08552489429712296
encoder.encoder.weight_hh_l0_reverse: 0.000379562028683722 0.08530302345752716
encoder.encoder.bias_ih_l0_reverse: 0.0196538083255291 0.08254537731409073
encoder.encoder.bias_hh_l0_reverse: 0.019948497414588928 0.08959352970123291
decider.lstm.weight_ih_l0: -0.0011178588028997183 0.14744046330451965
decider.lstm.weight_hh_l0: 0.0035273542162030935 0.14732438325881958
decider.lstm.bias_ih_l0: -0.014765926636755466 0.1395544409751892
decider.lstm.bias_hh_l0: 0.0210547037422657 0.1543036848306656
decider.linear1.weight: 0.005730902776122093 0.12232378125190735
decider.linear1.bias: 0.011439943686127663 0.11638233065605164
decider.linear2.weight: 0.004072778392583132 0.05595235526561737
decider.linear2.bias: 0.004360534250736237 0.05207962915301323
decider.linear3.weight: -0.004327850881963968 0.06355228275060654
decider.linear3.bias: -0.017294470220804214 0.0358189158141613

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 25500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.9896e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.0023830661084502935 0.08425884693861008
encoder.encoder.weight_hh_l0: -0.0005943147698417306 0.08791154623031616
encoder.encoder.bias_ih_l0: 0.012662957422435284 0.08905039727687836
encoder.encoder.bias_hh_l0: 0.02573493681848049 0.08774349093437195
encoder.encoder.weight_ih_l0_reverse: 0.002370124217122793 0.08552682399749756
encoder.encoder.weight_hh_l0_reverse: 0.00037980746128596365 0.08530553430318832
encoder.encoder.bias_ih_l0_reverse: 0.019664010033011436 0.08254639059305191
encoder.encoder.bias_hh_l0_reverse: 0.019958699122071266 0.08959827572107315
decider.lstm.weight_ih_l0: -0.0011168563505634665 0.14744949340820312
decider.lstm.weight_hh_l0: 0.0035361824557185173 0.14733365178108215
decider.lstm.bias_ih_l0: -0.014739545993506908 0.13954564929008484
decider.lstm.bias_hh_l0: 0.02108113095164299 0.15430282056331635
decider.linear1.weight: 0.005738488864153624 0.12235204130411148
decider.linear1.bias: 0.011457524262368679 0.11639873683452606
decider.linear2.weight: 0.004090670496225357 0.0559830404818058
decider.linear2.bias: 0.004369818605482578 0.05207787826657295
decider.linear3.weight: -0.004337814170867205 0.0636008232831955
decider.linear3.bias: -0.017295563593506813 0.03582131862640381

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 25600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.9896e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485211223364 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937493988312781 0.08791985362768173
encoder.encoder.bias_ih_l0: 0.01267297938466072 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.0003799053083639592 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891810297966 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360532939434 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163552990183234 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540768288075924 0.14733855426311493
decider.lstm.bias_ih_l0: -0.01472636591643095 0.139541357755661
decider.lstm.bias_hh_l0: 0.021094325929880142 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236595898866653
decider.linear1.bias: 0.01146622747182846 0.11640670895576477
decider.linear2.weight: 0.00413140282034874 0.056001726537942886
decider.linear2.bias: 0.004429643973708153 0.05207601189613342
decider.linear3.weight: -0.004366257227957249 0.06366384774446487
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 25700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.9896e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 25800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.9896e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 25900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.9896e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 26000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.9297e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 26100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.9297e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 26200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.9297e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 26300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.9297e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 26400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.9297e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 26500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.8704e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 26600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.8704e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 26700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.8704e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 26800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.8704e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 26900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.8704e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 27000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.8117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 27100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.8117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 27200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.8117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 27300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.8117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 27400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.8117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 27500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.7535e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 27600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.7535e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 27700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.7535e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 27800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.7535e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 27900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.7535e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 28000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.6960e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 28100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.6960e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 28200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.6960e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 28300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.6960e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 28400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.6960e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 28500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.6391e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 28600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.6391e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 28700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.6391e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 28800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.6391e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 28900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.6391e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 29000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.5827e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 29100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.5827e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 29200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.5827e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 29300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.5827e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 29400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.5827e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 29500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.5268e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 29600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.5268e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 29700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.5268e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 29800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.5268e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 29900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.5268e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 30000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.4716e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 30100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.4716e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 30200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.4716e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 30300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.4716e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 30400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.4716e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 30500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.4169e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 30600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.4169e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 30700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.4169e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 30800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.4169e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 30900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.4169e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 31000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.3627e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 31100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.3627e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 31200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.3627e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 31300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.3627e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 31400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.3627e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 31500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.3091e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 31600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.3091e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 31700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.3091e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 31800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.3091e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 31900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.3091e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 32000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.2560e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 32100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.2560e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 32200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.2560e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 32300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.2560e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 32400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.2560e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 32500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.2034e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 32600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.2034e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 32700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.2034e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 32800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.2034e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 32900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.2034e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 33000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.1514e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 33100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.1514e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 33200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.1514e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 33300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.1514e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 33400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.1514e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 33500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 33600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 33700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 33800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 33900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 34000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0489e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 34100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0489e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 34200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0489e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 34300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0489e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 34400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 5.0489e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 34500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 34600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 34700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 34800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 34900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 35000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9484e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 35100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9484e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 35200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9484e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 35300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9484e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 35400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.9484e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 35500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 35600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 35700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 35800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 35900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 36000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8499e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 36100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8499e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 36200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8499e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 36300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8499e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 36400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8499e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 36500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8014e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 36600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8014e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 36700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8014e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 36800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8014e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 36900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.8014e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 37000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 37100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 37200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 37300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 37400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 37500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7059e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 37600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7059e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 37700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7059e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 37800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7059e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 37900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.7059e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 38000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6588e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 38100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6588e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 38200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6588e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 38300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6588e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 38400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6588e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 38500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6122e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 38600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6122e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 38700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6122e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 38800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6122e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 38900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.6122e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 39000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5661e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 39100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5661e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 39200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5661e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 39300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5661e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 39400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5661e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 39500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5204e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 39600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5204e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 39700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5204e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 39800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5204e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 39900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.5204e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 40000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 40100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 40200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 40300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 40400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 40500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4305e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 40600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4305e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 40700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4305e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 40800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4305e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 40900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.4305e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 41000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3862e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 41100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3862e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 41200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3862e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 41300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3862e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 41400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3862e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 41500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3423e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 41600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3423e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 41700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3423e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 41800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3423e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 41900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.3423e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 42000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 42100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 42200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 42300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 42400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2989e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 42500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2559e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 42600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2559e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 42700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2559e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 42800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2559e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 42900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2559e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 43000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2133e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 43100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2133e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 43200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2133e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 43300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2133e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 43400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.2133e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 43500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1712e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 43600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1712e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 43700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1712e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 43800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1712e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 43900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1712e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 44000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1295e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 44100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1295e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 44200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1295e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 44300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1295e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 44400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.1295e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 44500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0882e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 44600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0882e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 44700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0882e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 44800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0882e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 44900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0882e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 45000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0473e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 45100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0473e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 45200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0473e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 45300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0473e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 45400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0473e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 45500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0068e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 45600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0068e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 45700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0068e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 45800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0068e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 45900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 4.0068e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 46000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9668e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 46100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9668e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 46200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9668e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 46300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9668e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 46400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9668e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 46500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 46600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 46700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 46800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 46900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.9271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 47000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8878e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 47100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8878e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 47200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8878e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 47300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8878e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 47400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8878e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 47500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8490e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 47600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8490e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 47700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8490e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 47800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8490e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 47900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8490e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 48000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8105e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 48100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8105e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 48200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8105e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 48300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8105e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 48400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.8105e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 48500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7724e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 48600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7724e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 48700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7724e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 48800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7724e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 48900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7724e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 49000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7346e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 49100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7346e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 49200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7346e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 49300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7346e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 49400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.7346e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 49500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 49600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 49700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 49800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 49900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6973e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 50000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6603e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 50100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6603e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 50200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6603e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 50300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6603e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 50400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6603e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 50500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6237e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 50600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6237e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 50700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6237e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 50800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6237e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 50900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.6237e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 51000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 51100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 51200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 51300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 51400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 51500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5516e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 51600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5516e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 51700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5516e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 51800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5516e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 51900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5516e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 52000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5161e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 52100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5161e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 52200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5161e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 52300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5161e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 52400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.5161e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 52500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4809e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 52600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4809e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 52700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4809e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 52800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4809e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 52900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4809e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 53000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4461e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 53100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4461e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 53200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4461e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 53300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4461e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 53400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4461e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 53500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 53600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 53700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 53800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 53900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.4117e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 54000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3775e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 54100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3775e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 54200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3775e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 54300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3775e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 54400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3775e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 54500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 54600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 54700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 54800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 54900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 55000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3103e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 55100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3103e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 55200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3103e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 55300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3103e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 55400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.3103e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 55500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2772e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 55600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2772e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 55700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2772e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 55800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2772e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 55900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2772e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 56000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2445e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 56100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2445e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 56200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2445e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 56300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2445e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 56400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2445e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 56500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2120e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 56600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2120e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 56700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2120e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 56800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2120e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 56900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.2120e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 57000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1799e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 57100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1799e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 57200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1799e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 57300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1799e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 57400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1799e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 57500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1481e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 57600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1481e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 57700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1481e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 57800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1481e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 57900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1481e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 58000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1166e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 58100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1166e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 58200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1166e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 58300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1166e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 58400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.1166e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 58500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0854e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 58600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0854e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 58700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0854e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 58800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0854e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 58900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0854e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 59000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0546e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 59100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0546e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 59200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0546e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 59300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0546e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 59400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0546e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 59500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0240e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 59600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0240e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 59700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0240e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 59800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0240e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 59900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 3.0240e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 60000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9938e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 60100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9938e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 60200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9938e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 60300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9938e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 60400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9938e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 60500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9639e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 60600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9639e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 60700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9639e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 60800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9639e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 60900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9639e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 61000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9342e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 61100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9342e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 61200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9342e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 61300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9342e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 61400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9342e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 61500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9049e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 61600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9049e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 61700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9049e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 61800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9049e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 61900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.9049e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 62000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8758e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 62100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8758e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 62200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8758e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 62300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8758e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 62400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8758e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 62500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8471e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 62600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8471e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 62700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8471e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 62800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8471e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 62900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8471e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 63000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8186e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 63100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8186e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 63200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8186e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 63300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8186e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 63400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.8186e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 63500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7904e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 63600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7904e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 63700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7904e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 63800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7904e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 63900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7904e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 64000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7625e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 64100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7625e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 64200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7625e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 64300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7625e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 64400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7625e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 64500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7349e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 64600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7349e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 64700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7349e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 64800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7349e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 64900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7349e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 65000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7075e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 65100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7075e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 65200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7075e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 65300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7075e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 65400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.7075e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 65500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6805e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 65600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6805e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 65700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6805e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 65800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6805e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 65900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6805e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 66000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6537e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 66100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6537e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 66200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6537e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 66300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6537e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 66400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6537e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 66500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 66600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 66700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 66800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 66900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6271e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 67000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6009e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 67100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6009e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 67200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6009e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 67300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6009e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 67400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.6009e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 67500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5748e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 67600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5748e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 67700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5748e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 67800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5748e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 67900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5748e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 68000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5491e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 68100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5491e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 68200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5491e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 68300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5491e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 68400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5491e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 68500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5236e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 68600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5236e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 68700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5236e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 68800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5236e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 68900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.5236e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 69000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 69100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 69200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 69300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 69400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4984e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 69500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4734e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 69600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4734e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 69700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4734e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 69800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4734e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 69900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4734e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 70000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4487e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 70100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4487e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 70200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4487e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 70300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4487e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 70400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4487e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 70500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4242e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 70600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4242e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 70700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4242e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 70800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4242e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 70900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.4242e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 71000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 71100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 71200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 71300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 71400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3999e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 71500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3759e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 71600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3759e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 71700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3759e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 71800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3759e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 71900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3759e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 72000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3522e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 72100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3522e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 72200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3522e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 72300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3522e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 72400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3522e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 72500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3286e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 72600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3286e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 72700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3286e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 72800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3286e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 72900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3286e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 73000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3054e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 73100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3054e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 73200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3054e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 73300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3054e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 73400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.3054e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 73500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2823e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 73600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2823e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 73700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2823e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 73800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2823e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 73900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2823e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 74000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2595e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 74100/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2595e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 74200/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2595e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 74300/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2595e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 74400/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2595e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 74500/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2369e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 74600/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2369e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 74700/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2369e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 74800/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2369e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 74900/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2369e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
==== episode 75000/75000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 2
probs = 0.0000 0.0000 1.0000 0.0000

Learning rate: 2.2145e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.002384485676884651 0.08426028490066528
encoder.encoder.weight_hh_l0: -0.0005937483510933816 0.08791986107826233
encoder.encoder.bias_ih_l0: 0.012672980315983295 0.0890522226691246
encoder.encoder.bias_hh_l0: 0.025744957849383354 0.08774473518133163
encoder.encoder.weight_ih_l0_reverse: 0.002370572881773114 0.08552776277065277
encoder.encoder.weight_hh_l0_reverse: 0.000379905104637146 0.08530671149492264
encoder.encoder.bias_ih_l0_reverse: 0.01966891996562481 0.08254685252904892
encoder.encoder.bias_hh_l0_reverse: 0.01996360719203949 0.08960049599409103
decider.lstm.weight_ih_l0: -0.0011163546005263925 0.14745403826236725
decider.lstm.weight_hh_l0: 0.003540769685059786 0.14733855426311493
decider.lstm.bias_ih_l0: -0.014726361259818077 0.139541357755661
decider.lstm.bias_hh_l0: 0.02109432965517044 0.15430183708667755
decider.linear1.weight: 0.005742295645177364 0.12236596643924713
decider.linear1.bias: 0.01146622933447361 0.11640670895576477
decider.linear2.weight: 0.004131397232413292 0.056001774966716766
decider.linear2.bias: 0.004429664462804794 0.05207602679729462
decider.linear3.weight: -0.004366378299891949 0.0636640265583992
decider.linear3.bias: -0.017296092584729195 0.035822514444589615

Rewards:
65.8452
65.8452
65.8452
objective = 7.8493649198208e-06
[INFO] : learning runtime (h:mm:ss): 0:18:38
[INFO] : learning end time: 12/18/2023 11:04:19 AM
