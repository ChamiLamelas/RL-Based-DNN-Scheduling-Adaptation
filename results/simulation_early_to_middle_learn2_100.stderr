Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 12:24:01 PM
==== episode 1/10000 ====
action = 0
probs = 0.2496 0.2517 0.2494 0.2494

action = 0
probs = 0.2494 0.2519 0.2494 0.2494

action = 0
probs = 0.2494 0.2519 0.2494 0.2494

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030066867475397885 0.08382798731327057
encoder.encoder.weight_hh_l0: -0.0004346595669630915 0.08493988960981369
encoder.encoder.bias_ih_l0: 0.006773008964955807 0.08568799495697021
encoder.encoder.bias_hh_l0: 0.016770096495747566 0.08572643995285034
encoder.encoder.weight_ih_l0_reverse: 0.0016379323787987232 0.08582903444766998
encoder.encoder.weight_hh_l0_reverse: 0.0022715849336236715 0.08397230505943298
encoder.encoder.bias_ih_l0_reverse: 0.022404436022043228 0.08511369675397873
encoder.encoder.bias_hh_l0_reverse: 0.014269871637225151 0.08350047469139099
decider.lstm.weight_ih_l0: -0.0003690148005262017 0.14689277112483978
decider.lstm.weight_hh_l0: -0.00143633468542248 0.1459912210702896
decider.lstm.bias_ih_l0: 0.01744951121509075 0.15304474532604218
decider.lstm.bias_hh_l0: -0.0015380275435745716 0.14339260756969452
decider.linear1.weight: 0.0018393360078334808 0.12068705260753632
decider.linear1.bias: 0.013287803158164024 0.11647672206163406
decider.linear2.weight: 0.003779552411288023 0.055137280374765396
decider.linear2.bias: 0.004318038932979107 0.05695607513189316
decider.linear3.weight: -0.030952436849474907 0.08705276250839233
decider.linear3.bias: -0.018916897475719452 0.05361822992563248

Rewards:
206.9982
206.9982
206.9982
objective = 287.4228210449219
==== episode 100/10000 ====
action = 1
probs = 0.0884 0.9106 0.0008 0.0002

action = 1
probs = 0.0066 0.9934 0.0000 0.0000

action = 1
probs = 0.0073 0.9927 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002979888813570142 0.08381558209657669
encoder.encoder.weight_hh_l0: -0.0004248714249115437 0.08489304035902023
encoder.encoder.bias_ih_l0: 0.00660704355686903 0.08565522730350494
encoder.encoder.bias_hh_l0: 0.016604134812951088 0.08572221547365189
encoder.encoder.weight_ih_l0_reverse: 0.0016486895037814975 0.08583914488554001
encoder.encoder.weight_hh_l0_reverse: 0.002281737746670842 0.08397646248340607
encoder.encoder.bias_ih_l0_reverse: 0.02242121659219265 0.08514060825109482
encoder.encoder.bias_hh_l0_reverse: 0.014286654070019722 0.08353324979543686
decider.lstm.weight_ih_l0: -0.0003834894159808755 0.14690689742565155
decider.lstm.weight_hh_l0: -0.001408719690516591 0.14597879350185394
decider.lstm.bias_ih_l0: 0.017324963584542274 0.15291264653205872
decider.lstm.bias_hh_l0: -0.0016625658608973026 0.14349062740802765
decider.linear1.weight: 0.0018400171538814902 0.12070302665233612
decider.linear1.bias: 0.01329182181507349 0.1163896694779396
decider.linear2.weight: 0.0037849065847694874 0.055188313126564026
decider.linear2.bias: 0.004376577213406563 0.05710524320602417
decider.linear3.weight: -0.033333130180835724 0.08903052657842636
decider.linear3.bias: -0.02270016446709633 0.05373078212141991

Rewards:
190.8927
190.8927
190.8927
objective = 6.850065231323242
==== episode 200/10000 ====
action = 1
probs = 0.0585 0.9411 0.0004 0.0001

action = 1
probs = 0.0023 0.9977 0.0000 0.0000

action = 1
probs = 0.0028 0.9972 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029917535721324384 0.08388582617044449
encoder.encoder.weight_hh_l0: -0.0004609190800692886 0.08499839901924133
encoder.encoder.bias_ih_l0: 0.006944122724235058 0.08574432134628296
encoder.encoder.bias_hh_l0: 0.016941213980317116 0.08582481741905212
encoder.encoder.weight_ih_l0_reverse: 0.0016388553194701672 0.08591395616531372
encoder.encoder.weight_hh_l0_reverse: 0.0023269110824912786 0.08404772728681564
encoder.encoder.bias_ih_l0_reverse: 0.022680481895804405 0.08528705686330795
encoder.encoder.bias_hh_l0_reverse: 0.014545919373631477 0.08364170044660568
decider.lstm.weight_ih_l0: -0.0003345982695464045 0.14699888229370117
decider.lstm.weight_hh_l0: -0.0014924833085387945 0.14602650701999664
decider.lstm.bias_ih_l0: 0.01790146343410015 0.1531832069158554
decider.lstm.bias_hh_l0: -0.001086072064936161 0.14356599748134613
decider.linear1.weight: 0.0018135961145162582 0.1207357868552208
decider.linear1.bias: 0.013517576269805431 0.11625012010335922
decider.linear2.weight: 0.0038455468602478504 0.05528441071510315
decider.linear2.bias: 0.004449648782610893 0.0572434701025486
decider.linear3.weight: -0.03502508997917175 0.09067685157060623
decider.linear3.bias: -0.02559235692024231 0.055149324238300323

Rewards:
190.8927
190.8927
190.8927
objective = 4.1862263679504395
==== episode 300/10000 ====
action = 1
probs = 0.0362 0.9636 0.0002 0.0000

action = 1
probs = 0.0007 0.9993 0.0000 0.0000

action = 1
probs = 0.0010 0.9990 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000303835840895772 0.0839855745434761
encoder.encoder.weight_hh_l0: -0.0004945177934132516 0.08514072746038437
encoder.encoder.bias_ih_l0: 0.007424795068800449 0.08584858477115631
encoder.encoder.bias_hh_l0: 0.017421886324882507 0.08594473451375961
encoder.encoder.weight_ih_l0_reverse: 0.001655536238104105 0.08602047711610794
encoder.encoder.weight_hh_l0_reverse: 0.0023840763606131077 0.08413207530975342
encoder.encoder.bias_ih_l0_reverse: 0.023008890450000763 0.08543284982442856
encoder.encoder.bias_hh_l0_reverse: 0.014874331653118134 0.08372609317302704
decider.lstm.weight_ih_l0: -0.0002749878622125834 0.14712485671043396
decider.lstm.weight_hh_l0: -0.0015858488623052835 0.14613409340381622
decider.lstm.bias_ih_l0: 0.01866006851196289 0.15334703028202057
decider.lstm.bias_hh_l0: -0.00032747327350080013 0.14372515678405762
decider.linear1.weight: 0.0017816759645938873 0.12078209221363068
decider.linear1.bias: 0.013890326023101807 0.11626731604337692
decider.linear2.weight: 0.00394838210195303 0.055391088128089905
decider.linear2.bias: 0.004559903405606747 0.05734480917453766
decider.linear3.weight: -0.0361756905913353 0.09192127734422684
decider.linear3.bias: -0.027694765478372574 0.056632477790117264

Rewards:
190.8927
190.8927
190.8927
objective = 2.469899892807007
==== episode 400/10000 ====
action = 1
probs = 0.0398 0.9601 0.0002 0.0000

action = 1
probs = 0.0007 0.9993 0.0000 0.0000

action = 1
probs = 0.0009 0.9991 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003074326377827674 0.08396017551422119
encoder.encoder.weight_hh_l0: -0.00048192834947258234 0.08509473502635956
encoder.encoder.bias_ih_l0: 0.007226727437227964 0.08582732081413269
encoder.encoder.bias_hh_l0: 0.017223812639713287 0.08591628819704056
encoder.encoder.weight_ih_l0_reverse: 0.001637907582335174 0.08599284291267395
encoder.encoder.weight_hh_l0_reverse: 0.002360443351790309 0.08411011844873428
encoder.encoder.bias_ih_l0_reverse: 0.022829126566648483 0.08541342616081238
encoder.encoder.bias_hh_l0_reverse: 0.014694572426378727 0.08370166271924973
decider.lstm.weight_ih_l0: -0.00028922775527462363 0.14708247780799866
decider.lstm.weight_hh_l0: -0.0015253237215802073 0.14610114693641663
decider.lstm.bias_ih_l0: 0.018387338146567345 0.153338223695755
decider.lstm.bias_hh_l0: -0.0006001899018883705 0.14364933967590332
decider.linear1.weight: 0.001787226996384561 0.1207684725522995
decider.linear1.bias: 0.013886619359254837 0.11623409390449524
decider.linear2.weight: 0.003957234788686037 0.05544907972216606
decider.linear2.bias: 0.00453164940699935 0.057353004813194275
decider.linear3.weight: -0.03711623698472977 0.09291106462478638
decider.linear3.bias: -0.029431678354740143 0.057077355682849884

Rewards:
190.8927
190.8927
190.8927
objective = 2.6961817741394043
==== episode 500/10000 ====
action = 1
probs = 0.0185 0.9814 0.0000 0.0000

action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0002 0.9998 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000305057066725567 0.08409852534532547
encoder.encoder.weight_hh_l0: -0.0005277596064843237 0.08531447499990463
encoder.encoder.bias_ih_l0: 0.0080391401425004 0.08596291393041611
encoder.encoder.bias_hh_l0: 0.018036222085356712 0.08605647832155228
encoder.encoder.weight_ih_l0_reverse: 0.0016588433645665646 0.08611021935939789
encoder.encoder.weight_hh_l0_reverse: 0.0024239090271294117 0.08419553935527802
encoder.encoder.bias_ih_l0_reverse: 0.023312930017709732 0.08557181060314178
encoder.encoder.bias_hh_l0_reverse: 0.015178374946117401 0.08378313481807709
decider.lstm.weight_ih_l0: -0.00020732759730890393 0.14727376401424408
decider.lstm.weight_hh_l0: -0.0017246981151401997 0.14626027643680573
decider.lstm.bias_ih_l0: 0.019551537930965424 0.1535676121711731
decider.lstm.bias_hh_l0: 0.0005640056915581226 0.14388564229011536
decider.linear1.weight: 0.0017416233895346522 0.12088270485401154
decider.linear1.bias: 0.01429952122271061 0.1162412017583847
decider.linear2.weight: 0.004148117266595364 0.05559767037630081
decider.linear2.bias: 0.004763234406709671 0.05747424066066742
decider.linear3.weight: -0.03766787052154541 0.09355157613754272
decider.linear3.bias: -0.030389204621315002 0.05853696167469025

Rewards:
190.8927
190.8927
190.8927
objective = 1.2184990644454956
==== episode 600/10000 ====
action = 1
probs = 0.0107 0.9893 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002956880780402571 0.08418898284435272
encoder.encoder.weight_hh_l0: -0.0005606038030236959 0.08548364788293839
encoder.encoder.bias_ih_l0: 0.008687946945428848 0.0860290676355362
encoder.encoder.bias_hh_l0: 0.018685029819607735 0.08610763400793076
encoder.encoder.weight_ih_l0_reverse: 0.001687850570306182 0.08617712557315826
encoder.encoder.weight_hh_l0_reverse: 0.0024622606579214334 0.08423712104558945
encoder.encoder.bias_ih_l0_reverse: 0.023735765367746353 0.085636205971241
encoder.encoder.bias_hh_l0_reverse: 0.015601213090121746 0.08382855355739594
decider.lstm.weight_ih_l0: -0.00017556930833961815 0.1474071890115738
decider.lstm.weight_hh_l0: -0.0019376797135919333 0.1463666558265686
decider.lstm.bias_ih_l0: 0.02035827934741974 0.15368546545505524
decider.lstm.bias_hh_l0: 0.0013707424513995647 0.14404304325580597
decider.linear1.weight: 0.0016798737924546003 0.12098235636949539
decider.linear1.bias: 0.014635555446147919 0.11628089100122452
decider.linear2.weight: 0.004397611599415541 0.05574297159910202
decider.linear2.bias: 0.005047767423093319 0.057455044239759445
decider.linear3.weight: -0.03798723965883255 0.09377561509609222
decider.linear3.bias: -0.030718475580215454 0.059278592467308044

Rewards:
190.8927
190.8927
190.8927
objective = 0.6928364038467407
==== episode 700/10000 ====
action = 1
probs = 0.0102 0.9898 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002967239124700427 0.0841955691576004
encoder.encoder.weight_hh_l0: -0.0005587040795944631 0.08548767119646072
encoder.encoder.bias_ih_l0: 0.008706354536116123 0.08602196723222733
encoder.encoder.bias_hh_l0: 0.018703438341617584 0.08609774708747864
encoder.encoder.weight_ih_l0_reverse: 0.001683612703345716 0.08617575466632843
encoder.encoder.weight_hh_l0_reverse: 0.00245787319727242 0.084236741065979
encoder.encoder.bias_ih_l0_reverse: 0.023734187707304955 0.08563072234392166
encoder.encoder.bias_hh_l0_reverse: 0.015599639154970646 0.08382121473550797
decider.lstm.weight_ih_l0: -0.0001808682718547061 0.1474161446094513
decider.lstm.weight_hh_l0: -0.001954411156475544 0.1463739424943924
decider.lstm.bias_ih_l0: 0.02038988284766674 0.15369485318660736
decider.lstm.bias_hh_l0: 0.001402352936565876 0.1440524458885193
decider.linear1.weight: 0.001675305888056755 0.12098714709281921
decider.linear1.bias: 0.014653889462351799 0.11626918613910675
decider.linear2.weight: 0.004436412826180458 0.055782489478588104
decider.linear2.bias: 0.005090206861495972 0.05741042643785477
decider.linear3.weight: -0.03819642215967178 0.09389752894639969
decider.linear3.bias: -0.03091881051659584 0.05937669426202774

Rewards:
190.8927
190.8927
190.8927
objective = 0.6640926599502563
==== episode 800/10000 ====
action = 1
probs = 0.0194 0.9805 0.0000 0.0000

action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0002 0.9998 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003031946253031492 0.08410068601369858
encoder.encoder.weight_hh_l0: -0.0005197251448407769 0.08528915047645569
encoder.encoder.bias_ih_l0: 0.008030670695006847 0.0859084203839302
encoder.encoder.bias_hh_l0: 0.01802775450050831 0.08597567677497864
encoder.encoder.weight_ih_l0_reverse: 0.0016782465390861034 0.0861152932047844
encoder.encoder.weight_hh_l0_reverse: 0.0024180656764656305 0.0842038244009018
encoder.encoder.bias_ih_l0_reverse: 0.023372260853648186 0.08551593869924545
encoder.encoder.bias_hh_l0_reverse: 0.015237707644701004 0.08380196988582611
decider.lstm.weight_ih_l0: -0.00023397592303808779 0.14726783335208893
decider.lstm.weight_hh_l0: -0.0017936676740646362 0.14625239372253418
decider.lstm.bias_ih_l0: 0.01951996237039566 0.15352781116962433
decider.lstm.bias_hh_l0: 0.0005324301309883595 0.14388012886047363
decider.linear1.weight: 0.0017246343195438385 0.1208726242184639
decider.linear1.bias: 0.014221583493053913 0.1162385642528534
decider.linear2.weight: 0.0042578489519655704 0.05570084974169731
decider.linear2.bias: 0.00483392458409071 0.057317040860652924
decider.linear3.weight: -0.03841198608279228 0.09396890550851822
decider.linear3.bias: -0.031160887330770493 0.05866390839219093

Rewards:
190.8927
190.8927
190.8927
objective = 1.277590274810791
==== episode 900/10000 ====
action = 1
probs = 0.0117 0.9883 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030241991044022143 0.08418379724025726
encoder.encoder.weight_hh_l0: -0.0005449753371067345 0.08543585240840912
encoder.encoder.bias_ih_l0: 0.008499732241034508 0.08600322902202606
encoder.encoder.bias_hh_l0: 0.018496813252568245 0.08607816696166992
encoder.encoder.weight_ih_l0_reverse: 0.001670897239819169 0.08616846799850464
encoder.encoder.weight_hh_l0_reverse: 0.0024396360386162996 0.0842374712228775
encoder.encoder.bias_ih_l0_reverse: 0.02357706055045128 0.08562183380126953
encoder.encoder.bias_hh_l0_reverse: 0.015442507341504097 0.08382479846477509
decider.lstm.weight_ih_l0: -0.00018883605662267655 0.14738860726356506
decider.lstm.weight_hh_l0: -0.0018950874218717217 0.14635369181632996
decider.lstm.bias_ih_l0: 0.020192358642816544 0.15366898477077484
decider.lstm.bias_hh_l0: 0.0012048191856592894 0.14402975142002106
decider.linear1.weight: 0.001698762527666986 0.1209578737616539
decider.linear1.bias: 0.014531505294144154 0.116246297955513
decider.linear2.weight: 0.004389453679323196 0.05578076094388962
decider.linear2.bias: 0.0050294408574700356 0.05740303546190262
decider.linear3.weight: -0.0387423038482666 0.0943366214632988
decider.linear3.bias: -0.03160814568400383 0.0595114603638649

Rewards:
190.8927
190.8927
190.8927
objective = 0.7592610716819763
==== episode 1000/10000 ====
action = 1
probs = 0.0075 0.9925 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002968104090541601 0.08425024896860123
encoder.encoder.weight_hh_l0: -0.0005700046312995255 0.08556989580392838
encoder.encoder.bias_ih_l0: 0.00893724337220192 0.08607733249664307
encoder.encoder.bias_hh_l0: 0.01893432065844536 0.08615795522928238
encoder.encoder.weight_ih_l0_reverse: 0.0016776506090536714 0.08621339499950409
encoder.encoder.weight_hh_l0_reverse: 0.002465863712131977 0.08426643162965775
encoder.encoder.bias_ih_l0_reverse: 0.023822693154215813 0.08569911867380142
encoder.encoder.bias_hh_l0_reverse: 0.01568814553320408 0.0838455781340599
decider.lstm.weight_ih_l0: -0.00015501327288802713 0.14748525619506836
decider.lstm.weight_hh_l0: -0.0020020711235702038 0.14643433690071106
decider.lstm.bias_ih_l0: 0.020747855305671692 0.15377114713191986
decider.lstm.bias_hh_l0: 0.0017603114247322083 0.14413908123970032
decider.linear1.weight: 0.00166151556186378 0.1210407093167305
decider.linear1.bias: 0.014824758283793926 0.11626257002353668
decider.linear2.weight: 0.004514388740062714 0.05585344508290291
decider.linear2.bias: 0.005202144850045443 0.057474084198474884
decider.linear3.weight: -0.03889470547437668 0.09453979879617691
decider.linear3.bias: -0.03180438280105591 0.060086771845817566

Rewards:
190.8927
190.8927
190.8927
objective = 0.4817114770412445
==== episode 1100/10000 ====
action = 1
probs = 0.0052 0.9948 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002898676320910454 0.0842989832162857
encoder.encoder.weight_hh_l0: -0.0005919382674619555 0.08568060398101807
encoder.encoder.bias_ih_l0: 0.009298006072640419 0.0861314982175827
encoder.encoder.bias_hh_l0: 0.019295085221529007 0.0862145870923996
encoder.encoder.weight_ih_l0_reverse: 0.0016898589674383402 0.08624991774559021
encoder.encoder.weight_hh_l0_reverse: 0.0024935316760092974 0.08429130911827087
encoder.encoder.bias_ih_l0_reverse: 0.02406523935496807 0.0857493057847023
encoder.encoder.bias_hh_l0_reverse: 0.015930693596601486 0.08385957777500153
decider.lstm.weight_ih_l0: -0.00013132728054188192 0.14755815267562866
decider.lstm.weight_hh_l0: -0.0020989300683140755 0.1464952826499939
decider.lstm.bias_ih_l0: 0.02117139846086502 0.15384458005428314
decider.lstm.bias_hh_l0: 0.002183862030506134 0.1442117840051651
decider.linear1.weight: 0.0016226579900830984 0.12111200392246246
decider.linear1.bias: 0.015064750798046589 0.11628324538469315
decider.linear2.weight: 0.004622976295650005 0.055913761258125305
decider.linear2.bias: 0.005343666300177574 0.057529717683792114
decider.linear3.weight: -0.03897663205862045 0.09466458112001419
decider.linear3.bias: -0.0319032222032547 0.060477517545223236

Rewards:
190.8927
190.8927
190.8927
objective = 0.33472129702568054
==== episode 1200/10000 ====
action = 1
probs = 0.0058 0.9942 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029254096443764865 0.08428269624710083
encoder.encoder.weight_hh_l0: -0.0005833085742779076 0.08563847094774246
encoder.encoder.bias_ih_l0: 0.00916299782693386 0.08610960841178894
encoder.encoder.bias_hh_l0: 0.0191600751131773 0.08618635684251785
encoder.encoder.weight_ih_l0_reverse: 0.0016837840666994452 0.08623556792736053
encoder.encoder.weight_hh_l0_reverse: 0.0024807301815599203 0.08428249508142471
encoder.encoder.bias_ih_l0_reverse: 0.023974446579813957 0.08572570979595184
encoder.encoder.bias_hh_l0_reverse: 0.015839900821447372 0.08383805304765701
decider.lstm.weight_ih_l0: -0.0001403010537615046 0.14753398299217224
decider.lstm.weight_hh_l0: -0.0020748465321958065 0.14647434651851654
decider.lstm.bias_ih_l0: 0.021026775240898132 0.15381701290607452
decider.lstm.bias_hh_l0: 0.002039231825619936 0.14419019222259521
decider.linear1.weight: 0.0016315174289047718 0.12108607590198517
decider.linear1.bias: 0.014967892318964005 0.11627259850502014
decider.linear2.weight: 0.004567894618958235 0.05590083450078964
decider.linear2.bias: 0.005266288295388222 0.05751829594373703
decider.linear3.weight: -0.03902766853570938 0.09468899667263031
decider.linear3.bias: -0.03196127712726593 0.06035793572664261

Rewards:
190.8927
190.8927
190.8927
objective = 0.37402647733688354
==== episode 1300/10000 ====
action = 1
probs = 0.0176 0.9823 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0002 0.9998 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003028848732355982 0.08412215113639832
encoder.encoder.weight_hh_l0: -0.0005207003559917212 0.08530701696872711
encoder.encoder.bias_ih_l0: 0.008088668808341026 0.08591476082801819
encoder.encoder.bias_hh_l0: 0.018085747957229614 0.08596701920032501
encoder.encoder.weight_ih_l0_reverse: 0.0016620309324935079 0.0861237645149231
encoder.encoder.weight_hh_l0_reverse: 0.0024094691034406424 0.08421184867620468
encoder.encoder.bias_ih_l0_reverse: 0.02335299365222454 0.08553661406040192
encoder.encoder.bias_hh_l0_reverse: 0.01521845068782568 0.08376718312501907
decider.lstm.weight_ih_l0: -0.00022527245164383203 0.1472962200641632
decider.lstm.weight_hh_l0: -0.001841698307543993 0.14627309143543243
decider.lstm.bias_ih_l0: 0.019677216187119484 0.15356482565402985
decider.lstm.bias_hh_l0: 0.000689678592607379 0.1439218372106552
decider.linear1.weight: 0.0017020459054037929 0.12088976800441742
decider.linear1.bias: 0.014262745156884193 0.11621631681919098
decider.linear2.weight: 0.004245924763381481 0.05575902760028839
decider.linear2.bias: 0.004811502061784267 0.05733007565140724
decider.linear3.weight: -0.03921075165271759 0.09472507983446121
decider.linear3.bias: -0.03220682591199875 0.05914520472288132

Rewards:
190.8927
190.8927
190.8927
objective = 1.154454231262207
==== episode 1400/10000 ====
action = 1
probs = 0.0365 0.9634 0.0001 0.0000

action = 1
probs = 0.0007 0.9993 0.0000 0.0000

action = 1
probs = 0.0014 0.9986 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003158923063892871 0.0840444341301918
encoder.encoder.weight_hh_l0: -0.0004999103839509189 0.08515932410955429
encoder.encoder.bias_ih_l0: 0.007586922496557236 0.0858512818813324
encoder.encoder.bias_hh_l0: 0.017584001645445824 0.08592236042022705
encoder.encoder.weight_ih_l0_reverse: 0.0016902830684557557 0.08610359579324722
encoder.encoder.weight_hh_l0_reverse: 0.0024259109050035477 0.08422250300645828
encoder.encoder.bias_ih_l0_reverse: 0.023274192586541176 0.08545427769422531
encoder.encoder.bias_hh_l0_reverse: 0.01513964869081974 0.08375220000743866
decider.lstm.weight_ih_l0: -0.00026948261074721813 0.1472008377313614
decider.lstm.weight_hh_l0: -0.0017669691005721688 0.1461920142173767
decider.lstm.bias_ih_l0: 0.01905093342065811 0.15337148308753967
decider.lstm.bias_hh_l0: 6.339419633150101e-05 0.14385515451431274
decider.linear1.weight: 0.0017092814669013023 0.12077934294939041
decider.linear1.bias: 0.013944491744041443 0.11624109745025635
decider.linear2.weight: 0.004083259031176567 0.05567583814263344
decider.linear2.bias: 0.00470399484038353 0.057241711765527725
decider.linear3.weight: -0.0397598072886467 0.0952230915427208
decider.linear3.bias: -0.03305763378739357 0.058592669665813446

Rewards:
190.8927
190.8927
190.8927
objective = 2.5131747722625732
==== episode 1500/10000 ====
action = 1
probs = 0.0222 0.9778 0.0000 0.0000

action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0006 0.9994 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032584770815446973 0.08414609730243683
encoder.encoder.weight_hh_l0: -0.0005197966238483787 0.08529062569141388
encoder.encoder.bias_ih_l0: 0.00794980302453041 0.08598466217517853
encoder.encoder.bias_hh_l0: 0.017946882173419 0.08603327721357346
encoder.encoder.weight_ih_l0_reverse: 0.001692029181867838 0.0861918181180954
encoder.encoder.weight_hh_l0_reverse: 0.0024418567772954702 0.08428418636322021
encoder.encoder.bias_ih_l0_reverse: 0.0234313253313303 0.08556841313838959
encoder.encoder.bias_hh_l0_reverse: 0.015296783298254013 0.08379954844713211
decider.lstm.weight_ih_l0: -0.00022545097453985363 0.14732010662555695
decider.lstm.weight_hh_l0: -0.001819659722968936 0.14630067348480225
decider.lstm.bias_ih_l0: 0.019681425765156746 0.15353551506996155
decider.lstm.bias_hh_l0: 0.0006938837468624115 0.14399832487106323
decider.linear1.weight: 0.0017118764808401465 0.12082752585411072
decider.linear1.bias: 0.01405551191419363 0.11623452603816986
decider.linear2.weight: 0.004116568714380264 0.055725760757923126
decider.linear2.bias: 0.004780558403581381 0.057321470230817795
decider.linear3.weight: -0.04051541909575462 0.0961313247680664
decider.linear3.bias: -0.034322649240493774 0.059972133487463

Rewards:
190.8927
190.8927
190.8927
objective = 1.4838840961456299
==== episode 1600/10000 ====
action = 1
probs = 0.0230 0.9769 0.0000 0.0000

action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0006 0.9994 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032757429289631546 0.08414291590452194
encoder.encoder.weight_hh_l0: -0.0005157882696948946 0.08527767658233643
encoder.encoder.bias_ih_l0: 0.007888173684477806 0.08597759902477264
encoder.encoder.bias_hh_l0: 0.017885250970721245 0.08602465689182281
encoder.encoder.weight_ih_l0_reverse: 0.0016858195886015892 0.08618829399347305
encoder.encoder.weight_hh_l0_reverse: 0.0024358127266168594 0.08428116887807846
encoder.encoder.bias_ih_l0_reverse: 0.02337711490690708 0.08556386083364487
encoder.encoder.bias_hh_l0_reverse: 0.01524257194250822 0.0837988629937172
decider.lstm.weight_ih_l0: -0.0002284016809426248 0.14731185138225555
decider.lstm.weight_hh_l0: -0.0018013707594946027 0.1462944746017456
decider.lstm.bias_ih_l0: 0.01961415261030197 0.15354163944721222
decider.lstm.bias_hh_l0: 0.0006266096606850624 0.14398503303527832
decider.linear1.weight: 0.0017178012058138847 0.12081964313983917
decider.linear1.bias: 0.014006750658154488 0.11623121798038483
decider.linear2.weight: 0.0041083674877882 0.05572710558772087
decider.linear2.bias: 0.0047623347491025925 0.05731899291276932
decider.linear3.weight: -0.0410742349922657 0.09678982943296432
decider.linear3.bias: -0.035279493778944016 0.060405515134334564

Rewards:
190.8927
190.8927
190.8927
objective = 1.5380351543426514
==== episode 1700/10000 ====
action = 1
probs = 0.0160 0.9840 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0003 0.9997 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033062128932215273 0.08421890437602997
encoder.encoder.weight_hh_l0: -0.0005330797284841537 0.08538298308849335
encoder.encoder.bias_ih_l0: 0.008204544894397259 0.08606872707605362
encoder.encoder.bias_hh_l0: 0.018201619386672974 0.08610843122005463
encoder.encoder.weight_ih_l0_reverse: 0.0016922010108828545 0.08625271171331406
encoder.encoder.weight_hh_l0_reverse: 0.002454132307320833 0.08432884514331818
encoder.encoder.bias_ih_l0_reverse: 0.023545129224658012 0.08564899861812592
encoder.encoder.bias_hh_l0_reverse: 0.015410586260259151 0.08383616805076599
decider.lstm.weight_ih_l0: -0.00019537887419573963 0.14740322530269623
decider.lstm.weight_hh_l0: -0.001855190610513091 0.14637491106987
decider.lstm.bias_ih_l0: 0.020107585936784744 0.1536395251750946
decider.lstm.bias_hh_l0: 0.0011200434528291225 0.14410127699375153
decider.linear1.weight: 0.0017101778648793697 0.12086852639913559
decider.linear1.bias: 0.014163137413561344 0.11624162644147873
decider.linear2.weight: 0.004168243147432804 0.05576809495687485
decider.linear2.bias: 0.004865250550210476 0.05739527568221092
decider.linear3.weight: -0.041463714092969894 0.09730039536952972
decider.linear3.bias: -0.035944800823926926 0.06127595901489258

Rewards:
190.8927
190.8927
190.8927
objective = 1.0572717189788818
==== episode 1800/10000 ====
action = 1
probs = 0.0098 0.9902 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032872045994736254 0.08431530743837357
encoder.encoder.weight_hh_l0: -0.0005601486191153526 0.08553484082221985
encoder.encoder.bias_ih_l0: 0.008687478490173817 0.08617759495973587
encoder.encoder.bias_hh_l0: 0.01868455298244953 0.08621673285961151
encoder.encoder.weight_ih_l0_reverse: 0.0017078524688258767 0.08633142709732056
encoder.encoder.weight_hh_l0_reverse: 0.0024823604617267847 0.08438672125339508
encoder.encoder.bias_ih_l0_reverse: 0.023828351870179176 0.08575477451086044
encoder.encoder.bias_hh_l0_reverse: 0.01569380797445774 0.08388515561819077
decider.lstm.weight_ih_l0: -0.00015298303333111107 0.14752143621444702
decider.lstm.weight_hh_l0: -0.00195578346028924 0.14647886157035828
decider.lstm.bias_ih_l0: 0.020782580599188805 0.1537463217973709
decider.lstm.bias_hh_l0: 0.0017950334586203098 0.1442481279373169
decider.linear1.weight: 0.0016847520601004362 0.12094921618700027
decider.linear1.bias: 0.01444339007139206 0.11627224087715149
decider.linear2.weight: 0.004281344823539257 0.055830031633377075
decider.linear2.bias: 0.005056214984506369 0.05749865993857384
decider.linear3.weight: -0.041647814214229584 0.09758434444665909
decider.linear3.bias: -0.03624586760997772 0.06209517642855644

Rewards:
190.8927
190.8927
190.8927
objective = 0.6398332118988037
==== episode 1900/10000 ====
action = 1
probs = 0.0134 0.9866 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0002 0.9998 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033294837339781225 0.08426088094711304
encoder.encoder.weight_hh_l0: -0.0005395877524279058 0.0854327455163002
encoder.encoder.bias_ih_l0: 0.008339960128068924 0.08611385524272919
encoder.encoder.bias_hh_l0: 0.018337031826376915 0.08615046739578247
encoder.encoder.weight_ih_l0_reverse: 0.001691404264420271 0.08628841489553452
encoder.encoder.weight_hh_l0_reverse: 0.0024607006926089525 0.084356389939785
encoder.encoder.bias_ih_l0_reverse: 0.023605847731232643 0.08569923043251038
encoder.encoder.bias_hh_l0_reverse: 0.01547129824757576 0.08385676890611649
decider.lstm.weight_ih_l0: -0.00017947127344086766 0.14744997024536133
decider.lstm.weight_hh_l0: -0.001874459208920598 0.1464158594608307
decider.lstm.bias_ih_l0: 0.020343396812677383 0.15368252992630005
decider.lstm.bias_hh_l0: 0.0013558492064476013 0.1441674679517746
decider.linear1.weight: 0.001711580902338028 0.12089082598686218
decider.linear1.bias: 0.014223601669073105 0.11624850332736969
decider.linear2.weight: 0.0041915904730558395 0.05579248070716858
decider.linear2.bias: 0.004913892596960068 0.057435400784015656
decider.linear3.weight: -0.04182124137878418 0.09775623679161072
decider.linear3.bias: -0.03652907907962799 0.06182758882641792

Rewards:
190.8927
190.8927
190.8927
objective = 0.8778454065322876
==== episode 2000/10000 ====
action = 1
probs = 0.0085 0.9915 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033042050199583173 0.08434682339429855
encoder.encoder.weight_hh_l0: -0.0005646871286444366 0.08557171374559402
encoder.encoder.bias_ih_l0: 0.008782767690718174 0.08620992302894592
encoder.encoder.bias_hh_l0: 0.01877984032034874 0.08624773472547531
encoder.encoder.weight_ih_l0_reverse: 0.001707048388198018 0.08635711669921875
encoder.encoder.weight_hh_l0_reverse: 0.0024867053143680096 0.08440790325403214
encoder.encoder.bias_ih_l0_reverse: 0.02386821061372757 0.08578874170780182
encoder.encoder.bias_hh_l0_reverse: 0.015733661130070686 0.08390067517757416
decider.lstm.weight_ih_l0: -0.00014256525901146233 0.14755505323410034
decider.lstm.weight_hh_l0: -0.001966003328561783 0.14650858938694
decider.lstm.bias_ih_l0: 0.02094130590558052 0.15377911925315857
decider.lstm.bias_hh_l0: 0.001953762024641037 0.1442953199148178
decider.linear1.weight: 0.0016866549849510193 0.12096655368804932
decider.linear1.bias: 0.014486795291304588 0.11627519875764847
decider.linear2.weight: 0.004303683061152697 0.055851805955171585
decider.linear2.bias: 0.005098382942378521 0.0575285404920578
decider.linear3.weight: -0.04196923226118088 0.09799381345510483
decider.linear3.bias: -0.03676727041602135 0.06253926455974579

Rewards:
190.8927
190.8927
190.8927
objective = 0.5557113885879517
==== episode 2100/10000 ====
action = 1
probs = 0.0060 0.9940 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003252801252529025 0.08440691977739334
encoder.encoder.weight_hh_l0: -0.0005852028843946755 0.08568039536476135
encoder.encoder.bias_ih_l0: 0.00913437083363533 0.08627547323703766
encoder.encoder.bias_hh_l0: 0.019131438806653023 0.08631639182567596
encoder.encoder.weight_ih_l0_reverse: 0.001722883083857596 0.08640504628419876
encoder.encoder.weight_hh_l0_reverse: 0.0025080442428588867 0.08444289863109589
encoder.encoder.bias_ih_l0_reverse: 0.024092158302664757 0.08584871143102646
encoder.encoder.bias_hh_l0_reverse: 0.015957610681653023 0.0839342400431633
decider.lstm.weight_ih_l0: -0.00011577668919926509 0.14763036370277405
decider.lstm.weight_hh_l0: -0.0020482223480939865 0.14657610654830933
decider.lstm.bias_ih_l0: 0.021384641528129578 0.1538466364145279
decider.lstm.bias_hh_l0: 0.002397090196609497 0.14437730610370636
decider.linear1.weight: 0.0016583101823925972 0.12103158235549927
decider.linear1.bias: 0.014713592827320099 0.11630158871412277
decider.linear2.weight: 0.0043950132094323635 0.05590168386697769
decider.linear2.bias: 0.005243030376732349 0.05760328099131584
decider.linear3.weight: -0.042045023292303085 0.09813054651021957
decider.linear3.bias: -0.0368821918964386 0.06300882250070572

Rewards:
190.8927
190.8927
190.8927
objective = 0.3899277150630951
==== episode 2200/10000 ====
action = 1
probs = 0.0045 0.9955 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031930787372402847 0.08445300161838531
encoder.encoder.weight_hh_l0: -0.0006029419018886983 0.08577149361371994
encoder.encoder.bias_ih_l0: 0.00942978635430336 0.08632440865039825
encoder.encoder.bias_hh_l0: 0.019426856189966202 0.0863695964217186
encoder.encoder.weight_ih_l0_reverse: 0.0017392507288604975 0.08644364029169083
encoder.encoder.weight_hh_l0_reverse: 0.0025281726848334074 0.08447084575891495
encoder.encoder.bias_ih_l0_reverse: 0.024299152195453644 0.08589116483926773
encoder.encoder.bias_hh_l0_reverse: 0.01616460457444191 0.08396267890930176
decider.lstm.weight_ih_l0: -9.415991371497512e-05 0.14768989384174347
decider.lstm.weight_hh_l0: -0.0021242669317871332 0.1466301679611206
decider.lstm.bias_ih_l0: 0.021741332486271858 0.1538981795310974
decider.lstm.bias_hh_l0: 0.002753780223429203 0.14443545043468475
decider.linear1.weight: 0.00162720016669482 0.12108946591615677
decider.linear1.bias: 0.014918484725058079 0.11632789671421051
decider.linear2.weight: 0.004477977752685547 0.05594480037689209
decider.linear2.bias: 0.005369171034544706 0.05766214430332184
decider.linear3.weight: -0.042089950293302536 0.09822199493646622
decider.linear3.bias: -0.036947064101696014 0.06335581839084625

Rewards:
190.8927
190.8927
190.8927
objective = 0.2909555435180664
==== episode 2300/10000 ====
action = 1
probs = 0.0060 0.9940 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032709931838326156 0.08441094309091568
encoder.encoder.weight_hh_l0: -0.0005828434368595481 0.08567529171705246
encoder.encoder.bias_ih_l0: 0.009105684235692024 0.08627331256866455
encoder.encoder.bias_hh_l0: 0.019102763384580612 0.08631689101457596
encoder.encoder.weight_ih_l0_reverse: 0.0017200709553435445 0.08640827983617783
encoder.encoder.weight_hh_l0_reverse: 0.0025030835531651974 0.08444724977016449
encoder.encoder.bias_ih_l0_reverse: 0.02406243421137333 0.0858529582619667
encoder.encoder.bias_hh_l0_reverse: 0.015927884727716446 0.08393336087465286
decider.lstm.weight_ih_l0: -0.00011800233187386766 0.14763185381889343
decider.lstm.weight_hh_l0: -0.0020484498236328363 0.14657782018184662
decider.lstm.bias_ih_l0: 0.02138393186032772 0.15383519232273102
decider.lstm.bias_hh_l0: 0.0023963754065334797 0.14438971877098083
decider.linear1.weight: 0.0016615099739283323 0.1210273876786232
decider.linear1.bias: 0.014686951413750648 0.11630039662122726
decider.linear2.weight: 0.0043770931661129 0.05590732768177986
decider.linear2.bias: 0.005223894026130438 0.05760687217116356
decider.linear3.weight: -0.042123496532440186 0.09822262823581696
decider.linear3.bias: -0.03699415549635887 0.06305308640003204

Rewards:
190.8927
190.8927
190.8927
objective = 0.39072543382644653
==== episode 2400/10000 ====
action = 1
probs = 0.0046 0.9954 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003228526620659977 0.08445721864700317
encoder.encoder.weight_hh_l0: -0.0005991838988848031 0.08576184511184692
encoder.encoder.bias_ih_l0: 0.009377963840961456 0.08632612228393555
encoder.encoder.bias_hh_l0: 0.019375042989850044 0.08636967092752457
encoder.encoder.weight_ih_l0_reverse: 0.0017340653575956821 0.08644531667232513
encoder.encoder.weight_hh_l0_reverse: 0.0025193477049469948 0.08447441458702087
encoder.encoder.bias_ih_l0_reverse: 0.02423781156539917 0.08589793741703033
encoder.encoder.bias_hh_l0_reverse: 0.016103260219097137 0.08396385610103607
decider.lstm.weight_ih_l0: -9.848341142060235e-05 0.14768899977207184
decider.lstm.weight_hh_l0: -0.002108396030962467 0.1466294527053833
decider.lstm.bias_ih_l0: 0.02171388640999794 0.15388831496238708
decider.lstm.bias_hh_l0: 0.0027263304218649864 0.1444489061832428
decider.linear1.weight: 0.0016380669549107552 0.12108029425144196
decider.linear1.bias: 0.01487888116389513 0.1163235604763031
decider.linear2.weight: 0.004457656294107437 0.05594749376177788
decider.linear2.bias: 0.005348455626517534 0.05766042694449425
decider.linear3.weight: -0.04217442497611046 0.09831999987363815
decider.linear3.bias: -0.037068139761686325 0.06340044736862183

Rewards:
190.8927
190.8927
190.8927
objective = 0.2980724275112152
==== episode 2500/10000 ====
action = 1
probs = 0.0036 0.9964 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003171902208123356 0.08449744433164597
encoder.encoder.weight_hh_l0: -0.0006152967107482255 0.08584390580654144
encoder.encoder.bias_ih_l0: 0.009639636613428593 0.08637143671512604
encoder.encoder.bias_hh_l0: 0.019636711105704308 0.08641616255044937
encoder.encoder.weight_ih_l0_reverse: 0.0017487859586253762 0.08647884428501129
encoder.encoder.weight_hh_l0_reverse: 0.0025371068622916937 0.08449866622686386
encoder.encoder.bias_ih_l0_reverse: 0.024420201778411865 0.08593572676181793
encoder.encoder.bias_hh_l0_reverse: 0.016285648569464684 0.08399146050214767
decider.lstm.weight_ih_l0: -7.99670597189106e-05 0.14774051308631897
decider.lstm.weight_hh_l0: -0.0021708079148083925 0.14667648077011108
decider.lstm.bias_ih_l0: 0.022016942501068115 0.15393835306167603
decider.lstm.bias_hh_l0: 0.0030293967574834824 0.144494891166687
decider.linear1.weight: 0.0016110751312226057 0.12113300710916519
decider.linear1.bias: 0.01506684347987175 0.11634735763072968
decider.linear2.weight: 0.0045364052057266235 0.05598622187972069
decider.linear2.bias: 0.005465912166982889 0.05771077796816826
decider.linear3.weight: -0.04220754653215408 0.09839361160993576
decider.linear3.bias: -0.03711424767971039 0.06369806081056595

Rewards:
190.8927
190.8927
190.8927
objective = 0.2296200841665268
==== episode 2600/10000 ====
action = 1
probs = 0.0028 0.9972 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000311220355797559 0.08453007787466049
encoder.encoder.weight_hh_l0: -0.0006296102656051517 0.08591511100530624
encoder.encoder.bias_ih_l0: 0.009867631830275059 0.08640757203102112
encoder.encoder.bias_hh_l0: 0.019864706322550774 0.08645402640104294
encoder.encoder.weight_ih_l0_reverse: 0.00176248699426651 0.08650752902030945
encoder.encoder.weight_hh_l0_reverse: 0.0025545423850417137 0.08451942354440689
encoder.encoder.bias_ih_l0_reverse: 0.024590210989117622 0.085965096950531
encoder.encoder.bias_hh_l0_reverse: 0.01645565591752529 0.084014393389225
decider.lstm.weight_ih_l0: -6.379157275659963e-05 0.147783562541008
decider.lstm.weight_hh_l0: -0.002228511031717062 0.14671608805656433
decider.lstm.bias_ih_l0: 0.022272281348705292 0.15398192405700684
decider.lstm.bias_hh_l0: 0.0032847304828464985 0.1445278823375702
decider.linear1.weight: 0.0015845221932977438 0.12118032574653625
decider.linear1.bias: 0.015232113189995289 0.11636918038129807
decider.linear2.weight: 0.00460521224886179 0.05602045729756355
decider.linear2.bias: 0.005565796047449112 0.05775484815239906
decider.linear3.weight: -0.04222975671291351 0.09844929724931717
decider.linear3.bias: -0.03714399039745331 0.06393752247095108

Rewards:
190.8927
190.8927
190.8927
objective = 0.18286047875881195
==== episode 2700/10000 ====
action = 1
probs = 0.0044 0.9956 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003254770126659423 0.08447419106960297
encoder.encoder.weight_hh_l0: -0.000600286410190165 0.08577662706375122
encoder.encoder.bias_ih_l0: 0.009399771690368652 0.08634060621261597
encoder.encoder.bias_hh_l0: 0.01939684897661209 0.08638160675764084
encoder.encoder.weight_ih_l0_reverse: 0.001734387595206499 0.0864562839269638
encoder.encoder.weight_hh_l0_reverse: 0.002514294348657131 0.08448581397533417
encoder.encoder.bias_ih_l0_reverse: 0.02423189766705036 0.08591343462467194
encoder.encoder.bias_hh_l0_reverse: 0.01609734818339348 0.08397066593170166
decider.lstm.weight_ih_l0: -9.776379738468677e-05 0.14770403504371643
decider.lstm.weight_hh_l0: -0.002120028715580702 0.14664317667484283
decider.lstm.bias_ih_l0: 0.021786589175462723 0.15389010310173035
decider.lstm.bias_hh_l0: 0.0027990369126200676 0.14447613060474396
decider.linear1.weight: 0.0016364076873287559 0.12108781188726425
decider.linear1.bias: 0.014897670596837997 0.11632911115884781
decider.linear2.weight: 0.004461507312953472 0.05596349388360977
decider.linear2.bias: 0.0053633470088243484 0.057675138115882874
decider.linear3.weight: -0.04226143658161163 0.0984293594956398
decider.linear3.bias: -0.03718796744942665 0.06351587921380997

Rewards:
190.8927
190.8927
190.8927
objective = 0.284015417098999
==== episode 2800/10000 ====
action = 1
probs = 0.0060 0.9940 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003331321058794856 0.08442936837673187
encoder.encoder.weight_hh_l0: -0.000579345622099936 0.08567719161510468
encoder.encoder.bias_ih_l0: 0.009065675549209118 0.08628405630588531
encoder.encoder.bias_hh_l0: 0.01906275562942028 0.08632242679595947
encoder.encoder.weight_ih_l0_reverse: 0.0017158511327579618 0.08641939610242844
encoder.encoder.weight_hh_l0_reverse: 0.0024915351532399654 0.08446156978607178
encoder.encoder.bias_ih_l0_reverse: 0.02400580421090126 0.08586955815553665
encoder.encoder.bias_hh_l0_reverse: 0.01587125100195408 0.08393611013889313
decider.lstm.weight_ih_l0: -0.00012087231152690947 0.14764311909675598
decider.lstm.weight_hh_l0: -0.002051384188234806 0.14658798277378082
decider.lstm.bias_ih_l0: 0.021425839513540268 0.1538235992193222
decider.lstm.bias_hh_l0: 0.0024382825940847397 0.1444222778081894
decider.linear1.weight: 0.0016652619233354926 0.12102550268173218
decider.linear1.bias: 0.014664034359157085 0.11630433797836304
decider.linear2.weight: 0.004360727500170469 0.05592626705765724
decider.linear2.bias: 0.005215181037783623 0.057615380734205246
decider.linear3.weight: -0.042315006256103516 0.09845319390296936
decider.linear3.bias: -0.03726556897163391 0.0632002055644989

Rewards:
190.8927
190.8927
190.8927
objective = 0.3882463872432709
==== episode 2900/10000 ====
action = 1
probs = 0.0044 0.9956 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032917846692726016 0.08448496460914612
encoder.encoder.weight_hh_l0: -0.0005981097347103059 0.08577702194452286
encoder.encoder.bias_ih_l0: 0.009375718422234058 0.08635024726390839
encoder.encoder.bias_hh_l0: 0.01937279663980007 0.08638807386159897
encoder.encoder.weight_ih_l0_reverse: 0.0017306976951658726 0.08646281063556671
encoder.encoder.weight_hh_l0_reverse: 0.0025081264320760965 0.0844932273030281
encoder.encoder.bias_ih_l0_reverse: 0.024189624935388565 0.08592448383569717
encoder.encoder.bias_hh_l0_reverse: 0.016055073589086533 0.08397460728883743
decider.lstm.weight_ih_l0: -9.94229267234914e-05 0.14771023392677307
decider.lstm.weight_hh_l0: -0.0021088768262416124 0.1466483622789383
decider.lstm.bias_ih_l0: 0.021792784333229065 0.15388989448547363
decider.lstm.bias_hh_l0: 0.002805231139063835 0.14449574053287506
decider.linear1.weight: 0.0016460426850244403 0.12108339369297028
decider.linear1.bias: 0.014873402193188667 0.11632645130157471
decider.linear2.weight: 0.004451402463018894 0.055971983820199966
decider.linear2.bias: 0.005357014015316963 0.057677045464515686
decider.linear3.weight: -0.042374588549137115 0.09856727719306946
decider.linear3.bias: -0.037352122366428375 0.0636189728975296

Rewards:
190.8927
190.8927
190.8927
objective = 0.2824997901916504
==== episode 3000/10000 ====
action = 1
probs = 0.0034 0.9966 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032419050694443285 0.08452817797660828
encoder.encoder.weight_hh_l0: -0.0006143565406091511 0.08586054295301437
encoder.encoder.bias_ih_l0: 0.009639134630560875 0.08640102297067642
encoder.encoder.bias_hh_l0: 0.019636213779449463 0.08644022047519684
encoder.encoder.weight_ih_l0_reverse: 0.001744273817166686 0.08649773895740509
encoder.encoder.weight_hh_l0_reverse: 0.0025237484369426966 0.08451827615499496
encoder.encoder.bias_ih_l0_reverse: 0.02435719408094883 0.08596691489219666
encoder.encoder.bias_hh_l0_reverse: 0.016222642734646797 0.0840064212679863
decider.lstm.weight_ih_l0: -8.164239989127964e-05 0.14776356518268585
decider.lstm.weight_hh_l0: -0.0021606585942208767 0.14669694006443024
decider.lstm.bias_ih_l0: 0.022090312093496323 0.15394414961338043
decider.lstm.bias_hh_l0: 0.0031027570366859436 0.144548237323761
decider.linear1.weight: 0.001626029028557241 0.12113454192876816
decider.linear1.bias: 0.015056898817420006 0.11634589731693268
decider.linear2.weight: 0.004529242403805256 0.05601141229271889
decider.linear2.bias: 0.005475369282066822 0.05772915482521057
decider.linear3.weight: -0.042411863803863525 0.09864744544029236
decider.linear3.bias: -0.03740394115447998 0.06394101679325104

Rewards:
190.8927
190.8927
190.8927
objective = 0.2158859223127365
==== episode 3100/10000 ====
action = 1
probs = 0.0027 0.9973 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031881354516372085 0.08456264436244965
encoder.encoder.weight_hh_l0: -0.0006285363342612982 0.0859316810965538
encoder.encoder.bias_ih_l0: 0.009865155443549156 0.08644118160009384
encoder.encoder.bias_hh_l0: 0.019862234592437744 0.08648238331079483
encoder.encoder.weight_ih_l0_reverse: 0.0017565980087965727 0.08652691543102264
encoder.encoder.weight_hh_l0_reverse: 0.0025387867353856564 0.08453912287950516
encoder.encoder.bias_ih_l0_reverse: 0.024510759860277176 0.0860004648566246
encoder.encoder.bias_hh_l0_reverse: 0.016376206651329994 0.08403298258781433
decider.lstm.weight_ih_l0: -6.640430365223438e-05 0.1478072553873062
decider.lstm.weight_hh_l0: -0.0022074063308537006 0.14673708379268646
decider.lstm.bias_ih_l0: 0.022337283939123154 0.15399013459682465
decider.lstm.bias_hh_l0: 0.0033497284166514874 0.14458663761615753
decider.linear1.weight: 0.001606159727089107 0.12117992341518402
decider.linear1.bias: 0.01521766185760498 0.1163637787103653
decider.linear2.weight: 0.0045969123020768166 0.05604572221636772
decider.linear2.bias: 0.005575716495513916 0.05777369439601898
decider.linear3.weight: -0.042436763644218445 0.09870743751525879
decider.linear3.bias: -0.03743727505207062 0.06419794261455536

Rewards:
190.8927
190.8927
190.8927
objective = 0.17126914858818054
==== episode 3200/10000 ====
action = 1
probs = 0.0022 0.9978 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003132221754640341 0.08459138125181198
encoder.encoder.weight_hh_l0: -0.0006412742077372968 0.08599446713924408
encoder.encoder.bias_ih_l0: 0.010065432637929916 0.08647432923316956
encoder.encoder.bias_hh_l0: 0.020062513649463654 0.08651772886514664
encoder.encoder.weight_ih_l0_reverse: 0.0017680182354524732 0.08655249327421188
encoder.encoder.weight_hh_l0_reverse: 0.0025537176989018917 0.0845574140548706
encoder.encoder.bias_ih_l0_reverse: 0.024655332788825035 0.08602797240018845
encoder.encoder.bias_hh_l0_reverse: 0.016520783305168152 0.0840558335185051
decider.lstm.weight_ih_l0: -5.2756964578293264e-05 0.14784467220306396
decider.lstm.weight_hh_l0: -0.0022506858222186565 0.14677168428897858
decider.lstm.bias_ih_l0: 0.022550443187355995 0.15403077006340027
decider.lstm.bias_hh_l0: 0.003562881611287594 0.14461582899093628
decider.linear1.weight: 0.0015862742438912392 0.12122134864330292
decider.linear1.bias: 0.015362954698503017 0.11638060957193375
decider.linear2.weight: 0.004657364450395107 0.05607650429010391
decider.linear2.bias: 0.005663474090397358 0.05781356245279312
decider.linear3.weight: -0.04245452955365181 0.09875532239675522
decider.linear3.bias: -0.03746030852198601 0.06441275775432587

Rewards:
190.8927
190.8927
190.8927
objective = 0.1393609642982483
==== episode 3300/10000 ====
action = 1
probs = 0.0018 0.9982 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003074707055930048 0.08461586385965347
encoder.encoder.weight_hh_l0: -0.0006528663216158748 0.08605097979307175
encoder.encoder.bias_ih_l0: 0.010245969519019127 0.08650227636098862
encoder.encoder.bias_hh_l0: 0.020243050530552864 0.08654768764972687
encoder.encoder.weight_ih_l0_reverse: 0.0017788172699511051 0.08657568693161011
encoder.encoder.weight_hh_l0_reverse: 0.0025688540190458298 0.08457405865192413
encoder.encoder.bias_ih_l0_reverse: 0.024793710559606552 0.08605101704597473
encoder.encoder.bias_hh_l0_reverse: 0.016659164801239967 0.08407653123140335
decider.lstm.weight_ih_l0: -4.021465792902745e-05 0.14787769317626953
decider.lstm.weight_hh_l0: -0.0022913061548024416 0.14680245518684387
decider.lstm.bias_ih_l0: 0.02273891493678093 0.15406660735607147
decider.lstm.bias_hh_l0: 0.0037513463757932186 0.1446395069360733
decider.linear1.weight: 0.0015649283304810524 0.1212606355547905
decider.linear1.bias: 0.01550350058823824 0.11639951914548874
decider.linear2.weight: 0.00471429992467165 0.056104402989149094
decider.linear2.bias: 0.005744216497987509 0.057850029319524765
decider.linear3.weight: -0.04246768727898598 0.09879497438669205
decider.linear3.bias: -0.03747688978910446 0.06459707766771317

Rewards:
190.8927
190.8927
190.8927
objective = 0.1157657727599144
==== episode 3400/10000 ====
action = 1
probs = 0.0015 0.9985 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003016656555701047 0.08463723957538605
encoder.encoder.weight_hh_l0: -0.0006635785684920847 0.08610264956951141
encoder.encoder.bias_ih_l0: 0.010411081835627556 0.08652656525373459
encoder.encoder.bias_hh_l0: 0.020408164709806442 0.08657358586788177
encoder.encoder.weight_ih_l0_reverse: 0.0017890124581754208 0.0865970253944397
encoder.encoder.weight_hh_l0_reverse: 0.0025840827729552984 0.08458943665027618
encoder.encoder.bias_ih_l0_reverse: 0.024926528334617615 0.0860704854130745
encoder.encoder.bias_hh_l0_reverse: 0.01679198630154133 0.08409491181373596
decider.lstm.weight_ih_l0: -2.853102887456771e-05 0.14790721237659454
decider.lstm.weight_hh_l0: -0.0023296596482396126 0.1468300223350525
decider.lstm.bias_ih_l0: 0.022907529026269913 0.15409959852695465
decider.lstm.bias_hh_l0: 0.003919967450201511 0.14465810358524323
decider.linear1.weight: 0.0015439193230122328 0.12129738926887512
decider.linear1.bias: 0.015632592141628265 0.11641830950975418
decider.linear2.weight: 0.004767498932778835 0.05613001808524132
decider.linear2.bias: 0.0058181253261864185 0.0578826442360878
decider.linear3.weight: -0.042477697134017944 0.09882867336273193
decider.linear3.bias: -0.03748917579650879 0.06475844979286194

Rewards:
190.8927
190.8927
190.8927
objective = 0.09763719886541367
==== episode 3500/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029582923161797225 0.08465616405010223
encoder.encoder.weight_hh_l0: -0.0006735335919074714 0.08615034818649292
encoder.encoder.bias_ih_l0: 0.01056353747844696 0.08654778450727463
encoder.encoder.bias_hh_l0: 0.020560622215270996 0.08659624308347702
encoder.encoder.weight_ih_l0_reverse: 0.001798634068109095 0.0866168960928917
encoder.encoder.weight_hh_l0_reverse: 0.002599482424557209 0.08460386842489243
encoder.encoder.bias_ih_l0_reverse: 0.02505470998585224 0.08608700335025787
encoder.encoder.bias_hh_l0_reverse: 0.016920169815421104 0.08411099761724472
decider.lstm.weight_ih_l0: -1.7492882761871442e-05 0.14793390035629272
decider.lstm.weight_hh_l0: -0.002366140950471163 0.14685499668121338
decider.lstm.bias_ih_l0: 0.02306026592850685 0.1541304737329483
decider.lstm.bias_hh_l0: 0.004072698764503002 0.14467255771160126
decider.linear1.weight: 0.0015232920413836837 0.12133190035820007
decider.linear1.bias: 0.015751853585243225 0.11643586307764053
decider.linear2.weight: 0.004816874861717224 0.0561537891626358
decider.linear2.bias: 0.005885511636734009 0.05791206285357475
decider.linear3.weight: -0.042485497891902924 0.09885799139738083
decider.linear3.bias: -0.03749851882457733 0.06490185111761093

Rewards:
190.8927
190.8927
190.8927
objective = 0.08334909379482269
==== episode 3600/10000 ====
action = 1
probs = 0.0011 0.9989 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002900255494751036 0.08467298001050949
encoder.encoder.weight_hh_l0: -0.0006827435572631657 0.08619436621665955
encoder.encoder.bias_ih_l0: 0.010704121552407742 0.08656632155179977
encoder.encoder.bias_hh_l0: 0.020701203495264053 0.08661601692438126
encoder.encoder.weight_ih_l0_reverse: 0.0018076668493449688 0.08663541823625565
encoder.encoder.weight_hh_l0_reverse: 0.0026149561163038015 0.08461745828390121
encoder.encoder.bias_ih_l0_reverse: 0.02517779916524887 0.08610094338655472
encoder.encoder.bias_hh_l0_reverse: 0.017043258994817734 0.08412495255470276
decider.lstm.weight_ih_l0: -7.0452688305522315e-06 0.14795811474323273
decider.lstm.weight_hh_l0: -0.0024007230531424284 0.14687758684158325
decider.lstm.bias_ih_l0: 0.023198692128062248 0.1541593074798584
decider.lstm.bias_hh_l0: 0.004211130551993847 0.14468365907669067
decider.linear1.weight: 0.0015031825751066208 0.12136424332857132
decider.linear1.bias: 0.015861917287111282 0.11645226925611496
decider.linear2.weight: 0.0048627001233398914 0.056175801903009415
decider.linear2.bias: 0.005947021301835775 0.05793870985507965
decider.linear3.weight: -0.042491644620895386 0.09888371080160141
decider.linear3.bias: -0.03750572353601456 0.06502961367368698

Rewards:
190.8927
190.8927
190.8927
objective = 0.07195352017879486
==== episode 3700/10000 ====
action = 1
probs = 0.0010 0.9990 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00028419680893421173 0.0846882238984108
encoder.encoder.weight_hh_l0: -0.0006913915276527405 0.08623573184013367
encoder.encoder.bias_ih_l0: 0.010836075060069561 0.08658279478549957
encoder.encoder.bias_hh_l0: 0.020833158865571022 0.0866336077451706
encoder.encoder.weight_ih_l0_reverse: 0.0018162722699344158 0.08665300160646439
encoder.encoder.weight_hh_l0_reverse: 0.0026306994259357452 0.08463051915168762
encoder.encoder.bias_ih_l0_reverse: 0.025297697633504868 0.0861128494143486
encoder.encoder.bias_hh_l0_reverse: 0.01716315932571888 0.08413717150688171
decider.lstm.weight_ih_l0: 3.0336900636029895e-06 0.14798052608966827
decider.lstm.weight_hh_l0: -0.0024340259842574596 0.14689846336841583
decider.lstm.bias_ih_l0: 0.023326581344008446 0.15418675541877747
decider.lstm.bias_hh_l0: 0.004339016508311033 0.14469210803508759
decider.linear1.weight: 0.0014833330642431974 0.12139502167701721
decider.linear1.bias: 0.01596524752676487 0.11646783351898193
decider.linear2.weight: 0.004906034097075462 0.05619656294584274
decider.linear2.bias: 0.006004292983561754 0.05796337127685547
decider.linear3.weight: -0.042496636509895325 0.09890685230493546
decider.linear3.bias: -0.0375114381313324 0.0651458352804184

Rewards:
190.8927
190.8927
190.8927
objective = 0.06263653934001923
==== episode 3800/10000 ====
action = 1
probs = 0.0009 0.9991 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002783393138088286 0.08470218628644943
encoder.encoder.weight_hh_l0: -0.0006995401345193386 0.08627483993768692
encoder.encoder.bias_ih_l0: 0.010960676707327366 0.08659754693508148
encoder.encoder.bias_hh_l0: 0.020957758650183678 0.08664930611848831
encoder.encoder.weight_ih_l0_reverse: 0.0018245014362037182 0.08666981756687164
encoder.encoder.weight_hh_l0_reverse: 0.002646738663315773 0.08464314788579941
encoder.encoder.bias_ih_l0_reverse: 0.02541484497487545 0.0861230120062828
encoder.encoder.bias_hh_l0_reverse: 0.01728031039237976 0.08414782583713531
decider.lstm.weight_ih_l0: 1.2830197192670312e-05 0.14800141751766205
decider.lstm.weight_hh_l0: -0.0024662483483552933 0.14691784977912903
decider.lstm.bias_ih_l0: 0.02344558760523796 0.15421298146247864
decider.lstm.bias_hh_l0: 0.004458025097846985 0.14469841122627258
decider.linear1.weight: 0.0014637060230597854 0.12142448872327805
decider.linear1.bias: 0.016062770038843155 0.1164826899766922
decider.linear2.weight: 0.004947241395711899 0.05621624365448952
decider.linear2.bias: 0.00605796417221427 0.057986337691545486
decider.linear3.weight: -0.04250073432922363 0.09892790764570236
decider.linear3.bias: -0.03751606494188309 0.06525242328643799

Rewards:
190.8927
190.8927
190.8927
objective = 0.054903771728277206
==== episode 3900/10000 ====
action = 1
probs = 0.0008 0.9992 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00027248330297879875 0.08471503853797913
encoder.encoder.weight_hh_l0: -0.0007072431035339832 0.08631207048892975
encoder.encoder.bias_ih_l0: 0.011078954674303532 0.08661080151796341
encoder.encoder.bias_hh_l0: 0.021076034754514694 0.08666336536407471
encoder.encoder.weight_ih_l0_reverse: 0.001832429668866098 0.08668601512908936
encoder.encoder.weight_hh_l0_reverse: 0.0026631325017660856 0.0846555307507515
encoder.encoder.bias_ih_l0_reverse: 0.025529835373163223 0.08613156527280807
encoder.encoder.bias_hh_l0_reverse: 0.017395300790667534 0.0841570794582367
decider.lstm.weight_ih_l0: 2.242458867840469e-05 0.14802105724811554
decider.lstm.weight_hh_l0: -0.0024976024869829416 0.14693593978881836
decider.lstm.bias_ih_l0: 0.02355717495083809 0.15423813462257385
decider.lstm.bias_hh_l0: 0.004569619428366423 0.1447027325630188
decider.linear1.weight: 0.0014442300889641047 0.12145281583070755
decider.linear1.bias: 0.016155382618308067 0.11649705469608307
decider.linear2.weight: 0.004986606538295746 0.056234993040561676
decider.linear2.bias: 0.00610852288082242 0.05800780653953552
decider.linear3.weight: -0.042504146695137024 0.09894727170467377
decider.linear3.bias: -0.03751983121037483 0.06535082310438156

Rewards:
190.8927
190.8927
190.8927
objective = 0.04842822998762131
==== episode 4000/10000 ====
action = 1
probs = 0.0007 0.9993 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002665966749191284 0.08472698926925659
encoder.encoder.weight_hh_l0: -0.0007145398412831128 0.08634767681360245
encoder.encoder.bias_ih_l0: 0.011191760189831257 0.08662275224924088
encoder.encoder.bias_hh_l0: 0.02118883840739727 0.0866759791970253
encoder.encoder.weight_ih_l0_reverse: 0.0018400723347440362 0.0867016613483429
encoder.encoder.weight_hh_l0_reverse: 0.002679886994883418 0.08466769754886627
encoder.encoder.bias_ih_l0_reverse: 0.02564282901585102 0.0861387550830841
encoder.encoder.bias_hh_l0_reverse: 0.01750829629600048 0.08416500687599182
decider.lstm.weight_ih_l0: 3.1863004551269114e-05 0.14803959429264069
decider.lstm.weight_hh_l0: -0.0025282115675508976 0.14695294201374054
decider.lstm.bias_ih_l0: 0.023662293329834938 0.15426242351531982
decider.lstm.bias_hh_l0: 0.004674735479056835 0.14470545947551727
decider.linear1.weight: 0.0014248723164200783 0.12148012965917587
decider.linear1.bias: 0.016243640333414078 0.11651089042425156
decider.linear2.weight: 0.005024295300245285 0.05625300854444504
decider.linear2.bias: 0.006156377959996462 0.05802798271179199
decider.linear3.weight: -0.04250701516866684 0.09896522015333176
decider.linear3.bias: -0.037522949278354645 0.06544223427772522

Rewards:
190.8927
190.8927
190.8927
objective = 0.04292871803045273
==== episode 4100/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000260714819887653 0.08473805338144302
encoder.encoder.weight_hh_l0: -0.0007213916396722198 0.08638150244951248
encoder.encoder.bias_ih_l0: 0.011298730969429016 0.08663343638181686
encoder.encoder.bias_hh_l0: 0.021295810118317604 0.08668723702430725
encoder.encoder.weight_ih_l0_reverse: 0.0018473693635314703 0.0867166668176651
encoder.encoder.weight_hh_l0_reverse: 0.0026968244928866625 0.08467958122491837
encoder.encoder.bias_ih_l0_reverse: 0.025752859190106392 0.08614469319581985
encoder.encoder.bias_hh_l0_reverse: 0.017618326470255852 0.08417162299156189
decider.lstm.weight_ih_l0: 4.109145811526105e-05 0.14805705845355988
decider.lstm.weight_hh_l0: -0.0025578755885362625 0.14696885645389557
decider.lstm.bias_ih_l0: 0.023760739713907242 0.1542857587337494
decider.lstm.bias_hh_l0: 0.004773194435983896 0.14470671117305756
decider.linear1.weight: 0.0014058351516723633 0.12150630354881287
decider.linear1.bias: 0.016327079385519028 0.11652408540248871
decider.linear2.weight: 0.005059983115643263 0.056270331144332886
decider.linear2.bias: 0.006201434880495071 0.05804680660367012
decider.linear3.weight: -0.042509421706199646 0.0989818125963211
decider.linear3.bias: -0.037525519728660583 0.06552676856517792

Rewards:
190.8927
190.8927
190.8927
objective = 0.03828352317214012
==== episode 4200/10000 ====
action = 1
probs = 0.0005 0.9995 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00025477164308540523 0.08474846929311752
encoder.encoder.weight_hh_l0: -0.0007279000128619373 0.08641413599252701
encoder.encoder.bias_ih_l0: 0.011401616968214512 0.08664312958717346
encoder.encoder.bias_hh_l0: 0.021398697048425674 0.08669740706682205
encoder.encoder.weight_ih_l0_reverse: 0.0018544304184615612 0.08673124760389328
encoder.encoder.weight_hh_l0_reverse: 0.002714127767831087 0.0846913680434227
encoder.encoder.bias_ih_l0_reverse: 0.02586129680275917 0.08614958077669144
encoder.encoder.bias_hh_l0_reverse: 0.01772676780819893 0.08417706936597824
decider.lstm.weight_ih_l0: 5.024306301493198e-05 0.1480737179517746
decider.lstm.weight_hh_l0: -0.0025870162062346935 0.14698392152786255
decider.lstm.bias_ih_l0: 0.02385430410504341 0.1543085277080536
decider.lstm.bias_hh_l0: 0.004866758827120066 0.14470669627189636
decider.linear1.weight: 0.0013868974056094885 0.12153170257806778
decider.linear1.bias: 0.016407042741775513 0.11653681099414825
decider.linear2.weight: 0.005094269290566444 0.05628720298409462
decider.linear2.bias: 0.006244446616619825 0.05806460976600647
decider.linear3.weight: -0.0425114780664444 0.09899739176034927
decider.linear3.bias: -0.037527699023485184 0.06560613960027695

Rewards:
190.8927
190.8927
190.8927
objective = 0.0342685841023922
==== episode 4300/10000 ====
action = 1
probs = 0.0005 0.9995 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00024876504903659225 0.08475834131240845
encoder.encoder.weight_hh_l0: -0.0007340859156101942 0.08644574135541916
encoder.encoder.bias_ih_l0: 0.011500921100378036 0.08665192127227783
encoder.encoder.bias_hh_l0: 0.021498002111911774 0.08670661598443985
encoder.encoder.weight_ih_l0_reverse: 0.0018612968269735575 0.08674547076225281
encoder.encoder.weight_hh_l0_reverse: 0.002731811022385955 0.08470312505960464
encoder.encoder.bias_ih_l0_reverse: 0.025968298316001892 0.0861535519361496
encoder.encoder.bias_hh_l0_reverse: 0.0178337674587965 0.08418148756027222
decider.lstm.weight_ih_l0: 5.935302033321932e-05 0.1480896770954132
decider.lstm.weight_hh_l0: -0.0026157302781939507 0.14699828624725342
decider.lstm.bias_ih_l0: 0.02394358441233635 0.1543307602405548
decider.lstm.bias_hh_l0: 0.004956034943461418 0.14470559358596802
decider.linear1.weight: 0.0013679716503247619 0.12155643850564957
decider.linear1.bias: 0.01648399978876114 0.11654914915561676
decider.linear2.weight: 0.005127375014126301 0.056303657591342926
decider.linear2.bias: 0.006285678595304489 0.05808144807815552
decider.linear3.weight: -0.04251326620578766 0.09901214390993118
decider.linear3.bias: -0.03752955049276352 0.06568093597888947

Rewards:
190.8927
190.8927
190.8927
objective = 0.030792711302638054
==== episode 4400/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00024273230519611388 0.08476778864860535
encoder.encoder.weight_hh_l0: -0.0007399885216727853 0.08647662401199341
encoder.encoder.bias_ih_l0: 0.01159730739891529 0.0866599902510643
encoder.encoder.bias_hh_l0: 0.021594390273094177 0.08671511709690094
encoder.encoder.weight_ih_l0_reverse: 0.001868175226263702 0.08675970882177353
encoder.encoder.weight_hh_l0_reverse: 0.0027498872950673103 0.08471526205539703
encoder.encoder.bias_ih_l0_reverse: 0.026073740795254707 0.08615700900554657
encoder.encoder.bias_hh_l0_reverse: 0.01793920435011387 0.084185890853405
decider.lstm.weight_ih_l0: 6.84428378008306e-05 0.14810505509376526
decider.lstm.weight_hh_l0: -0.0026440892834216356 0.1470121443271637
decider.lstm.bias_ih_l0: 0.024029158055782318 0.15435205399990082
decider.lstm.bias_hh_l0: 0.0050416006706655025 0.14470411837100983
decider.linear1.weight: 0.0013483341317623854 0.12158063799142838
decider.linear1.bias: 0.016559764742851257 0.11656127870082855
decider.linear2.weight: 0.0051600029692053795 0.056319709867239
decider.linear2.bias: 0.006325964815914631 0.058096744120121
decider.linear3.weight: -0.04251480847597122 0.0990261435508728
decider.linear3.bias: -0.037531133741140366 0.06575173139572144

Rewards:
190.8927
190.8927
190.8927
objective = 0.027779942378401756
==== episode 4500/10000 ====
action = 1
probs = 0.0016 0.9984 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029849662678316236 0.08462198078632355
encoder.encoder.weight_hh_l0: -0.0006857144180685282 0.08609458804130554
encoder.encoder.bias_ih_l0: 0.010396013036370277 0.0864737331867218
encoder.encoder.bias_hh_l0: 0.020393099635839462 0.08651125431060791
encoder.encoder.weight_ih_l0_reverse: 0.0018090560333803296 0.08659245818853378
encoder.encoder.weight_hh_l0_reverse: 0.002625388093292713 0.08457224816083908
encoder.encoder.bias_ih_l0_reverse: 0.025120796635746956 0.08597266674041748
encoder.encoder.bias_hh_l0_reverse: 0.016986260190606117 0.08400937169790268
decider.lstm.weight_ih_l0: -1.684892959019635e-05 0.14790846407413483
decider.lstm.weight_hh_l0: -0.002435410860925913 0.14682212471961975
decider.lstm.bias_ih_l0: 0.022965537384152412 0.1540963500738144
decider.lstm.bias_hh_l0: 0.003977986518293619 0.14459921419620514
decider.linear1.weight: 0.0014683408662676811 0.12131792306900024
decider.linear1.bias: 0.015614962205290794 0.11642022430896759
decider.linear2.weight: 0.004786712117493153 0.05615170672535896
decider.linear2.bias: 0.005805946886539459 0.05787072703242302
decider.linear3.weight: -0.042523328214883804 0.098871149122715
decider.linear3.bias: -0.037541043013334274 0.06461010873317719

Rewards:
190.8927
190.8927
190.8927
objective = 0.10175852477550507
==== episode 4600/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002946342574432492 0.0846511498093605
encoder.encoder.weight_hh_l0: -0.0006953404517844319 0.08615285158157349
encoder.encoder.bias_ih_l0: 0.010567963123321533 0.08651281893253326
encoder.encoder.bias_hh_l0: 0.020565049722790718 0.0865512415766716
encoder.encoder.weight_ih_l0_reverse: 0.0018173415446653962 0.08661758899688721
encoder.encoder.weight_hh_l0_reverse: 0.002634046133607626 0.08458948880434036
encoder.encoder.bias_ih_l0_reverse: 0.025218788534402847 0.0860048159956932
encoder.encoder.bias_hh_l0_reverse: 0.017084253951907158 0.08404028415679932
decider.lstm.weight_ih_l0: -6.730668246746063e-06 0.14794301986694336
decider.lstm.weight_hh_l0: -0.002460485091432929 0.1468539535999298
decider.lstm.bias_ih_l0: 0.023135073482990265 0.15412963926792145
decider.lstm.bias_hh_l0: 0.004147525876760483 0.1446341723203659
decider.linear1.weight: 0.0014608518686145544 0.12134981155395508
decider.linear1.bias: 0.015728548169136047 0.11643747985363007
decider.linear2.weight: 0.0048316465690732 0.05617770925164223
decider.linear2.bias: 0.005876576993614435 0.057907089591026306
decider.linear3.weight: -0.042536187916994095 0.09890783578157425
decider.linear3.bias: -0.03755611181259155 0.06480716913938522

Rewards:
190.8927
190.8927
190.8927
objective = 0.08460986614227295
==== episode 4700/10000 ====
action = 1
probs = 0.0011 0.9989 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029070573509670794 0.08467670530080795
encoder.encoder.weight_hh_l0: -0.0007039588526822627 0.08620531111955643
encoder.encoder.bias_ih_l0: 0.010722625069320202 0.08654684573411942
encoder.encoder.bias_hh_l0: 0.020719708874821663 0.08658621460199356
encoder.encoder.weight_ih_l0_reverse: 0.0018253388116136193 0.08664097636938095
encoder.encoder.weight_hh_l0_reverse: 0.002643271815031767 0.08460672944784164
encoder.encoder.bias_ih_l0_reverse: 0.02531394362449646 0.08603378385305405
encoder.encoder.bias_hh_l0_reverse: 0.01717940717935562 0.08406811207532883
decider.lstm.weight_ih_l0: 2.342071411476354e-06 0.14797356724739075
decider.lstm.weight_hh_l0: -0.00248361355625093 0.14688245952129364
decider.lstm.bias_ih_l0: 0.023285914212465286 0.15415902435779572
decider.lstm.bias_hh_l0: 0.004298363346606493 0.14466407895088196
decider.linear1.weight: 0.0014523286372423172 0.12137982994318008
decider.linear1.bias: 0.015837376937270164 0.11645384132862091
decider.linear2.weight: 0.004874640144407749 0.05620136111974716
decider.linear2.bias: 0.005942779593169689 0.057937800884246826
decider.linear3.weight: -0.04254615679383278 0.09893940389156342
decider.linear3.bias: -0.03756755590438843 0.06498076021671295

Rewards:
190.8927
190.8927
190.8927
objective = 0.071687713265419
==== episode 4800/10000 ====
action = 1
probs = 0.0027 0.9973 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031786097679287195 0.08455850183963776
encoder.encoder.weight_hh_l0: -0.000657266762573272 0.08593136072158813
encoder.encoder.bias_ih_l0: 0.00986962579190731 0.08637522906064987
encoder.encoder.bias_hh_l0: 0.0198667049407959 0.08640968799591064
encoder.encoder.weight_ih_l0_reverse: 0.0017824312672019005 0.0865253433585167
encoder.encoder.weight_hh_l0_reverse: 0.0025797346606850624 0.08451999723911285
encoder.encoder.bias_ih_l0_reverse: 0.02474077232182026 0.08589713275432587
encoder.encoder.bias_hh_l0_reverse: 0.016606228426098824 0.08393599092960358
decider.lstm.weight_ih_l0: -5.102286013425328e-05 0.14781615138053894
decider.lstm.weight_hh_l0: -0.0023522167466580868 0.14673477411270142
decider.lstm.bias_ih_l0: 0.022477012127637863 0.1539926826953888
decider.lstm.bias_hh_l0: 0.003489461727440357 0.14452090859413147
decider.linear1.weight: 0.001509533729404211 0.12121280282735825
decider.linear1.bias: 0.015210136771202087 0.1163640022277832
decider.linear2.weight: 0.004616971127688885 0.056098081171512604
decider.linear2.bias: 0.005564210005104542 0.057785097509622574
decider.linear3.weight: -0.042579665780067444 0.098869189620018
decider.linear3.bias: -0.037609945982694626 0.06408163905143738

Rewards:
190.8927
190.8927
190.8927
objective = 0.17182767391204834
==== episode 4900/10000 ====
action = 1
probs = 0.0021 0.9979 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003150017582811415 0.08460520207881927
encoder.encoder.weight_hh_l0: -0.0006712657050229609 0.08601562678813934
encoder.encoder.bias_ih_l0: 0.01011313870549202 0.0864398330450058
encoder.encoder.bias_hh_l0: 0.020110219717025757 0.08647137135267258
encoder.encoder.weight_ih_l0_reverse: 0.0017943247221410275 0.08656328171491623
encoder.encoder.weight_hh_l0_reverse: 0.002589987823739648 0.08454503864049911
encoder.encoder.bias_ih_l0_reverse: 0.024863505735993385 0.0859438106417656
encoder.encoder.bias_hh_l0_reverse: 0.01672896184027195 0.08398062735795975
decider.lstm.weight_ih_l0: -3.639895294327289e-05 0.14787203073501587
decider.lstm.weight_hh_l0: -0.002385774627327919 0.14678500592708588
decider.lstm.bias_ih_l0: 0.022734306752681732 0.1540393829345703
decider.lstm.bias_hh_l0: 0.003746751695871353 0.1445891410112381
decider.linear1.weight: 0.0015024661552160978 0.1212543398141861
decider.linear1.bias: 0.015359936282038689 0.11638554185628891
decider.linear2.weight: 0.0046790847554802895 0.056134480983018875
decider.linear2.bias: 0.00566432299092412 0.057833004742860794
decider.linear3.weight: -0.04261496663093567 0.09893963485956192
decider.linear3.bias: -0.037654291838407516 0.0643971860408783

Rewards:
190.8927
190.8927
190.8927
objective = 0.1336483657360077
==== episode 5000/10000 ====
action = 1
probs = 0.0020 0.9980 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003167145769111812 0.08459758758544922
encoder.encoder.weight_hh_l0: -0.0006678698118776083 0.0859975814819336
encoder.encoder.bias_ih_l0: 0.010056348517537117 0.08642815798521042
encoder.encoder.bias_hh_l0: 0.020053427666425705 0.08646020293235779
encoder.encoder.weight_ih_l0_reverse: 0.001791811897419393 0.08655567467212677
encoder.encoder.weight_hh_l0_reverse: 0.0025851500686258078 0.08453913778066635
encoder.encoder.bias_ih_l0_reverse: 0.024823984131217003 0.08593607693910599
encoder.encoder.bias_hh_l0_reverse: 0.016689445823431015 0.08397316932678223
decider.lstm.weight_ih_l0: -4.0459555748384446e-05 0.14786024391651154
decider.lstm.weight_hh_l0: -0.0023764946963638067 0.14677363634109497
decider.lstm.bias_ih_l0: 0.022677233442664146 0.1540265679359436
decider.lstm.bias_hh_l0: 0.0036896774545311928 0.1445786952972412
decider.linear1.weight: 0.001506512751802802 0.12124349176883698
decider.linear1.bias: 0.015320375561714172 0.11638044565916061
decider.linear2.weight: 0.004660643637180328 0.056133072823286057
decider.linear2.bias: 0.005639461800456047 0.0578230656683445
decider.linear3.weight: -0.04263949394226074 0.09896164387464523
decider.linear3.bias: -0.03768425062298775 0.06434710323810577

Rewards:
190.8927
190.8927
190.8927
objective = 0.13044843077659607
==== episode 5100/10000 ====
action = 1
probs = 0.0033 0.9967 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032986787846311927 0.08454820513725281
encoder.encoder.weight_hh_l0: -0.0006444883183576167 0.08587329834699631
encoder.encoder.bias_ih_l0: 0.00965084694325924 0.08635079115629196
encoder.encoder.bias_hh_l0: 0.01964792050421238 0.0863783210515976
encoder.encoder.weight_ih_l0_reverse: 0.0017717118607833982 0.0865079015493393
encoder.encoder.weight_hh_l0_reverse: 0.0025565035175532103 0.08450446277856827
encoder.encoder.bias_ih_l0_reverse: 0.024555997923016548 0.08587803691625595
encoder.encoder.bias_hh_l0_reverse: 0.01642145775258541 0.08391816169023514
decider.lstm.weight_ih_l0: -6.437329284381121e-05 0.1477891504764557
decider.lstm.weight_hh_l0: -0.0023146970197558403 0.14670604467391968
decider.lstm.bias_ih_l0: 0.022294985130429268 0.1539510190486908
decider.lstm.bias_hh_l0: 0.0033074249513447285 0.14451296627521515
decider.linear1.weight: 0.00153289083391428 0.12116603553295135
decider.linear1.bias: 0.015019161626696587 0.11633981019258499
decider.linear2.weight: 0.004536977969110012 0.05609328672289848
decider.linear2.bias: 0.00545766856521368 0.057752273976802826
decider.linear3.weight: -0.04271218180656433 0.0989973396062851
decider.linear3.bias: -0.03778059035539627 0.06395453214645386

Rewards:
190.8927
190.8927
190.8927
objective = 0.2101432979106903
==== episode 5200/10000 ====
action = 1
probs = 0.0025 0.9975 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003276343923062086 0.08460253477096558
encoder.encoder.weight_hh_l0: -0.0006603229558095336 0.08596715331077576
encoder.encoder.bias_ih_l0: 0.009920500218868256 0.0864250436425209
encoder.encoder.bias_hh_l0: 0.019917568191885948 0.08644763380289078
encoder.encoder.weight_ih_l0_reverse: 0.0017844835529103875 0.08655136078596115
encoder.encoder.weight_hh_l0_reverse: 0.002567903371527791 0.08453346788883209
encoder.encoder.bias_ih_l0_reverse: 0.024689095094799995 0.08592979609966278
encoder.encoder.bias_hh_l0_reverse: 0.016554560512304306 0.08396606147289276
decider.lstm.weight_ih_l0: -4.788063233718276e-05 0.14785544574260712
decider.lstm.weight_hh_l0: -0.0023522283881902695 0.1467660814523697
decider.lstm.bias_ih_l0: 0.022593937814235687 0.15400484204292297
decider.lstm.bias_hh_l0: 0.0036063813604414463 0.14459660649299622
decider.linear1.weight: 0.0015262456145137548 0.12121112644672394
decider.linear1.bias: 0.015178107656538486 0.11636137217283249
decider.linear2.weight: 0.0046060518361628056 0.05613372474908829
decider.linear2.bias: 0.005568110849708319 0.057805050164461136
decider.linear3.weight: -0.04276749864220619 0.09909490495920181
decider.linear3.bias: -0.037852268666028976 0.06432876735925674

Rewards:
190.8927
190.8927
190.8927
objective = 0.15902163088321686
==== episode 5300/10000 ====
action = 1
probs = 0.0020 0.9980 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003242825041525066 0.08464492112398148
encoder.encoder.weight_hh_l0: -0.0006735753850080073 0.0860443040728569
encoder.encoder.bias_ih_l0: 0.010145005770027637 0.08648277074098587
encoder.encoder.bias_hh_l0: 0.020142072811722755 0.08650358021259308
encoder.encoder.weight_ih_l0_reverse: 0.00179509655572474 0.08658632636070251
encoder.encoder.weight_hh_l0_reverse: 0.00257864105515182 0.08455770462751389
encoder.encoder.bias_ih_l0_reverse: 0.024808315560221672 0.085971400141716
encoder.encoder.bias_hh_l0_reverse: 0.016673779115080833 0.08400408178567886
decider.lstm.weight_ih_l0: -3.468096110736951e-05 0.14790752530097961
decider.lstm.weight_hh_l0: -0.002384138759225607 0.14681404829025269
decider.lstm.bias_ih_l0: 0.022834960371255875 0.15404921770095825
decider.lstm.bias_hh_l0: 0.003847404383122921 0.1446588784456253
decider.linear1.weight: 0.0015187504468485713 0.12125111371278763
decider.linear1.bias: 0.015319816768169403 0.11638110131025314
decider.linear2.weight: 0.004666291642934084 0.056167978793382645
decider.linear2.bias: 0.005662873387336731 0.05784933641552925
decider.linear3.weight: -0.04280421882867813 0.09916608780622482
decider.linear3.bias: -0.03789836913347244 0.06462650746107101

Rewards:
190.8927
190.8927
190.8927
objective = 0.1256527155637741
==== episode 5400/10000 ====
action = 1
probs = 0.0016 0.9984 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003203827072866261 0.0846794992685318
encoder.encoder.weight_hh_l0: -0.0006849992787465453 0.08611010760068893
encoder.encoder.bias_ih_l0: 0.010337861254811287 0.08652990311384201
encoder.encoder.bias_hh_l0: 0.02033492922782898 0.08655021339654922
encoder.encoder.weight_ih_l0_reverse: 0.0018042644951492548 0.08661583065986633
encoder.encoder.weight_hh_l0_reverse: 0.0025889475364238024 0.08457887172698975
encoder.encoder.bias_ih_l0_reverse: 0.024917615577578545 0.08600611239671707
encoder.encoder.bias_hh_l0_reverse: 0.016783079132437706 0.08403550088405609
decider.lstm.weight_ih_l0: -2.3563354261568747e-05 0.14795038104057312
decider.lstm.weight_hh_l0: -0.002412118948996067 0.1468539983034134
decider.lstm.bias_ih_l0: 0.023037193343043327 0.15408746898174286
decider.lstm.bias_hh_l0: 0.004049642011523247 0.14470748603343964
decider.linear1.weight: 0.001510741887614131 0.12128724902868271
decider.linear1.bias: 0.015448304824531078 0.1163991317152977
decider.linear2.weight: 0.004719945602118969 0.056197892874479294
decider.linear2.bias: 0.005746118258684874 0.05788780748844147
decider.linear3.weight: -0.042830295860767365 0.09922151267528534
decider.linear3.bias: -0.03793024644255638 0.06487391889095306

Rewards:
190.8927
190.8927
190.8927
objective = 0.10230183601379395
==== episode 5500/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000316193385515362 0.08470860868692398
encoder.encoder.weight_hh_l0: -0.0006950584356673062 0.08616767078638077
encoder.encoder.bias_ih_l0: 0.010507323779165745 0.08656962215900421
encoder.encoder.bias_hh_l0: 0.020504388958215714 0.08659002929925919
encoder.encoder.weight_ih_l0_reverse: 0.001812364673241973 0.08664153516292572
encoder.encoder.weight_hh_l0_reverse: 0.0025989303831011057 0.0845978632569313
encoder.encoder.bias_ih_l0_reverse: 0.025019288063049316 0.08603587746620178
encoder.encoder.bias_hh_l0_reverse: 0.01688474416732788 0.08406221866607666
decider.lstm.weight_ih_l0: -1.3864599168300629e-05 0.14798681437969208
decider.lstm.weight_hh_l0: -0.002437194809317589 0.14688833057880402
decider.lstm.bias_ih_l0: 0.02321171946823597 0.15412136912345886
decider.lstm.bias_hh_l0: 0.004224169999361038 0.14474673569202423
decider.linear1.weight: 0.0015024698805063963 0.12132042646408081
decider.linear1.bias: 0.015566217713057995 0.116415835916996
decider.linear2.weight: 0.00476834224537015 0.05622461065649986
decider.linear2.bias: 0.005820348858833313 0.05792222544550896
decider.linear3.weight: -0.04284970834851265 0.0992666557431221
decider.linear3.bias: -0.037953443825244904 0.06508581340312958

Rewards:
190.8927
190.8927
190.8927
objective = 0.08514159917831421
==== episode 5600/10000 ====
action = 1
probs = 0.0011 0.9989 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003118905005976558 0.08473346382379532
encoder.encoder.weight_hh_l0: -0.0007039717165753245 0.08621851354837418
encoder.encoder.bias_ih_l0: 0.01065743900835514 0.0866035521030426
encoder.encoder.bias_hh_l0: 0.020654506981372833 0.08662436902523041
encoder.encoder.weight_ih_l0_reverse: 0.0018195586744695902 0.08666422963142395
encoder.encoder.weight_hh_l0_reverse: 0.0026085569988936186 0.08461503684520721
encoder.encoder.bias_ih_l0_reverse: 0.025113943964242935 0.08606169372797012
encoder.encoder.bias_hh_l0_reverse: 0.0169793963432312 0.08408526331186295
decider.lstm.weight_ih_l0: -5.267523192742374e-06 0.1480182558298111
decider.lstm.weight_hh_l0: -0.002459823852404952 0.1469181627035141
decider.lstm.bias_ih_l0: 0.023364044725894928 0.1541517823934555
decider.lstm.bias_hh_l0: 0.004376497119665146 0.14477890729904175
decider.linear1.weight: 0.001494100783020258 0.12135092169046402
decider.linear1.bias: 0.015674607828259468 0.11643113940954208
decider.linear2.weight: 0.004812284372746944 0.05624862760305405
decider.linear2.bias: 0.005887000821530819 0.05795310065150261
decider.linear3.weight: -0.04286456108093262 0.09930430352687836
decider.linear3.bias: -0.037970807403326035 0.0652696043252945

Rewards:
190.8927
190.8927
190.8927
objective = 0.07218135893344879
==== episode 5700/10000 ====
action = 1
probs = 0.0010 0.9990 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003074929118156433 0.08475542068481445
encoder.encoder.weight_hh_l0: -0.0007120534428395331 0.08626461774110794
encoder.encoder.bias_ih_l0: 0.010794058442115784 0.08663347363471985
encoder.encoder.bias_hh_l0: 0.020791130140423775 0.08665493875741959
encoder.encoder.weight_ih_l0_reverse: 0.0018260458018630743 0.08668495714664459
encoder.encoder.weight_hh_l0_reverse: 0.002617971273139119 0.08463098108768463
encoder.encoder.bias_ih_l0_reverse: 0.02520395629107952 0.08608484268188477
encoder.encoder.bias_hh_l0_reverse: 0.017069406807422638 0.08410578221082687
decider.lstm.weight_ih_l0: 2.588238430689671e-06 0.14804619550704956
decider.lstm.weight_hh_l0: -0.0024807320442050695 0.1469448208808899
decider.lstm.bias_ih_l0: 0.023500626906752586 0.15417970716953278
decider.lstm.bias_hh_l0: 0.004513082094490528 0.14480607211589813
decider.linear1.weight: 0.001485570683144033 0.12137957662343979
decider.linear1.bias: 0.015776613727211952 0.11644461005926132
decider.linear2.weight: 0.004853169433772564 0.056270256638526917
decider.linear2.bias: 0.005948236212134361 0.05798143520951271
decider.linear3.weight: -0.042876359075307846 0.09933686256408691
decider.linear3.bias: -0.037984367460012436 0.06543351709842682

Rewards:
190.8927
190.8927
190.8927
objective = 0.06199497729539871
==== episode 5800/10000 ====
action = 1
probs = 0.0054 0.9946 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034940673504024744 0.0844888761639595
encoder.encoder.weight_hh_l0: -0.0006101399776525795 0.0857079029083252
encoder.encoder.bias_ih_l0: 0.009091969579458237 0.08624488115310669
encoder.encoder.bias_hh_l0: 0.019089041277766228 0.08626905828714371
encoder.encoder.weight_ih_l0_reverse: 0.0017485737334936857 0.08644846826791763
encoder.encoder.weight_hh_l0_reverse: 0.0025085597299039364 0.08445784449577332
encoder.encoder.bias_ih_l0_reverse: 0.0241566002368927 0.08581740409135818
encoder.encoder.bias_hh_l0_reverse: 0.016022050753235817 0.08386798202991486
decider.lstm.weight_ih_l0: -0.00010153017501579598 0.14767798781394958
decider.lstm.weight_hh_l0: -0.002228003228083253 0.14659850299358368
decider.lstm.bias_ih_l0: 0.02173449844121933 0.15383635461330414
decider.lstm.bias_hh_l0: 0.0027469452470541 0.14441229403018951
decider.linear1.weight: 0.0015708886785432696 0.12106440961360931
decider.linear1.bias: 0.01463512983173132 0.11629395186901093
decider.linear2.weight: 0.004363590851426125 0.056068070232868195
decider.linear2.bias: 0.005216943100094795 0.057658735662698746
decider.linear3.weight: -0.04293756186962128 0.09920237213373184
decider.linear3.bias: -0.038065355271101 0.0634731575846672

Rewards:
190.8927
190.8927
190.8927
objective = 0.35073134303092957
==== episode 5900/10000 ====
action = 1
probs = 0.0039 0.9961 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003520472382660955 0.08457150310277939
encoder.encoder.weight_hh_l0: -0.0006301483954302967 0.08583124727010727
encoder.encoder.bias_ih_l0: 0.009424439631402493 0.08635735511779785
encoder.encoder.bias_hh_l0: 0.019421512261033058 0.08636397123336792
encoder.encoder.weight_ih_l0_reverse: 0.0017645322950556874 0.08651312440633774
encoder.encoder.weight_hh_l0_reverse: 0.002521469723433256 0.08450181037187576
encoder.encoder.bias_ih_l0_reverse: 0.02430611476302147 0.08588723838329315
encoder.encoder.bias_hh_l0_reverse: 0.016171565279364586 0.08393482863903046
decider.lstm.weight_ih_l0: -7.859295146772638e-05 0.14778275787830353
decider.lstm.weight_hh_l0: -0.0022750869393348694 0.1466941386461258
decider.lstm.bias_ih_l0: 0.0221701767295599 0.1539132446050644
decider.lstm.bias_hh_l0: 0.00318261981010437 0.1445508599281311
decider.linear1.weight: 0.001569327898323536 0.12111249566078186
decider.linear1.bias: 0.014783136546611786 0.11630964279174805
decider.linear2.weight: 0.0044401539489626884 0.056120365858078
decider.linear2.bias: 0.005338687915354967 0.05772562697529793
decider.linear3.weight: -0.043110594153404236 0.09944970160722733
decider.linear3.bias: -0.038306694477796555 0.0640544667840004

Rewards:
190.8927
190.8927
190.8927
objective = 0.24894946813583374
==== episode 6000/10000 ====
action = 1
probs = 0.0029 0.9971 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035062181996181607 0.08463497459888458
encoder.encoder.weight_hh_l0: -0.0006482008029706776 0.08593545109033585
encoder.encoder.bias_ih_l0: 0.00972040556371212 0.08644323796033859
encoder.encoder.bias_hh_l0: 0.019717475399374962 0.0864436998963356
encoder.encoder.weight_ih_l0_reverse: 0.0017777996836230159 0.08656341582536697
encoder.encoder.weight_hh_l0_reverse: 0.0025339308194816113 0.08453671634197235
encoder.encoder.bias_ih_l0_reverse: 0.024449896067380905 0.08594343066215515
encoder.encoder.bias_hh_l0_reverse: 0.01631534844636917 0.08398614078760147
decider.lstm.weight_ih_l0: -6.072785618016496e-05 0.14786303043365479
decider.lstm.weight_hh_l0: -0.002316354541108012 0.14676859974861145
decider.lstm.bias_ih_l0: 0.02252131700515747 0.1539747714996338
decider.lstm.bias_hh_l0: 0.0035337619483470917 0.14465254545211792
decider.linear1.weight: 0.0015637578908354044 0.12116026878356934
decider.linear1.bias: 0.01494141947478056 0.11632797122001648
decider.linear2.weight: 0.004515211563557386 0.05616508424282074
decider.linear2.bias: 0.005456586368381977 0.05778251960873604
decider.linear3.weight: -0.04321005940437317 0.09960564970970154
decider.linear3.bias: -0.03844024986028671 0.0645064041018486

Rewards:
190.8927
190.8927
190.8927
objective = 0.18346542119979858
==== episode 6100/10000 ====
action = 1
probs = 0.0022 0.9978 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034758527181111276 0.08468209952116013
encoder.encoder.weight_hh_l0: -0.0006630549905821681 0.0860181525349617
encoder.encoder.bias_ih_l0: 0.009960072115063667 0.08650708198547363
encoder.encoder.bias_hh_l0: 0.01995714381337166 0.08650603145360947
encoder.encoder.weight_ih_l0_reverse: 0.001788318157196045 0.08660143613815308
encoder.encoder.weight_hh_l0_reverse: 0.002544939983636141 0.08456378430128098
encoder.encoder.bias_ih_l0_reverse: 0.02457437850534916 0.08598648011684418
encoder.encoder.bias_hh_l0_reverse: 0.016439829021692276 0.08402436226606369
decider.lstm.weight_ih_l0: -4.710498978965916e-05 0.14792300760746002
decider.lstm.weight_hh_l0: -0.0023500171955674887 0.1468248963356018
decider.lstm.bias_ih_l0: 0.02279193513095379 0.15402303636074066
decider.lstm.bias_hh_l0: 0.003804377745836973 0.14472505450248718
decider.linear1.weight: 0.0015570999821648002 0.12120212614536285
decider.linear1.bias: 0.015083018690347672 0.11634561419487
decider.linear2.weight: 0.004579625092446804 0.05620157718658447
decider.linear2.bias: 0.005556426011025906 0.057829100638628006
decider.linear3.weight: -0.04327237606048584 0.09971101582050323
decider.linear3.bias: -0.03852112963795662 0.06484925001859665

Rewards:
190.8927
190.8927
190.8927
objective = 0.14285412430763245
==== episode 6200/10000 ====
action = 1
probs = 0.0018 0.9982 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003437662380747497 0.08471952378749847
encoder.encoder.weight_hh_l0: -0.0006758442032150924 0.08608762919902802
encoder.encoder.bias_ih_l0: 0.01016366295516491 0.08655812591314316
encoder.encoder.bias_hh_l0: 0.0201607346534729 0.08655723929405212
encoder.encoder.weight_ih_l0_reverse: 0.0017972271889448166 0.08663243800401688
encoder.encoder.weight_hh_l0_reverse: 0.0025552259758114815 0.08458641171455383
encoder.encoder.bias_ih_l0_reverse: 0.024687189608812332 0.08602151274681091
encoder.encoder.bias_hh_l0_reverse: 0.016552641987800598 0.08405477553606033
decider.lstm.weight_ih_l0: -3.585740705602802e-05 0.14797119796276093
decider.lstm.weight_hh_l0: -0.0023790255654603243 0.14687058329582214
decider.lstm.bias_ih_l0: 0.023014340549707413 0.15406371653079987
decider.lstm.bias_hh_l0: 0.004026790149509907 0.14478056132793427
decider.linear1.weight: 0.001549666514620185 0.12123993039131165
decider.linear1.bias: 0.015212769620120525 0.11636200547218323
decider.linear2.weight: 0.004636705387383699 0.05623229220509529
decider.linear2.bias: 0.005643878132104874 0.05786938965320587
decider.linear3.weight: -0.04331531375646591 0.09978918731212616
decider.linear3.bias: -0.038575299084186554 0.06512767821550369

Rewards:
190.8927
190.8927
190.8927
objective = 0.11512380093336105
==== episode 6300/10000 ====
action = 1
probs = 0.0015 0.9985 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033953061210922897 0.08475035429000854
encoder.encoder.weight_hh_l0: -0.0006871132645756006 0.08614777773618698
encoder.encoder.bias_ih_l0: 0.010341164655983448 0.08660050481557846
encoder.encoder.bias_hh_l0: 0.020338239148259163 0.08660046011209488
encoder.encoder.weight_ih_l0_reverse: 0.0018050034996122122 0.08665876090526581
encoder.encoder.weight_hh_l0_reverse: 0.0025650530587881804 0.08460608869791031
encoder.encoder.bias_ih_l0_reverse: 0.024791516363620758 0.08605100214481354
encoder.encoder.bias_hh_l0_reverse: 0.016656968742609024 0.08407992124557495
decider.lstm.weight_ih_l0: -2.6159099434153177e-05 0.1480114907026291
decider.lstm.weight_hh_l0: -0.0024047375191003084 0.14690908789634705
decider.lstm.bias_ih_l0: 0.0232035331428051 0.15409928560256958
decider.lstm.bias_hh_l0: 0.00421598507091403 0.14482475817203522
decider.linear1.weight: 0.0015418132534250617 0.12127457559108734
decider.linear1.bias: 0.015332682989537716 0.11637741327285767
decider.linear2.weight: 0.004688372369855642 0.05625792220234871
decider.linear2.bias: 0.0057219211012125015 0.05790526792407036
decider.linear3.weight: -0.043346576392650604 0.09985045343637466
decider.linear3.bias: -0.03861377760767937 0.06536230444908142

Rewards:
190.8927
190.8927
190.8927
objective = 0.09509620070457458
==== episode 6400/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033506451291032135 0.08477645367383957
encoder.encoder.weight_hh_l0: -0.0006972119444981217 0.08620096743106842
encoder.encoder.bias_ih_l0: 0.01049895491451025 0.08663663268089294
encoder.encoder.bias_hh_l0: 0.020496023818850517 0.08663768321275711
encoder.encoder.weight_ih_l0_reverse: 0.001811922644264996 0.0866817906498909
encoder.encoder.weight_hh_l0_reverse: 0.002574558136984706 0.08462364971637726
encoder.encoder.bias_ih_l0_reverse: 0.024889282882213593 0.08607646077871323
encoder.encoder.bias_hh_l0_reverse: 0.01675473153591156 0.08410125970840454
decider.lstm.weight_ih_l0: -1.7537326129968278e-05 0.14804613590240479
decider.lstm.weight_hh_l0: -0.0024279863573610783 0.1469424068927765
decider.lstm.bias_ih_l0: 0.0233684703707695 0.1541311889886856
decider.lstm.bias_hh_l0: 0.004380922764539719 0.14486093819141388
decider.linear1.weight: 0.0015337252989411354 0.12130676209926605
decider.linear1.bias: 0.015444271266460419 0.11639165133237839
decider.linear2.weight: 0.004735514987260103 0.05628122761845589
decider.linear2.bias: 0.005792473442852497 0.057937707751989365
decider.linear3.weight: -0.04337026923894882 0.09990040212869644
decider.linear3.bias: -0.03864229843020439 0.06556527316570282

Rewards:
190.8927
190.8927
190.8927
objective = 0.08002258092164993
==== episode 6500/10000 ====
action = 1
probs = 0.0011 0.9989 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033045909367501736 0.0847991406917572
encoder.encoder.weight_hh_l0: -0.0007063735974952579 0.08624882996082306
encoder.encoder.bias_ih_l0: 0.010641736909747124 0.08666811883449554
encoder.encoder.bias_hh_l0: 0.020638806745409966 0.08667049556970596
encoder.encoder.weight_ih_l0_reverse: 0.0018180955667048693 0.08670251071453094
encoder.encoder.weight_hh_l0_reverse: 0.002583806635811925 0.08463961631059647
encoder.encoder.bias_ih_l0_reverse: 0.02498193271458149 0.08609900623559952
encoder.encoder.bias_hh_l0_reverse: 0.016847383230924606 0.08411982655525208
decider.lstm.weight_ih_l0: -9.697079804027453e-06 0.14807657897472382
decider.lstm.weight_hh_l0: -0.002449329011142254 0.14697180688381195
decider.lstm.bias_ih_l0: 0.02351493202149868 0.1541602462530136
decider.lstm.bias_hh_l0: 0.004527383018285036 0.1448911726474762
decider.linear1.weight: 0.0015254284953698516 0.12133694440126419
decider.linear1.bias: 0.015549452975392342 0.11640423536300659
decider.linear2.weight: 0.004779031500220299 0.05630268529057503
decider.linear2.bias: 0.005856997333467007 0.05796745792031288
decider.linear3.weight: -0.04338877648115158 0.09994237869977951
decider.linear3.bias: -0.038664139807224274 0.0657443255186081

Rewards:
190.8927
190.8927
190.8927
objective = 0.06831624358892441
==== episode 6600/10000 ====
action = 1
probs = 0.0009 0.9991 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032582401763647795 0.08481892198324203
encoder.encoder.weight_hh_l0: -0.000714686291757971 0.08629202097654343
encoder.encoder.bias_ih_l0: 0.010771041736006737 0.08669565618038177
encoder.encoder.bias_hh_l0: 0.02076810970902443 0.08669938892126083
encoder.encoder.weight_ih_l0_reverse: 0.0018236407777294517 0.08672120422124863
encoder.encoder.weight_hh_l0_reverse: 0.0025927915703505278 0.08465421944856644
encoder.encoder.bias_ih_l0_reverse: 0.025069460272789 0.08611900359392166
encoder.encoder.bias_hh_l0_reverse: 0.01693490892648697 0.08413602411746979
decider.lstm.weight_ih_l0: -2.509597607058822e-06 0.1481035053730011
decider.lstm.weight_hh_l0: -0.002468958031386137 0.14699794352054596
decider.lstm.bias_ih_l0: 0.023645620793104172 0.15418684482574463
decider.lstm.bias_hh_l0: 0.004658072255551815 0.14491665363311768
decider.linear1.weight: 0.0015170912956818938 0.12136518210172653
decider.linear1.bias: 0.015648003667593002 0.11641579866409302
decider.linear2.weight: 0.004819207824766636 0.056322455406188965
decider.linear2.bias: 0.005916003603488207 0.057994771748781204
decider.linear3.weight: -0.04340345039963722 0.09997817128896713
decider.linear3.bias: -0.03868115320801735 0.06590322405099869

Rewards:
190.8927
190.8927
190.8927
objective = 0.05909086391329765
==== episode 6700/10000 ====
action = 1
probs = 0.0008 0.9992 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032124825520440936 0.08483656495809555
encoder.encoder.weight_hh_l0: -0.0007223559077829123 0.08633190393447876
encoder.encoder.bias_ih_l0: 0.01089033018797636 0.08672033250331879
encoder.encoder.bias_hh_l0: 0.020887399092316628 0.08672528713941574
encoder.encoder.weight_ih_l0_reverse: 0.0018287226557731628 0.0867384746670723
encoder.encoder.weight_hh_l0_reverse: 0.0026016654446721077 0.08466795831918716
encoder.encoder.bias_ih_l0_reverse: 0.025153690949082375 0.08613703399896622
encoder.encoder.bias_hh_l0_reverse: 0.01701914332807064 0.08415050804615021
decider.lstm.weight_ih_l0: 4.23684696215787e-06 0.14812789857387543
decider.lstm.weight_hh_l0: -0.0024873940274119377 0.14702168107032776
decider.lstm.bias_ih_l0: 0.023765046149492264 0.15421149134635925
decider.lstm.bias_hh_l0: 0.004777487833052874 0.1449386030435562
decider.linear1.weight: 0.0015086138155311346 0.12139201909303665
decider.linear1.bias: 0.015742287039756775 0.11642739921808243
decider.linear2.weight: 0.004856999963521957 0.05634099617600441
decider.linear2.bias: 0.0059709749184548855 0.058020345866680145
decider.linear3.weight: -0.04341544210910797 0.10000959038734436
decider.linear3.bias: -0.0386948361992836 0.06604747474193573

Rewards:
190.8927
190.8927
190.8927
objective = 0.051590051501989365
==== episode 6800/10000 ====
action = 1
probs = 0.0007 0.9993 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003166457172483206 0.08485202491283417
encoder.encoder.weight_hh_l0: -0.0007294417591765523 0.08636849373579025
encoder.encoder.bias_ih_l0: 0.010998089797794819 0.08674101531505585
encoder.encoder.bias_hh_l0: 0.020995164290070534 0.08674894273281097
encoder.encoder.weight_ih_l0_reverse: 0.0018321025418117642 0.08675264567136765
encoder.encoder.weight_hh_l0_reverse: 0.0026096643414348364 0.08467917144298553
encoder.encoder.bias_ih_l0_reverse: 0.025229500606656075 0.08615320175886154
encoder.encoder.bias_hh_l0_reverse: 0.01709495298564434 0.08416260778903961
decider.lstm.weight_ih_l0: 1.0648145689629018e-05 0.14815007150173187
decider.lstm.weight_hh_l0: -0.0025047066155821085 0.14704325795173645
decider.lstm.bias_ih_l0: 0.02387407422065735 0.1542351394891739
decider.lstm.bias_hh_l0: 0.0048865205608308315 0.14495716989040375
decider.linear1.weight: 0.001498886151239276 0.12141797691583633
decider.linear1.bias: 0.015837086364626884 0.11643396317958832
decider.linear2.weight: 0.004892813973128796 0.05635853856801987
decider.linear2.bias: 0.006022492423653603 0.0580444298684597
decider.linear3.weight: -0.04342539608478546 0.1000375896692276
decider.linear3.bias: -0.03870600834488869 0.06617964059114456

Rewards:
190.8927
190.8927
190.8927
objective = 0.045297011733055115
==== episode 6900/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003120367764495313 0.08486584573984146
encoder.encoder.weight_hh_l0: -0.0007360324962064624 0.08640249073505402
encoder.encoder.bias_ih_l0: 0.011097092181444168 0.08675909042358398
encoder.encoder.bias_hh_l0: 0.021094167605042458 0.08677054196596146
encoder.encoder.weight_ih_l0_reverse: 0.0018346214201301336 0.08676497638225555
encoder.encoder.weight_hh_l0_reverse: 0.0026173472870141268 0.08468900620937347
encoder.encoder.bias_ih_l0_reverse: 0.025300638750195503 0.08616786450147629
encoder.encoder.bias_hh_l0_reverse: 0.01716609112918377 0.08417309820652008
decider.lstm.weight_ih_l0: 1.673489714448806e-05 0.14817044138908386
decider.lstm.weight_hh_l0: -0.0025210885796695948 0.14706310629844666
decider.lstm.bias_ih_l0: 0.023974616080522537 0.15425777435302734
decider.lstm.bias_hh_l0: 0.004987065680325031 0.14497309923171997
decider.linear1.weight: 0.0014885093551129103 0.12144310027360916
decider.linear1.bias: 0.01593027263879776 0.11643780767917633
decider.linear2.weight: 0.004926920868456364 0.056375421583652496
decider.linear2.bias: 0.006070930510759354 0.0580671951174736
decider.linear3.weight: -0.04343370720744133 0.1000627726316452
decider.linear3.bias: -0.038715213537216187 0.06630144268274307

Rewards:
190.8927
190.8927
190.8927
objective = 0.03999510034918785
==== episode 7000/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030741008231416345 0.08487852662801743
encoder.encoder.weight_hh_l0: -0.0007422214839607477 0.08643455803394318
encoder.encoder.bias_ih_l0: 0.011190354824066162 0.08677564561367035
encoder.encoder.bias_hh_l0: 0.021187428385019302 0.08679015934467316
encoder.encoder.weight_ih_l0_reverse: 0.0018371447222307324 0.08677683025598526
encoder.encoder.weight_hh_l0_reverse: 0.0026252230163663626 0.0846986174583435
encoder.encoder.bias_ih_l0_reverse: 0.025370797142386436 0.0861814022064209
encoder.encoder.bias_hh_l0_reverse: 0.017236253246665 0.08418284356594086
decider.lstm.weight_ih_l0: 2.2534131858265027e-05 0.14818941056728363
decider.lstm.weight_hh_l0: -0.0025367396883666515 0.1470816284418106
decider.lstm.bias_ih_l0: 0.024068474769592285 0.15427915751934052
decider.lstm.bias_hh_l0: 0.005080929957330227 0.1449872851371765
decider.linear1.weight: 0.0014779990306124091 0.1214674860239029
decider.linear1.bias: 0.016021333634853363 0.11644188314676285
decider.linear2.weight: 0.004960385151207447 0.05639123171567917
decider.linear2.bias: 0.006117644719779491 0.05808897688984871
decider.linear3.weight: -0.04344073683023453 0.10008567571640015
decider.linear3.bias: -0.038722872734069824 0.06641446053981781

Rewards:
190.8927
190.8927
190.8927
objective = 0.03555882349610329
==== episode 7100/10000 ====
action = 1
probs = 0.0005 0.9995 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003027962811756879 0.08489009737968445
encoder.encoder.weight_hh_l0: -0.0007480143685825169 0.08646465092897415
encoder.encoder.bias_ih_l0: 0.011277850717306137 0.08679061383008957
encoder.encoder.bias_hh_l0: 0.021274928003549576 0.08680777251720428
encoder.encoder.weight_ih_l0_reverse: 0.0018396922387182713 0.08678819239139557
encoder.encoder.weight_hh_l0_reverse: 0.0026332016568630934 0.08470796048641205
encoder.encoder.bias_ih_l0_reverse: 0.025439493358135223 0.08619385212659836
encoder.encoder.bias_hh_l0_reverse: 0.01730494759976864 0.08419202268123627
decider.lstm.weight_ih_l0: 2.805063377309125e-05 0.14820702373981476
decider.lstm.weight_hh_l0: -0.0025516264140605927 0.14709888398647308
decider.lstm.bias_ih_l0: 0.02415587566792965 0.15429922938346863
decider.lstm.bias_hh_l0: 0.005168324336409569 0.14500007033348083
decider.linear1.weight: 0.001467243768274784 0.12149129062891006
decider.linear1.bias: 0.01611163094639778 0.11644677072763443
decider.linear2.weight: 0.0049933623522520065 0.05640606954693794
decider.linear2.bias: 0.0061627947725355625 0.05810995399951935
decider.linear3.weight: -0.04344666004180908 0.10010647028684616
decider.linear3.bias: -0.03872925043106079 0.06651902943849564

Rewards:
190.8927
190.8927
190.8927
objective = 0.03181726112961769
==== episode 7200/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029819062910974026 0.0849008783698082
encoder.encoder.weight_hh_l0: -0.0007535106269642711 0.0864933431148529
encoder.encoder.bias_ih_l0: 0.011361203156411648 0.08680460602045059
encoder.encoder.bias_hh_l0: 0.021358279511332512 0.08682406693696976
encoder.encoder.weight_ih_l0_reverse: 0.0018421513959765434 0.08679916709661484
encoder.encoder.weight_hh_l0_reverse: 0.002641257829964161 0.08471705764532089
encoder.encoder.bias_ih_l0_reverse: 0.02550707757472992 0.08620551228523254
encoder.encoder.bias_hh_l0_reverse: 0.017372531816363335 0.08420050889253616
decider.lstm.weight_ih_l0: 3.3379383239662275e-05 0.1482236087322235
decider.lstm.weight_hh_l0: -0.002565977396443486 0.14711514115333557
decider.lstm.bias_ih_l0: 0.02423841506242752 0.15431857109069824
decider.lstm.bias_hh_l0: 0.005250872112810612 0.14501143991947174
decider.linear1.weight: 0.001456590136513114 0.12151435017585754
decider.linear1.bias: 0.01619833894073963 0.11645157635211945
decider.linear2.weight: 0.005025163292884827 0.056420501321554184
decider.linear2.bias: 0.006205743178725243 0.05813007056713104
decider.linear3.weight: -0.04345175623893738 0.10012570768594742
decider.linear3.bias: -0.03873465582728386 0.06661737710237503

Rewards:
190.8927
190.8927
190.8927
objective = 0.028603333979845047
==== episode 7300/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029360255575738847 0.08491097390651703
encoder.encoder.weight_hh_l0: -0.0007587084546685219 0.08652067929506302
encoder.encoder.bias_ih_l0: 0.011440870352089405 0.08681749552488327
encoder.encoder.bias_hh_l0: 0.021437950432300568 0.08683940023183823
encoder.encoder.weight_ih_l0_reverse: 0.0018446004251018167 0.08680994063615799
encoder.encoder.weight_hh_l0_reverse: 0.002649453468620777 0.08472608774900436
encoder.encoder.bias_ih_l0_reverse: 0.025574177503585815 0.0862165242433548
encoder.encoder.bias_hh_l0_reverse: 0.017439624294638634 0.08420871943235397
decider.lstm.weight_ih_l0: 3.853039743262343e-05 0.14823925495147705
decider.lstm.weight_hh_l0: -0.0025798387359827757 0.14713050425052643
decider.lstm.bias_ih_l0: 0.024316594004631042 0.15433703362941742
decider.lstm.bias_hh_l0: 0.0053290375508368015 0.14502157270908356
decider.linear1.weight: 0.0014457844663411379 0.12153729796409607
decider.linear1.bias: 0.0162828229367733 0.11645929515361786
decider.linear2.weight: 0.005056608468294144 0.05643449351191521
decider.linear2.bias: 0.006247646640986204 0.058150142431259155
decider.linear3.weight: -0.04345618188381195 0.10014364868402481
decider.linear3.bias: -0.03873930871486664 0.06671032309532166

Rewards:
190.8927
190.8927
190.8927
objective = 0.02582969330251217
==== episode 7400/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00028901780024170876 0.0849204957485199
encoder.encoder.weight_hh_l0: -0.000763661926612258 0.08654692769050598
encoder.encoder.bias_ih_l0: 0.011517358012497425 0.0868295282125473
encoder.encoder.bias_hh_l0: 0.02151443436741829 0.0868537649512291
encoder.encoder.weight_ih_l0_reverse: 0.0018469744827598333 0.08682045340538025
encoder.encoder.weight_hh_l0_reverse: 0.0026577285025268793 0.08473493903875351
encoder.encoder.bias_ih_l0_reverse: 0.025640448555350304 0.0862269401550293
encoder.encoder.bias_hh_l0_reverse: 0.01750589907169342 0.08421647548675537
decider.lstm.weight_ih_l0: 4.3550709960982203e-05 0.14825409650802612
decider.lstm.weight_hh_l0: -0.0025932928547263145 0.1471451073884964
decider.lstm.bias_ih_l0: 0.024391043931245804 0.15435490012168884
decider.lstm.bias_hh_l0: 0.005403493996709585 0.1450306475162506
decider.linear1.weight: 0.0014349592383950949 0.12155983597040176
decider.linear1.bias: 0.01636490225791931 0.11646758764982224
decider.linear2.weight: 0.005087378900498152 0.05644814670085907
decider.linear2.bias: 0.006288120523095131 0.058169685304164886
decider.linear3.weight: -0.04346003383398056 0.10016041994094849
decider.linear3.bias: -0.03874329477548599 0.06679853796958923

Rewards:
190.8927
190.8927
190.8927
objective = 0.02340902015566826
==== episode 7500/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002844335394911468 0.08492948859930038
encoder.encoder.weight_hh_l0: -0.000768401543609798 0.08657221496105194
encoder.encoder.bias_ih_l0: 0.011591014452278614 0.08684083819389343
encoder.encoder.bias_hh_l0: 0.021588090807199478 0.08686718344688416
encoder.encoder.weight_ih_l0_reverse: 0.0018492587842047215 0.08683070540428162
encoder.encoder.weight_hh_l0_reverse: 0.002666056388989091 0.08474362641572952
encoder.encoder.bias_ih_l0_reverse: 0.025705823674798012 0.08623682707548141
encoder.encoder.bias_hh_l0_reverse: 0.01757127419114113 0.08422374725341797
decider.lstm.weight_ih_l0: 4.8466135922353715e-05 0.14826828241348267
decider.lstm.weight_hh_l0: -0.002606390044093132 0.14715903997421265
decider.lstm.bias_ih_l0: 0.024462219327688217 0.15437225997447968
decider.lstm.bias_hh_l0: 0.005474667064845562 0.14503881335258484
decider.linear1.weight: 0.0014241673052310944 0.12158187478780746
decider.linear1.bias: 0.016444653272628784 0.11647570878267288
decider.linear2.weight: 0.005117376334965229 0.056461531668901443
decider.linear2.bias: 0.0063270945101976395 0.05818859115242958
decider.linear3.weight: -0.043463416397571564 0.10017625987529755
decider.linear3.bias: -0.03874676674604416 0.06688255816698074

Rewards:
190.8927
190.8927
190.8927
objective = 0.021269191056489944
==== episode 7600/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002798937202896923 0.0849379450082779
encoder.encoder.weight_hh_l0: -0.0007729021017439663 0.08659641444683075
encoder.encoder.bias_ih_l0: 0.011661453172564507 0.08685138076543808
encoder.encoder.bias_hh_l0: 0.021658530458807945 0.08687964826822281
encoder.encoder.weight_ih_l0_reverse: 0.001851433771662414 0.08684060722589493
encoder.encoder.weight_hh_l0_reverse: 0.0026743507478386164 0.08475206792354584
encoder.encoder.bias_ih_l0_reverse: 0.025769729167222977 0.08624614775180817
encoder.encoder.bias_hh_l0_reverse: 0.017635177820920944 0.08423049747943878
decider.lstm.weight_ih_l0: 5.3243562433635816e-05 0.1482817381620407
decider.lstm.weight_hh_l0: -0.0026190467178821564 0.147172212600708
decider.lstm.bias_ih_l0: 0.02452978491783142 0.15438905358314514
decider.lstm.bias_hh_l0: 0.005542222410440445 0.14504607021808624
decider.linear1.weight: 0.0014135086676105857 0.12160325795412064
decider.linear1.bias: 0.016521519050002098 0.11648356914520264
decider.linear2.weight: 0.005146400071680546 0.05647454038262367
decider.linear2.bias: 0.0063643488101661205 0.05820673331618309
decider.linear3.weight: -0.04346635937690735 0.10019107162952423
decider.linear3.bias: -0.038749754428863525 0.06696204841136932

Rewards:
190.8927
190.8927
190.8927
objective = 0.019395004957914352
==== episode 7700/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00027534767286852 0.08494600653648376
encoder.encoder.weight_hh_l0: -0.0007772265234962106 0.08661986142396927
encoder.encoder.bias_ih_l0: 0.011729689314961433 0.08686132729053497
encoder.encoder.bias_hh_l0: 0.021726766601204872 0.08689136803150177
encoder.encoder.weight_ih_l0_reverse: 0.0018535279668867588 0.08685031533241272
encoder.encoder.weight_hh_l0_reverse: 0.0026826912071555853 0.08476037532091141
encoder.encoder.bias_ih_l0_reverse: 0.0258328877389431 0.0862550362944603
encoder.encoder.bias_hh_l0_reverse: 0.017698341980576515 0.08423686772584915
decider.lstm.weight_ih_l0: 5.794780372525565e-05 0.14829464256763458
decider.lstm.weight_hh_l0: -0.0026314323768019676 0.14718489348888397
decider.lstm.bias_ih_l0: 0.024594761431217194 0.15440545976161957
decider.lstm.bias_hh_l0: 0.005607218015938997 0.14505264163017273
decider.linear1.weight: 0.0014028617879375815 0.12162426114082336
decider.linear1.bias: 0.016596531495451927 0.11649131029844284
decider.linear2.weight: 0.0051748137921094894 0.056487344205379486
decider.linear2.bias: 0.006400404032319784 0.05822436884045601
decider.linear3.weight: -0.04346897825598717 0.1002051904797554
decider.linear3.bias: -0.03875236213207245 0.06703822314739227

Rewards:
190.8927
190.8927
190.8927
objective = 0.017725735902786255
==== episode 7800/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00027075893012806773 0.08495370298624039
encoder.encoder.weight_hh_l0: -0.0007813933189027011 0.08664271235466003
encoder.encoder.bias_ih_l0: 0.01179592590779066 0.08687058091163635
encoder.encoder.bias_hh_l0: 0.021793004125356674 0.08690237253904343
encoder.encoder.weight_ih_l0_reverse: 0.0018554702401161194 0.08685982972383499
encoder.encoder.weight_hh_l0_reverse: 0.0026910663582384586 0.08476851135492325
encoder.encoder.bias_ih_l0_reverse: 0.02589522860944271 0.08626367896795273
encoder.encoder.bias_hh_l0_reverse: 0.01776067726314068 0.08424286544322968
decider.lstm.weight_ih_l0: 6.260020745685324e-05 0.14830709993839264
decider.lstm.weight_hh_l0: -0.002643578452989459 0.14719712734222412
decider.lstm.bias_ih_l0: 0.024657391011714935 0.15442150831222534
decider.lstm.bias_hh_l0: 0.005669845268130302 0.14505864679813385
decider.linear1.weight: 0.0013917682226747274 0.12164540588855743
decider.linear1.bias: 0.016671858727931976 0.11649870872497559
decider.linear2.weight: 0.005203103646636009 0.05649993196129799
decider.linear2.bias: 0.0064359079115092754 0.05824177712202072
decider.linear3.weight: -0.0434713140130043 0.10021866112947464
decider.linear3.bias: -0.03875471279025078 0.06711145490407944

Rewards:
190.8927
190.8927
190.8927
objective = 0.016234807670116425
==== episode 7900/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002661564212758094 0.08496108651161194
encoder.encoder.weight_hh_l0: -0.0007854117429815233 0.08666496723890305
encoder.encoder.bias_ih_l0: 0.011860390193760395 0.08687933534383774
encoder.encoder.bias_hh_l0: 0.021857470273971558 0.08691275119781494
encoder.encoder.weight_ih_l0_reverse: 0.0018573346314951777 0.08686917275190353
encoder.encoder.weight_hh_l0_reverse: 0.002699491800740361 0.08477654308080673
encoder.encoder.bias_ih_l0_reverse: 0.025956954807043076 0.0862719938158989
encoder.encoder.bias_hh_l0_reverse: 0.017822405323386192 0.08424851298332214
decider.lstm.weight_ih_l0: 6.720088276779279e-05 0.14831914007663727
decider.lstm.weight_hh_l0: -0.0026555024087429047 0.14720892906188965
decider.lstm.bias_ih_l0: 0.024717912077903748 0.15443725883960724
decider.lstm.bias_hh_l0: 0.005730349104851484 0.1450640857219696
decider.linear1.weight: 0.0013806287897750735 0.12166628986597061
decider.linear1.bias: 0.01674576662480831 0.11650596559047699
decider.linear2.weight: 0.005230952054262161 0.05651237070560455
decider.linear2.bias: 0.006470455788075924 0.0582587830722332
decider.linear3.weight: -0.043473392724990845 0.10023155808448792
decider.linear3.bias: -0.03875671327114105 0.06718191504478455

Rewards:
190.8927
190.8927
190.8927
objective = 0.014899453148245811
==== episode 8000/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002615452103782445 0.0849681869149208
encoder.encoder.weight_hh_l0: -0.0007892901194281876 0.08668667078018188
encoder.encoder.bias_ih_l0: 0.011923241429030895 0.08688762784004211
encoder.encoder.bias_hh_l0: 0.021920323371887207 0.08692257106304169
encoder.encoder.weight_ih_l0_reverse: 0.001859133830294013 0.08687838166952133
encoder.encoder.weight_hh_l0_reverse: 0.002707966137677431 0.08478448539972305
encoder.encoder.bias_ih_l0_reverse: 0.026018118485808372 0.08627999573945999
encoder.encoder.bias_hh_l0_reverse: 0.01788357086479664 0.08425385504961014
decider.lstm.weight_ih_l0: 7.175595965236425e-05 0.14833077788352966
decider.lstm.weight_hh_l0: -0.0026672272942960262 0.14722032845020294
decider.lstm.bias_ih_l0: 0.02477646991610527 0.15445274114608765
decider.lstm.bias_hh_l0: 0.005788902286440134 0.14506898820400238
decider.linear1.weight: 0.0013694860972464085 0.12168688327074051
decider.linear1.bias: 0.016818178817629814 0.11651312559843063
decider.linear2.weight: 0.005258343648165464 0.05652466416358948
decider.linear2.bias: 0.006504057440906763 0.058275386691093445
decider.linear3.weight: -0.04347525164484978 0.1002439558506012
decider.linear3.bias: -0.038758534938097 0.06724993884563446

Rewards:
190.8927
190.8927
190.8927
objective = 0.013696897774934769
==== episode 8100/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00025697259115986526 0.08497496694326401
encoder.encoder.weight_hh_l0: -0.0007930015563033521 0.08670765906572342
encoder.encoder.bias_ih_l0: 0.011984012089669704 0.0868954211473465
encoder.encoder.bias_hh_l0: 0.021981097757816315 0.08693177253007889
encoder.encoder.weight_ih_l0_reverse: 0.0018608539830893278 0.08688737452030182
encoder.encoder.weight_hh_l0_reverse: 0.0027164032217115164 0.08479226380586624
encoder.encoder.bias_ih_l0_reverse: 0.026078151538968086 0.08628764003515244
encoder.encoder.bias_hh_l0_reverse: 0.017943602055311203 0.08425886183977127
decider.lstm.weight_ih_l0: 7.622979319421574e-05 0.14834195375442505
decider.lstm.weight_hh_l0: -0.0026786578819155693 0.14723125100135803
decider.lstm.bias_ih_l0: 0.024832677096128464 0.15446777641773224
decider.lstm.bias_hh_l0: 0.005845114588737488 0.14507333934307098
decider.linear1.weight: 0.001358455396257341 0.1217069998383522
decider.linear1.bias: 0.016888462007045746 0.11652016639709473
decider.linear2.weight: 0.005285042338073254 0.05653669685125351
decider.linear2.bias: 0.00653648329898715 0.05829143524169922
decider.linear3.weight: -0.04347691312432289 0.10025577247142792
decider.linear3.bias: -0.03876013681292534 0.067315012216568

Rewards:
190.8927
190.8927
190.8927
objective = 0.012619550339877605
==== episode 8200/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00025238475063815713 0.0849815383553505
encoder.encoder.weight_hh_l0: -0.0007965925033204257 0.08672820776700974
encoder.encoder.bias_ih_l0: 0.012043485417962074 0.08690281957387924
encoder.encoder.bias_hh_l0: 0.02204057388007641 0.08694050461053848
encoder.encoder.weight_ih_l0_reverse: 0.0018625142984092236 0.08689625561237335
encoder.encoder.weight_hh_l0_reverse: 0.0027248896658420563 0.08479996025562286
encoder.encoder.bias_ih_l0_reverse: 0.02613772824406624 0.08629503101110458
encoder.encoder.bias_hh_l0_reverse: 0.018003186210989952 0.08426360040903091
decider.lstm.weight_ih_l0: 8.067603630479425e-05 0.14835280179977417
decider.lstm.weight_hh_l0: -0.0026899364311248064 0.14724181592464447
decider.lstm.bias_ih_l0: 0.02488727495074272 0.1544826179742813
decider.lstm.bias_hh_l0: 0.005899726413190365 0.145077183842659
decider.linear1.weight: 0.0013474139850586653 0.1217268705368042
decider.linear1.bias: 0.0169574823230505 0.11652714014053345
decider.linear2.weight: 0.005311151966452599 0.05654863640666008
decider.linear2.bias: 0.006568134296685457 0.05830714851617813
decider.linear3.weight: -0.04347839951515198 0.10026717931032181
decider.linear3.bias: -0.03876151517033577 0.06737799197435379

Rewards:
190.8927
190.8927
190.8927
objective = 0.011644642800092697
==== episode 8300/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00024778328952379525 0.08498788625001907
encoder.encoder.weight_hh_l0: -0.0008000694215297699 0.08674836158752441
encoder.encoder.bias_ih_l0: 0.01210177130997181 0.08690984547138214
encoder.encoder.bias_hh_l0: 0.022098859772086143 0.08694878965616226
encoder.encoder.weight_ih_l0_reverse: 0.0018641211790964007 0.08690503984689713
encoder.encoder.weight_hh_l0_reverse: 0.002733425935730338 0.08480759710073471
encoder.encoder.bias_ih_l0_reverse: 0.026196880266070366 0.08630218356847763
encoder.encoder.bias_hh_l0_reverse: 0.018062330782413483 0.08426807820796967
decider.lstm.weight_ih_l0: 8.509866893291473e-05 0.1483633816242218
decider.lstm.weight_hh_l0: -0.0027010731864720583 0.14725209772586823
decider.lstm.bias_ih_l0: 0.02494039572775364 0.15449725091457367
decider.lstm.bias_hh_l0: 0.005952838342636824 0.14508061110973358
decider.linear1.weight: 0.0013363538309931755 0.12174655497074127
decider.linear1.bias: 0.017025332897901535 0.11653406172990799
decider.linear2.weight: 0.005336876958608627 0.05656049773097038
decider.linear2.bias: 0.006599054671823978 0.05832255631685257
decider.linear3.weight: -0.04347973316907883 0.10027820616960526
decider.linear3.bias: -0.03876280039548874 0.06743912398815155

Rewards:
190.8927
190.8927
190.8927
objective = 0.010753202252089977
==== episode 8400/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00024316846975125372 0.08499406278133392
encoder.encoder.weight_hh_l0: -0.0008034371421672404 0.08676812797784805
encoder.encoder.bias_ih_l0: 0.012158958241343498 0.08691652119159698
encoder.encoder.bias_hh_l0: 0.022156046703457832 0.08695667237043381
encoder.encoder.weight_ih_l0_reverse: 0.0018656756728887558 0.08691373467445374
encoder.encoder.weight_hh_l0_reverse: 0.002742009935900569 0.08481516689062119
encoder.encoder.bias_ih_l0_reverse: 0.026255620643496513 0.08630913496017456
encoder.encoder.bias_hh_l0_reverse: 0.018121065571904182 0.08427232503890991
decider.lstm.weight_ih_l0: 8.950367191573605e-05 0.14837366342544556
decider.lstm.weight_hh_l0: -0.002712087705731392 0.1472620815038681
decider.lstm.bias_ih_l0: 0.02499213255941868 0.1545117199420929
decider.lstm.bias_hh_l0: 0.006004581227898598 0.14508360624313354
decider.linear1.weight: 0.0013252689968794584 0.12176603078842163
decider.linear1.bias: 0.01709209755063057 0.11654090881347656
decider.linear2.weight: 0.005362308584153652 0.05657227709889412
decider.linear2.bias: 0.00662930216640234 0.058337654918432236
decider.linear3.weight: -0.043480951339006424 0.10028891265392303
decider.linear3.bias: -0.038763999938964844 0.06749852001667023

Rewards:
190.8927
190.8927
190.8927
objective = 0.009945226833224297
==== episode 8500/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00023853681341279298 0.08500006794929504
encoder.encoder.weight_hh_l0: -0.0008067009039223194 0.08678756654262543
encoder.encoder.bias_ih_l0: 0.012215129099786282 0.08692286163568497
encoder.encoder.bias_hh_l0: 0.02221221663057804 0.08696414530277252
encoder.encoder.weight_ih_l0_reverse: 0.0018671806901693344 0.08692234754562378
encoder.encoder.weight_hh_l0_reverse: 0.002750641666352749 0.08482268452644348
encoder.encoder.bias_ih_l0_reverse: 0.02631397731602192 0.08631588518619537
encoder.encoder.bias_hh_l0_reverse: 0.018179424107074738 0.08427634090185165
decider.lstm.weight_ih_l0: 9.389620390720665e-05 0.1483837068080902
decider.lstm.weight_hh_l0: -0.002722990233451128 0.1472717970609665
decider.lstm.bias_ih_l0: 0.025042586028575897 0.1545260101556778
decider.lstm.bias_hh_l0: 0.006055028177797794 0.14508625864982605
decider.linear1.weight: 0.0013141495874151587 0.12178534269332886
decider.linear1.bias: 0.017157841473817825 0.11654771119356155
decider.linear2.weight: 0.005387455690652132 0.05658400058746338
decider.linear2.bias: 0.0066589065827429295 0.05835247412323952
decider.linear3.weight: -0.043482065200805664 0.10029932856559753
decider.linear3.bias: -0.038765065371990204 0.06755624711513519

Rewards:
190.8927
190.8927
190.8927
objective = 0.009205539710819721
==== episode 8600/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00023393459559883922 0.08500585705041885
encoder.encoder.weight_hh_l0: -0.000809833116363734 0.08680649101734161
encoder.encoder.bias_ih_l0: 0.012269828468561172 0.0869288295507431
encoder.encoder.bias_hh_l0: 0.022266916930675507 0.08697119355201721
encoder.encoder.weight_ih_l0_reverse: 0.0018686222610995173 0.08693079650402069
encoder.encoder.weight_hh_l0_reverse: 0.002759236376732588 0.08483009040355682
encoder.encoder.bias_ih_l0_reverse: 0.026371397078037262 0.08632239699363708
encoder.encoder.bias_hh_l0_reverse: 0.018236853182315826 0.0842801034450531
decider.lstm.weight_ih_l0: 9.823828440858051e-05 0.1483933925628662
decider.lstm.weight_hh_l0: -0.0027336799539625645 0.14728118479251862
decider.lstm.bias_ih_l0: 0.025091350078582764 0.15454000234603882
decider.lstm.bias_hh_l0: 0.006103800144046545 0.14508850872516632
decider.linear1.weight: 0.0013031023554503918 0.12180430442094803
decider.linear1.bias: 0.017222007736563683 0.11655441671609879
decider.linear2.weight: 0.005412086378782988 0.05659555271267891
decider.linear2.bias: 0.006687619257718325 0.05836689472198486
decider.linear3.weight: -0.04348307102918625 0.10030937939882278
decider.linear3.bias: -0.03876589983701706 0.06761177629232407

Rewards:
190.8927
190.8927
190.8927
objective = 0.008534139022231102
==== episode 8700/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00022931396961212158 0.08501152694225311
encoder.encoder.weight_hh_l0: -0.0008128720801323652 0.08682513236999512
encoder.encoder.bias_ih_l0: 0.012323703616857529 0.08693450689315796
encoder.encoder.bias_hh_l0: 0.022320793941617012 0.08697790652513504
encoder.encoder.weight_ih_l0_reverse: 0.0018700193613767624 0.08693918585777283
encoder.encoder.weight_hh_l0_reverse: 0.0027678825426846743 0.08483745157718658
encoder.encoder.bias_ih_l0_reverse: 0.026428503915667534 0.08632875233888626
encoder.encoder.bias_hh_l0_reverse: 0.018293961882591248 0.08428366482257843
decider.lstm.weight_ih_l0: 0.00010257613030262291 0.1484028697013855
decider.lstm.weight_hh_l0: -0.002744282130151987 0.14729033410549164
decider.lstm.bias_ih_l0: 0.025139033794403076 0.1545538455247879
decider.lstm.bias_hh_l0: 0.006151493638753891 0.14509038627147675
decider.linear1.weight: 0.0012920103035867214 0.12182313948869705
decider.linear1.bias: 0.017285309731960297 0.11656108498573303
decider.linear2.weight: 0.005436483770608902 0.056607067584991455
decider.linear2.bias: 0.006715783849358559 0.05838107317686081
decider.linear3.weight: -0.04348398372530937 0.10031919181346893
decider.linear3.bias: -0.03876668959856033 0.0676659420132637

Rewards:
190.8927
190.8927
190.8927
objective = 0.007919642142951488
==== episode 8800/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000224664545385167 0.08501706272363663
encoder.encoder.weight_hh_l0: -0.0008158166892826557 0.08684353530406952
encoder.encoder.bias_ih_l0: 0.01237674243748188 0.08693990111351013
encoder.encoder.bias_hh_l0: 0.022373832762241364 0.0869843065738678
encoder.encoder.weight_ih_l0_reverse: 0.0018713753670454025 0.0869474783539772
encoder.encoder.weight_hh_l0_reverse: 0.002776576206088066 0.08484476059675217
encoder.encoder.bias_ih_l0_reverse: 0.02648526057600975 0.08633492887020111
encoder.encoder.bias_hh_l0_reverse: 0.018350720405578613 0.08428706228733063
decider.lstm.weight_ih_l0: 0.00010691359057091177 0.14841218292713165
decider.lstm.weight_hh_l0: -0.0027548223733901978 0.14729927480220795
decider.lstm.bias_ih_l0: 0.025185734033584595 0.15456755459308624
decider.lstm.bias_hh_l0: 0.00619819201529026 0.1450919508934021
decider.linear1.weight: 0.0012808647006750107 0.12184189260005951
decider.linear1.bias: 0.017347807064652443 0.11656812578439713
decider.linear2.weight: 0.005461068823933601 0.05661848559975624
decider.linear2.bias: 0.006743810139596462 0.05839462950825691
decider.linear3.weight: -0.04348481446504593 0.10032876580953598
decider.linear3.bias: -0.03876743093132973 0.0677187591791153

Rewards:
190.8927
190.8927
190.8927
objective = 0.007354462519288063
==== episode 8900/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00021999444288667291 0.08502248674631119
encoder.encoder.weight_hh_l0: -0.0008186731138266623 0.08686169981956482
encoder.encoder.bias_ih_l0: 0.01242904644459486 0.08694502711296082
encoder.encoder.bias_hh_l0: 0.022426137700676918 0.08699039369821548
encoder.encoder.weight_ih_l0_reverse: 0.0018726933049038053 0.08695570379495621
encoder.encoder.weight_hh_l0_reverse: 0.0027853196952492 0.08485203236341476
encoder.encoder.bias_ih_l0_reverse: 0.02654171921312809 0.08634097129106522
encoder.encoder.bias_hh_l0_reverse: 0.018407179042696953 0.0842902734875679
decider.lstm.weight_ih_l0: 0.00011125672608613968 0.1484213024377823
decider.lstm.weight_hh_l0: -0.0027652925346046686 0.14730800688266754
decider.lstm.bias_ih_l0: 0.025231488049030304 0.1545812040567398
decider.lstm.bias_hh_l0: 0.006243936251848936 0.1450931578874588
decider.linear1.weight: 0.0012696617050096393 0.121860571205616
decider.linear1.bias: 0.017409536987543106 0.11657527089118958
decider.linear2.weight: 0.005485665053129196 0.05662985146045685
decider.linear2.bias: 0.006771467626094818 0.05840784311294556
decider.linear3.weight: -0.043485578149557114 0.10033814609050751
decider.linear3.bias: -0.03876810520887375 0.0677703469991684

Rewards:
190.8927
190.8927
190.8927
objective = 0.006834805011749268
==== episode 9000/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00021530341473408043 0.08502781391143799
encoder.encoder.weight_hh_l0: -0.0008214436238631606 0.0868796557188034
encoder.encoder.bias_ih_l0: 0.012480707839131355 0.0869498997926712
encoder.encoder.bias_hh_l0: 0.02247779257595539 0.08699620515108109
encoder.encoder.weight_ih_l0_reverse: 0.001873972825706005 0.08696387708187103
encoder.encoder.weight_hh_l0_reverse: 0.002794116036966443 0.08485927432775497
encoder.encoder.bias_ih_l0_reverse: 0.026597917079925537 0.08634687960147858
encoder.encoder.bias_hh_l0_reverse: 0.01846337877213955 0.08429331332445145
decider.lstm.weight_ih_l0: 0.00011560089478734881 0.1484302431344986
decider.lstm.weight_hh_l0: -0.0027757114730775356 0.1473165601491928
decider.lstm.bias_ih_l0: 0.025276336818933487 0.15459471940994263
decider.lstm.bias_hh_l0: 0.006288792472332716 0.14509408175945282
decider.linear1.weight: 0.0012583949137479067 0.12187913060188293
decider.linear1.bias: 0.01747055910527706 0.11658237874507904
decider.linear2.weight: 0.005510065238922834 0.056641191244125366
decider.linear2.bias: 0.006798652466386557 0.05842086672782898
decider.linear3.weight: -0.043486278504133224 0.10034731775522232
decider.linear3.bias: -0.038768768310546875 0.06782077252864838

Rewards:
190.8927
190.8927
190.8927
objective = 0.006356876343488693
==== episode 9100/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000210636731935665 0.08503299951553345
encoder.encoder.weight_hh_l0: -0.0008241047617048025 0.08689724653959274
encoder.encoder.bias_ih_l0: 0.01253126747906208 0.08695448189973831
encoder.encoder.bias_hh_l0: 0.022528350353240967 0.08700167387723923
encoder.encoder.weight_ih_l0_reverse: 0.0018752043833956122 0.08697193115949631
encoder.encoder.weight_hh_l0_reverse: 0.002802879549562931 0.08486643433570862
encoder.encoder.bias_ih_l0_reverse: 0.02665332704782486 0.08635260909795761
encoder.encoder.bias_hh_l0_reverse: 0.018518788740038872 0.08429612964391708
decider.lstm.weight_ih_l0: 0.00011991590145044029 0.1484389305114746
decider.lstm.weight_hh_l0: -0.002785981632769108 0.1473248451948166
decider.lstm.bias_ih_l0: 0.02531992457807064 0.15460799634456635
decider.lstm.bias_hh_l0: 0.006332372780889273 0.14509466290473938
decider.linear1.weight: 0.0012471784139052033 0.12189742922782898
decider.linear1.bias: 0.017530299723148346 0.11658939719200134
decider.linear2.weight: 0.005534041207283735 0.056652411818504333
decider.linear2.bias: 0.006825127638876438 0.058433566242456436
decider.linear3.weight: -0.043486904352903366 0.10035620629787445
decider.linear3.bias: -0.03876934573054314 0.06786960363388062

Rewards:
190.8927
190.8927
190.8927
objective = 0.0059206741861999035
==== episode 9200/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00020594667876139283 0.08503811061382294
encoder.encoder.weight_hh_l0: -0.0008266874356195331 0.08691466599702835
encoder.encoder.bias_ih_l0: 0.012581311166286469 0.08695882558822632
encoder.encoder.bias_hh_l0: 0.02257838472723961 0.08700687438249588
encoder.encoder.weight_ih_l0_reverse: 0.0018764021806418896 0.0869799479842186
encoder.encoder.weight_hh_l0_reverse: 0.0028117005713284016 0.08487357944250107
encoder.encoder.bias_ih_l0_reverse: 0.026708535850048065 0.08635824173688889
encoder.encoder.bias_hh_l0_reverse: 0.018573995679616928 0.0842987671494484
decider.lstm.weight_ih_l0: 0.00012423958105500787 0.14844748377799988
decider.lstm.weight_hh_l0: -0.0027962042950093746 0.14733295142650604
decider.lstm.bias_ih_l0: 0.025362780317664146 0.15462125837802887
decider.lstm.bias_hh_l0: 0.006375214550644159 0.14509500563144684
decider.linear1.weight: 0.0012358942767605186 0.12191564589738846
decider.linear1.bias: 0.017589401453733444 0.11659637838602066
decider.linear2.weight: 0.0055578178726136684 0.05666360631585121
decider.linear2.bias: 0.0068511683493852615 0.05844590812921524
decider.linear3.weight: -0.04348747804760933 0.10036492347717285
decider.linear3.bias: -0.03876989707350731 0.06791741400957108

Rewards:
190.8927
190.8927
190.8927
objective = 0.005514818709343672
==== episode 9300/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00020123380818404257 0.08504315465688705
encoder.encoder.weight_hh_l0: -0.000829189782962203 0.08693192899227142
encoder.encoder.bias_ih_l0: 0.012630864977836609 0.08696295320987701
encoder.encoder.bias_hh_l0: 0.0226279404014349 0.08701182901859283
encoder.encoder.weight_ih_l0_reverse: 0.0018775659846141934 0.0869879275560379
encoder.encoder.weight_hh_l0_reverse: 0.0028205786366015673 0.08488072454929352
encoder.encoder.bias_ih_l0_reverse: 0.0267635527998209 0.08636374771595001
encoder.encoder.bias_hh_l0_reverse: 0.01862901635468006 0.08430124074220657
decider.lstm.weight_ih_l0: 0.00012858114496339113 0.1484558880329132
decider.lstm.weight_hh_l0: -0.0028064087964594364 0.14734090864658356
decider.lstm.bias_ih_l0: 0.025404898449778557 0.15463435649871826
decider.lstm.bias_hh_l0: 0.0064173429273068905 0.14509502053260803
decider.linear1.weight: 0.0012245425023138523 0.12193380296230316
decider.linear1.bias: 0.017647892236709595 0.116603322327137
decider.linear2.weight: 0.005581322126090527 0.056674789637327194
decider.linear2.bias: 0.006876703817397356 0.05845794454216957
decider.linear3.weight: -0.04348801076412201 0.10037347674369812
decider.linear3.bias: -0.03877045586705208 0.06796426326036453

Rewards:
190.8927
190.8927
190.8927
objective = 0.005143103189766407
==== episode 9400/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00019649631576612592 0.085048146545887
encoder.encoder.weight_hh_l0: -0.0008316164021380246 0.08694905787706375
encoder.encoder.bias_ih_l0: 0.012679965235292912 0.0869668647646904
encoder.encoder.bias_hh_l0: 0.02267703413963318 0.08701654523611069
encoder.encoder.weight_ih_l0_reverse: 0.0018787034787237644 0.08699586987495422
encoder.encoder.weight_hh_l0_reverse: 0.0028295149095356464 0.08488785475492477
encoder.encoder.bias_ih_l0_reverse: 0.02681838721036911 0.08636917173862457
encoder.encoder.bias_hh_l0_reverse: 0.018683847039937973 0.08430353552103043
decider.lstm.weight_ih_l0: 0.00013294107338879257 0.14846418797969818
decider.lstm.weight_hh_l0: -0.0028165921103209257 0.14734870195388794
decider.lstm.bias_ih_l0: 0.025446299463510513 0.15464745461940765
decider.lstm.bias_hh_l0: 0.006458747200667858 0.14509478211402893
decider.linear1.weight: 0.0012131138937547803 0.1219518855214119
decider.linear1.bias: 0.017705809324979782 0.11661024391651154
decider.linear2.weight: 0.005604675970971584 0.056685976684093475
decider.linear2.bias: 0.006901861634105444 0.05846982076764107
decider.linear3.weight: -0.043488509953022 0.10038192570209503
decider.linear3.bias: -0.03877092897891998 0.06801018863916397

Rewards:
190.8927
190.8927
190.8927
objective = 0.004794148728251457
==== episode 9500/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00019173357577528805 0.08505308628082275
encoder.encoder.weight_hh_l0: -0.0008339654887095094 0.08696605265140533
encoder.encoder.bias_ih_l0: 0.012728649191558361 0.08697056025266647
encoder.encoder.bias_hh_l0: 0.02272571250796318 0.08702102303504944
encoder.encoder.weight_ih_l0_reverse: 0.0018798118690028787 0.08700378239154816
encoder.encoder.weight_hh_l0_reverse: 0.00283850752748549 0.08489498496055603
encoder.encoder.bias_ih_l0_reverse: 0.026873035356402397 0.08637449890375137
encoder.encoder.bias_hh_l0_reverse: 0.01873849518597126 0.08430567383766174
decider.lstm.weight_ih_l0: 0.00013732005027122796 0.14847232401371002
decider.lstm.weight_hh_l0: -0.00282674515619874 0.14735634624958038
decider.lstm.bias_ih_l0: 0.02548712119460106 0.15466055274009705
decider.lstm.bias_hh_l0: 0.00649959035217762 0.14509427547454834
decider.linear1.weight: 0.0012016023974865675 0.12196991592645645
decider.linear1.bias: 0.017763201147317886 0.11661715060472488
decider.linear2.weight: 0.005627901293337345 0.05669718608260155
decider.linear2.bias: 0.006926667410880327 0.05848156660795212
decider.linear3.weight: -0.04348897933959961 0.10039022564888
decider.linear3.bias: -0.0387713760137558 0.06805519759654999

Rewards:
190.8927
190.8927
190.8927
objective = 0.004475538618862629
==== episode 9600/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00018699273641686887 0.08505793660879135
encoder.encoder.weight_hh_l0: -0.0008362170774489641 0.08698277175426483
encoder.encoder.bias_ih_l0: 0.012776465155184269 0.08697403222322464
encoder.encoder.bias_hh_l0: 0.022773532196879387 0.0870252326130867
encoder.encoder.weight_ih_l0_reverse: 0.0018808820750564337 0.08701158314943314
encoder.encoder.weight_hh_l0_reverse: 0.00284747127443552 0.08490206301212311
encoder.encoder.bias_ih_l0_reverse: 0.02692697010934353 0.08637969940900803
encoder.encoder.bias_hh_l0_reverse: 0.01879243552684784 0.08430761098861694
decider.lstm.weight_ih_l0: 0.00014167747576721013 0.14848029613494873
decider.lstm.weight_hh_l0: -0.002836810890585184 0.1473637968301773
decider.lstm.bias_ih_l0: 0.02552691474556923 0.15467339754104614
decider.lstm.bias_hh_l0: 0.0065393755212426186 0.14509345591068268
decider.linear1.weight: 0.001190119655802846 0.1219877228140831
decider.linear1.bias: 0.017819499596953392 0.11662397533655167
decider.linear2.weight: 0.005650757811963558 0.05670829862356186
decider.linear2.bias: 0.00695087481290102 0.058493055403232574
decider.linear3.weight: -0.043489404022693634 0.10039827972650528
decider.linear3.bias: -0.03877165541052818 0.06809879094362259

Rewards:
190.8927
190.8927
190.8927
objective = 0.004179688170552254
==== episode 9700/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00018222659127786756 0.08506275713443756
encoder.encoder.weight_hh_l0: -0.0008383952081203461 0.08699940145015717
encoder.encoder.bias_ih_l0: 0.012823950499296188 0.08697729557752609
encoder.encoder.bias_hh_l0: 0.022821011021733284 0.08702923357486725
encoder.encoder.weight_ih_l0_reverse: 0.0018819306278601289 0.08701936155557632
encoder.encoder.weight_hh_l0_reverse: 0.002856496023014188 0.08490913361310959
encoder.encoder.bias_ih_l0_reverse: 0.02698076143860817 0.08638482540845871
encoder.encoder.bias_hh_l0_reverse: 0.01884623058140278 0.08430939167737961
decider.lstm.weight_ih_l0: 0.00014605805336032063 0.1484881490468979
decider.lstm.weight_hh_l0: -0.0028468770906329155 0.1473711133003235
decider.lstm.bias_ih_l0: 0.025566132739186287 0.15468627214431763
decider.lstm.bias_hh_l0: 0.00657860841602087 0.1450924575328827
decider.linear1.weight: 0.0011785471579059958 0.12200549244880676
decider.linear1.bias: 0.017875339835882187 0.11663078516721725
decider.linear2.weight: 0.005673499777913094 0.05671944469213486
decider.linear2.bias: 0.006974766496568918 0.058504413813352585
decider.linear3.weight: -0.04348978400230408 0.10040619969367981
decider.linear3.bias: -0.03877192735671997 0.06814160197973251

Rewards:
190.8927
190.8927
190.8927
objective = 0.003906596917659044
==== episode 9800/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00017743035277817398 0.08506753295660019
encoder.encoder.weight_hh_l0: -0.000840500695630908 0.08701594173908234
encoder.encoder.bias_ih_l0: 0.012871122919023037 0.08698036521673203
encoder.encoder.bias_hh_l0: 0.022868189960718155 0.08703301101922989
encoder.encoder.weight_ih_l0_reverse: 0.0018829533364623785 0.08702711015939713
encoder.encoder.weight_hh_l0_reverse: 0.002865583635866642 0.08491621166467667
encoder.encoder.bias_ih_l0_reverse: 0.027034420520067215 0.08638986200094223
encoder.encoder.bias_hh_l0_reverse: 0.018899891525506973 0.08431101590394974
decider.lstm.weight_ih_l0: 0.00015047009219415486 0.14849591255187988
decider.lstm.weight_hh_l0: -0.0028569521382451057 0.14737828075885773
decider.lstm.bias_ih_l0: 0.025604866445064545 0.15469904243946075
decider.lstm.bias_hh_l0: 0.00661733653396368 0.14509117603302002
decider.linear1.weight: 0.001166879665106535 0.12202323973178864
decider.linear1.bias: 0.01793072372674942 0.11663758009672165
decider.linear2.weight: 0.005696121137589216 0.056730616837739944
decider.linear2.bias: 0.006998341530561447 0.058515653014183044
decider.linear3.weight: -0.04349011182785034 0.100413978099823
decider.linear3.bias: -0.03877212107181549 0.06818363815546036

Rewards:
190.8927
190.8927
190.8927
objective = 0.0036486778408288956
==== episode 9900/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00017260602908208966 0.08507230132818222
encoder.encoder.weight_hh_l0: -0.0008425312698818743 0.08703242242336273
encoder.encoder.bias_ih_l0: 0.012918020598590374 0.08698324859142303
encoder.encoder.bias_hh_l0: 0.022915076464414597 0.08703658729791641
encoder.encoder.weight_ih_l0_reverse: 0.0018839582335203886 0.08703483641147614
encoder.encoder.weight_hh_l0_reverse: 0.0028747343458235264 0.08492331951856613
encoder.encoder.bias_ih_l0_reverse: 0.027087939903140068 0.08639485388994217
encoder.encoder.bias_hh_l0_reverse: 0.018953416496515274 0.08431248366832733
decider.lstm.weight_ih_l0: 0.00015491354861296713 0.14850358664989471
decider.lstm.weight_hh_l0: -0.00286704208701849 0.1473853588104248
decider.lstm.bias_ih_l0: 0.025643084198236465 0.15471182763576508
decider.lstm.bias_hh_l0: 0.006655537523329258 0.14508958160877228
decider.linear1.weight: 0.0011551132192835212 0.12204096466302872
decider.linear1.bias: 0.01798565685749054 0.11664436012506485
decider.linear2.weight: 0.005718635860830545 0.056741826236248016
decider.linear2.bias: 0.00702161667868495 0.05852677673101425
decider.linear3.weight: -0.04349039867520332 0.10042162984609604
decider.linear3.bias: -0.03877229988574982 0.06822492182254791

Rewards:
190.8927
190.8927
190.8927
objective = 0.003413517726585269
==== episode 10000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00016775481344666332 0.08507705479860306
encoder.encoder.weight_hh_l0: -0.0008444886771030724 0.08704882860183716
encoder.encoder.bias_ih_l0: 0.012964657507836819 0.08698596805334091
encoder.encoder.bias_hh_l0: 0.022961709648370743 0.08703995496034622
encoder.encoder.weight_ih_l0_reverse: 0.0018849411280825734 0.08704254031181335
encoder.encoder.weight_hh_l0_reverse: 0.0028839483857154846 0.08493044227361679
encoder.encoder.bias_ih_l0_reverse: 0.027141334488987923 0.08639978617429733
encoder.encoder.bias_hh_l0_reverse: 0.019006812945008278 0.0843137875199318
decider.lstm.weight_ih_l0: 0.00015938423166517168 0.1485111564397812
decider.lstm.weight_hh_l0: -0.002877145539969206 0.14739231765270233
decider.lstm.bias_ih_l0: 0.02568085677921772 0.15472471714019775
decider.lstm.bias_hh_l0: 0.00669327424839139 0.14508779346942902
decider.linear1.weight: 0.0011432436294853687 0.12205866724252701
decider.linear1.bias: 0.018040163442492485 0.11665112525224686
decider.linear2.weight: 0.0057410504668951035 0.056753069162368774
decider.linear2.bias: 0.007044603116810322 0.05853777378797531
decider.linear3.weight: -0.04349064826965332 0.10042916238307953
decider.linear3.bias: -0.03877249360084534 0.06826552748680115

Rewards:
190.8927
190.8927
190.8927
objective = 0.0031897369772195816
[INFO] : learning runtime (h:mm:ss): 0:02:32
[INFO] : learning end time: 12/17/2023 12:26:33 PM
