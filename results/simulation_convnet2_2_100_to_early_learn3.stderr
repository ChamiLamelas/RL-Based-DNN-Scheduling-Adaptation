Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(18, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/18/2023 12:43:58 AM
==== episode 1/10000 ====
action = 0
probs = 0.2494 0.2519 0.2494 0.2494

action = 0
probs = 0.2494 0.2519 0.2494 0.2494

action = 0
probs = 0.2494 0.2519 0.2494 0.2494

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 5.330327621777542e-05 0.08557401597499847
encoder.encoder.weight_hh_l0: -0.0005871002795174718 0.08819954842329025
encoder.encoder.bias_ih_l0: 0.015573114156723022 0.08763390779495239
encoder.encoder.bias_hh_l0: 0.02557021751999855 0.08802544325590134
encoder.encoder.weight_ih_l0_reverse: 0.0018303963588550687 0.08725878596305847
encoder.encoder.weight_hh_l0_reverse: 0.002862347988411784 0.085008904337883
encoder.encoder.bias_ih_l0_reverse: 0.02852681651711464 0.08649472147226334
encoder.encoder.bias_hh_l0_reverse: 0.02039223536849022 0.084774449467659
decider.lstm.weight_ih_l0: 0.0005886146682314575 0.1491212546825409
decider.lstm.weight_hh_l0: -0.0032300155144184828 0.14797012507915497
decider.lstm.bias_ih_l0: 0.028376709669828415 0.15716949105262756
decider.lstm.bias_hh_l0: 0.009389247745275497 0.14365758001804352
decider.linear1.weight: 0.0007639412651769817 0.12373099476099014
decider.linear1.bias: 0.022220518440008163 0.11631909012794495
decider.linear2.weight: 0.00700555881485343 0.058190759271383286
decider.linear2.bias: 0.008748339489102364 0.0584355965256691
decider.linear3.weight: -0.06864084303379059 0.1299138069152832
decider.linear3.bias: -0.06498465687036514 0.09602414816617966

Rewards:
62.9344
62.9344
62.9344
objective = 87.40348815917969
==== episode 100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00015958506264723837 0.08574976772069931
encoder.encoder.weight_hh_l0: -0.0005545693566091359 0.08852321654558182
encoder.encoder.bias_ih_l0: 0.016378113999962807 0.08779578655958176
encoder.encoder.bias_hh_l0: 0.026375217363238335 0.08833345770835876
encoder.encoder.weight_ih_l0_reverse: 0.0018814632203429937 0.08748023211956024
encoder.encoder.weight_hh_l0_reverse: 0.0029031133744865656 0.08513641357421875
encoder.encoder.bias_ih_l0_reverse: 0.029199881479144096 0.08663501590490341
encoder.encoder.bias_hh_l0_reverse: 0.021065296605229378 0.08494991064071655
decider.lstm.weight_ih_l0: 0.0006677026394754648 0.14930540323257446
decider.lstm.weight_hh_l0: -0.0033235764130949974 0.14815063774585724
decider.lstm.bias_ih_l0: 0.02912762016057968 0.15737232565879822
decider.lstm.bias_hh_l0: 0.010140159167349339 0.1439136266708374
decider.linear1.weight: 0.0007319307187572122 0.12387260794639587
decider.linear1.bias: 0.022577032446861267 0.11629661917686462
decider.linear2.weight: 0.007132337894290686 0.05829261988401413
decider.linear2.bias: 0.008942173793911934 0.058687180280685425
decider.linear3.weight: -0.06864064186811447 0.1300099790096283
decider.linear3.bias: -0.06498429924249649 0.09672572463750839

Rewards:
57.3517
57.3517
57.3517
objective = 7.976331289683003e-06
==== episode 200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018278270727023482 0.08578060567378998
encoder.encoder.weight_hh_l0: -0.0005465760477818549 0.08857682347297668
encoder.encoder.bias_ih_l0: 0.01654810644686222 0.08781291544437408
encoder.encoder.bias_hh_l0: 0.02654520981013775 0.08836862444877625
encoder.encoder.weight_ih_l0_reverse: 0.0018872934160754085 0.08752263337373734
encoder.encoder.weight_hh_l0_reverse: 0.0029097781516611576 0.08515168726444244
encoder.encoder.bias_ih_l0_reverse: 0.02934136986732483 0.0866563692688942
encoder.encoder.bias_hh_l0_reverse: 0.02120678871870041 0.08498033136129379
decider.lstm.weight_ih_l0: 0.0006851842626929283 0.14933738112449646
decider.lstm.weight_hh_l0: -0.0033451500348746777 0.14818425476551056
decider.lstm.bias_ih_l0: 0.029264355078339577 0.15741845965385437
decider.lstm.bias_hh_l0: 0.010276909917593002 0.1439441740512848
decider.linear1.weight: 0.0007168090669438243 0.12391865998506546
decider.linear1.bias: 0.02271682396531105 0.1163063794374466
decider.linear2.weight: 0.007174787111580372 0.058324508368968964
decider.linear2.bias: 0.00900212861597538 0.058750949800014496
decider.linear3.weight: -0.06864064931869507 0.13003990054130554
decider.linear3.bias: -0.06498430669307709 0.09688330441713333

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 1000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 1100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 1200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 1300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 1400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 1500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 1600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 1700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 1800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 1900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 2000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 2100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 2200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 2300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 2400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 2500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 2600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 2700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 2800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 2900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 3000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 3100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 3200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 3300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 3400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 3500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 3600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 3700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 3800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 3900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 4000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 4100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 4200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 4300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 4400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 4500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 4600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 4700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 4800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 4900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 5000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 5100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 5200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 5300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 5400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 5500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 5600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 5700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 5800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 5900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 6000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 6100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 6200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 6300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 6400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 6500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 6600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 6700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 6800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 6900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 7000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 7100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 7200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 7300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 7400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 7500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 7600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 7700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 7800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 7900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 8000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 8100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 8200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 8300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 8400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 8500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 8600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 8700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 8800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 8900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 9000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 9100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 9200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 9300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 9400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 9500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 9600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 9700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 9800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 9900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
==== episode 10000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 0.00018510810332372785 0.08578367531299591
encoder.encoder.weight_hh_l0: -0.0005457496154122055 0.08858207613229752
encoder.encoder.bias_ih_l0: 0.016565430909395218 0.08781459182500839
encoder.encoder.bias_hh_l0: 0.026562532410025597 0.08837196230888367
encoder.encoder.weight_ih_l0_reverse: 0.00188784534111619 0.08752688765525818
encoder.encoder.weight_hh_l0_reverse: 0.0029104328714311123 0.08515313267707825
encoder.encoder.bias_ih_l0_reverse: 0.029355717822909355 0.08665851503610611
encoder.encoder.bias_hh_l0_reverse: 0.021221134811639786 0.08498338609933853
decider.lstm.weight_ih_l0: 0.0006869618664495647 0.14934052526950836
decider.lstm.weight_hh_l0: -0.0033473470248281956 0.14818759262561798
decider.lstm.bias_ih_l0: 0.029277881607413292 0.15742306411266327
decider.lstm.bias_hh_l0: 0.010290446691215038 0.1439470499753952
decider.linear1.weight: 0.0007151546888053417 0.12392355501651764
decider.linear1.bias: 0.02273176796734333 0.11630761623382568
decider.linear2.weight: 0.007179247215390205 0.05832787603139877
decider.linear2.bias: 0.009008356370031834 0.0587574765086174
decider.linear3.weight: -0.06864064931869507 0.13004304468631744
decider.linear3.bias: -0.06498430669307709 0.0968991219997406

Rewards:
57.3517
57.3517
57.3517
objective = 6.83685539115686e-06
[INFO] : learning runtime (h:mm:ss): 0:02:23
[INFO] : learning end time: 12/18/2023 12:46:20 AM
