Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 12:31:44 PM
==== episode 1/10000 ====
action = 0
probs = 0.3319 0.4198 0.1138 0.1346

action = 0
probs = 0.2136 0.6817 0.0335 0.0712

action = 0
probs = 0.2469 0.6966 0.0197 0.0368

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00014412828022614121 0.08285563439130783
encoder.encoder.weight_hh_l0: -0.0003172662982251495 0.08413001149892807
encoder.encoder.bias_ih_l0: 0.005229594185948372 0.08514953404664993
encoder.encoder.bias_hh_l0: 0.01522665936499834 0.08419246971607208
encoder.encoder.weight_ih_l0_reverse: 0.000874177785590291 0.08486128598451614
encoder.encoder.weight_hh_l0_reverse: 0.0035584853030741215 0.08352600038051605
encoder.encoder.bias_ih_l0_reverse: 0.023517102003097534 0.08349118381738663
encoder.encoder.bias_hh_l0_reverse: 0.015382680110633373 0.08236336708068848
decider.lstm.weight_ih_l0: -4.52984131698031e-05 0.14635655283927917
decider.lstm.weight_hh_l0: 0.0019829755183309317 0.14629244804382324
decider.lstm.bias_ih_l0: 0.013895388692617416 0.15778055787086487
decider.lstm.bias_hh_l0: -0.00509205786511302 0.13944028317928314
decider.linear1.weight: 0.0041240667924284935 0.11991877853870392
decider.linear1.bias: 0.012964431196451187 0.11569363623857498
decider.linear2.weight: 0.002296865452080965 0.05232889577746391
decider.linear2.bias: 0.003878055140376091 0.05563237890601158
decider.linear3.weight: -0.004871398210525513 0.056305836886167526
decider.linear3.bias: 0.019892040640115738 0.0627780482172966

Rewards:
206.9982
206.9982
206.9982
objective = 279.15460205078125
==== episode 100/10000 ====
action = 0
probs = 0.3380 0.4438 0.0946 0.1237

action = 1
probs = 0.2134 0.7166 0.0206 0.0494

action = 1
probs = 0.2040 0.7456 0.0158 0.0345

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00013934656453784555 0.08296599239110947
encoder.encoder.weight_hh_l0: -0.0003304988204035908 0.08425173163414001
encoder.encoder.bias_ih_l0: 0.005692698992788792 0.08529319614171982
encoder.encoder.bias_hh_l0: 0.01568976417183876 0.08427779376506805
encoder.encoder.weight_ih_l0_reverse: 0.0009118274319916964 0.08494699746370316
encoder.encoder.weight_hh_l0_reverse: 0.0036829104647040367 0.08361445367336273
encoder.encoder.bias_ih_l0_reverse: 0.023910989984869957 0.08353112637996674
encoder.encoder.bias_hh_l0_reverse: 0.01577656716108322 0.08235763758420944
decider.lstm.weight_ih_l0: 1.5878677004366182e-05 0.14645202457904816
decider.lstm.weight_hh_l0: 0.0020756416488438845 0.14637021720409393
decider.lstm.bias_ih_l0: 0.014306841418147087 0.1579306572675705
decider.lstm.bias_hh_l0: -0.0046805934980511665 0.13959373533725739
decider.linear1.weight: 0.004122690763324499 0.11996195465326309
decider.linear1.bias: 0.013157667592167854 0.11567056179046631
decider.linear2.weight: 0.002402739366516471 0.052364956587553024
decider.linear2.bias: 0.004011126235127449 0.05577386915683746
decider.linear3.weight: -0.005405045114457607 0.05640473961830139
decider.linear3.bias: 0.01928728073835373 0.062444765120744705

Rewards:
198.8019
198.8019
198.8019
objective = 113.42437744140625
==== episode 200/10000 ====
action = 1
probs = 0.3714 0.4170 0.0904 0.1212

action = 1
probs = 0.3875 0.5375 0.0243 0.0507

action = 0
probs = 0.3558 0.5976 0.0152 0.0314

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00012991718540433794 0.08298422396183014
encoder.encoder.weight_hh_l0: -0.0003383990842849016 0.0842609629034996
encoder.encoder.bias_ih_l0: 0.005685768555849791 0.08531948924064636
encoder.encoder.bias_hh_l0: 0.01568283513188362 0.08425842970609665
encoder.encoder.weight_ih_l0_reverse: 0.0009060896700248122 0.0849532037973404
encoder.encoder.weight_hh_l0_reverse: 0.0036661734338849783 0.08362533152103424
encoder.encoder.bias_ih_l0_reverse: 0.023851653560996056 0.0835646316409111
encoder.encoder.bias_hh_l0_reverse: 0.01571723259985447 0.08233386278152466
decider.lstm.weight_ih_l0: 9.839236554398667e-07 0.14644324779510498
decider.lstm.weight_hh_l0: 0.002068117493763566 0.14637933671474457
decider.lstm.bias_ih_l0: 0.014265631325542927 0.15788494050502777
decider.lstm.bias_hh_l0: -0.004721805918961763 0.1396060436964035
decider.linear1.weight: 0.0041169459000229836 0.11997713893651962
decider.linear1.bias: 0.01305691059678793 0.11567112058401108
decider.linear2.weight: 0.0024642818607389927 0.05237456411123276
decider.linear2.bias: 0.004078868310898542 0.05575396493077278
decider.linear3.weight: -0.005569387227296829 0.05641532316803932
decider.linear3.bias: 0.0192043948918581 0.06184817850589752

Rewards:
214.5191
214.5191
214.5191
objective = 180.81668090820312
==== episode 300/10000 ====
action = 3
probs = 0.3734 0.4319 0.0812 0.1135

action = 0
probs = 0.5750 0.3561 0.0211 0.0478

action = 0
probs = 0.5432 0.4201 0.0113 0.0254

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -6.722144462401047e-05 0.08314640074968338
encoder.encoder.weight_hh_l0: -0.00034512599813751876 0.08443054556846619
encoder.encoder.bias_ih_l0: 0.006362695712596178 0.08560175448656082
encoder.encoder.bias_hh_l0: 0.016359763219952583 0.08440733700990677
encoder.encoder.weight_ih_l0_reverse: 0.0009553012205287814 0.08510482311248779
encoder.encoder.weight_hh_l0_reverse: 0.00391424261033535 0.08379128575325012
encoder.encoder.bias_ih_l0_reverse: 0.024532422423362732 0.08360887318849564
encoder.encoder.bias_hh_l0_reverse: 0.016397999599575996 0.08251353353261948
decider.lstm.weight_ih_l0: 0.00013132438471075147 0.14656883478164673
decider.lstm.weight_hh_l0: 0.0021767732687294483 0.14647933840751648
decider.lstm.bias_ih_l0: 0.015095108188688755 0.15794572234153748
decider.lstm.bias_hh_l0: -0.0038923281244933605 0.1396818310022354
decider.linear1.weight: 0.00412339810281992 0.12002969533205032
decider.linear1.bias: 0.013303295709192753 0.1157301664352417
decider.linear2.weight: 0.0025455448776483536 0.052432797849178314
decider.linear2.bias: 0.004215621389448643 0.05578805133700371
decider.linear3.weight: -0.005672692321240902 0.056529510766267776
decider.linear3.bias: 0.01905512437224388 0.06161341071128845

Rewards:
182.5781
182.5781
182.5781
objective = 203.2598876953125
==== episode 400/10000 ====
action = 0
probs = 0.3550 0.4896 0.0669 0.0885

action = 0
probs = 0.5651 0.4013 0.0107 0.0229

action = 1
probs = 0.4738 0.5096 0.0055 0.0111

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -1.067534049070673e-05 0.0833219438791275
encoder.encoder.weight_hh_l0: -0.0003331604821141809 0.08466924726963043
encoder.encoder.bias_ih_l0: 0.007248981390148401 0.08585500717163086
encoder.encoder.bias_hh_l0: 0.017246047034859657 0.08463990688323975
encoder.encoder.weight_ih_l0_reverse: 0.0010057870531454682 0.08524422347545624
encoder.encoder.weight_hh_l0_reverse: 0.00417368533089757 0.08394526690244675
encoder.encoder.bias_ih_l0_reverse: 0.025235043838620186 0.0836367979645729
encoder.encoder.bias_hh_l0_reverse: 0.0171006191521883 0.08258481323719025
decider.lstm.weight_ih_l0: 0.00028349951026029885 0.14671239256858826
decider.lstm.weight_hh_l0: 0.002288657706230879 0.1465817391872406
decider.lstm.bias_ih_l0: 0.015965614467859268 0.15810023248195648
decider.lstm.bias_hh_l0: -0.0030218143947422504 0.13972444832324982
decider.linear1.weight: 0.004151675850152969 0.12010841071605682
decider.linear1.bias: 0.013685491867363453 0.11576011776924133
decider.linear2.weight: 0.0027088825590908527 0.05248934403061867
decider.linear2.bias: 0.0044519174844026566 0.05586550757288933
decider.linear3.weight: -0.005948951467871666 0.05668463185429573
decider.linear3.bias: 0.018787387758493423 0.06152518093585968

Rewards:
198.5688
198.5688
198.5688
objective = 150.95594787597656
==== episode 500/10000 ====
action = 1
probs = 0.3429 0.4961 0.0748 0.0862

action = 0
probs = 0.5775 0.3773 0.0189 0.0263

action = 0
probs = 0.5358 0.4410 0.0096 0.0136

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -1.4028846635483205e-05 0.08329980820417404
encoder.encoder.weight_hh_l0: -0.00033588422229513526 0.08464058488607407
encoder.encoder.bias_ih_l0: 0.007135728374123573 0.08585585653781891
encoder.encoder.bias_hh_l0: 0.017132794484496117 0.08463636040687561
encoder.encoder.weight_ih_l0_reverse: 0.0010007524397224188 0.08522631973028183
encoder.encoder.weight_hh_l0_reverse: 0.00414259685203433 0.0839322879910469
encoder.encoder.bias_ih_l0_reverse: 0.02513143979012966 0.0836302638053894
encoder.encoder.bias_hh_l0_reverse: 0.016997016966342926 0.0826200395822525
decider.lstm.weight_ih_l0: 0.00028023350751027465 0.14669577777385712
decider.lstm.weight_hh_l0: 0.002290278673171997 0.14656545221805573
decider.lstm.bias_ih_l0: 0.01593700610101223 0.1580275595188141
decider.lstm.bias_hh_l0: -0.003050415776669979 0.139710932970047
decider.linear1.weight: 0.004152113571763039 0.12010018527507782
decider.linear1.bias: 0.013608313165605068 0.11575955152511597
decider.linear2.weight: 0.002679285127669573 0.052490461617708206
decider.linear2.bias: 0.004407299216836691 0.05576346814632416
decider.linear3.weight: -0.005901783239096403 0.05668263137340546
decider.linear3.bias: 0.018906932324171066 0.06170934438705444

Rewards:
209.2595
209.2595
209.2595
objective = 130.72154235839844
==== episode 600/10000 ====
action = 3
probs = 0.3157 0.5267 0.0748 0.0828

action = 0
probs = 0.4837 0.4687 0.0208 0.0268

action = 1
probs = 0.3945 0.5817 0.0104 0.0134

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.071603017218877e-06 0.08332885801792145
encoder.encoder.weight_hh_l0: -0.0003176449681632221 0.08466561883687973
encoder.encoder.bias_ih_l0: 0.007219093851745129 0.0858902558684349
encoder.encoder.bias_hh_l0: 0.017216157168149948 0.0846833884716034
encoder.encoder.weight_ih_l0_reverse: 0.001019777380861342 0.08525664359331131
encoder.encoder.weight_hh_l0_reverse: 0.0041733174584805965 0.08396191895008087
encoder.encoder.bias_ih_l0_reverse: 0.025258133187890053 0.08360474556684494
encoder.encoder.bias_hh_l0_reverse: 0.01712370663881302 0.08266709744930267
decider.lstm.weight_ih_l0: 0.00031470454996451735 0.14673687517642975
decider.lstm.weight_hh_l0: 0.0023329348769038916 0.14659321308135986
decider.lstm.bias_ih_l0: 0.01611407846212387 0.1581472009420395
decider.lstm.bias_hh_l0: -0.0028733438812196255 0.13974513113498688
decider.linear1.weight: 0.004161683842539787 0.12009391188621521
decider.linear1.bias: 0.01366661861538887 0.11578967422246933
decider.linear2.weight: 0.0026597240939736366 0.05249377340078354
decider.linear2.bias: 0.004395334981381893 0.05580294132232666
decider.linear3.weight: -0.005885585211217403 0.056631144136190414
decider.linear3.bias: 0.018866728991270065 0.0620194673538208

Rewards:
194.5957
194.5957
194.5957
objective = 243.8338623046875
==== episode 700/10000 ====
action = 1
probs = 0.3624 0.4829 0.0713 0.0834

action = 0
probs = 0.5661 0.3885 0.0188 0.0266

action = 1
probs = 0.5445 0.4277 0.0111 0.0167

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -7.366537829511799e-06 0.08334043622016907
encoder.encoder.weight_hh_l0: -0.00030399576644413173 0.08466077595949173
encoder.encoder.bias_ih_l0: 0.007142957299947739 0.08588311076164246
encoder.encoder.bias_hh_l0: 0.017140021547675133 0.08465567231178284
encoder.encoder.weight_ih_l0_reverse: 0.0010246695019304752 0.08525773882865906
encoder.encoder.weight_hh_l0_reverse: 0.004173879977315664 0.0839700922369957
encoder.encoder.bias_ih_l0_reverse: 0.025236565619707108 0.08365967869758606
encoder.encoder.bias_hh_l0_reverse: 0.017102133482694626 0.08256145566701889
decider.lstm.weight_ih_l0: 0.0003065704077016562 0.14673811197280884
decider.lstm.weight_hh_l0: 0.0023274379782378674 0.14662380516529083
decider.lstm.bias_ih_l0: 0.016025496646761894 0.15811815857887268
decider.lstm.bias_hh_l0: -0.002961923833936453 0.1398046910762787
decider.linear1.weight: 0.00415443442761898 0.12008965760469437
decider.linear1.bias: 0.013621175661683083 0.11584850400686264
decider.linear2.weight: 0.0026782252825796604 0.05248810350894928
decider.linear2.bias: 0.004449100233614445 0.055805549025535583
decider.linear3.weight: -0.005924923345446587 0.056572798639535904
decider.linear3.bias: 0.018765555694699287 0.061268117278814316

Rewards:
218.0870
218.0870
218.0870
objective = 156.02481079101562
==== episode 800/10000 ====
action = 0
probs = 0.3679 0.5050 0.0574 0.0697

action = 0
probs = 0.5966 0.3728 0.0130 0.0176

action = 1
probs = 0.4473 0.5339 0.0074 0.0114

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.398919554660097e-05 0.08352133631706238
encoder.encoder.weight_hh_l0: -0.00026064508710987866 0.08487658947706223
encoder.encoder.bias_ih_l0: 0.007872811518609524 0.08611198514699936
encoder.encoder.bias_hh_l0: 0.017869876697659492 0.08481916785240173
encoder.encoder.weight_ih_l0_reverse: 0.0010907979449257255 0.08543016016483307
encoder.encoder.weight_hh_l0_reverse: 0.004462857730686665 0.08415363729000092
encoder.encoder.bias_ih_l0_reverse: 0.026004845276474953 0.08375471830368042
encoder.encoder.bias_hh_l0_reverse: 0.01787041686475277 0.08253104239702225
decider.lstm.weight_ih_l0: 0.00044202772551216185 0.14689777791500092
decider.lstm.weight_hh_l0: 0.00243151793256402 0.14675697684288025
decider.lstm.bias_ih_l0: 0.016798775643110275 0.15828649699687958
decider.lstm.bias_hh_l0: -0.0021886425092816353 0.1399509310722351
decider.linear1.weight: 0.004191318526864052 0.12014883011579514
decider.linear1.bias: 0.014103669673204422 0.11603131890296936
decider.linear2.weight: 0.00280242832377553 0.05253015086054802
decider.linear2.bias: 0.004723706282675266 0.05588091164827347
decider.linear3.weight: -0.00601564347743988 0.05665230378508568
decider.linear3.bias: 0.01846056431531906 0.06085757538676262

Rewards:
198.5688
198.5688
198.5688
objective = 141.91195678710938
==== episode 900/10000 ====
action = 1
probs = 0.2251 0.6382 0.0601 0.0766

action = 1
probs = 0.2347 0.7043 0.0233 0.0377

action = 0
probs = 0.1917 0.7750 0.0122 0.0211

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.209054557373747e-05 0.08355212211608887
encoder.encoder.weight_hh_l0: -0.00024299215874634683 0.08486182987689972
encoder.encoder.bias_ih_l0: 0.007918810471892357 0.08614196628332138
encoder.encoder.bias_hh_l0: 0.0179158765822649 0.08482655882835388
encoder.encoder.weight_ih_l0_reverse: 0.0011338167823851109 0.08547985553741455
encoder.encoder.weight_hh_l0_reverse: 0.004525911528617144 0.08419467508792877
encoder.encoder.bias_ih_l0_reverse: 0.026261648163199425 0.08357212692499161
encoder.encoder.bias_hh_l0_reverse: 0.01812722347676754 0.0828699916601181
decider.lstm.weight_ih_l0: 0.000492262071929872 0.1469307839870453
decider.lstm.weight_hh_l0: 0.0024515935219824314 0.14672604203224182
decider.lstm.bias_ih_l0: 0.017119532451033592 0.1585339605808258
decider.lstm.bias_hh_l0: -0.0018678931519389153 0.13980954885482788
decider.linear1.weight: 0.004162292927503586 0.12011516839265823
decider.linear1.bias: 0.014014095067977905 0.115882508456707
decider.linear2.weight: 0.002614201745018363 0.05251428484916687
decider.linear2.bias: 0.0044151488691568375 0.05592380091547966
decider.linear3.weight: -0.005802628584206104 0.05653171241283417
decider.linear3.bias: 0.01871214620769024 0.06311806291341782

Rewards:
214.5191
214.5191
214.5191
objective = 175.28582763671875
==== episode 1000/10000 ====
action = 0
probs = 0.2432 0.6158 0.0650 0.0760

action = 1
probs = 0.2861 0.6679 0.0182 0.0277

action = 1
probs = 0.2707 0.6973 0.0127 0.0193

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.0317731923569227e-06 0.0835205614566803
encoder.encoder.weight_hh_l0: -0.00023601252178195864 0.08482686430215836
encoder.encoder.bias_ih_l0: 0.007735274266451597 0.08610399812459946
encoder.encoder.bias_hh_l0: 0.01773233897984028 0.08481275290250778
encoder.encoder.weight_ih_l0_reverse: 0.0010926325339823961 0.08542989194393158
encoder.encoder.weight_hh_l0_reverse: 0.0044129216112196445 0.08414604514837265
encoder.encoder.bias_ih_l0_reverse: 0.02599243074655533 0.08356773853302002
encoder.encoder.bias_hh_l0_reverse: 0.017858006060123444 0.08285198360681534
decider.lstm.weight_ih_l0: 0.0004579868109431118 0.14689801633358002
decider.lstm.weight_hh_l0: 0.002396881580352783 0.14670762419700623
decider.lstm.bias_ih_l0: 0.016857711598277092 0.15849296748638153
decider.lstm.bias_hh_l0: -0.002129699569195509 0.13981810212135315
decider.linear1.weight: 0.004143511410802603 0.12009809911251068
decider.linear1.bias: 0.013902584090828896 0.11587967723608017
decider.linear2.weight: 0.002608093898743391 0.05251123383641243
decider.linear2.bias: 0.0043925149366259575 0.05587201938033104
decider.linear3.weight: -0.005849736742675304 0.05651244521141052
decider.linear3.bias: 0.018727432936429977 0.06280431151390076

Rewards:
198.8019
198.8019
198.8019
objective = 144.3265380859375
==== episode 1100/10000 ====
action = 0
probs = 0.1945 0.6914 0.0544 0.0597

action = 1
probs = 0.1923 0.7742 0.0141 0.0194

action = 1
probs = 0.1830 0.7945 0.0095 0.0130

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.8762485675979406e-05 0.08370095491409302
encoder.encoder.weight_hh_l0: -0.00023454451002180576 0.0850411206483841
encoder.encoder.bias_ih_l0: 0.008514947257936 0.08631470054388046
encoder.encoder.bias_hh_l0: 0.01851201243698597 0.08499183505773544
encoder.encoder.weight_ih_l0_reverse: 0.0011707961093634367 0.08561107516288757
encoder.encoder.weight_hh_l0_reverse: 0.004729139618575573 0.0843287780880928
encoder.encoder.bias_ih_l0_reverse: 0.02683211676776409 0.08362364768981934
encoder.encoder.bias_hh_l0_reverse: 0.018697697669267654 0.08298206329345703
decider.lstm.weight_ih_l0: 0.0005909949541091919 0.14704442024230957
decider.lstm.weight_hh_l0: 0.0025376835837960243 0.14680293202400208
decider.lstm.bias_ih_l0: 0.017721954733133316 0.158700093626976
decider.lstm.bias_hh_l0: -0.0012654606252908707 0.1398012936115265
decider.linear1.weight: 0.004187395796179771 0.12016179412603378
decider.linear1.bias: 0.014276662841439247 0.11592721939086914
decider.linear2.weight: 0.002707053441554308 0.05254984647035599
decider.linear2.bias: 0.004556775093078613 0.05596901848912239
decider.linear3.weight: -0.005926268175244331 0.05662419646978378
decider.linear3.bias: 0.01859656348824501 0.06334614753723145

Rewards:
198.8019
198.8019
198.8019
objective = 140.71630859375
==== episode 1200/10000 ====
action = 1
probs = 0.1543 0.7534 0.0441 0.0482

action = 1
probs = 0.1838 0.7702 0.0194 0.0265

action = 1
probs = 0.1238 0.8556 0.0088 0.0117

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 8.21255162009038e-05 0.08387620747089386
encoder.encoder.weight_hh_l0: -0.00020929655875079334 0.0852641686797142
encoder.encoder.bias_ih_l0: 0.009271172806620598 0.08651799708604813
encoder.encoder.bias_hh_l0: 0.019268235191702843 0.08514022827148438
encoder.encoder.weight_ih_l0_reverse: 0.0012581257615238428 0.08580658584833145
encoder.encoder.weight_hh_l0_reverse: 0.00508943572640419 0.08453626185655594
encoder.encoder.bias_ih_l0_reverse: 0.027717122808098793 0.08371489495038986
encoder.encoder.bias_hh_l0_reverse: 0.019582699984312057 0.08301990479230881
decider.lstm.weight_ih_l0: 0.0007265753811225295 0.1471923440694809
decider.lstm.weight_hh_l0: 0.002648822031915188 0.14691215753555298
decider.lstm.bias_ih_l0: 0.01856294833123684 0.15881045162677765
decider.lstm.bias_hh_l0: -0.0004244614392518997 0.13986103236675262
decider.linear1.weight: 0.004233759827911854 0.12022583186626434
decider.linear1.bias: 0.014645730145275593 0.11607615649700165
decider.linear2.weight: 0.0027760695666074753 0.0525960810482502
decider.linear2.bias: 0.004696277901530266 0.05602908879518509
decider.linear3.weight: -0.005905859172344208 0.056688375771045685
decider.linear3.bias: 0.018518421798944473 0.0637253075838089

Rewards:
190.8927
190.8927
190.8927
objective = 44.55712127685547
==== episode 1300/10000 ====
action = 1
probs = 0.1681 0.7436 0.0402 0.0480

action = 1
probs = 0.2482 0.7004 0.0200 0.0315

action = 1
probs = 0.1661 0.8092 0.0096 0.0152

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000113260219222866 0.08391156792640686
encoder.encoder.weight_hh_l0: -0.00017860688967630267 0.08530282974243164
encoder.encoder.bias_ih_l0: 0.009315138682723045 0.08655203133821487
encoder.encoder.bias_hh_l0: 0.01931220293045044 0.08516818284988403
encoder.encoder.weight_ih_l0_reverse: 0.001291800057515502 0.08586487174034119
encoder.encoder.weight_hh_l0_reverse: 0.0051860930398106575 0.08460091054439545
encoder.encoder.bias_ih_l0_reverse: 0.027925994247198105 0.08377665281295776
encoder.encoder.bias_hh_l0_reverse: 0.01979156956076622 0.08299510180950165
decider.lstm.weight_ih_l0: 0.000755920831579715 0.14722184836864471
decider.lstm.weight_hh_l0: 0.002669289242476225 0.14695090055465698
decider.lstm.bias_ih_l0: 0.01867481879889965 0.15882129967212677
decider.lstm.bias_hh_l0: -0.00031259353272616863 0.13990150392055511
decider.linear1.weight: 0.004241765942424536 0.12023865431547165
decider.linear1.bias: 0.01472402736544609 0.11613153666257858
decider.linear2.weight: 0.0027921414002776146 0.052612509578466415
decider.linear2.bias: 0.004751669242978096 0.056073643267154694
decider.linear3.weight: -0.005937819369137287 0.05666106194257736
decider.linear3.bias: 0.01840341091156006 0.06335514783859253

Rewards:
190.8927
190.8927
190.8927
objective = 54.983787536621094
==== episode 1400/10000 ====
action = 1
probs = 0.2100 0.7042 0.0375 0.0482

action = 0
probs = 0.4964 0.4352 0.0248 0.0436

action = 1
probs = 0.4375 0.5247 0.0138 0.0240

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00012109346425859258 0.08399410545825958
encoder.encoder.weight_hh_l0: -0.00010798651055665687 0.08540322631597519
encoder.encoder.bias_ih_l0: 0.009513793513178825 0.08667037636041641
encoder.encoder.bias_hh_l0: 0.01951085776090622 0.0852445662021637
encoder.encoder.weight_ih_l0_reverse: 0.0013199230888858438 0.08597710728645325
encoder.encoder.weight_hh_l0_reverse: 0.0053632850758731365 0.08475115895271301
encoder.encoder.bias_ih_l0_reverse: 0.028333144262433052 0.08391199260950089
encoder.encoder.bias_hh_l0_reverse: 0.020198721438646317 0.08298613131046295
decider.lstm.weight_ih_l0: 0.0008142502629198134 0.14728613197803497
decider.lstm.weight_hh_l0: 0.0026972051709890366 0.14703500270843506
decider.lstm.bias_ih_l0: 0.018905391916632652 0.15882019698619843
decider.lstm.bias_hh_l0: -8.201086893677711e-05 0.1399688720703125
decider.linear1.weight: 0.00426016841083765 0.12027695775032043
decider.linear1.bias: 0.01495517697185278 0.11628759652376175
decider.linear2.weight: 0.002848969306796789 0.05266096442937851
decider.linear2.bias: 0.004879191517829895 0.05601673573255539
decider.linear3.weight: -0.005927730351686478 0.05669895187020302
decider.linear3.bias: 0.018310241401195526 0.062432434409856796

Rewards:
218.0870
218.0870
218.0870
objective = 123.29241943359375
==== episode 1500/10000 ====
action = 1
probs = 0.2264 0.7077 0.0290 0.0369

action = 0
probs = 0.6488 0.3093 0.0156 0.0262

action = 1
probs = 0.5803 0.3951 0.0090 0.0155

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00015673399320803583 0.08413013070821762
encoder.encoder.weight_hh_l0: -9.133360435953364e-05 0.08559293299913406
encoder.encoder.bias_ih_l0: 0.01010205689817667 0.0868300125002861
encoder.encoder.bias_hh_l0: 0.020099123939871788 0.08538936823606491
encoder.encoder.weight_ih_l0_reverse: 0.0013884952059015632 0.08615033328533173
encoder.encoder.weight_hh_l0_reverse: 0.005682039074599743 0.08493583649396896
encoder.encoder.bias_ih_l0_reverse: 0.029094522818922997 0.08405610918998718
encoder.encoder.bias_hh_l0_reverse: 0.020960092544555664 0.08295054733753204
decider.lstm.weight_ih_l0: 0.0009244124521501362 0.1474032700061798
decider.lstm.weight_hh_l0: 0.002736304886639118 0.1471462994813919
decider.lstm.bias_ih_l0: 0.019519057124853134 0.15881770849227905
decider.lstm.bias_hh_l0: 0.0005316564347594976 0.1400442123413086
decider.linear1.weight: 0.004278284497559071 0.12037023901939392
decider.linear1.bias: 0.015349509194493294 0.11646389961242676
decider.linear2.weight: 0.003030697349458933 0.05273022502660751
decider.linear2.bias: 0.005161426495760679 0.05611521005630493
decider.linear3.weight: -0.0061150211840868 0.05689888447523117
decider.linear3.bias: 0.018041813746094704 0.06161533668637276

Rewards:
218.0870
218.0870
218.0870
objective = 124.08110046386719
==== episode 1600/10000 ====
action = 1
probs = 0.1893 0.7571 0.0235 0.0300

action = 1
probs = 0.6201 0.3458 0.0131 0.0211

action = 1
probs = 0.5479 0.4319 0.0074 0.0128

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00019556141342036426 0.08426431566476822
encoder.encoder.weight_hh_l0: -7.344456389546394e-05 0.08575309813022614
encoder.encoder.bias_ih_l0: 0.010591559112071991 0.08695194870233536
encoder.encoder.bias_hh_l0: 0.020588623359799385 0.0855242982506752
encoder.encoder.weight_ih_l0_reverse: 0.0014536958187818527 0.0862981528043747
encoder.encoder.weight_hh_l0_reverse: 0.00598699739202857 0.08509919047355652
encoder.encoder.bias_ih_l0_reverse: 0.02979036420583725 0.0840734988451004
encoder.encoder.bias_hh_l0_reverse: 0.021655935794115067 0.0829988643527031
decider.lstm.weight_ih_l0: 0.0010267029283568263 0.14749358594417572
decider.lstm.weight_hh_l0: 0.0027710916474461555 0.1472192108631134
decider.lstm.bias_ih_l0: 0.02005981281399727 0.15886379778385162
decider.lstm.bias_hh_l0: 0.0010724139865487814 0.14004410803318024
decider.linear1.weight: 0.004280296619981527 0.12043178826570511
decider.linear1.bias: 0.015496905893087387 0.11653522402048111
decider.linear2.weight: 0.003105564508587122 0.052771005779504776
decider.linear2.bias: 0.005262741819024086 0.056189440190792084
decider.linear3.weight: -0.006210043095052242 0.056977447122335434
decider.linear3.bias: 0.017914962023496628 0.06184559315443039

Rewards:
190.8927
190.8927
190.8927
objective = 138.7024383544922
==== episode 1700/10000 ====
action = 1
probs = 0.1643 0.7903 0.0185 0.0270

action = 1
probs = 0.6449 0.3227 0.0110 0.0214

action = 1
probs = 0.4950 0.4865 0.0059 0.0126

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002166956546716392 0.08435502648353577
encoder.encoder.weight_hh_l0: -7.117258064681664e-05 0.08588555455207825
encoder.encoder.bias_ih_l0: 0.011003375984728336 0.08705499768257141
encoder.encoder.bias_hh_l0: 0.021000437438488007 0.08561870455741882
encoder.encoder.weight_ih_l0_reverse: 0.0014932327903807163 0.08641944080591202
encoder.encoder.weight_hh_l0_reverse: 0.0062092565931379795 0.08522893488407135
encoder.encoder.bias_ih_l0_reverse: 0.030303454026579857 0.08414311707019806
encoder.encoder.bias_hh_l0_reverse: 0.022169027477502823 0.08297920972108841
decider.lstm.weight_ih_l0: 0.0011191413505002856 0.147565096616745
decider.lstm.weight_hh_l0: 0.002815307816490531 0.1472804993391037
decider.lstm.bias_ih_l0: 0.02054637484252453 0.15886186063289642
decider.lstm.bias_hh_l0: 0.0015589729882776737 0.14008666574954987
decider.linear1.weight: 0.00429979944601655 0.1204945296049118
decider.linear1.bias: 0.015745775774121284 0.11658447980880737
decider.linear2.weight: 0.003135504201054573 0.05282501131296158
decider.linear2.bias: 0.005320930387824774 0.05629581958055496
decider.linear3.weight: -0.006277028005570173 0.05709012597799301
decider.linear3.bias: 0.01780952699482441 0.06197357177734375

Rewards:
190.8927
190.8927
190.8927
objective = 132.79078674316406
==== episode 1800/10000 ====
action = 1
probs = 0.1255 0.8347 0.0173 0.0225

action = 1
probs = 0.5495 0.4172 0.0129 0.0204

action = 0
probs = 0.4252 0.5574 0.0064 0.0110

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002466160512994975 0.08446300774812698
encoder.encoder.weight_hh_l0: -6.79061995469965e-05 0.0860152319073677
encoder.encoder.bias_ih_l0: 0.011415102519094944 0.08715978264808655
encoder.encoder.bias_hh_l0: 0.021412162110209465 0.08574279397726059
encoder.encoder.weight_ih_l0_reverse: 0.0015352870104834437 0.08651843667030334
encoder.encoder.weight_hh_l0_reverse: 0.006391618400812149 0.08533643931150436
encoder.encoder.bias_ih_l0_reverse: 0.030745267868041992 0.08413553237915039
encoder.encoder.bias_hh_l0_reverse: 0.022610845044255257 0.08302422612905502
decider.lstm.weight_ih_l0: 0.0011877302313223481 0.14762887358665466
decider.lstm.weight_hh_l0: 0.002848453586921096 0.14732563495635986
decider.lstm.bias_ih_l0: 0.020903626456856728 0.15890713036060333
decider.lstm.bias_hh_l0: 0.0019162308890372515 0.14008277654647827
decider.linear1.weight: 0.00430293707177043 0.12052279710769653
decider.linear1.bias: 0.015802768990397453 0.11661285161972046
decider.linear2.weight: 0.0031670681200921535 0.05284322798252106
decider.linear2.bias: 0.005352008622139692 0.0562768280506134
decider.linear3.weight: -0.006264442577958107 0.057098738849163055
decider.linear3.bias: 0.017852753400802612 0.06252025067806244

Rewards:
214.5191
214.5191
214.5191
objective = 136.57208251953125
==== episode 1900/10000 ====
action = 1
probs = 0.1381 0.8272 0.0156 0.0191

action = 0
probs = 0.6493 0.3278 0.0093 0.0136

action = 0
probs = 0.5056 0.4813 0.0051 0.0080

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00025021075271070004 0.0844833105802536
encoder.encoder.weight_hh_l0: -6.044640394975431e-05 0.08605660498142242
encoder.encoder.bias_ih_l0: 0.011495544575154781 0.08719595521688461
encoder.encoder.bias_hh_l0: 0.02149260975420475 0.08578476309776306
encoder.encoder.weight_ih_l0_reverse: 0.0015533980913460255 0.08656575530767441
encoder.encoder.weight_hh_l0_reverse: 0.006461843848228455 0.08538562059402466
encoder.encoder.bias_ih_l0_reverse: 0.030904673039913177 0.08421532809734344
encoder.encoder.bias_hh_l0_reverse: 0.02277025207877159 0.08298295736312866
decider.lstm.weight_ih_l0: 0.0012094115372747183 0.1476544588804245
decider.lstm.weight_hh_l0: 0.002858417807146907 0.14735758304595947
decider.lstm.bias_ih_l0: 0.02100948989391327 0.15887250006198883
decider.lstm.bias_hh_l0: 0.0020220987498760223 0.1401178538799286
decider.linear1.weight: 0.004318569786846638 0.12056683748960495
decider.linear1.bias: 0.016001353040337563 0.11669663339853287
decider.linear2.weight: 0.003259024117141962 0.052878882735967636
decider.linear2.bias: 0.005494680721312761 0.056297142058610916
decider.linear3.weight: -0.006414824165403843 0.05721033364534378
decider.linear3.bias: 0.01766873337328434 0.06199275329709053

Rewards:
209.2595
209.2595
209.2595
objective = 90.9280014038086
==== episode 2000/10000 ====
action = 1
probs = 0.0876 0.8852 0.0122 0.0150

action = 0
probs = 0.4102 0.5612 0.0121 0.0165

action = 1
probs = 0.2952 0.6919 0.0052 0.0078

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002799572830554098 0.08463586866855621
encoder.encoder.weight_hh_l0: -7.39452225388959e-05 0.08625908941030502
encoder.encoder.bias_ih_l0: 0.012159234844148159 0.08736552298069
encoder.encoder.bias_hh_l0: 0.02215629443526268 0.08594609797000885
encoder.encoder.weight_ih_l0_reverse: 0.00159566814545542 0.08670363575220108
encoder.encoder.weight_hh_l0_reverse: 0.006663584616035223 0.08552742004394531
encoder.encoder.bias_ih_l0_reverse: 0.031479865312576294 0.08421123772859573
encoder.encoder.bias_hh_l0_reverse: 0.023345444351434708 0.083000548183918
decider.lstm.weight_ih_l0: 0.0013086515245959163 0.14774556457996368
decider.lstm.weight_hh_l0: 0.0029178056865930557 0.14741522073745728
decider.lstm.bias_ih_l0: 0.02154092863202095 0.158940389752388
decider.lstm.bias_hh_l0: 0.0025535367894917727 0.1401309072971344
decider.linear1.weight: 0.0043326434679329395 0.1206064447760582
decider.linear1.bias: 0.016096657142043114 0.11671897768974304
decider.linear2.weight: 0.0032635461539030075 0.052894677966833115
decider.linear2.bias: 0.005493184085935354 0.05636654421687126
decider.linear3.weight: -0.006340313702821732 0.0571821890771389
decider.linear3.bias: 0.017712276428937912 0.0630166232585907

Rewards:
218.0870
218.0870
218.0870
objective = 100.42958068847656
==== episode 2100/10000 ====
action = 2
probs = 0.0985 0.8750 0.0119 0.0146

action = 1
probs = 0.4519 0.5257 0.0097 0.0127

action = 1
probs = 0.3742 0.6142 0.0047 0.0069

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000251899502472952 0.08463738858699799
encoder.encoder.weight_hh_l0: -5.5778513342374936e-05 0.08627006411552429
encoder.encoder.bias_ih_l0: 0.012128137983381748 0.08739016205072403
encoder.encoder.bias_hh_l0: 0.022125201299786568 0.08597050607204437
encoder.encoder.weight_ih_l0_reverse: 0.0016071104910224676 0.08670505881309509
encoder.encoder.weight_hh_l0_reverse: 0.006720403674989939 0.08555463701486588
encoder.encoder.bias_ih_l0_reverse: 0.03154067322611809 0.0842415913939476
encoder.encoder.bias_hh_l0_reverse: 0.023406250402331352 0.08297703415155411
decider.lstm.weight_ih_l0: 0.0013012413401156664 0.14775027334690094
decider.lstm.weight_hh_l0: 0.0029094398487359285 0.14743468165397644
decider.lstm.bias_ih_l0: 0.021496111527085304 0.15892866253852844
decider.lstm.bias_hh_l0: 0.002508721314370632 0.14014063775539398
decider.linear1.weight: 0.00432620570063591 0.12061072885990143
decider.linear1.bias: 0.016075758263468742 0.11668339371681213
decider.linear2.weight: 0.0033184695057570934 0.05289095640182495
decider.linear2.bias: 0.00558161735534668 0.05638843774795532
decider.linear3.weight: -0.006437375210225582 0.05719272792339325
decider.linear3.bias: 0.017597801983356476 0.06262733787298203

Rewards:
175.5749
175.5749
175.5749
objective = 325.3180236816406
==== episode 2200/10000 ====
action = 1
probs = 0.1042 0.8702 0.0125 0.0131

action = 1
probs = 0.4416 0.5373 0.0105 0.0106

action = 1
probs = 0.3305 0.6591 0.0050 0.0054

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002549511846154928 0.0845986008644104
encoder.encoder.weight_hh_l0: -6.115882570156828e-05 0.08621904253959656
encoder.encoder.bias_ih_l0: 0.012007591314613819 0.0873330682516098
encoder.encoder.bias_hh_l0: 0.022004656493663788 0.08592461049556732
encoder.encoder.weight_ih_l0_reverse: 0.0015831153141334653 0.08666777610778809
encoder.encoder.weight_hh_l0_reverse: 0.006618557497859001 0.0855008065700531
encoder.encoder.bias_ih_l0_reverse: 0.03133731335401535 0.08421988040208817
encoder.encoder.bias_hh_l0_reverse: 0.02320288121700287 0.08298800140619278
decider.lstm.weight_ih_l0: 0.0012894280953332782 0.14773358404636383
decider.lstm.weight_hh_l0: 0.0029045219998806715 0.14741452038288116
decider.lstm.bias_ih_l0: 0.021457958966493607 0.15889513492584229
decider.lstm.bias_hh_l0: 0.0024705594405531883 0.1401270627975464
decider.linear1.weight: 0.004329630173742771 0.12060728669166565
decider.linear1.bias: 0.016073521226644516 0.11671457439661026
decider.linear2.weight: 0.00332396337762475 0.05289292708039284
decider.linear2.bias: 0.005581599194556475 0.05635678023099899
decider.linear3.weight: -0.006484687328338623 0.05719825625419617
decider.linear3.bias: 0.017527904361486435 0.062444575130939484

Rewards:
190.8927
190.8927
190.8927
objective = 74.89739227294922
==== episode 2300/10000 ====
action = 1
probs = 0.1330 0.8442 0.0114 0.0114

action = 1
probs = 0.5429 0.4426 0.0074 0.0071

action = 1
probs = 0.4191 0.5736 0.0036 0.0037

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00024494261015206575 0.0845620259642601
encoder.encoder.weight_hh_l0: -6.570542609551921e-05 0.08619748800992966
encoder.encoder.bias_ih_l0: 0.011909009888768196 0.08731748908758163
encoder.encoder.bias_hh_l0: 0.02190607413649559 0.08589911460876465
encoder.encoder.weight_ih_l0_reverse: 0.0015854325611144304 0.08667007833719254
encoder.encoder.weight_hh_l0_reverse: 0.006629914045333862 0.08550301939249039
encoder.encoder.bias_ih_l0_reverse: 0.031315725296735764 0.08429432660341263
encoder.encoder.bias_hh_l0_reverse: 0.02318129874765873 0.0829334706068039
decider.lstm.weight_ih_l0: 0.0012753591872751713 0.14773310720920563
decider.lstm.weight_hh_l0: 0.002897385973483324 0.14742857217788696
decider.lstm.bias_ih_l0: 0.021388795226812363 0.1588578224182129
decider.lstm.bias_hh_l0: 0.002401395235210657 0.1401727944612503
decider.linear1.weight: 0.00434831203892827 0.12064230442047119
decider.linear1.bias: 0.01624436117708683 0.1167539730668068
decider.linear2.weight: 0.0034285602159798145 0.052917130291461945
decider.linear2.bias: 0.005722829606384039 0.05639340355992317
decider.linear3.weight: -0.006690119858831167 0.05729684606194496
decider.linear3.bias: 0.017259646207094193 0.06164110451936722

Rewards:
190.8927
190.8927
190.8927
objective = 98.0111312866211
==== episode 2400/10000 ====
action = 1
probs = 0.1357 0.8443 0.0105 0.0095

action = 1
probs = 0.6857 0.3028 0.0063 0.0052

action = 0
probs = 0.5313 0.4627 0.0032 0.0028

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002541164867579937 0.08463042229413986
encoder.encoder.weight_hh_l0: -5.4210624512052163e-05 0.08628901839256287
encoder.encoder.bias_ih_l0: 0.01214196439832449 0.08742271363735199
encoder.encoder.bias_hh_l0: 0.02213902398943901 0.08597693592309952
encoder.encoder.weight_ih_l0_reverse: 0.0016117737395688891 0.08677369356155396
encoder.encoder.weight_hh_l0_reverse: 0.006784734781831503 0.08561313897371292
encoder.encoder.bias_ih_l0_reverse: 0.03166249766945839 0.08437304198741913
encoder.encoder.bias_hh_l0_reverse: 0.023528069257736206 0.08294949680566788
decider.lstm.weight_ih_l0: 0.001333514112047851 0.14778153598308563
decider.lstm.weight_hh_l0: 0.0029156915843486786 0.14747507870197296
decider.lstm.bias_ih_l0: 0.021654803305864334 0.1588568389415741
decider.lstm.bias_hh_l0: 0.002667403547093272 0.14020657539367676
decider.linear1.weight: 0.004366571083664894 0.12070432305335999
decider.linear1.bias: 0.016523106023669243 0.1168285608291626
decider.linear2.weight: 0.0035261844750493765 0.0529804453253746
decider.linear2.bias: 0.005891529377549887 0.056374091655015945
decider.linear3.weight: -0.006788507103919983 0.05749213322997093
decider.linear3.bias: 0.017149023711681366 0.06128992512822151

Rewards:
214.5191
214.5191
214.5191
objective = 142.75990295410156
==== episode 2500/10000 ====
action = 1
probs = 0.1383 0.8421 0.0106 0.0090

action = 0
probs = 0.6817 0.3043 0.0081 0.0059

action = 1
probs = 0.5772 0.4154 0.0041 0.0032

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00024652155116200447 0.084681436419487
encoder.encoder.weight_hh_l0: -3.7591478758258745e-05 0.08634912967681885
encoder.encoder.bias_ih_l0: 0.012258858419954777 0.08749370276927948
encoder.encoder.bias_hh_l0: 0.022255921736359596 0.08603417128324509
encoder.encoder.weight_ih_l0_reverse: 0.0016406694194301963 0.08682221174240112
encoder.encoder.weight_hh_l0_reverse: 0.006898683030158281 0.08568454533815384
encoder.encoder.bias_ih_l0_reverse: 0.031883228570222855 0.08440858125686646
encoder.encoder.bias_hh_l0_reverse: 0.02374880202114582 0.0829421654343605
decider.lstm.weight_ih_l0: 0.0013505067909136415 0.14780686795711517
decider.lstm.weight_hh_l0: 0.0029164424631744623 0.14750364422798157
decider.lstm.bias_ih_l0: 0.021709706634283066 0.15887700021266937
decider.lstm.bias_hh_l0: 0.0027222975622862577 0.14022143185138702
decider.linear1.weight: 0.004367752932012081 0.1207023561000824
decider.linear1.bias: 0.016529321670532227 0.11685363948345184
decider.linear2.weight: 0.0035455122124403715 0.052984319627285004
decider.linear2.bias: 0.005932767875492573 0.05635081231594086
decider.linear3.weight: -0.00673966808244586 0.057470209896564484
decider.linear3.bias: 0.01714193820953369 0.06124762445688248

Rewards:
218.0870
218.0870
218.0870
objective = 104.20339965820312
==== episode 2600/10000 ====
action = 1
probs = 0.1235 0.8622 0.0079 0.0065

action = 0
probs = 0.7533 0.2376 0.0054 0.0038

action = 0
probs = 0.6767 0.3185 0.0028 0.0021

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002827965363394469 0.0848301500082016
encoder.encoder.weight_hh_l0: -3.4641278034541756e-05 0.08655664324760437
encoder.encoder.bias_ih_l0: 0.012827377766370773 0.08770544826984406
encoder.encoder.bias_hh_l0: 0.022824440151453018 0.08620963245630264
encoder.encoder.weight_ih_l0_reverse: 0.001706979121081531 0.08701480180025101
encoder.encoder.weight_hh_l0_reverse: 0.007211282383650541 0.0859001874923706
encoder.encoder.bias_ih_l0_reverse: 0.0326087512075901 0.08452502638101578
encoder.encoder.bias_hh_l0_reverse: 0.02447432279586792 0.08293750882148743
decider.lstm.weight_ih_l0: 0.0014572655782103539 0.14790473878383636
decider.lstm.weight_hh_l0: 0.002957581775262952 0.14759932458400726
decider.lstm.bias_ih_l0: 0.02220764383673668 0.1589125543832779
decider.lstm.bias_hh_l0: 0.003220229409635067 0.1402929723262787
decider.linear1.weight: 0.004391060210764408 0.12081676721572876
decider.linear1.bias: 0.016948649659752846 0.11693693697452545
decider.linear2.weight: 0.0037185673136264086 0.05306515097618103
decider.linear2.bias: 0.006205528974533081 0.05642621964216232
decider.linear3.weight: -0.0069239819422364235 0.05772712081670761
decider.linear3.bias: 0.01691318489611149 0.06102047488093376

Rewards:
209.2595
209.2595
209.2595
objective = 57.347530364990234
==== episode 2700/10000 ====
action = 1
probs = 0.1398 0.8426 0.0095 0.0082

action = 0
probs = 0.7769 0.2133 0.0054 0.0044

action = 0
probs = 0.7271 0.2676 0.0028 0.0025

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002495061489753425 0.08477114140987396
encoder.encoder.weight_hh_l0: -2.796510307234712e-05 0.08647181838750839
encoder.encoder.bias_ih_l0: 0.012570574879646301 0.08764386177062988
encoder.encoder.bias_hh_l0: 0.022567633539438248 0.08614163845777512
encoder.encoder.weight_ih_l0_reverse: 0.0016880148323252797 0.08695023506879807
encoder.encoder.weight_hh_l0_reverse: 0.00714384438470006 0.08584374189376831
encoder.encoder.bias_ih_l0_reverse: 0.03238220140337944 0.0844949409365654
encoder.encoder.bias_hh_l0_reverse: 0.024247774854302406 0.08297473937273026
decider.lstm.weight_ih_l0: 0.0014165736502036452 0.14786453545093536
decider.lstm.weight_hh_l0: 0.0029393541626632214 0.147561714053154
decider.lstm.bias_ih_l0: 0.022014539688825607 0.15888242423534393
decider.lstm.bias_hh_l0: 0.003027124796062708 0.14026647806167603
decider.linear1.weight: 0.00438250508159399 0.12076877802610397
decider.linear1.bias: 0.016772354021668434 0.1168694719672203
decider.linear2.weight: 0.0036479525733739138 0.05302878096699715
decider.linear2.bias: 0.006118508987128735 0.0563746839761734
decider.linear3.weight: -0.006840524263679981 0.05761793628334999
decider.linear3.bias: 0.01703682169318199 0.06097175180912018

Rewards:
209.2595
209.2595
209.2595
objective = 51.785911560058594
==== episode 2800/10000 ====
action = 1
probs = 0.2649 0.6972 0.0211 0.0168

action = 2
probs = 0.8128 0.1673 0.0114 0.0084

action = 1
probs = 0.7872 0.2008 0.0066 0.0054

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00014520056720357388 0.08440054208040237
encoder.encoder.weight_hh_l0: 1.133081877924269e-05 0.08598821610212326
encoder.encoder.bias_ih_l0: 0.011076424270868301 0.08718648552894592
encoder.encoder.bias_hh_l0: 0.021073486655950546 0.08569202572107315
encoder.encoder.weight_ih_l0_reverse: 0.0015847411705181003 0.08654846251010895
encoder.encoder.weight_hh_l0_reverse: 0.006511595565825701 0.08542512357234955
encoder.encoder.bias_ih_l0_reverse: 0.030790036544203758 0.08434927463531494
encoder.encoder.bias_hh_l0_reverse: 0.022655609995126724 0.08297087252140045
decider.lstm.weight_ih_l0: 0.0011475541396066546 0.14761915802955627
decider.lstm.weight_hh_l0: 0.002829453442245722 0.14735129475593567
decider.lstm.bias_ih_l0: 0.020585015416145325 0.15875095129013062
decider.lstm.bias_hh_l0: 0.001597592607140541 0.14020079374313354
decider.linear1.weight: 0.004342581145465374 0.12056455761194229
decider.linear1.bias: 0.01608995348215103 0.11673715710639954
decider.linear2.weight: 0.0034582968801259995 0.05288901925086975
decider.linear2.bias: 0.005797451362013817 0.0560913011431694
decider.linear3.weight: -0.006491773761808872 0.05720894783735275
decider.linear3.bias: 0.017482509836554527 0.0604395791888237

Rewards:
200.4463
200.4463
200.4463
objective = 430.20989990234375
==== episode 2900/10000 ====
action = 1
probs = 0.1814 0.7880 0.0168 0.0138

action = 0
probs = 0.6388 0.3396 0.0120 0.0096

action = 0
probs = 0.5461 0.4418 0.0064 0.0057

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00015628263645339757 0.08449607342481613
encoder.encoder.weight_hh_l0: -1.0685455890779849e-05 0.08609182387590408
encoder.encoder.bias_ih_l0: 0.01140919141471386 0.08726265281438828
encoder.encoder.bias_hh_l0: 0.021406257525086403 0.08580168336629868
encoder.encoder.weight_ih_l0_reverse: 0.0015857004327699542 0.08660901337862015
encoder.encoder.weight_hh_l0_reverse: 0.006567868869751692 0.08546366542577744
encoder.encoder.bias_ih_l0_reverse: 0.03098577819764614 0.08427619189023972
encoder.encoder.bias_hh_l0_reverse: 0.02285134792327881 0.08300096541643143
decider.lstm.weight_ih_l0: 0.0011926551815122366 0.14766950905323029
decider.lstm.weight_hh_l0: 0.0028588518034666777 0.1473717838525772
decider.lstm.bias_ih_l0: 0.020920677110552788 0.15881659090518951
decider.lstm.bias_hh_l0: 0.0019332605879753828 0.14015339314937592
decider.linear1.weight: 0.004342495463788509 0.12055755406618118
decider.linear1.bias: 0.016033606603741646 0.11666016280651093
decider.linear2.weight: 0.0034108618274331093 0.05288834497332573
decider.linear2.bias: 0.005701753776520491 0.0562313087284565
decider.linear3.weight: -0.006583618000149727 0.05718161165714264
decider.linear3.bias: 0.017369581386446953 0.06140478700399399

Rewards:
209.2595
209.2595
209.2595
objective = 90.07433319091797
==== episode 3000/10000 ====
action = 1
probs = 0.1213 0.8607 0.0102 0.0078

action = 0
probs = 0.5717 0.4123 0.0095 0.0066

action = 1
probs = 0.4607 0.5313 0.0045 0.0035

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002118153788615018 0.08477071672677994
encoder.encoder.weight_hh_l0: -3.5838329495163634e-05 0.08644315600395203
encoder.encoder.bias_ih_l0: 0.012424389831721783 0.08759485185146332
encoder.encoder.bias_hh_l0: 0.02242145501077175 0.08611349016427994
encoder.encoder.weight_ih_l0_reverse: 0.0016625517746433616 0.08688656985759735
encoder.encoder.weight_hh_l0_reverse: 0.006971870083361864 0.08575944602489471
encoder.encoder.bias_ih_l0_reverse: 0.03203890100121498 0.08438239991664886
encoder.encoder.bias_hh_l0_reverse: 0.023904476314783096 0.08300525695085526
decider.lstm.weight_ih_l0: 0.0013607606524601579 0.14784501492977142
decider.lstm.weight_hh_l0: 0.002943475730717182 0.14751940965652466
decider.lstm.bias_ih_l0: 0.021869858726859093 0.15890757739543915
decider.lstm.bias_hh_l0: 0.002882445929571986 0.1401945799589157
decider.linear1.weight: 0.004373782780021429 0.12067712843418121
decider.linear1.bias: 0.016494935378432274 0.11679206788539886
decider.linear2.weight: 0.0035301828756928444 0.05297693982720375
decider.linear2.bias: 0.005911075510084629 0.05638650059700012
decider.linear3.weight: -0.006772040855139494 0.05742668733000755
decider.linear3.bias: 0.017049085348844528 0.061742763966321945

Rewards:
218.0870
218.0870
218.0870
objective = 97.534912109375
==== episode 3100/10000 ====
action = 1
probs = 0.1461 0.8356 0.0108 0.0075

action = 0
probs = 0.7171 0.2712 0.0070 0.0046

action = 0
probs = 0.6813 0.3125 0.0036 0.0027

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022317058756016195 0.08480722457170486
encoder.encoder.weight_hh_l0: -2.242903610749636e-05 0.08649604767560959
encoder.encoder.bias_ih_l0: 0.012461662292480469 0.08766315877437592
encoder.encoder.bias_hh_l0: 0.022458728402853012 0.08616431057453156
encoder.encoder.weight_ih_l0_reverse: 0.0017098062671720982 0.08695190399885178
encoder.encoder.weight_hh_l0_reverse: 0.007142940536141396 0.08585008233785629
encoder.encoder.bias_ih_l0_reverse: 0.032329268753528595 0.084462970495224
encoder.encoder.bias_hh_l0_reverse: 0.024194836616516113 0.08300743997097015
decider.lstm.weight_ih_l0: 0.0013772256206721067 0.14786432683467865
decider.lstm.weight_hh_l0: 0.0029446594417095184 0.1475529670715332
decider.lstm.bias_ih_l0: 0.02189958095550537 0.15891961753368378
decider.lstm.bias_hh_l0: 0.002912167925387621 0.14023616909980774
decider.linear1.weight: 0.004381910897791386 0.12071826308965683
decider.linear1.bias: 0.016614284366369247 0.11688943207263947
decider.linear2.weight: 0.003613957203924656 0.053012389689683914
decider.linear2.bias: 0.006050937343388796 0.05636966601014137
decider.linear3.weight: -0.006900728680193424 0.05757682025432587
decider.linear3.bias: 0.016926873475313187 0.06112565100193024

Rewards:
209.2595
209.2595
209.2595
objective = 62.48784637451172
==== episode 3200/10000 ====
action = 1
probs = 0.1572 0.8232 0.0112 0.0085

action = 1
probs = 0.7885 0.2004 0.0064 0.0047

action = 0
probs = 0.7406 0.2532 0.0035 0.0028

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00021507068595383316 0.08479391038417816
encoder.encoder.weight_hh_l0: -1.4352344805956818e-05 0.08647508174180984
encoder.encoder.bias_ih_l0: 0.012387786991894245 0.08764874935150146
encoder.encoder.bias_hh_l0: 0.022384852170944214 0.08613944798707962
encoder.encoder.weight_ih_l0_reverse: 0.0016980746295303106 0.08693629503250122
encoder.encoder.weight_hh_l0_reverse: 0.007107894867658615 0.08583500236272812
encoder.encoder.bias_ih_l0_reverse: 0.03224071487784386 0.08445592224597931
encoder.encoder.bias_hh_l0_reverse: 0.024106277152895927 0.08302374929189682
decider.lstm.weight_ih_l0: 0.0013654701178893447 0.14785391092300415
decider.lstm.weight_hh_l0: 0.0029354807920753956 0.14754508435726166
decider.lstm.bias_ih_l0: 0.021825071424245834 0.15891186892986298
decider.lstm.bias_hh_l0: 0.0028376621194183826 0.14022840559482574
decider.linear1.weight: 0.004382545128464699 0.12071715295314789
decider.linear1.bias: 0.016614681109786034 0.1169196367263794
decider.linear2.weight: 0.003607021179050207 0.05302118882536888
decider.linear2.bias: 0.006052836775779724 0.05632335692644119
decider.linear3.weight: -0.006859607063233852 0.057572055608034134
decider.linear3.bias: 0.016992488875985146 0.0609704963862896

Rewards:
214.5191
214.5191
214.5191
objective = 150.33091735839844
==== episode 3300/10000 ====
action = 1
probs = 0.0996 0.8841 0.0100 0.0063

action = 1
probs = 0.6634 0.3215 0.0097 0.0053

action = 1
probs = 0.4954 0.4971 0.0047 0.0028

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002640708116814494 0.08490251749753952
encoder.encoder.weight_hh_l0: -2.9654895115527324e-05 0.086593858897686
encoder.encoder.bias_ih_l0: 0.012789024971425533 0.08772601187229156
encoder.encoder.bias_hh_l0: 0.02278609201312065 0.08623497933149338
encoder.encoder.weight_ih_l0_reverse: 0.001696480787359178 0.08702113479375839
encoder.encoder.weight_hh_l0_reverse: 0.007124653551727533 0.08587227016687393
encoder.encoder.bias_ih_l0_reverse: 0.032433103770017624 0.08443710952997208
encoder.encoder.bias_hh_l0_reverse: 0.024298671633005142 0.08304024487733841
decider.lstm.weight_ih_l0: 0.0014283814234659076 0.147905632853508
decider.lstm.weight_hh_l0: 0.0029734058771282434 0.1475677490234375
decider.lstm.bias_ih_l0: 0.022180505096912384 0.15897130966186523
decider.lstm.bias_hh_l0: 0.0031930794939398766 0.1402057260274887
decider.linear1.weight: 0.004386599175632 0.1207270547747612
decider.linear1.bias: 0.016669755801558495 0.11694610863924026
decider.linear2.weight: 0.0035678597632795572 0.05303708463907242
decider.linear2.bias: 0.005997090134769678 0.056287214159965515
decider.linear3.weight: -0.006816055625677109 0.0576092004776001
decider.linear3.bias: 0.017064575105905533 0.06191210076212883

Rewards:
190.8927
190.8927
190.8927
objective = 124.50988006591797
==== episode 3400/10000 ====
action = 1
probs = 0.0823 0.9036 0.0090 0.0051

action = 0
probs = 0.6033 0.3836 0.0089 0.0043

action = 1
probs = 0.4611 0.5325 0.0042 0.0022

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003000719880219549 0.08498743176460266
encoder.encoder.weight_hh_l0: -3.9597773138666525e-05 0.08670064806938171
encoder.encoder.bias_ih_l0: 0.013076520524919033 0.08782094717025757
encoder.encoder.bias_hh_l0: 0.023073583841323853 0.08634048700332642
encoder.encoder.weight_ih_l0_reverse: 0.0017312603304162621 0.08711446076631546
encoder.encoder.weight_hh_l0_reverse: 0.007257105782628059 0.08595883101224899
encoder.encoder.bias_ih_l0_reverse: 0.03276418149471283 0.08447684347629547
encoder.encoder.bias_hh_l0_reverse: 0.024629749357700348 0.0830339565873146
decider.lstm.weight_ih_l0: 0.001471842173486948 0.14795419573783875
decider.lstm.weight_hh_l0: 0.002997125033289194 0.14761488139629364
decider.lstm.bias_ih_l0: 0.022395122796297073 0.15902379155158997
decider.lstm.bias_hh_l0: 0.0034077016171067953 0.1402328461408615
decider.linear1.weight: 0.004393952898681164 0.12076184898614883
decider.linear1.bias: 0.016772622242569923 0.11699820309877396
decider.linear2.weight: 0.0036194699350744486 0.05305764451622963
decider.linear2.bias: 0.006072476506233215 0.056338343769311905
decider.linear3.weight: -0.006906438618898392 0.057710424065589905
decider.linear3.bias: 0.01698121428489685 0.0621369406580925

Rewards:
218.0870
218.0870
218.0870
objective = 89.91099548339844
==== episode 3500/10000 ====
action = 1
probs = 0.1126 0.8724 0.0097 0.0053

action = 0
probs = 0.7396 0.2492 0.0078 0.0034

action = 1
probs = 0.6578 0.3359 0.0043 0.0020

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00026719088782556355 0.08497054874897003
encoder.encoder.weight_hh_l0: -1.7274736819672398e-05 0.0866849422454834
encoder.encoder.bias_ih_l0: 0.012944068759679794 0.08783821016550064
encoder.encoder.bias_hh_l0: 0.02294113114476204 0.0863327831029892
encoder.encoder.weight_ih_l0_reverse: 0.0017415032489225268 0.08709952235221863
encoder.encoder.weight_hh_l0_reverse: 0.007312878035008907 0.08599354326725006
encoder.encoder.bias_ih_l0_reverse: 0.0327698215842247 0.08450482040643692
encoder.encoder.bias_hh_l0_reverse: 0.02463538572192192 0.08302852511405945
decider.lstm.weight_ih_l0: 0.0014553769724443555 0.14794692397117615
decider.lstm.weight_hh_l0: 0.0029779598116874695 0.14762265980243683
decider.lstm.bias_ih_l0: 0.022270461544394493 0.15898308157920837
decider.lstm.bias_hh_l0: 0.0032830412965267897 0.14025554060935974
decider.linear1.weight: 0.0043963100761175156 0.12077455967664719
decider.linear1.bias: 0.016837619245052338 0.11704669892787933
decider.linear2.weight: 0.003704556729644537 0.05307743325829506
decider.linear2.bias: 0.0062119727954268456 0.056325513869524
decider.linear3.weight: -0.00701488833874464 0.057797305285930634
decider.linear3.bias: 0.016795311123132706 0.06143232434988022

Rewards:
218.0870
218.0870
218.0870
objective = 111.15312194824219
==== episode 3600/10000 ====
action = 1
probs = 0.1728 0.8109 0.0106 0.0056

action = 0
probs = 0.8430 0.1499 0.0050 0.0022

action = 0
probs = 0.8213 0.1747 0.0027 0.0013

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002263053465867415 0.0848962739109993
encoder.encoder.weight_hh_l0: -2.2456288206740282e-06 0.08661241084337234
encoder.encoder.bias_ih_l0: 0.012656603008508682 0.08780589699745178
encoder.encoder.bias_hh_l0: 0.022653665393590927 0.0862768292427063
encoder.encoder.weight_ih_l0_reverse: 0.001742090447805822 0.08705548942089081
encoder.encoder.weight_hh_l0_reverse: 0.007335657253861427 0.08599373698234558
encoder.encoder.bias_ih_l0_reverse: 0.032677460461854935 0.08455019444227219
encoder.encoder.bias_hh_l0_reverse: 0.024543026462197304 0.08301862329244614
decider.lstm.weight_ih_l0: 0.0014168862253427505 0.14791886508464813
decider.lstm.weight_hh_l0: 0.0029525896534323692 0.14761722087860107
decider.lstm.bias_ih_l0: 0.02204090729355812 0.15892568230628967
decider.lstm.bias_hh_l0: 0.0030534921679645777 0.14028938114643097
decider.linear1.weight: 0.004406854510307312 0.12079841643571854
decider.linear1.bias: 0.016960643231868744 0.11704431474208832
decider.linear2.weight: 0.003816139418631792 0.05309062451124191
decider.linear2.bias: 0.0063791130669415 0.05633076652884483
decider.linear3.weight: -0.007187992334365845 0.057893238961696625
decider.linear3.bias: 0.016561631113290787 0.060422174632549286

Rewards:
209.2595
209.2595
209.2595
objective = 40.26557540893555
==== episode 3700/10000 ====
action = 0
probs = 0.1917 0.7938 0.0093 0.0052

action = 0
probs = 0.9000 0.0963 0.0025 0.0012

action = 0
probs = 0.6944 0.3028 0.0018 0.0010

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002281313354615122 0.08493652939796448
encoder.encoder.weight_hh_l0: 1.5055655921969446e-06 0.0866708979010582
encoder.encoder.bias_ih_l0: 0.012779922224581242 0.08787976205348969
encoder.encoder.bias_hh_l0: 0.02277698926627636 0.0863223597407341
encoder.encoder.weight_ih_l0_reverse: 0.0017640290316194296 0.0871082991361618
encoder.encoder.weight_hh_l0_reverse: 0.007441462483257055 0.08606938272714615
encoder.encoder.bias_ih_l0_reverse: 0.03288162127137184 0.08460301905870438
encoder.encoder.bias_hh_l0_reverse: 0.02474718913435936 0.08300529420375824
decider.lstm.weight_ih_l0: 0.0014396114274859428 0.14794756472110748
decider.lstm.weight_hh_l0: 0.002956592943519354 0.14765018224716187
decider.lstm.bias_ih_l0: 0.022134818136692047 0.15892966091632843
decider.lstm.bias_hh_l0: 0.003147401846945286 0.14032483100891113
decider.linear1.weight: 0.00441393256187439 0.12083502113819122
decider.linear1.bias: 0.017128586769104004 0.11708560585975647
decider.linear2.weight: 0.0038888691924512386 0.0531228668987751
decider.linear2.bias: 0.0064928880892694 0.05638638883829117
decider.linear3.weight: -0.007290114648640156 0.057956185191869736
decider.linear3.bias: 0.01636519655585289 0.06001489609479904

Rewards:
206.9982
206.9982
206.9982
objective = 146.418212890625
==== episode 3800/10000 ====
action = 1
probs = 0.3081 0.6775 0.0092 0.0052

action = 0
probs = 0.9346 0.0624 0.0020 0.0010

action = 0
probs = 0.9363 0.0621 0.0011 0.0006

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00020406744442880154 0.08486846089363098
encoder.encoder.weight_hh_l0: 3.3840894957393175e-06 0.08662864565849304
encoder.encoder.bias_ih_l0: 0.01260997261852026 0.08787167817354202
encoder.encoder.bias_hh_l0: 0.022607045248150826 0.08625082671642303
encoder.encoder.weight_ih_l0_reverse: 0.001765105640515685 0.08708412945270538
encoder.encoder.weight_hh_l0_reverse: 0.007467371877282858 0.08608100563287735
encoder.encoder.bias_ih_l0_reverse: 0.032839335501194 0.08468864113092422
encoder.encoder.bias_hh_l0_reverse: 0.024704907089471817 0.08294603228569031
decider.lstm.weight_ih_l0: 0.0014080750988796353 0.14793354272842407
decider.lstm.weight_hh_l0: 0.0029400449711829424 0.14765222370624542
decider.lstm.bias_ih_l0: 0.02195591852068901 0.15888996422290802
decider.lstm.bias_hh_l0: 0.0029684994369745255 0.1404060274362564
decider.linear1.weight: 0.004427559208124876 0.12089196592569351
decider.linear1.bias: 0.017424706369638443 0.11713463813066483
decider.linear2.weight: 0.00405819620937109 0.05315115302801132
decider.linear2.bias: 0.006744744721800089 0.056393545120954514
decider.linear3.weight: -0.0074650999158620834 0.05806984752416611
decider.linear3.bias: 0.01608693227171898 0.05880994722247124

Rewards:
209.2595
209.2595
209.2595
objective = 36.46540069580078
==== episode 3900/10000 ====
action = 1
probs = 0.4038 0.5837 0.0080 0.0045

action = 0
probs = 0.9620 0.0363 0.0012 0.0006

action = 0
probs = 0.9624 0.0366 0.0006 0.0003

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001973632606677711 0.08486194163560867
encoder.encoder.weight_hh_l0: -2.4846792712196475e-07 0.08665487170219421
encoder.encoder.bias_ih_l0: 0.012695667333900928 0.0879373848438263
encoder.encoder.bias_hh_l0: 0.022692736238241196 0.0862530767917633
encoder.encoder.weight_ih_l0_reverse: 0.0017663567559793591 0.08712717145681381
encoder.encoder.weight_hh_l0_reverse: 0.007532903924584389 0.08613915741443634
encoder.encoder.bias_ih_l0_reverse: 0.03297530487179756 0.08478543907403946
encoder.encoder.bias_hh_l0_reverse: 0.02484087459743023 0.08292032778263092
decider.lstm.weight_ih_l0: 0.0014222325989976525 0.14795975387096405
decider.lstm.weight_hh_l0: 0.0029442214872688055 0.14768250286579132
decider.lstm.bias_ih_l0: 0.022037344053387642 0.15886251628398895
decider.lstm.bias_hh_l0: 0.0030499231070280075 0.14048580825328827
decider.linear1.weight: 0.004438326694071293 0.12097261101007462
decider.linear1.bias: 0.017786866053938866 0.11720363050699234
decider.linear2.weight: 0.004227417055517435 0.05319182947278023
decider.linear2.bias: 0.007014579139649868 0.0564439557492733
decider.linear3.weight: -0.007613523863255978 0.05821315944194794
decider.linear3.bias: 0.015851018950343132 0.05800626426935196

Rewards:
209.2595
209.2595
209.2595
objective = 42.928401947021484
==== episode 4000/10000 ====
action = 1
probs = 0.4838 0.5038 0.0078 0.0047

action = 0
probs = 0.9563 0.0419 0.0012 0.0006

action = 0
probs = 0.9587 0.0404 0.0006 0.0004

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00015749954036436975 0.08476458489894867
encoder.encoder.weight_hh_l0: 3.9526462387584615e-06 0.08656022697687149
encoder.encoder.bias_ih_l0: 0.012418702244758606 0.08786068111658096
encoder.encoder.bias_hh_l0: 0.022415775805711746 0.08615412563085556
encoder.encoder.weight_ih_l0_reverse: 0.001745649497024715 0.08704812079668045
encoder.encoder.weight_hh_l0_reverse: 0.007428591605275869 0.08607954531908035
encoder.encoder.bias_ih_l0_reverse: 0.03269769996404648 0.08480280637741089
encoder.encoder.bias_hh_l0_reverse: 0.024563265964388847 0.08292169123888016
decider.lstm.weight_ih_l0: 0.0013692821376025677 0.14791566133499146
decider.lstm.weight_hh_l0: 0.0029327496886253357 0.14764641225337982
decider.lstm.bias_ih_l0: 0.02176813594996929 0.15878748893737793
decider.lstm.bias_hh_l0: 0.0027807075530290604 0.14052772521972656
decider.linear1.weight: 0.004442594945430756 0.12095363438129425
decider.linear1.bias: 0.01778072863817215 0.1172255128622055
decider.linear2.weight: 0.004246297758072615 0.053168170154094696
decider.linear2.bias: 0.007057401351630688 0.05647426098585129
decider.linear3.weight: -0.007716893218457699 0.05812846124172211
decider.linear3.bias: 0.015772081911563873 0.05758941173553467

Rewards:
209.2595
209.2595
209.2595
objective = 53.88433837890625
==== episode 4100/10000 ====
action = 0
probs = 0.5051 0.4801 0.0097 0.0051

action = 0
probs = 0.9659 0.0328 0.0010 0.0004

action = 0
probs = 0.9148 0.0840 0.0007 0.0004

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00013441569171845913 0.08466695994138718
encoder.encoder.weight_hh_l0: 8.98199050425319e-06 0.08644674718379974
encoder.encoder.bias_ih_l0: 0.012097351253032684 0.08774127811193466
encoder.encoder.bias_hh_l0: 0.022094424813985825 0.0860481858253479
encoder.encoder.weight_ih_l0_reverse: 0.001720635686069727 0.08694557845592499
encoder.encoder.weight_hh_l0_reverse: 0.007261903025209904 0.08596349507570267
encoder.encoder.bias_ih_l0_reverse: 0.03231821581721306 0.08476598560810089
encoder.encoder.bias_hh_l0_reverse: 0.024183787405490875 0.08293505758047104
decider.lstm.weight_ih_l0: 0.0013078865595161915 0.14785069227218628
decider.lstm.weight_hh_l0: 0.002920654136687517 0.1475883275270462
decider.lstm.bias_ih_l0: 0.02144298329949379 0.15874876081943512
decider.lstm.bias_hh_l0: 0.002455550478771329 0.14051541686058044
decider.linear1.weight: 0.004443192854523659 0.12091072648763657
decider.linear1.bias: 0.01760493405163288 0.11718754470348358
decider.linear2.weight: 0.004204851575195789 0.05313216149806976
decider.linear2.bias: 0.00698322057723999 0.05639641731977463
decider.linear3.weight: -0.007654995191842318 0.05807949975132942
decider.linear3.bias: 0.01592998206615448 0.05761543661355972

Rewards:
206.9982
206.9982
206.9982
objective = 55.671077728271484
==== episode 4200/10000 ====
action = 0
probs = 0.5891 0.3925 0.0123 0.0060

action = 0
probs = 0.9809 0.0179 0.0008 0.0003

action = 0
probs = 0.9501 0.0488 0.0007 0.0003

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00011235512647544965 0.08453578501939774
encoder.encoder.weight_hh_l0: 1.1053144589823205e-05 0.08631857484579086
encoder.encoder.bias_ih_l0: 0.011737396009266376 0.087603859603405
encoder.encoder.bias_hh_l0: 0.021734468638896942 0.08590903878211975
encoder.encoder.weight_ih_l0_reverse: 0.001684869173914194 0.08683015406131744
encoder.encoder.weight_hh_l0_reverse: 0.007070111110806465 0.08583065122365952
encoder.encoder.bias_ih_l0_reverse: 0.03188979625701904 0.08475888520479202
encoder.encoder.bias_hh_l0_reverse: 0.02375536784529686 0.08292632550001144
decider.lstm.weight_ih_l0: 0.0012323170667514205 0.14777401089668274
decider.lstm.weight_hh_l0: 0.0029095113277435303 0.14752411842346191
decider.lstm.bias_ih_l0: 0.02104821987450123 0.15870647132396698
decider.lstm.bias_hh_l0: 0.002060782629996538 0.14053454995155334
decider.linear1.weight: 0.004447145387530327 0.12090329825878143
decider.linear1.bias: 0.017542436718940735 0.11715381592512131
decider.linear2.weight: 0.004223846830427647 0.05310766398906708
decider.linear2.bias: 0.006963977124541998 0.05628048628568649
decider.linear3.weight: -0.00750754727050662 0.05805545300245285
decider.linear3.bias: 0.016237180680036545 0.057361114770174026

Rewards:
206.9982
206.9982
206.9982
objective = 41.369056701660156
==== episode 4300/10000 ====
action = 0
probs = 0.5224 0.4621 0.0104 0.0051

action = 0
probs = 0.9760 0.0230 0.0008 0.0003

action = 0
probs = 0.9415 0.0576 0.0006 0.0003

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00013656950613949448 0.08465179800987244
encoder.encoder.weight_hh_l0: 5.198848157306202e-06 0.08643030375242233
encoder.encoder.bias_ih_l0: 0.012031752616167068 0.08770621567964554
encoder.encoder.bias_hh_l0: 0.022028828039765358 0.0860198363661766
encoder.encoder.weight_ih_l0_reverse: 0.001711105927824974 0.08693289011716843
encoder.encoder.weight_hh_l0_reverse: 0.00725875748321414 0.08594324439764023
encoder.encoder.bias_ih_l0_reverse: 0.03228328749537468 0.08474183082580566
encoder.encoder.bias_hh_l0_reverse: 0.024148859083652496 0.08292564749717712
decider.lstm.weight_ih_l0: 0.0012980344472452998 0.14784149825572968
decider.lstm.weight_hh_l0: 0.002918716985732317 0.14757615327835083
decider.lstm.bias_ih_l0: 0.021391037851572037 0.1587904542684555
decider.lstm.bias_hh_l0: 0.002403602236881852 0.1405005007982254
decider.linear1.weight: 0.004450447391718626 0.1209251657128334
decider.linear1.bias: 0.017606060951948166 0.11717544496059418
decider.linear2.weight: 0.0042664241045713425 0.05314047262072563
decider.linear2.bias: 0.007025925908237696 0.05638662353157997
decider.linear3.weight: -0.007677112706005573 0.05816017463803291
decider.linear3.bias: 0.015956658869981766 0.05749637261033058

Rewards:
206.9982
206.9982
206.9982
objective = 50.6390495300293
==== episode 4400/10000 ====
action = 0
probs = 0.5639 0.4235 0.0084 0.0041

action = 0
probs = 0.9805 0.0188 0.0005 0.0002

action = 0
probs = 0.9558 0.0436 0.0004 0.0002

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00014546795864589512 0.08470852673053741
encoder.encoder.weight_hh_l0: -1.7559527165644795e-08 0.08650611340999603
encoder.encoder.bias_ih_l0: 0.012250258587300777 0.087807796895504
encoder.encoder.bias_hh_l0: 0.022247333079576492 0.08609053492546082
encoder.encoder.weight_ih_l0_reverse: 0.001723740017041564 0.08700721710920334
encoder.encoder.weight_hh_l0_reverse: 0.0073877498507499695 0.08603759109973907
encoder.encoder.bias_ih_l0_reverse: 0.0325438492000103 0.08480778336524963
encoder.encoder.bias_hh_l0_reverse: 0.024409420788288116 0.08290866762399673
decider.lstm.weight_ih_l0: 0.0013347939820960164 0.14789117872714996
decider.lstm.weight_hh_l0: 0.002926317974925041 0.14762111008167267
decider.lstm.bias_ih_l0: 0.021595101803541183 0.1588004231452942
decider.lstm.bias_hh_l0: 0.0026076636277139187 0.14054186642169952
decider.linear1.weight: 0.004460659809410572 0.1209830716252327
decider.linear1.bias: 0.017846178263425827 0.11722025275230408
decider.linear2.weight: 0.004377271048724651 0.05317791923880577
decider.linear2.bias: 0.007211259566247463 0.056463971734046936
decider.linear3.weight: -0.007832436822354794 0.05827959254384041
decider.linear3.bias: 0.01570281945168972 0.05706414952874184

Rewards:
206.9982
206.9982
206.9982
objective = 44.00786590576172
==== episode 4500/10000 ====
action = 0
probs = 0.6038 0.3836 0.0081 0.0046

action = 0
probs = 0.9869 0.0126 0.0004 0.0002

action = 0
probs = 0.9653 0.0342 0.0003 0.0002

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00014173678937368095 0.08467081189155579
encoder.encoder.weight_hh_l0: -1.305103296544985e-06 0.08647098392248154
encoder.encoder.bias_ih_l0: 0.012141370214521885 0.08777680993080139
encoder.encoder.bias_hh_l0: 0.02213844284415245 0.08604288846254349
encoder.encoder.weight_ih_l0_reverse: 0.0017147875623777509 0.08698245882987976
encoder.encoder.weight_hh_l0_reverse: 0.007339843548834324 0.0860058143734932
encoder.encoder.bias_ih_l0_reverse: 0.032428402453660965 0.08481723070144653
encoder.encoder.bias_hh_l0_reverse: 0.024293970316648483 0.08291045576334
decider.lstm.weight_ih_l0: 0.0013145277043804526 0.14787191152572632
decider.lstm.weight_hh_l0: 0.002923338208347559 0.14760814607143402
decider.lstm.bias_ih_l0: 0.021491043269634247 0.15878985822200775
decider.lstm.bias_hh_l0: 0.00250360369682312 0.14055711030960083
decider.linear1.weight: 0.004464971832931042 0.12099874764680862
decider.linear1.bias: 0.0178535133600235 0.11722028255462646
decider.linear2.weight: 0.004406856372952461 0.053178608417510986
decider.linear2.bias: 0.007232990115880966 0.05645010247826576
decider.linear3.weight: -0.00777293648570776 0.05823880434036255
decider.linear3.bias: 0.015812652185559273 0.056863900274038315

Rewards:
206.9982
206.9982
206.9982
objective = 38.16063690185547
==== episode 4600/10000 ====
action = 0
probs = 0.5159 0.4714 0.0078 0.0049

action = 0
probs = 0.9807 0.0186 0.0004 0.0002

action = 0
probs = 0.9543 0.0451 0.0003 0.0002

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00015833434008527547 0.08471744507551193
encoder.encoder.weight_hh_l0: -1.4488578017335385e-06 0.08649561554193497
encoder.encoder.bias_ih_l0: 0.01219111680984497 0.08776615560054779
encoder.encoder.bias_hh_l0: 0.02218819037079811 0.08606310188770294
encoder.encoder.weight_ih_l0_reverse: 0.0017280918546020985 0.08699870854616165
encoder.encoder.weight_hh_l0_reverse: 0.007368611171841621 0.08600916713476181
encoder.encoder.bias_ih_l0_reverse: 0.032500263303518295 0.08475035429000854
encoder.encoder.bias_hh_l0_reverse: 0.024365829303860664 0.0829172357916832
decider.lstm.weight_ih_l0: 0.0013332526432350278 0.14788052439689636
decider.lstm.weight_hh_l0: 0.002923521911725402 0.1476106494665146
decider.lstm.bias_ih_l0: 0.02156832441687584 0.15885421633720398
decider.lstm.bias_hh_l0: 0.0025808836799114943 0.14049842953681946
decider.linear1.weight: 0.004464657045900822 0.1209724172949791
decider.linear1.bias: 0.01770722307264805 0.1171691045165062
decider.linear2.weight: 0.0043622227385640144 0.05318017676472664
decider.linear2.bias: 0.0071302903816103935 0.05649922043085098
decider.linear3.weight: -0.0078080384992063046 0.058224331587553024
decider.linear3.bias: 0.015761680901050568 0.057377006858587265

Rewards:
206.9982
206.9982
206.9982
objective = 50.237789154052734
==== episode 4700/10000 ====
action = 1
probs = 0.3785 0.6108 0.0065 0.0041

action = 0
probs = 0.9435 0.0550 0.0009 0.0006

action = 0
probs = 0.9503 0.0490 0.0004 0.0003

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001893762091640383 0.08483457565307617
encoder.encoder.weight_hh_l0: -3.641080866145785e-06 0.08659569174051285
encoder.encoder.bias_ih_l0: 0.012492544017732143 0.08784662932157516
encoder.encoder.bias_hh_l0: 0.02248961478471756 0.08617783337831497
encoder.encoder.weight_ih_l0_reverse: 0.0017486294964328408 0.0870848298072815
encoder.encoder.weight_hh_l0_reverse: 0.007458336651325226 0.08606929332017899
encoder.encoder.bias_ih_l0_reverse: 0.03276744857430458 0.08472096174955368
encoder.encoder.bias_hh_l0_reverse: 0.024633018299937248 0.08294346183538437
decider.lstm.weight_ih_l0: 0.0013951935106888413 0.14793451130390167
decider.lstm.weight_hh_l0: 0.00293967267498374 0.14764629304409027
decider.lstm.bias_ih_l0: 0.021891921758651733 0.1589156985282898
decider.lstm.bias_hh_l0: 0.002904490102082491 0.1404377967119217
decider.linear1.weight: 0.0044500334188342094 0.12095824629068375
decider.linear1.bias: 0.017629368230700493 0.11722217500209808
decider.linear2.weight: 0.0043099792674183846 0.05319371074438095
decider.linear2.bias: 0.0070688421837985516 0.05660978704690933
decider.linear3.weight: -0.007954677566885948 0.058269746601581573
decider.linear3.bias: 0.015517456457018852 0.05801497772336006

Rewards:
209.2595
209.2595
209.2595
objective = 42.0026969909668
==== episode 4800/10000 ====
action = 1
probs = 0.3909 0.6002 0.0055 0.0035

action = 0
probs = 0.9572 0.0418 0.0006 0.0004

action = 0
probs = 0.9612 0.0383 0.0003 0.0002

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002067122986773029 0.084903784096241
encoder.encoder.weight_hh_l0: -7.748007192276418e-06 0.08668378740549088
encoder.encoder.bias_ih_l0: 0.012736279517412186 0.08794623613357544
encoder.encoder.bias_hh_l0: 0.022733349353075027 0.08625627309083939
encoder.encoder.weight_ih_l0_reverse: 0.0017626873450353742 0.08716745674610138
encoder.encoder.weight_hh_l0_reverse: 0.007574695628136396 0.08615836501121521
encoder.encoder.bias_ih_l0_reverse: 0.033028122037649155 0.08477737009525299
encoder.encoder.bias_hh_l0_reverse: 0.024893688037991524 0.08293446153402328
decider.lstm.weight_ih_l0: 0.0014398901257663965 0.14798465371131897
decider.lstm.weight_hh_l0: 0.0029550930485129356 0.14769263565540314
decider.lstm.bias_ih_l0: 0.022127853706479073 0.15894056856632233
decider.lstm.bias_hh_l0: 0.003140436951071024 0.14045989513397217
decider.linear1.weight: 0.004455855581909418 0.12101037055253983
decider.linear1.bias: 0.017825491726398468 0.11726659536361694
decider.linear2.weight: 0.004406851716339588 0.05323565751314163
decider.linear2.bias: 0.007220272906124592 0.056670401245355606
decider.linear3.weight: -0.008087899535894394 0.058409493416547775
decider.linear3.bias: 0.0153004489839077 0.05772258713841438

Rewards:
209.2595
209.2595
209.2595
objective = 41.41883850097656
==== episode 4900/10000 ====
action = 0
probs = 0.4499 0.5421 0.0049 0.0031

action = 0
probs = 0.9763 0.0233 0.0003 0.0002

action = 0
probs = 0.9152 0.0844 0.0003 0.0002

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00019347383931744844 0.08489369601011276
encoder.encoder.weight_hh_l0: -8.186697414203081e-06 0.08669254183769226
encoder.encoder.bias_ih_l0: 0.01274513453245163 0.08797510713338852
encoder.encoder.bias_hh_l0: 0.02274220436811447 0.08626709133386612
encoder.encoder.weight_ih_l0_reverse: 0.0017568018520250916 0.08718261122703552
encoder.encoder.weight_hh_l0_reverse: 0.00760225486010313 0.08619250357151031
encoder.encoder.bias_ih_l0_reverse: 0.03304881975054741 0.08482527732849121
encoder.encoder.bias_hh_l0_reverse: 0.024914387613534927 0.08293325453996658
decider.lstm.weight_ih_l0: 0.0014423015527427197 0.14799611270427704
decider.lstm.weight_hh_l0: 0.002957264194265008 0.14770691096782684
decider.lstm.bias_ih_l0: 0.02214857004582882 0.15890350937843323
decider.lstm.bias_hh_l0: 0.003161144210025668 0.14050257205963135
decider.linear1.weight: 0.00445872638374567 0.12103954702615738
decider.linear1.bias: 0.017996111884713173 0.11730843037366867
decider.linear2.weight: 0.004482253920286894 0.053257476538419724
decider.linear2.bias: 0.00735790841281414 0.05669185891747475
decider.linear3.weight: -0.008207789622247219 0.05846940726041794
decider.linear3.bias: 0.015106968581676483 0.05720396712422371

Rewards:
206.9982
206.9982
206.9982
objective = 62.88376998901367
==== episode 5000/10000 ====
action = 1
probs = 0.5167 0.4766 0.0041 0.0026

action = 0
probs = 0.9801 0.0194 0.0003 0.0002

action = 0
probs = 0.9804 0.0194 0.0001 0.0001

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002006899449042976 0.08492767810821533
encoder.encoder.weight_hh_l0: -1.1970531886618119e-05 0.08675365149974823
encoder.encoder.bias_ih_l0: 0.012912478297948837 0.08805821090936661
encoder.encoder.bias_hh_l0: 0.02290954813361168 0.08632571250200272
encoder.encoder.weight_ih_l0_reverse: 0.0017624428728595376 0.08724549412727356
encoder.encoder.weight_hh_l0_reverse: 0.00769752636551857 0.08626550436019897
encoder.encoder.bias_ih_l0_reverse: 0.033247917890548706 0.08489588648080826
encoder.encoder.bias_hh_l0_reverse: 0.025113485753536224 0.08291210234165192
decider.lstm.weight_ih_l0: 0.00147021294105798 0.14803454279899597
decider.lstm.weight_hh_l0: 0.002968018874526024 0.14774532616138458
decider.lstm.bias_ih_l0: 0.02230512537062168 0.1589137464761734
decider.lstm.bias_hh_l0: 0.0033176944125443697 0.14055117964744568
decider.linear1.weight: 0.004469819366931915 0.12110380828380585
decider.linear1.bias: 0.0182420052587986 0.11734296381473541
decider.linear2.weight: 0.004599960520863533 0.05330018326640129
decider.linear2.bias: 0.007540294900536537 0.056737642735242844
decider.linear3.weight: -0.008317604660987854 0.05860450118780136
decider.linear3.bias: 0.014932164922356606 0.0566822811961174

Rewards:
209.2595
209.2595
209.2595
objective = 54.4749755859375
==== episode 5100/10000 ====
action = 1
probs = 0.5272 0.4656 0.0042 0.0029

action = 0
probs = 0.9770 0.0225 0.0003 0.0002

action = 0
probs = 0.9767 0.0231 0.0001 0.0001

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001793672126950696 0.08486928790807724
encoder.encoder.weight_hh_l0: -8.908712516131345e-06 0.08668369054794312
encoder.encoder.bias_ih_l0: 0.01268996112048626 0.08798836916685104
encoder.encoder.bias_hh_l0: 0.0226870346814394 0.08625869452953339
encoder.encoder.weight_ih_l0_reverse: 0.0017512671183794737 0.08718768507242203
encoder.encoder.weight_hh_l0_reverse: 0.0076207653619349 0.08621376007795334
encoder.encoder.bias_ih_l0_reverse: 0.03303253650665283 0.08487002551555634
encoder.encoder.bias_hh_l0_reverse: 0.02489810809493065 0.08293115347623825
decider.lstm.weight_ih_l0: 0.0014344832161441445 0.14799772202968597
decider.lstm.weight_hh_l0: 0.002954695373773575 0.14771419763565063
decider.lstm.bias_ih_l0: 0.022114664316177368 0.15887577831745148
decider.lstm.bias_hh_l0: 0.003127233125269413 0.14054860174655914
decider.linear1.weight: 0.00446573831140995 0.12106729298830032
decider.linear1.bias: 0.018110409379005432 0.11733917146921158
decider.linear2.weight: 0.0045496150851249695 0.05328001081943512
decider.linear2.bias: 0.00748123275116086 0.056728795170784
decider.linear3.weight: -0.00830641109496355 0.058510396629571915
decider.linear3.bias: 0.01495739072561264 0.056653942912817

Rewards:
209.2595
209.2595
209.2595
objective = 56.58266830444336
==== episode 5200/10000 ====
action = 1
probs = 0.6188 0.3754 0.0034 0.0024

action = 0
probs = 0.9889 0.0109 0.0002 0.0001

action = 0
probs = 0.9896 0.0103 0.0001 0.0001

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00018841885321307927 0.08491551876068115
encoder.encoder.weight_hh_l0: -1.327291738562053e-05 0.08676809072494507
encoder.encoder.bias_ih_l0: 0.012910732999444008 0.08809129893779755
encoder.encoder.bias_hh_l0: 0.022907804697752 0.08633890002965927
encoder.encoder.weight_ih_l0_reverse: 0.0017553112702444196 0.08726406842470169
encoder.encoder.weight_hh_l0_reverse: 0.007757226470857859 0.08631063252687454
encoder.encoder.bias_ih_l0_reverse: 0.03331083059310913 0.08495870232582092
encoder.encoder.bias_hh_l0_reverse: 0.0251763928681612 0.08288522809743881
decider.lstm.weight_ih_l0: 0.0014699703315272927 0.1480483114719391
decider.lstm.weight_hh_l0: 0.0029681636951863766 0.14776493608951569
decider.lstm.bias_ih_l0: 0.022318996489048004 0.15889883041381836
decider.lstm.bias_hh_l0: 0.0033315580803900957 0.14060792326927185
decider.linear1.weight: 0.004483074881136417 0.12115365266799927
decider.linear1.bias: 0.018436910584568977 0.11734938621520996
decider.linear2.weight: 0.004716087132692337 0.05333424732089043
decider.linear2.bias: 0.00771186500787735 0.056767068803310394
decider.linear3.weight: -0.008409612812101841 0.058679863810539246
decider.linear3.bias: 0.014792424626648426 0.05600712448358536

Rewards:
209.2595
209.2595
209.2595
objective = 69.84549713134766
==== episode 5300/10000 ====
action = 1
probs = 0.5428 0.4507 0.0036 0.0028

action = 0
probs = 0.9841 0.0155 0.0002 0.0002

action = 0
probs = 0.9840 0.0158 0.0001 0.0001

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00019047758542001247 0.0849086120724678
encoder.encoder.weight_hh_l0: -1.2476765732571948e-05 0.08673233538866043
encoder.encoder.bias_ih_l0: 0.012802011333405972 0.0880286768078804
encoder.encoder.bias_hh_l0: 0.022799082100391388 0.0862954705953598
encoder.encoder.weight_ih_l0_reverse: 0.0017600993160158396 0.08723107725381851
encoder.encoder.weight_hh_l0_reverse: 0.007698103319853544 0.08626248687505722
encoder.encoder.bias_ih_l0_reverse: 0.033187344670295715 0.08488986641168594
encoder.encoder.bias_hh_l0_reverse: 0.025052906945347786 0.08291184902191162
decider.lstm.weight_ih_l0: 0.0014573013177141547 0.14802420139312744
decider.lstm.weight_hh_l0: 0.0029602288268506527 0.14774052798748016
decider.lstm.bias_ih_l0: 0.022232847288250923 0.158912792801857
decider.lstm.bias_hh_l0: 0.0032454056199640036 0.14055684208869934
decider.linear1.weight: 0.004471028223633766 0.12110496312379837
decider.linear1.bias: 0.018220582976937294 0.11733101308345795
decider.linear2.weight: 0.004628284834325314 0.05331619456410408
decider.linear2.bias: 0.007562045473605394 0.0567612424492836
decider.linear3.weight: -0.008379638195037842 0.05861271172761917
decider.linear3.bias: 0.014848622493445873 0.05648611858487129

Rewards:
209.2595
209.2595
209.2595
objective = 57.82186508178711
==== episode 5400/10000 ====
action = 0
probs = 0.5251 0.4690 0.0033 0.0026

action = 0
probs = 0.9854 0.0144 0.0001 0.0001

action = 0
probs = 0.9333 0.0664 0.0001 0.0001

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00018268480198457837 0.08491604775190353
encoder.encoder.weight_hh_l0: -1.1606824045884423e-05 0.08673757314682007
encoder.encoder.bias_ih_l0: 0.012815914116799831 0.08804246038198471
encoder.encoder.bias_hh_l0: 0.02281298115849495 0.0863087847828865
encoder.encoder.weight_ih_l0_reverse: 0.0017613052623346448 0.08723936229944229
encoder.encoder.weight_hh_l0_reverse: 0.007696059998124838 0.08627438545227051
encoder.encoder.bias_ih_l0_reverse: 0.033177100121974945 0.08489183336496353
encoder.encoder.bias_hh_l0_reverse: 0.025042666122317314 0.08293703943490982
decider.lstm.weight_ih_l0: 0.001461452106013894 0.14802882075309753
decider.lstm.weight_hh_l0: 0.00296104047447443 0.14774233102798462
decider.lstm.bias_ih_l0: 0.022250086069107056 0.15888971090316772
decider.lstm.bias_hh_l0: 0.003262652549892664 0.14056073129177094
decider.linear1.weight: 0.004462742246687412 0.12109256535768509
decider.linear1.bias: 0.01821432076394558 0.11738435924053192
decider.linear2.weight: 0.004605093039572239 0.05331706628203392
decider.linear2.bias: 0.007563377730548382 0.05679395794868469
decider.linear3.weight: -0.008480103686451912 0.058612480759620667
decider.linear3.bias: 0.014686242677271366 0.056476693600416183

Rewards:
206.9982
206.9982
206.9982
objective = 50.231624603271484
==== episode 5500/10000 ====
action = 2
probs = 0.4024 0.5923 0.0029 0.0023

action = 0
probs = 0.9657 0.0339 0.0002 0.0002

action = 0
probs = 0.9477 0.0520 0.0001 0.0001

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002120941790053621 0.0850265622138977
encoder.encoder.weight_hh_l0: -1.4739954167453106e-05 0.08684015274047852
encoder.encoder.bias_ih_l0: 0.01310617383569479 0.08811607211828232
encoder.encoder.bias_hh_l0: 0.023103240877389908 0.08639413118362427
encoder.encoder.weight_ih_l0_reverse: 0.001786229433491826 0.08730945736169815
encoder.encoder.weight_hh_l0_reverse: 0.007786915171891451 0.08633726835250854
encoder.encoder.bias_ih_l0_reverse: 0.03344075009226799 0.08486548811197281
encoder.encoder.bias_hh_l0_reverse: 0.02530631422996521 0.08293300867080688
decider.lstm.weight_ih_l0: 0.0015144484350457788 0.14807452261447906
decider.lstm.weight_hh_l0: 0.0029775570146739483 0.14777550101280212
decider.lstm.bias_ih_l0: 0.022508591413497925 0.15895628929138184
decider.lstm.bias_hh_l0: 0.0035211597569286823 0.1405119001865387
decider.linear1.weight: 0.004457812290638685 0.12108661979436874
decider.linear1.bias: 0.018169047310948372 0.11737588793039322
decider.linear2.weight: 0.004561926703900099 0.0533251129090786
decider.linear2.bias: 0.0074907694943249226 0.05686886981129646
decider.linear3.weight: -0.008572116494178772 0.058666426688432693
decider.linear3.bias: 0.014539932832121849 0.0570811852812767

Rewards:
188.7237
188.7237
188.7237
objective = 372.7298583984375
==== episode 5600/10000 ====
action = 1
probs = 0.3633 0.6308 0.0034 0.0025

action = 0
probs = 0.9296 0.0696 0.0004 0.0003

action = 0
probs = 0.9280 0.0716 0.0002 0.0002

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001920024660648778 0.08496788889169693
encoder.encoder.weight_hh_l0: -1.019391947920667e-05 0.0867525041103363
encoder.encoder.bias_ih_l0: 0.012856435030698776 0.08801756054162979
encoder.encoder.bias_hh_l0: 0.02285350300371647 0.0863242968916893
encoder.encoder.weight_ih_l0_reverse: 0.0017709197709336877 0.08723224699497223
encoder.encoder.weight_hh_l0_reverse: 0.007683602627366781 0.08625538647174835
encoder.encoder.bias_ih_l0_reverse: 0.03318178653717041 0.08479435741901398
encoder.encoder.bias_hh_l0_reverse: 0.02504735440015793 0.08296851813793182
decider.lstm.weight_ih_l0: 0.0014724297216162086 0.14802846312522888
decider.lstm.weight_hh_l0: 0.002956609707325697 0.1477307230234146
decider.lstm.bias_ih_l0: 0.022282086312770844 0.15892888605594635
decider.lstm.bias_hh_l0: 0.003294651862233877 0.1404791921377182
decider.linear1.weight: 0.0044514574110507965 0.12102668732404709
decider.linear1.bias: 0.017906183376908302 0.1173754408955574
decider.linear2.weight: 0.004453578498214483 0.05328284204006195
decider.linear2.bias: 0.007353491149842739 0.05684908851981163
decider.linear3.weight: -0.008568674325942993 0.058550115674734116
decider.linear3.bias: 0.014561699703335762 0.057393647730350494

Rewards:
209.2595
209.2595
209.2595
objective = 42.43604278564453
==== episode 5700/10000 ====
action = 1
probs = 0.4480 0.5462 0.0033 0.0025

action = 0
probs = 0.9349 0.0644 0.0004 0.0003

action = 0
probs = 0.9346 0.0650 0.0002 0.0002

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00015792176418472081 0.0848633423447609
encoder.encoder.weight_hh_l0: -3.4056185995723354e-06 0.08664867281913757
encoder.encoder.bias_ih_l0: 0.012532019056379795 0.08793466538190842
encoder.encoder.bias_hh_l0: 0.02252908982336521 0.08624599874019623
encoder.encoder.weight_ih_l0_reverse: 0.001745781279169023 0.08715776354074478
encoder.encoder.weight_hh_l0_reverse: 0.0075849806889891624 0.08619488030672073
encoder.encoder.bias_ih_l0_reverse: 0.032872918993234634 0.08480661362409592
encoder.encoder.bias_hh_l0_reverse: 0.024738486856222153 0.08299385756254196
decider.lstm.weight_ih_l0: 0.0014168653870001435 0.14798177778720856
decider.lstm.weight_hh_l0: 0.002934047719463706 0.14769907295703888
decider.lstm.bias_ih_l0: 0.021997099742293358 0.1588495969772339
decider.lstm.bias_hh_l0: 0.003009666223078966 0.14052392542362213
decider.linear1.weight: 0.004453129600733519 0.1210174486041069
decider.linear1.bias: 0.017895104363560677 0.11739518493413925
decider.linear2.weight: 0.004491970408707857 0.053281333297491074
decider.linear2.bias: 0.007453735452145338 0.05683913826942444
decider.linear3.weight: -0.00868787057697773 0.05853995680809021
decider.linear3.bias: 0.014363648369908333 0.05669655278325081

Rewards:
209.2595
209.2595
209.2595
objective = 51.59727096557617
==== episode 5800/10000 ====
action = 0
probs = 0.6252 0.3701 0.0027 0.0020

action = 0
probs = 0.9829 0.0170 0.0001 0.0001

action = 0
probs = 0.9556 0.0443 0.0001 0.0001

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00015067189815454185 0.08485040068626404
encoder.encoder.weight_hh_l0: -5.2760719881916884e-06 0.08668702840805054
encoder.encoder.bias_ih_l0: 0.012605615891516209 0.08801376819610596
encoder.encoder.bias_hh_l0: 0.022602688521146774 0.0862802267074585
encoder.encoder.weight_ih_l0_reverse: 0.0017378894845023751 0.08720105141401291
encoder.encoder.weight_hh_l0_reverse: 0.0076791075989604 0.08627285063266754
encoder.encoder.bias_ih_l0_reverse: 0.03300589695572853 0.08493751287460327
encoder.encoder.bias_hh_l0_reverse: 0.0248714592307806 0.0829455554485321
decider.lstm.weight_ih_l0: 0.0014200558653101325 0.14800861477851868
decider.lstm.weight_hh_l0: 0.002938102465122938 0.14773628115653992
decider.lstm.bias_ih_l0: 0.022048145532608032 0.158824622631073
decider.lstm.bias_hh_l0: 0.0030607148073613644 0.14063268899917603
decider.linear1.weight: 0.004464695230126381 0.12110075354576111
decider.linear1.bias: 0.018199047073721886 0.1174464076757431
decider.linear2.weight: 0.00468346755951643 0.053333502262830734
decider.linear2.bias: 0.007753133773803711 0.056864332407712936
decider.linear3.weight: -0.008796267211437225 0.058682337403297424
decider.linear3.bias: 0.014184230007231236 0.05547221750020981

Rewards:
206.9982
206.9982
206.9982
objective = 36.737552642822266
==== episode 5900/10000 ====
action = 1
probs = 0.5391 0.4562 0.0027 0.0020

action = 0
probs = 0.9582 0.0414 0.0002 0.0002

action = 1
probs = 0.9580 0.0418 0.0001 0.0001

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00015333987539634109 0.08488596230745316
encoder.encoder.weight_hh_l0: -5.45076136404532e-06 0.08670345693826675
encoder.encoder.bias_ih_l0: 0.01264702994376421 0.08802011609077454
encoder.encoder.bias_hh_l0: 0.022644098848104477 0.08630220592021942
encoder.encoder.weight_ih_l0_reverse: 0.0017511546611785889 0.08721460402011871
encoder.encoder.weight_hh_l0_reverse: 0.00769257266074419 0.08628617972135544
encoder.encoder.bias_ih_l0_reverse: 0.0330486036837101 0.08489783108234406
encoder.encoder.bias_hh_l0_reverse: 0.02491416409611702 0.08298167586326599
decider.lstm.weight_ih_l0: 0.001438014442101121 0.14801789820194244
decider.lstm.weight_hh_l0: 0.0029412023723125458 0.14774048328399658
decider.lstm.bias_ih_l0: 0.022122053429484367 0.15882574021816254
decider.lstm.bias_hh_l0: 0.003134610131382942 0.14058713614940643
decider.linear1.weight: 0.004458111710846424 0.12106592953205109
decider.linear1.bias: 0.01810101792216301 0.11745224893093109
decider.linear2.weight: 0.004613358061760664 0.053322531282901764
decider.linear2.bias: 0.007675030268728733 0.056884508579969406
decider.linear3.weight: -0.008894072845578194 0.05868459865450859
decider.linear3.bias: 0.014023547992110252 0.05591413378715515

Rewards:
218.0870
218.0870
218.0870
objective = 290.9892883300781
==== episode 6000/10000 ====
action = 0
probs = 0.5808 0.4143 0.0026 0.0022

action = 0
probs = 0.9773 0.0225 0.0001 0.0001

action = 0
probs = 0.9200 0.0797 0.0001 0.0001

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001436416059732437 0.0848405584692955
encoder.encoder.weight_hh_l0: -4.7660587370046414e-06 0.08666063100099564
encoder.encoder.bias_ih_l0: 0.012520156800746918 0.08798913657665253
encoder.encoder.bias_hh_l0: 0.022517232224345207 0.08626996725797653
encoder.encoder.weight_ih_l0_reverse: 0.0017436238704249263 0.08719059824943542
encoder.encoder.weight_hh_l0_reverse: 0.0076422919519245625 0.08625492453575134
encoder.encoder.bias_ih_l0_reverse: 0.03292867913842201 0.08491954952478409
encoder.encoder.bias_hh_l0_reverse: 0.024794237688183784 0.08299308270215988
decider.lstm.weight_ih_l0: 0.0014151015784591436 0.14799726009368896
decider.lstm.weight_hh_l0: 0.002936157863587141 0.1477270871400833
decider.lstm.bias_ih_l0: 0.022016556933522224 0.15879037976264954
decider.lstm.bias_hh_l0: 0.0030291180592030287 0.1406066119670868
decider.linear1.weight: 0.004456580616533756 0.12106993049383163
decider.linear1.bias: 0.018095634877681732 0.11744891852140427
decider.linear2.weight: 0.004629053175449371 0.053322479128837585
decider.linear2.bias: 0.007687777280807495 0.05684856325387955
decider.linear3.weight: -0.008842630311846733 0.05865166708827019
decider.linear3.bias: 0.01412849873304367 0.0556982159614563

Rewards:
206.9982
206.9982
206.9982
objective = 44.8186149597168
==== episode 6100/10000 ====
action = 0
probs = 0.5990 0.3966 0.0024 0.0020

action = 0
probs = 0.9801 0.0197 0.0001 0.0001

action = 0
probs = 0.9135 0.0863 0.0001 0.0001

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00014296673180069774 0.08485649526119232
encoder.encoder.weight_hh_l0: -6.837510682089487e-06 0.08668050169944763
encoder.encoder.bias_ih_l0: 0.012575261294841766 0.08802517503499985
encoder.encoder.bias_hh_l0: 0.022572334855794907 0.0862998366355896
encoder.encoder.weight_ih_l0_reverse: 0.001748194103129208 0.0872194841504097
encoder.encoder.weight_hh_l0_reverse: 0.007664836011826992 0.08628343045711517
encoder.encoder.bias_ih_l0_reverse: 0.03297584131360054 0.08494870364665985
encoder.encoder.bias_hh_l0_reverse: 0.02484140545129776 0.08301156759262085
decider.lstm.weight_ih_l0: 0.0014265980571508408 0.1480124294757843
decider.lstm.weight_hh_l0: 0.002939955098554492 0.14774072170257568
decider.lstm.bias_ih_l0: 0.022080035880208015 0.15877816081047058
decider.lstm.bias_hh_l0: 0.003092598170042038 0.14062243700027466
decider.linear1.weight: 0.0044523850083351135 0.12108515202999115
decider.linear1.bias: 0.018164150416851044 0.11747178435325623
decider.linear2.weight: 0.004656210541725159 0.05334052816033363
decider.linear2.bias: 0.007740015629678965 0.056876290589571
decider.linear3.weight: -0.008937401697039604 0.058717504143714905
decider.linear3.bias: 0.013971873559057713 0.05551137775182724

Rewards:
206.9982
206.9982
206.9982
objective = 42.98994064331055
==== episode 6200/10000 ====
action = 0
probs = 0.4024 0.5916 0.0029 0.0031

action = 0
probs = 0.9089 0.0904 0.0003 0.0004

action = 1
probs = 0.6675 0.3319 0.0003 0.0004

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00011918909876840189 0.08480777591466904
encoder.encoder.weight_hh_l0: 6.921553449501516e-06 0.08656039834022522
encoder.encoder.bias_ih_l0: 0.012269081547856331 0.08787741512060165
encoder.encoder.bias_hh_l0: 0.02226615883409977 0.08620362728834152
encoder.encoder.weight_ih_l0_reverse: 0.0017455079359933734 0.08710841089487076
encoder.encoder.weight_hh_l0_reverse: 0.007418014109134674 0.08613428473472595
encoder.encoder.bias_ih_l0_reverse: 0.03254213556647301 0.08476941287517548
encoder.encoder.bias_hh_l0_reverse: 0.024407701566815376 0.08313484489917755
decider.lstm.weight_ih_l0: 0.0013854816788807511 0.14793844521045685
decider.lstm.weight_hh_l0: 0.0029168804176151752 0.14766162633895874
decider.lstm.bias_ih_l0: 0.021810157224535942 0.15874022245407104
decider.lstm.bias_hh_l0: 0.0028227167204022408 0.14049701392650604
decider.linear1.weight: 0.004432977642863989 0.12095876038074493
decider.linear1.bias: 0.017770664766430855 0.1173442080616951
decider.linear2.weight: 0.004341633524745703 0.05326525866985321
decider.linear2.bias: 0.007308884058147669 0.056855227798223495
decider.linear3.weight: -0.008749832399189472 0.0584571436047554
decider.linear3.bias: 0.014266005717217922 0.05703185126185417

Rewards:
198.5688
198.5688
198.5688
objective = 139.5630340576172
==== episode 6300/10000 ====
action = 0
probs = 0.3997 0.5951 0.0025 0.0027

action = 0
probs = 0.9194 0.0801 0.0002 0.0003

action = 0
probs = 0.5907 0.4087 0.0002 0.0003

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00012113802222302184 0.0848519504070282
encoder.encoder.weight_hh_l0: 1.22201436170144e-06 0.08661191165447235
encoder.encoder.bias_ih_l0: 0.012435369193553925 0.08794249594211578
encoder.encoder.bias_hh_l0: 0.022432450205087662 0.0862748846411705
encoder.encoder.weight_ih_l0_reverse: 0.0017414821777492762 0.08716455101966858
encoder.encoder.weight_hh_l0_reverse: 0.0074616787023842335 0.08617958426475525
encoder.encoder.bias_ih_l0_reverse: 0.03266138583421707 0.08481580764055252
encoder.encoder.bias_hh_l0_reverse: 0.02452694997191429 0.08315249532461166
decider.lstm.weight_ih_l0: 0.0014219945296645164 0.14797702431678772
decider.lstm.weight_hh_l0: 0.0029324088245630264 0.14769133925437927
decider.lstm.bias_ih_l0: 0.022024724632501602 0.15874114632606506
decider.lstm.bias_hh_l0: 0.0030372762121260166 0.1404983401298523
decider.linear1.weight: 0.004442769102752209 0.12099334597587585
decider.linear1.bias: 0.017925452440977097 0.11737233400344849
decider.linear2.weight: 0.004397802986204624 0.05329999700188637
decider.linear2.bias: 0.007405701093375683 0.05689232051372528
decider.linear3.weight: -0.008857226930558681 0.05857479199767113
decider.linear3.bias: 0.014073744416236877 0.05694207176566124

Rewards:
206.9982
206.9982
206.9982
objective = 105.39112854003906
==== episode 6400/10000 ====
action = 0
probs = 0.4358 0.5597 0.0022 0.0023

action = 0
probs = 0.9465 0.0531 0.0002 0.0002

action = 1
probs = 0.6627 0.3369 0.0002 0.0002

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00012883286399301142 0.08490616083145142
encoder.encoder.weight_hh_l0: -3.822624421445653e-06 0.08668805658817291
encoder.encoder.bias_ih_l0: 0.012610750272870064 0.08803419023752213
encoder.encoder.bias_hh_l0: 0.02260783687233925 0.08634386211633682
encoder.encoder.weight_ih_l0_reverse: 0.0017539635300636292 0.08723924309015274
encoder.encoder.weight_hh_l0_reverse: 0.0076066297478973866 0.08628065884113312
encoder.encoder.bias_ih_l0_reverse: 0.032936763018369675 0.08487970381975174
encoder.encoder.bias_hh_l0_reverse: 0.024802327156066895 0.08313482254743576
decider.lstm.weight_ih_l0: 0.0014610923826694489 0.148025244474411
decider.lstm.weight_hh_l0: 0.0029487512074410915 0.14773567020893097
decider.lstm.bias_ih_l0: 0.022232340648770332 0.15876230597496033
decider.lstm.bias_hh_l0: 0.0032448971178382635 0.14052742719650269
decider.linear1.weight: 0.004451213404536247 0.12103433161973953
decider.linear1.bias: 0.018066897988319397 0.11743579804897308
decider.linear2.weight: 0.004489250015467405 0.053335562348365784
decider.linear2.bias: 0.007544639520347118 0.05692518129944801
decider.linear3.weight: -0.00898253358900547 0.058706119656562805
decider.linear3.bias: 0.013864702545106411 0.056522712111473083

Rewards:
198.5688
198.5688
198.5688
objective = 130.6212158203125
==== episode 6500/10000 ====
action = 1
probs = 0.4512 0.5448 0.0019 0.0021

action = 0
probs = 0.9480 0.0516 0.0002 0.0003

action = 0
probs = 0.8939 0.1058 0.0001 0.0002

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00013681993004865944 0.08495444804430008
encoder.encoder.weight_hh_l0: -8.209382940549403e-06 0.08674637973308563
encoder.encoder.bias_ih_l0: 0.012760162353515625 0.0880960002541542
encoder.encoder.bias_hh_l0: 0.02275724895298481 0.08640044182538986
encoder.encoder.weight_ih_l0_reverse: 0.0017639044672250748 0.08730281889438629
encoder.encoder.weight_hh_l0_reverse: 0.007726189214736223 0.08635999262332916
encoder.encoder.bias_ih_l0_reverse: 0.03315650299191475 0.08491536974906921
encoder.encoder.bias_hh_l0_reverse: 0.025022068992257118 0.08312931656837463
decider.lstm.weight_ih_l0: 0.0014977303799241781 0.148064985871315
decider.lstm.weight_hh_l0: 0.0029615412931889296 0.14777085185050964
decider.lstm.bias_ih_l0: 0.022419221699237823 0.1587907373905182
decider.lstm.bias_hh_l0: 0.0034317858517169952 0.14054444432258606
decider.linear1.weight: 0.004456773400306702 0.1210615411400795
decider.linear1.bias: 0.018138594925403595 0.11746595054864883
decider.linear2.weight: 0.0045404937118291855 0.053361471742391586
decider.linear2.bias: 0.007624660152941942 0.05697314441204071
decider.linear3.weight: -0.009094097651541233 0.05880946293473244
decider.linear3.bias: 0.013673919253051281 0.05631961673498154

Rewards:
209.2595
209.2595
209.2595
objective = 53.91123580932617
==== episode 6600/10000 ====
action = 1
probs = 0.4776 0.5188 0.0017 0.0019

action = 0
probs = 0.9629 0.0367 0.0001 0.0002

action = 0
probs = 0.9229 0.0769 0.0001 0.0001

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00015086654457263649 0.08500582724809647
encoder.encoder.weight_hh_l0: -1.0391688192612492e-05 0.08681128174066544
encoder.encoder.bias_ih_l0: 0.012898217886686325 0.08817246556282043
encoder.encoder.bias_hh_l0: 0.02289530076086521 0.08645336329936981
encoder.encoder.weight_ih_l0_reverse: 0.0017760898917913437 0.08736052364110947
encoder.encoder.weight_hh_l0_reverse: 0.007838761433959007 0.08643946796655655
encoder.encoder.bias_ih_l0_reverse: 0.03336549550294876 0.0849539190530777
encoder.encoder.bias_hh_l0_reverse: 0.02523105964064598 0.08310393244028091
decider.lstm.weight_ih_l0: 0.001527836313471198 0.14810164272785187
decider.lstm.weight_hh_l0: 0.0029717045836150646 0.14780640602111816
decider.lstm.bias_ih_l0: 0.022563643753528595 0.15882466733455658
decider.lstm.bias_hh_l0: 0.0035762048792093992 0.14055998623371124
decider.linear1.weight: 0.00445631705224514 0.12108753621578217
decider.linear1.bias: 0.018207505345344543 0.1175088882446289
decider.linear2.weight: 0.004624985158443451 0.05338829755783081
decider.linear2.bias: 0.0077376896515488625 0.057012878358364105
decider.linear3.weight: -0.009197894483804703 0.05891954153776169
decider.linear3.bias: 0.013500100001692772 0.05601608380675316

Rewards:
209.2595
209.2595
209.2595
objective = 54.00019836425781
==== episode 6700/10000 ====
action = 1
probs = 0.4130 0.5839 0.0015 0.0016

action = 0
probs = 0.9591 0.0406 0.0001 0.0002

action = 0
probs = 0.9053 0.0944 0.0001 0.0001

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00017391967412550002 0.08509540557861328
encoder.encoder.weight_hh_l0: -1.4495133655145764e-05 0.08689781278371811
encoder.encoder.bias_ih_l0: 0.013152816332876682 0.08825510740280151
encoder.encoder.bias_hh_l0: 0.023149902001023293 0.08653456717729568
encoder.encoder.weight_ih_l0_reverse: 0.0017856063786894083 0.08743122220039368
encoder.encoder.weight_hh_l0_reverse: 0.007904724217951298 0.08649781346321106
encoder.encoder.bias_ih_l0_reverse: 0.033554524183273315 0.08495735377073288
encoder.encoder.bias_hh_l0_reverse: 0.025420088320970535 0.08311166614294052
decider.lstm.weight_ih_l0: 0.001580217620357871 0.14814838767051697
decider.lstm.weight_hh_l0: 0.002991613931953907 0.147840216755867
decider.lstm.bias_ih_l0: 0.022823553532361984 0.15887825191020966
decider.lstm.bias_hh_l0: 0.0038361160550266504 0.1405302882194519
decider.linear1.weight: 0.004454422742128372 0.12110546976327896
decider.linear1.bias: 0.018258797004818916 0.11750846356153488
decider.linear2.weight: 0.0046457103453576565 0.05341274291276932
decider.linear2.bias: 0.007751565892249346 0.057064179331064224
decider.linear3.weight: -0.009292172268033028 0.05902671813964844
decider.linear3.bias: 0.013343879021704197 0.05627545714378357

Rewards:
209.2595
209.2595
209.2595
objective = 47.381710052490234
==== episode 6800/10000 ====
action = 1
probs = 0.5251 0.4720 0.0014 0.0015

action = 0
probs = 0.9804 0.0195 0.0001 0.0001

action = 1
probs = 0.9596 0.0403 0.0001 0.0001

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00017270870739594102 0.08509216457605362
encoder.encoder.weight_hh_l0: -1.3588928595709149e-05 0.08691759407520294
encoder.encoder.bias_ih_l0: 0.013150129467248917 0.0882968157529831
encoder.encoder.bias_hh_l0: 0.023147212341427803 0.08655406534671783
encoder.encoder.weight_ih_l0_reverse: 0.001788428402505815 0.08746316283941269
encoder.encoder.weight_hh_l0_reverse: 0.00800083577632904 0.08655918389558792
encoder.encoder.bias_ih_l0_reverse: 0.03369762748479843 0.08503182977437973
encoder.encoder.bias_hh_l0_reverse: 0.0255631934851408 0.08308719843626022
decider.lstm.weight_ih_l0: 0.0015808515017852187 0.14816373586654663
decider.lstm.weight_hh_l0: 0.0029925263952463865 0.1478661745786667
decider.lstm.bias_ih_l0: 0.02282995730638504 0.15887723863124847
decider.lstm.bias_hh_l0: 0.0038425219245254993 0.14058591425418854
decider.linear1.weight: 0.004465975798666477 0.12114954739809036
decider.linear1.bias: 0.018418163061141968 0.11754729598760605
decider.linear2.weight: 0.0047579435631632805 0.05344516783952713
decider.linear2.bias: 0.00792399886995554 0.057065580040216446
decider.linear3.weight: -0.009382487274706364 0.05913589894771576
decider.linear3.bias: 0.013195235282182693 0.055548857897520065

Rewards:
218.0870
218.0870
218.0870
objective = 289.5062255859375
==== episode 6900/10000 ====
action = 1
probs = 0.4054 0.5915 0.0015 0.0016

action = 0
probs = 0.9218 0.0778 0.0002 0.0003

action = 0
probs = 0.8850 0.1147 0.0001 0.0002

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00015270225412677974 0.08506390452384949
encoder.encoder.weight_hh_l0: -7.731497134955134e-06 0.08685357123613358
encoder.encoder.bias_ih_l0: 0.012912355363368988 0.08819442242383957
encoder.encoder.bias_hh_l0: 0.022909440100193024 0.08650340884923935
encoder.encoder.weight_ih_l0_reverse: 0.0017922568367794156 0.08736652880907059
encoder.encoder.weight_hh_l0_reverse: 0.00795358419418335 0.08650358766317368
encoder.encoder.bias_ih_l0_reverse: 0.03349993750452995 0.08490106463432312
encoder.encoder.bias_hh_l0_reverse: 0.025365499779582024 0.08311549574136734
decider.lstm.weight_ih_l0: 0.001536047668196261 0.14811553061008453
decider.lstm.weight_hh_l0: 0.0029639238491654396 0.1478184014558792
decider.lstm.bias_ih_l0: 0.022559333592653275 0.1588623821735382
decider.lstm.bias_hh_l0: 0.0035718884319067 0.1405198574066162
decider.linear1.weight: 0.004452673718333244 0.12105036526918411
decider.linear1.bias: 0.018015941604971886 0.11752727627754211
decider.linear2.weight: 0.004571149125695229 0.053387418389320374
decider.linear2.bias: 0.007687913719564676 0.0571020245552063
decider.linear3.weight: -0.00947805866599083 0.05899043753743172
decider.linear3.bias: 0.013034084811806679 0.05618427321314812

Rewards:
209.2595
209.2595
209.2595
objective = 50.83172607421875
==== episode 7000/10000 ====
action = 1
probs = 0.2406 0.7572 0.0011 0.0012

action = 0
probs = 0.8296 0.1699 0.0002 0.0003

action = 0
probs = 0.7652 0.2345 0.0001 0.0002

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002119375712936744 0.08527856320142746
encoder.encoder.weight_hh_l0: -1.8996643120772205e-05 0.08706803619861603
encoder.encoder.bias_ih_l0: 0.013593479059636593 0.08836400508880615
encoder.encoder.bias_hh_l0: 0.023590564727783203 0.08669742941856384
encoder.encoder.weight_ih_l0_reverse: 0.0018120347522199154 0.0875186026096344
encoder.encoder.weight_hh_l0_reverse: 0.00809055007994175 0.08662565797567368
encoder.encoder.bias_ih_l0_reverse: 0.03397492319345474 0.08489851653575897
encoder.encoder.bias_hh_l0_reverse: 0.025840483605861664 0.08309169858694077
decider.lstm.weight_ih_l0: 0.0016534504247829318 0.14822673797607422
decider.lstm.weight_hh_l0: 0.0030206814408302307 0.14789815247058868
decider.lstm.bias_ih_l0: 0.02317964844405651 0.15897256135940552
decider.lstm.bias_hh_l0: 0.004192212596535683 0.14045456051826477
decider.linear1.weight: 0.004456042777746916 0.12107034772634506
decider.linear1.bias: 0.018069662153720856 0.11755502969026566
decider.linear2.weight: 0.004539551213383675 0.05340484902262688
decider.linear2.bias: 0.00762523990124464 0.05723460391163826
decider.linear3.weight: -0.009579690173268318 0.0590921975672245
decider.linear3.bias: 0.012862015515565872 0.057251039892435074

Rewards:
209.2595
209.2595
209.2595
objective = 51.10006332397461
==== episode 7100/10000 ====
action = 1
probs = 0.3135 0.6843 0.0011 0.0012

action = 0
probs = 0.9317 0.0680 0.0001 0.0002

action = 0
probs = 0.9048 0.0950 0.0001 0.0001

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00024021390709094703 0.08533024042844772
encoder.encoder.weight_hh_l0: -1.2264787983440328e-05 0.08714063465595245
encoder.encoder.bias_ih_l0: 0.01371670886874199 0.08846908807754517
encoder.encoder.bias_hh_l0: 0.023713797330856323 0.08675039559602737
encoder.encoder.weight_ih_l0_reverse: 0.0018384224968031049 0.08759256452322006
encoder.encoder.weight_hh_l0_reverse: 0.00822435412555933 0.08672554790973663
encoder.encoder.bias_ih_l0_reverse: 0.0342310294508934 0.08499518781900406
encoder.encoder.bias_hh_l0_reverse: 0.02609659545123577 0.0830664411187172
decider.lstm.weight_ih_l0: 0.0016821649624034762 0.14826041460037231
decider.lstm.weight_hh_l0: 0.003027728758752346 0.14794370532035828
decider.lstm.bias_ih_l0: 0.0232989601790905 0.15901604294776917
decider.lstm.bias_hh_l0: 0.004311524797230959 0.140493705868721
decider.linear1.weight: 0.004455722868442535 0.12112020701169968
decider.linear1.bias: 0.018208418041467667 0.11759445071220398
decider.linear2.weight: 0.004669138230383396 0.053450729697942734
decider.linear2.bias: 0.007810770999640226 0.05722227320075035
decider.linear3.weight: -0.009674095548689365 0.05927611142396927
decider.linear3.bias: 0.01270611584186554 0.0564911887049675

Rewards:
209.2595
209.2595
209.2595
objective = 38.37572479248047
==== episode 7200/10000 ====
action = 0
probs = 0.4023 0.5955 0.0010 0.0011

action = 0
probs = 0.9762 0.0237 0.0000 0.0001

action = 0
probs = 0.8709 0.1289 0.0001 0.0001

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002379000943619758 0.08532529324293137
encoder.encoder.weight_hh_l0: -1.0914015547314193e-05 0.08715139329433441
encoder.encoder.bias_ih_l0: 0.013705243356525898 0.08850734680891037
encoder.encoder.bias_hh_l0: 0.023702334612607956 0.08675611019134521
encoder.encoder.weight_ih_l0_reverse: 0.0018372812774032354 0.0876193419098854
encoder.encoder.weight_hh_l0_reverse: 0.008269503712654114 0.08675883710384369
encoder.encoder.bias_ih_l0_reverse: 0.03429458662867546 0.08506119251251221
encoder.encoder.bias_hh_l0_reverse: 0.026160147041082382 0.08304816484451294
decider.lstm.weight_ih_l0: 0.0016841947799548507 0.14827163517475128
decider.lstm.weight_hh_l0: 0.0030278663616627455 0.1479616016149521
decider.lstm.bias_ih_l0: 0.023313693702220917 0.15902161598205566
decider.lstm.bias_hh_l0: 0.004326249472796917 0.14053766429424286
decider.linear1.weight: 0.004468908999115229 0.1211724579334259
decider.linear1.bias: 0.018413087353110313 0.11760284751653671
decider.linear2.weight: 0.004785623401403427 0.05348801985383034
decider.linear2.bias: 0.007985062897205353 0.05721215531229973
decider.linear3.weight: -0.009759695269167423 0.05941314250230789
decider.linear3.bias: 0.012567014433443546 0.055798567831516266

Rewards:
206.9982
206.9982
206.9982
objective = 74.01475524902344
==== episode 7300/10000 ====
action = 0
probs = 0.4409 0.5569 0.0010 0.0012

action = 0
probs = 0.9751 0.0248 0.0000 0.0001

action = 0
probs = 0.8836 0.1163 0.0001 0.0001

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00021627791284117848 0.0852721557021141
encoder.encoder.weight_hh_l0: -9.35665320866974e-06 0.08709856867790222
encoder.encoder.bias_ih_l0: 0.013514681719243526 0.08846461027860641
encoder.encoder.bias_hh_l0: 0.023511771112680435 0.08671141415834427
encoder.encoder.weight_ih_l0_reverse: 0.001830930239520967 0.08757036924362183
encoder.encoder.weight_hh_l0_reverse: 0.008264612406492233 0.08674061298370361
encoder.encoder.bias_ih_l0_reverse: 0.03418128192424774 0.08504905551671982
encoder.encoder.bias_hh_l0_reverse: 0.026046840474009514 0.08305200934410095
decider.lstm.weight_ih_l0: 0.0016466114902868867 0.14824330806732178
decider.lstm.weight_hh_l0: 0.003005816601216793 0.1479395180940628
decider.lstm.bias_ih_l0: 0.023112095892429352 0.15899235010147095
decider.lstm.bias_hh_l0: 0.004124647006392479 0.14055092632770538
decider.linear1.weight: 0.00446739699691534 0.12115638703107834
decider.linear1.bias: 0.01837727800011635 0.11759963631629944
decider.linear2.weight: 0.0047958241775631905 0.05348500981926918
decider.linear2.bias: 0.00801533181220293 0.057214073836803436
decider.linear3.weight: -0.00984451174736023 0.05941350758075714
decider.linear3.bias: 0.012428373098373413 0.05547347664833069

Rewards:
206.9982
206.9982
206.9982
objective = 66.78182220458984
==== episode 7400/10000 ====
action = 1
probs = 0.4884 0.5095 0.0010 0.0011

action = 0
probs = 0.9728 0.0270 0.0001 0.0001

action = 0
probs = 0.9691 0.0308 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002190435625379905 0.08527375012636185
encoder.encoder.weight_hh_l0: -8.106636414595414e-06 0.08710890263319016
encoder.encoder.bias_ih_l0: 0.013528513722121716 0.08848018199205399
encoder.encoder.bias_hh_l0: 0.023525603115558624 0.08671342581510544
encoder.encoder.weight_ih_l0_reverse: 0.0018342019757255912 0.08757957816123962
encoder.encoder.weight_hh_l0_reverse: 0.0083059873431921 0.08676254749298096
encoder.encoder.bias_ih_l0_reverse: 0.03424365818500519 0.08507804572582245
encoder.encoder.bias_hh_l0_reverse: 0.02610921300947666 0.08303099870681763
decider.lstm.weight_ih_l0: 0.0016420326428487897 0.1482488214969635
decider.lstm.weight_hh_l0: 0.0030022284481674433 0.14794786274433136
decider.lstm.bias_ih_l0: 0.023087015375494957 0.15901215374469757
decider.lstm.bias_hh_l0: 0.00409956369549036 0.14057907462120056
decider.linear1.weight: 0.0044771833345294 0.12118109315633774
decider.linear1.bias: 0.01845467835664749 0.11759665608406067
decider.linear2.weight: 0.004859366454184055 0.05350233614444733
decider.linear2.bias: 0.008120053447782993 0.057239633053541183
decider.linear3.weight: -0.00993206724524498 0.059487003833055496
decider.linear3.bias: 0.012283414602279663 0.05508532002568245

Rewards:
209.2595
209.2595
209.2595
objective = 51.144893646240234
==== episode 7500/10000 ====
action = 1
probs = 0.4451 0.5529 0.0009 0.0011

action = 0
probs = 0.9625 0.0373 0.0001 0.0001

action = 0
probs = 0.9625 0.0375 0.0000 0.0001

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022709894983563572 0.08529845625162125
encoder.encoder.weight_hh_l0: -7.615685262862826e-06 0.08712919056415558
encoder.encoder.bias_ih_l0: 0.013579845428466797 0.08848337829113007
encoder.encoder.bias_hh_l0: 0.02357693575322628 0.08672665059566498
encoder.encoder.weight_ih_l0_reverse: 0.001843961770646274 0.08758414536714554
encoder.encoder.weight_hh_l0_reverse: 0.008332675322890282 0.08677592873573303
encoder.encoder.bias_ih_l0_reverse: 0.03429292142391205 0.08505924046039581
encoder.encoder.bias_hh_l0_reverse: 0.02615847997367382 0.0830276608467102
decider.lstm.weight_ih_l0: 0.0016477954341098666 0.14825433492660522
decider.lstm.weight_hh_l0: 0.0030016396194696426 0.14795136451721191
decider.lstm.bias_ih_l0: 0.023100782185792923 0.1590377539396286
decider.lstm.bias_hh_l0: 0.0041133263148367405 0.14056240022182465
decider.linear1.weight: 0.004481336567550898 0.12116847932338715
decider.linear1.bias: 0.018383005633950233 0.11759309470653534
decider.linear2.weight: 0.004849090240895748 0.053501781076192856
decider.linear2.bias: 0.00811032485216856 0.0572708398103714
decider.linear3.weight: -0.010019024834036827 0.05952465534210205
decider.linear3.bias: 0.012139515951275826 0.05521883815526962

Rewards:
209.2595
209.2595
209.2595
objective = 46.66549301147461
==== episode 7600/10000 ====
action = 1
probs = 0.6167 0.3810 0.0010 0.0013

action = 0
probs = 0.9816 0.0182 0.0001 0.0001

action = 0
probs = 0.9809 0.0190 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00016089141718111932 0.08512479811906815
encoder.encoder.weight_hh_l0: -6.511092124128481e-06 0.0869612842798233
encoder.encoder.bias_ih_l0: 0.013025606982409954 0.08835645020008087
encoder.encoder.bias_hh_l0: 0.023022696375846863 0.08656758069992065
encoder.encoder.weight_ih_l0_reverse: 0.0018169943941757083 0.08746012300252914
encoder.encoder.weight_hh_l0_reverse: 0.00823801290243864 0.08669020980596542
encoder.encoder.bias_ih_l0_reverse: 0.033915091305971146 0.08506715297698975
encoder.encoder.bias_hh_l0_reverse: 0.025780653581023216 0.08303223550319672
decider.lstm.weight_ih_l0: 0.0015492994571104646 0.1481698602437973
decider.lstm.weight_hh_l0: 0.0029613254591822624 0.14788493514060974
decider.lstm.bias_ih_l0: 0.02261962927877903 0.158939927816391
decider.lstm.bias_hh_l0: 0.0036321645602583885 0.1406317949295044
decider.linear1.weight: 0.004482636693865061 0.12116546183824539
decider.linear1.bias: 0.018390629440546036 0.1175730973482132
decider.linear2.weight: 0.004865190479904413 0.053488630801439285
decider.linear2.bias: 0.00814160518348217 0.05718371644616127
decider.linear3.weight: -0.009892452508211136 0.05940164998173714
decider.linear3.bias: 0.012396195903420448 0.054422859102487564

Rewards:
209.2595
209.2595
209.2595
objective = 69.95602416992188
==== episode 7700/10000 ====
action = 0
probs = 0.6288 0.3691 0.0009 0.0012

action = 0
probs = 0.9888 0.0111 0.0000 0.0000

action = 0
probs = 0.9631 0.0368 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00016523274825885892 0.08515029400587082
encoder.encoder.weight_hh_l0: -6.7016003413300496e-06 0.08699502795934677
encoder.encoder.bias_ih_l0: 0.013115598820149899 0.08839252591133118
encoder.encoder.bias_hh_l0: 0.023112690076231956 0.08660145103931427
encoder.encoder.weight_ih_l0_reverse: 0.0018139827298000455 0.08749163150787354
encoder.encoder.weight_hh_l0_reverse: 0.008280305191874504 0.08672476559877396
encoder.encoder.bias_ih_l0_reverse: 0.034004390239715576 0.08510017395019531
encoder.encoder.bias_hh_l0_reverse: 0.025869952514767647 0.0830162763595581
decider.lstm.weight_ih_l0: 0.001567576895467937 0.14819276332855225
decider.lstm.weight_hh_l0: 0.0029690894298255444 0.14790701866149902
decider.lstm.bias_ih_l0: 0.022724391892552376 0.1589522808790207
decider.lstm.bias_hh_l0: 0.0037369290366768837 0.1406477391719818
decider.linear1.weight: 0.004487817641347647 0.12119109183549881
decider.linear1.bias: 0.018479907885193825 0.11757232993841171
decider.linear2.weight: 0.004915308207273483 0.05350714921951294
decider.linear2.bias: 0.008219516836106777 0.057211726903915405
decider.linear3.weight: -0.009976555593311787 0.05948260426521301
decider.linear3.bias: 0.012253031134605408 0.0542256124317646

Rewards:
206.9982
206.9982
206.9982
objective = 35.38227081298828
==== episode 7800/10000 ====
action = 1
probs = 0.6392 0.3588 0.0009 0.0011

action = 0
probs = 0.9845 0.0154 0.0000 0.0001

action = 0
probs = 0.9847 0.0153 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00016386840434279293 0.0851592943072319
encoder.encoder.weight_hh_l0: -6.38105848338455e-06 0.08700823783874512
encoder.encoder.bias_ih_l0: 0.013138827867805958 0.08841083198785782
encoder.encoder.bias_hh_l0: 0.023135919123888016 0.08661312609910965
encoder.encoder.weight_ih_l0_reverse: 0.001815088209696114 0.0875035896897316
encoder.encoder.weight_hh_l0_reverse: 0.008304335176944733 0.0867442861199379
encoder.encoder.bias_ih_l0_reverse: 0.03403641656041145 0.08511466532945633
encoder.encoder.bias_hh_l0_reverse: 0.025901982560753822 0.08301364630460739
decider.lstm.weight_ih_l0: 0.0015728636644780636 0.1482008844614029
decider.lstm.weight_hh_l0: 0.0029709236696362495 0.1479147970676422
decider.lstm.bias_ih_l0: 0.022746633738279343 0.15895229578018188
decider.lstm.bias_hh_l0: 0.003759163897484541 0.14065976440906525
decider.linear1.weight: 0.00449182465672493 0.12120155990123749
decider.linear1.bias: 0.01852303184568882 0.11758099496364594
decider.linear2.weight: 0.004941796883940697 0.05351899191737175
decider.linear2.bias: 0.00826670415699482 0.0572364367544651
decider.linear3.weight: -0.010057341307401657 0.059540752321481705
decider.linear3.bias: 0.012115994468331337 0.05407629534602165

Rewards:
209.2595
209.2595
209.2595
objective = 73.66184997558594
==== episode 7900/10000 ====
action = 0
probs = 0.7621 0.2365 0.0006 0.0008

action = 0
probs = 0.9956 0.0044 0.0000 0.0000

action = 0
probs = 0.9851 0.0149 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00015817437088117003 0.08520114421844482
encoder.encoder.weight_hh_l0: -5.574703209276777e-06 0.08709292113780975
encoder.encoder.bias_ih_l0: 0.013376676477491856 0.08853704482316971
encoder.encoder.bias_hh_l0: 0.023373769596219063 0.08671241253614426
encoder.encoder.weight_ih_l0_reverse: 0.0017864482942968607 0.08758723735809326
encoder.encoder.weight_hh_l0_reverse: 0.00841314997524023 0.08684075623750687
encoder.encoder.bias_ih_l0_reverse: 0.034259356558322906 0.0852612629532814
encoder.encoder.bias_hh_l0_reverse: 0.026124924421310425 0.08294805139303207
decider.lstm.weight_ih_l0: 0.001607756013981998 0.1482652872800827
decider.lstm.weight_hh_l0: 0.0029902018141001463 0.14797313511371613
decider.lstm.bias_ih_l0: 0.023001782596111298 0.15893922746181488
decider.lstm.bias_hh_l0: 0.004014324396848679 0.14076386392116547
decider.linear1.weight: 0.00449120718985796 0.12131255120038986
decider.linear1.bias: 0.018943820148706436 0.11760889738798141
decider.linear2.weight: 0.005109481979161501 0.05357867479324341
decider.linear2.bias: 0.008530604653060436 0.057289641350507736
decider.linear3.weight: -0.010127924382686615 0.05966859683394432
decider.linear3.bias: 0.01199790183454752 0.053161706775426865

Rewards:
206.9982
206.9982
206.9982
objective = 20.08678436279297
==== episode 8000/10000 ====
action = 0
probs = 0.7677 0.2305 0.0007 0.0011

action = 0
probs = 0.9961 0.0038 0.0000 0.0000

action = 0
probs = 0.9865 0.0135 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001448359980713576 0.08513472229242325
encoder.encoder.weight_hh_l0: -4.9947739171329886e-06 0.08701576292514801
encoder.encoder.bias_ih_l0: 0.013152096420526505 0.08845192193984985
encoder.encoder.bias_hh_l0: 0.023149188607931137 0.08662372082471848
encoder.encoder.weight_ih_l0_reverse: 0.001785803702659905 0.08752374351024628
encoder.encoder.weight_hh_l0_reverse: 0.008339492604136467 0.08677941560745239
encoder.encoder.bias_ih_l0_reverse: 0.03408043459057808 0.08522757887840271
encoder.encoder.bias_hh_l0_reverse: 0.02594600059092045 0.0829552710056305
decider.lstm.weight_ih_l0: 0.0015639443881809711 0.1482180953025818
decider.lstm.weight_hh_l0: 0.0029739639721810818 0.14793407917022705
decider.lstm.bias_ih_l0: 0.022770801559090614 0.15892393887043
decider.lstm.bias_hh_l0: 0.003783344989642501 0.14076055586338043
decider.linear1.weight: 0.004496182315051556 0.12129013240337372
decider.linear1.bias: 0.01883155107498169 0.11756183207035065
decider.linear2.weight: 0.005071178078651428 0.053555794060230255
decider.linear2.bias: 0.008443022146821022 0.057230621576309204
decider.linear3.weight: -0.009983108378946781 0.059580009430646896
decider.linear3.bias: 0.01227328460663557 0.05329551175236702

Rewards:
206.9982
206.9982
206.9982
objective = 19.44330596923828
==== episode 8100/10000 ====
action = 0
probs = 0.7823 0.2161 0.0006 0.0010

action = 0
probs = 0.9958 0.0042 0.0000 0.0000

action = 0
probs = 0.9852 0.0147 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00013702563592232764 0.08514150232076645
encoder.encoder.weight_hh_l0: -4.867887582804542e-06 0.08702931553125381
encoder.encoder.bias_ih_l0: 0.013172418810427189 0.08849090337753296
encoder.encoder.bias_hh_l0: 0.023169510066509247 0.086642786860466
encoder.encoder.weight_ih_l0_reverse: 0.0017842156812548637 0.08753788471221924
encoder.encoder.weight_hh_l0_reverse: 0.008379637263715267 0.08681806921958923
encoder.encoder.bias_ih_l0_reverse: 0.034122489392757416 0.08525041490793228
encoder.encoder.bias_hh_l0_reverse: 0.025988059118390083 0.08296651393175125
decider.lstm.weight_ih_l0: 0.0015689136926084757 0.14823001623153687
decider.lstm.weight_hh_l0: 0.0029755192808806896 0.14794382452964783
decider.lstm.bias_ih_l0: 0.022793177515268326 0.1588939130306244
decider.lstm.bias_hh_l0: 0.003805716522037983 0.14078381657600403
decider.linear1.weight: 0.0044929636642336845 0.12128789722919464
decider.linear1.bias: 0.01885407604277134 0.11760715395212173
decider.linear2.weight: 0.005057868547737598 0.053558070212602615
decider.linear2.bias: 0.008462432771921158 0.057242054492235184
decider.linear3.weight: -0.01004558801651001 0.059589412063360214
decider.linear3.bias: 0.012170000933110714 0.05312848463654518

Rewards:
206.9982
206.9982
206.9982
objective = 18.260929107666016
==== episode 8200/10000 ====
action = 0
probs = 0.8535 0.1454 0.0004 0.0007

action = 0
probs = 0.9972 0.0028 0.0000 0.0000

action = 0
probs = 0.9870 0.0130 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00013085514365229756 0.0852198526263237
encoder.encoder.weight_hh_l0: -5.880343906028429e-06 0.08714452385902405
encoder.encoder.bias_ih_l0: 0.013486990705132484 0.08868934959173203
encoder.encoder.bias_hh_l0: 0.02348407916724682 0.08678548783063889
encoder.encoder.weight_ih_l0_reverse: 0.0017606517067179084 0.08764391392469406
encoder.encoder.weight_hh_l0_reverse: 0.008544838055968285 0.08696667104959488
encoder.encoder.bias_ih_l0_reverse: 0.034416310489177704 0.08538955450057983
encoder.encoder.bias_hh_l0_reverse: 0.02628188021481037 0.08295482397079468
decider.lstm.weight_ih_l0: 0.0016221004771068692 0.14831432700157166
decider.lstm.weight_hh_l0: 0.002997038885951042 0.14801320433616638
decider.lstm.bias_ih_l0: 0.023117925971746445 0.1588391214609146
decider.lstm.bias_hh_l0: 0.0041304659098386765 0.14086684584617615
decider.linear1.weight: 0.004465674515813589 0.12135187536478043
decider.linear1.bias: 0.019163714721798897 0.11773322522640228
decider.linear2.weight: 0.005104392766952515 0.05359581112861633
decider.linear2.bias: 0.008604295551776886 0.05726172775030136
decider.linear3.weight: -0.01010255515575409 0.05962132290005684
decider.linear3.bias: 0.012077544815838337 0.05243764817714691

Rewards:
206.9982
206.9982
206.9982
objective = 12.029104232788086
==== episode 8300/10000 ====
action = 0
probs = 0.8867 0.1125 0.0003 0.0005

action = 0
probs = 0.9983 0.0017 0.0000 0.0000

action = 0
probs = 0.9917 0.0083 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001414706202922389 0.0852881595492363
encoder.encoder.weight_hh_l0: -7.262253802764462e-06 0.08723268657922745
encoder.encoder.bias_ih_l0: 0.013743972405791283 0.08879327774047852
encoder.encoder.bias_hh_l0: 0.023741060867905617 0.08688974380493164
encoder.encoder.weight_ih_l0_reverse: 0.0017421056982129812 0.08772147446870804
encoder.encoder.weight_hh_l0_reverse: 0.00861324742436409 0.08702662587165833
encoder.encoder.bias_ih_l0_reverse: 0.03460266813635826 0.08547845482826233
encoder.encoder.bias_hh_l0_reverse: 0.026468243449926376 0.08291927725076675
decider.lstm.weight_ih_l0: 0.0016643630806356668 0.14837349951267242
decider.lstm.weight_hh_l0: 0.003015091409906745 0.14806222915649414
decider.lstm.bias_ih_l0: 0.0233983863145113 0.1588517278432846
decider.lstm.bias_hh_l0: 0.004410924855619669 0.14090396463871002
decider.linear1.weight: 0.00445971917361021 0.12142487615346909
decider.linear1.bias: 0.019423147663474083 0.1177639588713646
decider.linear2.weight: 0.005207189358770847 0.05363478511571884
decider.linear2.bias: 0.008761652745306492 0.057309847325086594
decider.linear3.weight: -0.01014769822359085 0.0597066730260849
decider.linear3.bias: 0.012007087469100952 0.05201816186308861

Rewards:
206.9982
206.9982
206.9982
objective = 8.996618270874023
==== episode 8400/10000 ====
action = 0
probs = 0.8918 0.1074 0.0003 0.0005

action = 0
probs = 0.9984 0.0016 0.0000 0.0000

action = 0
probs = 0.9921 0.0079 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00014435812772717327 0.08530963957309723
encoder.encoder.weight_hh_l0: -7.724189345026389e-06 0.08725836127996445
encoder.encoder.bias_ih_l0: 0.013814345002174377 0.08882567286491394
encoder.encoder.bias_hh_l0: 0.023811429738998413 0.0869184359908104
encoder.encoder.weight_ih_l0_reverse: 0.0017394318711012602 0.08774465322494507
encoder.encoder.weight_hh_l0_reverse: 0.008636826649308205 0.08704856038093567
encoder.encoder.bias_ih_l0_reverse: 0.03465664014220238 0.08549901098012924
encoder.encoder.bias_hh_l0_reverse: 0.026522215455770493 0.08291693031787872
decider.lstm.weight_ih_l0: 0.0016774119576439261 0.14839039742946625
decider.lstm.weight_hh_l0: 0.0030200255569070578 0.1480766385793686
decider.lstm.bias_ih_l0: 0.023472191765904427 0.15885517001152039
decider.lstm.bias_hh_l0: 0.00448472797870636 0.14091187715530396
decider.linear1.weight: 0.004456589929759502 0.12144151329994202
decider.linear1.bias: 0.019487066194415092 0.11776892095804214
decider.linear2.weight: 0.005231364630162716 0.05364525690674782
decider.linear2.bias: 0.008800017647445202 0.05732366815209389
decider.linear3.weight: -0.010189162567257881 0.05974399670958519
decider.linear3.bias: 0.011943322606384754 0.05191458389163017

Rewards:
206.9982
206.9982
206.9982
objective = 8.560876846313477
==== episode 8500/10000 ====
action = 0
probs = 0.9003 0.0990 0.0003 0.0005

action = 0
probs = 0.9986 0.0014 0.0000 0.0000

action = 0
probs = 0.9927 0.0073 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00014690398529637605 0.08533531427383423
encoder.encoder.weight_hh_l0: -8.169447937689256e-06 0.08728983253240585
encoder.encoder.bias_ih_l0: 0.013897871598601341 0.0888664647936821
encoder.encoder.bias_hh_l0: 0.023894960060715675 0.08695437759160995
encoder.encoder.weight_ih_l0_reverse: 0.0017342775827273726 0.0877717137336731
encoder.encoder.weight_hh_l0_reverse: 0.00866700429469347 0.08707632124423981
encoder.encoder.bias_ih_l0_reverse: 0.03472087159752846 0.08552557229995728
encoder.encoder.bias_hh_l0_reverse: 0.026586446911096573 0.08291283249855042
decider.lstm.weight_ih_l0: 0.001692647929303348 0.1484108716249466
decider.lstm.weight_hh_l0: 0.003025968326255679 0.148093581199646
decider.lstm.bias_ih_l0: 0.02356058731675148 0.1588561087846756
decider.lstm.bias_hh_l0: 0.004573123995214701 0.1409221589565277
decider.linear1.weight: 0.004452139139175415 0.1214592307806015
decider.linear1.bias: 0.019555414095520973 0.11778959631919861
decider.linear2.weight: 0.005261101294308901 0.05365649238228798
decider.linear2.bias: 0.008844230324029922 0.05733717978000641
decider.linear3.weight: -0.010227762162685394 0.05977925285696983
decider.linear3.bias: 0.01188481505960226 0.05178380012512207

Rewards:
206.9982
206.9982
206.9982
objective = 7.852652549743652
==== episode 8600/10000 ====
action = 0
probs = 0.8928 0.1065 0.0003 0.0005

action = 0
probs = 0.9984 0.0016 0.0000 0.0000

action = 0
probs = 0.9915 0.0085 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00014557830581907183 0.08532742410898209
encoder.encoder.weight_hh_l0: -7.609391104779206e-06 0.08727703243494034
encoder.encoder.bias_ih_l0: 0.01385454647243023 0.08885430544614792
encoder.encoder.bias_hh_l0: 0.023851634934544563 0.08694005757570267
encoder.encoder.weight_ih_l0_reverse: 0.0017364250961691141 0.08776137977838516
encoder.encoder.weight_hh_l0_reverse: 0.008670140989124775 0.08707883954048157
encoder.encoder.bias_ih_l0_reverse: 0.034700483083724976 0.08551102876663208
encoder.encoder.bias_hh_l0_reverse: 0.026566054672002792 0.08292234688997269
decider.lstm.weight_ih_l0: 0.0016873374115675688 0.14840301871299744
decider.lstm.weight_hh_l0: 0.0030225461814552546 0.1480884701013565
decider.lstm.bias_ih_l0: 0.023516185581684113 0.15885251760482788
decider.lstm.bias_hh_l0: 0.004528714809566736 0.14091233909130096
decider.linear1.weight: 0.0044503044337034225 0.12144383788108826
decider.linear1.bias: 0.01950039714574814 0.11778847128152847
decider.linear2.weight: 0.0052444953471422195 0.053652141243219376
decider.linear2.bias: 0.008820309303700924 0.05733271315693855
decider.linear3.weight: -0.010267013683915138 0.059791870415210724
decider.linear3.bias: 0.011825417168438435 0.05184442177414894

Rewards:
206.9982
206.9982
206.9982
objective = 8.528512954711914
==== episode 8700/10000 ====
action = 0
probs = 0.8840 0.1152 0.0003 0.0005

action = 0
probs = 0.9983 0.0017 0.0000 0.0000

action = 0
probs = 0.9907 0.0093 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00014530908083543181 0.08531466871500015
encoder.encoder.weight_hh_l0: -7.1804165600042325e-06 0.08725795149803162
encoder.encoder.bias_ih_l0: 0.013799754902720451 0.08882927894592285
encoder.encoder.bias_hh_l0: 0.023796843364834785 0.08691808581352234
encoder.encoder.weight_ih_l0_reverse: 0.0017404579557478428 0.08774780482053757
encoder.encoder.weight_hh_l0_reverse: 0.008657890371978283 0.08706867694854736
encoder.encoder.bias_ih_l0_reverse: 0.03466568514704704 0.08549365401268005
encoder.encoder.bias_hh_l0_reverse: 0.026531262323260307 0.0829285979270935
decider.lstm.weight_ih_l0: 0.0016793982358649373 0.14839132130146027
decider.lstm.weight_hh_l0: 0.003018207149580121 0.14808030426502228
decider.lstm.bias_ih_l0: 0.02346157655119896 0.15885481238365173
decider.lstm.bias_hh_l0: 0.004474102985113859 0.1409010887145996
decider.linear1.weight: 0.004450622946023941 0.12143073230981827
decider.linear1.bias: 0.01944618858397007 0.11777843534946442
decider.linear2.weight: 0.005238017067313194 0.05364824831485748
decider.linear2.bias: 0.008799162693321705 0.05733369290828705
decider.linear3.weight: -0.01030812505632639 0.059812698513269424
decider.linear3.bias: 0.011763057671487331 0.05192643776535988

Rewards:
206.9982
206.9982
206.9982
objective = 9.273116111755371
==== episode 8800/10000 ====
action = 0
probs = 0.8576 0.1414 0.0003 0.0006

action = 0
probs = 0.9975 0.0025 0.0000 0.0000

action = 0
probs = 0.9860 0.0140 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00014036588254384696 0.08527685701847076
encoder.encoder.weight_hh_l0: -6.31380044069374e-06 0.08720526844263077
encoder.encoder.bias_ih_l0: 0.013644875958561897 0.08877119421958923
encoder.encoder.bias_hh_l0: 0.023641955107450485 0.0868573933839798
encoder.encoder.weight_ih_l0_reverse: 0.0017528226599097252 0.08770732581615448
encoder.encoder.weight_hh_l0_reverse: 0.008634639903903008 0.08704986423254013
encoder.encoder.bias_ih_l0_reverse: 0.0345764197409153 0.08543966710567474
encoder.encoder.bias_hh_l0_reverse: 0.026441998779773712 0.08295480906963348
decider.lstm.weight_ih_l0: 0.0016543297097086906 0.14835761487483978
decider.lstm.weight_hh_l0: 0.003004771191626787 0.14805373549461365
decider.lstm.bias_ih_l0: 0.023292381316423416 0.15884807705879211
decider.lstm.bias_hh_l0: 0.004304909147322178 0.14087530970573425
decider.linear1.weight: 0.004445010796189308 0.12138351052999496
decider.linear1.bias: 0.019286802038550377 0.11775844544172287
decider.linear2.weight: 0.005169984418898821 0.05362679064273834
decider.linear2.bias: 0.008699450641870499 0.05730906501412392
decider.linear3.weight: -0.0103541174903512 0.05980284884572029
decider.linear3.bias: 0.011692590080201626 0.0522141307592392

Rewards:
206.9982
206.9982
206.9982
objective = 11.743781089782715
==== episode 8900/10000 ====
action = 0
probs = 0.8112 0.1877 0.0004 0.0007

action = 0
probs = 0.9965 0.0035 0.0000 0.0000

action = 0
probs = 0.9801 0.0198 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001421626948285848 0.08523194491863251
encoder.encoder.weight_hh_l0: -5.876183422515169e-06 0.08713863790035248
encoder.encoder.bias_ih_l0: 0.013461803086102009 0.08867233246564865
encoder.encoder.bias_hh_l0: 0.02345888502895832 0.0867827758193016
encoder.encoder.weight_ih_l0_reverse: 0.0017659201985225081 0.08765792846679688
encoder.encoder.weight_hh_l0_reverse: 0.008574195206165314 0.0869959145784378
encoder.encoder.bias_ih_l0_reverse: 0.03445305675268173 0.08537622541189194
encoder.encoder.bias_hh_l0_reverse: 0.026318632066249847 0.08297310024499893
decider.lstm.weight_ih_l0: 0.0016232747584581375 0.14831240475177765
decider.lstm.weight_hh_l0: 0.0029896495398133993 0.14801867306232452
decider.lstm.bias_ih_l0: 0.023101288825273514 0.15886259078979492
decider.lstm.bias_hh_l0: 0.004113831557333469 0.14082981646060944
decider.linear1.weight: 0.004443416837602854 0.12133875489234924
decider.linear1.bias: 0.019100505858659744 0.11771194636821747
decider.linear2.weight: 0.005123022943735123 0.053604789078235626
decider.linear2.bias: 0.008596256375312805 0.05730057135224342
decider.linear3.weight: -0.010420937091112137 0.059828221797943115
decider.linear3.bias: 0.011585433967411518 0.05262841656804085

Rewards:
206.9982
206.9982
206.9982
objective = 16.061553955078125
==== episode 9000/10000 ====
action = 1
probs = 0.7318 0.2669 0.0005 0.0009

action = 0
probs = 0.9898 0.0102 0.0000 0.0000

action = 0
probs = 0.9869 0.0131 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001382288319291547 0.08518391847610474
encoder.encoder.weight_hh_l0: -4.1761754800972994e-06 0.08706720173358917
encoder.encoder.bias_ih_l0: 0.01325057353824377 0.08856139332056046
encoder.encoder.bias_hh_l0: 0.023247653618454933 0.08669717609882355
encoder.encoder.weight_ih_l0_reverse: 0.0017866370035335422 0.0875973105430603
encoder.encoder.weight_hh_l0_reverse: 0.008523950353264809 0.08694838732481003
encoder.encoder.bias_ih_l0_reverse: 0.034330230206251144 0.08528389036655426
encoder.encoder.bias_hh_l0_reverse: 0.02619580738246441 0.08299729973077774
decider.lstm.weight_ih_l0: 0.001584421843290329 0.14825811982154846
decider.lstm.weight_hh_l0: 0.0029684966430068016 0.1479751318693161
decider.lstm.bias_ih_l0: 0.022856447845697403 0.1588781774044037
decider.lstm.bias_hh_l0: 0.003868984756991267 0.14078161120414734
decider.linear1.weight: 0.004439454060047865 0.12126872688531876
decider.linear1.bias: 0.018833806738257408 0.11769043654203415
decider.linear2.weight: 0.005013527814298868 0.05357074737548828
decider.linear2.bias: 0.008429281413555145 0.057292740792036057
decider.linear3.weight: -0.010501038283109665 0.05982280895113945
decider.linear3.bias: 0.011454308405518532 0.05319322273135185

Rewards:
209.2595
209.2595
209.2595
objective = 93.78736877441406
==== episode 9100/10000 ====
action = 0
probs = 0.7334 0.2653 0.0005 0.0008

action = 0
probs = 0.9925 0.0075 0.0000 0.0000

action = 0
probs = 0.9642 0.0357 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00013817925355397165 0.08518534898757935
encoder.encoder.weight_hh_l0: -4.769682618643856e-06 0.08706831187009811
encoder.encoder.bias_ih_l0: 0.01324253249913454 0.08856987953186035
encoder.encoder.bias_hh_l0: 0.023239614441990852 0.08670070767402649
encoder.encoder.weight_ih_l0_reverse: 0.0017875870689749718 0.0876016691327095
encoder.encoder.weight_hh_l0_reverse: 0.008531625382602215 0.08695703744888306
encoder.encoder.bias_ih_l0_reverse: 0.03433055430650711 0.08529043942689896
encoder.encoder.bias_hh_l0_reverse: 0.026196131482720375 0.08300602436065674
decider.lstm.weight_ih_l0: 0.001584985526278615 0.1482604593038559
decider.lstm.weight_hh_l0: 0.002968402812257409 0.14797742664813995
decider.lstm.bias_ih_l0: 0.022855479270219803 0.15886954963207245
decider.lstm.bias_hh_l0: 0.0038680073339492083 0.1407839059829712
decider.linear1.weight: 0.004438359290361404 0.12126794457435608
decider.linear1.bias: 0.01883627474308014 0.11769770830869675
decider.linear2.weight: 0.005015141796320677 0.053575966507196426
decider.linear2.bias: 0.00844447873532772 0.057304758578538895
decider.linear3.weight: -0.010591006837785244 0.05987723916769028
decider.linear3.bias: 0.011304507963359356 0.05310962721705437

Rewards:
206.9982
206.9982
206.9982
objective = 24.4274959564209
==== episode 9200/10000 ====
action = 0
probs = 0.6536 0.3451 0.0005 0.0009

action = 0
probs = 0.9895 0.0105 0.0000 0.0000

action = 0
probs = 0.9571 0.0428 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00016226123261731118 0.08520729094743729
encoder.encoder.weight_hh_l0: -3.943240699300077e-06 0.08707047998905182
encoder.encoder.bias_ih_l0: 0.013282169587910175 0.08852700889110565
encoder.encoder.bias_hh_l0: 0.02327924594283104 0.08668702095746994
encoder.encoder.weight_ih_l0_reverse: 0.0018014719244092703 0.08760208636522293
encoder.encoder.weight_hh_l0_reverse: 0.008514132350683212 0.08693026751279831
encoder.encoder.bias_ih_l0_reverse: 0.03436582162976265 0.08523853123188019
encoder.encoder.bias_hh_l0_reverse: 0.026231398805975914 0.08301109820604324
decider.lstm.weight_ih_l0: 0.0015902925515547395 0.14824984967708588
decider.lstm.weight_hh_l0: 0.002964301034808159 0.14796839654445648
decider.lstm.bias_ih_l0: 0.022843144834041595 0.1589486300945282
decider.lstm.bias_hh_l0: 0.0038556652143597603 0.14072862267494202
decider.linear1.weight: 0.004439846612513065 0.1212557703256607
decider.linear1.bias: 0.018752189353108406 0.11767123639583588
decider.linear2.weight: 0.005003940314054489 0.053570572286844254
decider.linear2.bias: 0.008390916511416435 0.05734648555517197
decider.linear3.weight: -0.010686641559004784 0.059961237013339996
decider.linear3.bias: 0.011144265532493591 0.0535745806992054

Rewards:
206.9982
206.9982
206.9982
objective = 33.096466064453125
==== episode 9300/10000 ====
action = 0
probs = 0.6587 0.3396 0.0007 0.0010

action = 0
probs = 0.9920 0.0080 0.0000 0.0000

action = 0
probs = 0.9688 0.0312 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00015591464762110263 0.08512362837791443
encoder.encoder.weight_hh_l0: -3.27939983435499e-06 0.0869704857468605
encoder.encoder.bias_ih_l0: 0.013021325692534447 0.08839733153581619
encoder.encoder.bias_hh_l0: 0.023018406704068184 0.08658444881439209
encoder.encoder.weight_ih_l0_reverse: 0.0018008295446634293 0.08752954006195068
encoder.encoder.weight_hh_l0_reverse: 0.008421855047345161 0.08684166520833969
encoder.encoder.bias_ih_l0_reverse: 0.034186720848083496 0.0852072462439537
encoder.encoder.bias_hh_l0_reverse: 0.026052303612232208 0.08299504965543747
decider.lstm.weight_ih_l0: 0.001524709747172892 0.14818459749221802
decider.lstm.weight_hh_l0: 0.002937732031568885 0.14791558682918549
decider.lstm.bias_ih_l0: 0.022534430027008057 0.1589595079421997
decider.lstm.bias_hh_l0: 0.0035469497088342905 0.14071711897850037
decider.linear1.weight: 0.004446030594408512 0.12123775482177734
decider.linear1.bias: 0.018631810322403908 0.11761396378278732
decider.linear2.weight: 0.00497551541775465 0.05353902652859688
decider.linear2.bias: 0.00829249806702137 0.05724683403968811
decider.linear3.weight: -0.010459663346409798 0.05984779819846153
decider.linear3.bias: 0.011568110436201096 0.05369476228952408

Rewards:
206.9982
206.9982
206.9982
objective = 31.552595138549805
==== episode 9400/10000 ====
action = 0
probs = 0.6868 0.3112 0.0008 0.0013

action = 0
probs = 0.9942 0.0057 0.0000 0.0000

action = 0
probs = 0.9753 0.0247 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00013798415602650493 0.08503677695989609
encoder.encoder.weight_hh_l0: -4.032111064589117e-06 0.08687589317560196
encoder.encoder.bias_ih_l0: 0.012749348767101765 0.0882926657795906
encoder.encoder.bias_hh_l0: 0.022746430709958076 0.08649014681577682
encoder.encoder.weight_ih_l0_reverse: 0.0017966788727790117 0.08746352046728134
encoder.encoder.weight_hh_l0_reverse: 0.00832275953143835 0.08675944805145264
encoder.encoder.bias_ih_l0_reverse: 0.03397754952311516 0.08519382029771805
encoder.encoder.bias_hh_l0_reverse: 0.02584313414990902 0.08298701792955399
decider.lstm.weight_ih_l0: 0.0014611835358664393 0.1481238454580307
decider.lstm.weight_hh_l0: 0.0029153621289879084 0.14786772429943085
decider.lstm.bias_ih_l0: 0.022246289998292923 0.1589331328868866
decider.lstm.bias_hh_l0: 0.0032588038593530655 0.1407325267791748
decider.linear1.weight: 0.0044462792575359344 0.12122616916894913
decider.linear1.bias: 0.018557582050561905 0.11756248772144318
decider.linear2.weight: 0.004956720396876335 0.05352500453591347
decider.linear2.bias: 0.008224287070333958 0.05718786641955376
decider.linear3.weight: -0.010283010080456734 0.05974193662405014
decider.linear3.bias: 0.011908970773220062 0.05375530570745468

Rewards:
206.9982
206.9982
206.9982
objective = 28.05580711364746
==== episode 9500/10000 ====
action = 0
probs = 0.7258 0.2724 0.0007 0.0011

action = 0
probs = 0.9964 0.0036 0.0000 0.0000

action = 0
probs = 0.9834 0.0166 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001412044366588816 0.08508406579494476
encoder.encoder.weight_hh_l0: -4.746413196698995e-06 0.08693499863147736
encoder.encoder.bias_ih_l0: 0.012908169999718666 0.08836883306503296
encoder.encoder.bias_hh_l0: 0.0229052547365427 0.08654949069023132
encoder.encoder.weight_ih_l0_reverse: 0.0017879214137792587 0.0875135138630867
encoder.encoder.weight_hh_l0_reverse: 0.00841808132827282 0.08683641999959946
encoder.encoder.bias_ih_l0_reverse: 0.034112349152565 0.08524437248706818
encoder.encoder.bias_hh_l0_reverse: 0.025977937504649162 0.08297452330589294
decider.lstm.weight_ih_l0: 0.001499429577961564 0.148169606924057
decider.lstm.weight_hh_l0: 0.002931852824985981 0.14790403842926025
decider.lstm.bias_ih_l0: 0.022439585998654366 0.1589326113462448
decider.lstm.bias_hh_l0: 0.0034521049819886684 0.1407468616962433
decider.linear1.weight: 0.004452076740562916 0.12127433717250824
decider.linear1.bias: 0.018739240244030952 0.11755603551864624
decider.linear2.weight: 0.00504979956895113 0.053561240434646606
decider.linear2.bias: 0.008346923626959324 0.05721377208828926
decider.linear3.weight: -0.010357826948165894 0.05984462797641754
decider.linear3.bias: 0.011776641942560673 0.05338514596223831

Rewards:
206.9982
206.9982
206.9982
objective = 23.51923179626465
==== episode 9600/10000 ====
action = 0
probs = 0.8064 0.1922 0.0005 0.0008

action = 0
probs = 0.9983 0.0017 0.0000 0.0000

action = 0
probs = 0.9914 0.0085 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001325677294516936 0.08512893319129944
encoder.encoder.weight_hh_l0: -4.706001163867768e-06 0.08700190484523773
encoder.encoder.bias_ih_l0: 0.013077020645141602 0.08847733587026596
encoder.encoder.bias_hh_l0: 0.02307410165667534 0.08662621676921844
encoder.encoder.weight_ih_l0_reverse: 0.0017674965783953667 0.0875711664557457
encoder.encoder.weight_hh_l0_reverse: 0.008530760183930397 0.08693573623895645
encoder.encoder.bias_ih_l0_reverse: 0.03424646705389023 0.0853392630815506
encoder.encoder.bias_hh_l0_reverse: 0.02611205354332924 0.08295166492462158
decider.lstm.weight_ih_l0: 0.0015348846791312099 0.14822685718536377
decider.lstm.weight_hh_l0: 0.0029504462145268917 0.14794985949993134
decider.lstm.bias_ih_l0: 0.022648684680461884 0.15889108180999756
decider.lstm.bias_hh_l0: 0.0036612057592719793 0.1407993882894516
decider.linear1.weight: 0.0044597056694328785 0.12134340405464172
decider.linear1.bias: 0.018999570980668068 0.11756142228841782
decider.linear2.weight: 0.005170757416635752 0.053606919944286346
decider.linear2.bias: 0.008528930135071278 0.057244595140218735
decider.linear3.weight: -0.010417132638394833 0.05993657559156418
decider.linear3.bias: 0.011674465611577034 0.05270357429981232

Rewards:
206.9982
206.9982
206.9982
objective = 15.558337211608887
==== episode 9700/10000 ====
action = 0
probs = 0.7778 0.2208 0.0005 0.0009

action = 0
probs = 0.9979 0.0021 0.0000 0.0000

action = 0
probs = 0.9897 0.0102 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00014017790090292692 0.08513057976961136
encoder.encoder.weight_hh_l0: -4.876875664194813e-06 0.08699654787778854
encoder.encoder.bias_ih_l0: 0.013064244762063026 0.08845368027687073
encoder.encoder.bias_hh_l0: 0.023061327636241913 0.08661514520645142
encoder.encoder.weight_ih_l0_reverse: 0.0017760940827429295 0.08756735175848007
encoder.encoder.weight_hh_l0_reverse: 0.008514650166034698 0.08692046999931335
encoder.encoder.bias_ih_l0_reverse: 0.03423858433961868 0.0853131115436554
encoder.encoder.bias_hh_l0_reverse: 0.026104172691702843 0.08296313881874084
decider.lstm.weight_ih_l0: 0.0015347324078902602 0.14821761846542358
decider.lstm.weight_hh_l0: 0.002948179142549634 0.1479436606168747
decider.lstm.bias_ih_l0: 0.022627171128988266 0.15891365706920624
decider.lstm.bias_hh_l0: 0.003639683360233903 0.14077411592006683
decider.linear1.weight: 0.004457748029381037 0.12132935225963593
decider.linear1.bias: 0.018941663205623627 0.11755438148975372
decider.linear2.weight: 0.0051551032811403275 0.05360466614365578
decider.linear2.bias: 0.00849100761115551 0.05726039409637451
decider.linear3.weight: -0.010474612936377525 0.05996711179614067
decider.linear3.bias: 0.011575719341635704 0.05289348587393761

Rewards:
206.9982
206.9982
206.9982
objective = 18.1964054107666
==== episode 9800/10000 ====
action = 0
probs = 0.8366 0.1624 0.0004 0.0007

action = 0
probs = 0.9989 0.0011 0.0000 0.0000

action = 0
probs = 0.9941 0.0059 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00013774223043583333 0.08518693596124649
encoder.encoder.weight_hh_l0: -4.802620424015913e-06 0.08707170933485031
encoder.encoder.bias_ih_l0: 0.013264385052025318 0.08856800198554993
encoder.encoder.bias_hh_l0: 0.02326146699488163 0.08670252561569214
encoder.encoder.weight_ih_l0_reverse: 0.0017584427259862423 0.08762862533330917
encoder.encoder.weight_hh_l0_reverse: 0.008610309101641178 0.08700567483901978
encoder.encoder.bias_ih_l0_reverse: 0.034380100667476654 0.08539508283138275
encoder.encoder.bias_hh_l0_reverse: 0.026245683431625366 0.08294184505939484
decider.lstm.weight_ih_l0: 0.001579560455866158 0.14827944338321686
decider.lstm.weight_hh_l0: 0.002969632390886545 0.1479918509721756
decider.lstm.bias_ih_l0: 0.022878972813487053 0.1588970273733139
decider.lstm.bias_hh_l0: 0.003891485743224621 0.14081314206123352
decider.linear1.weight: 0.004461837932467461 0.1213945597410202
decider.linear1.bias: 0.019192643463611603 0.11756308376789093
decider.linear2.weight: 0.005272127687931061 0.05364476144313812
decider.linear2.bias: 0.00866764597594738 0.057287439703941345
decider.linear3.weight: -0.010528573766350746 0.060051094740629196
decider.linear3.bias: 0.01148472260683775 0.05232767015695572

Rewards:
206.9982
206.9982
206.9982
objective = 12.802366256713867
==== episode 9900/10000 ====
action = 0
probs = 0.8395 0.1594 0.0004 0.0006

action = 0
probs = 0.9990 0.0010 0.0000 0.0000

action = 0
probs = 0.9948 0.0052 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00014057844236958772 0.08519592136144638
encoder.encoder.weight_hh_l0: -4.227542831358733e-06 0.08708129078149796
encoder.encoder.bias_ih_l0: 0.013291866518557072 0.08857414871454239
encoder.encoder.bias_hh_l0: 0.023288944736123085 0.0867113247513771
encoder.encoder.weight_ih_l0_reverse: 0.0017578508704900742 0.08763861656188965
encoder.encoder.weight_hh_l0_reverse: 0.008617997169494629 0.08701371401548386
encoder.encoder.bias_ih_l0_reverse: 0.03439619019627571 0.08540410548448563
encoder.encoder.bias_hh_l0_reverse: 0.026261774823069572 0.08294134587049484
decider.lstm.weight_ih_l0: 0.0015861612046137452 0.14828583598136902
decider.lstm.weight_hh_l0: 0.00297195790335536 0.1479981541633606
decider.lstm.bias_ih_l0: 0.02291025221347809 0.15890422463417053
decider.lstm.bias_hh_l0: 0.003922769799828529 0.14081093668937683
decider.linear1.weight: 0.004466288723051548 0.12140830606222153
decider.linear1.bias: 0.019233200699090958 0.11754323542118073
decider.linear2.weight: 0.005304165184497833 0.05365525558590889
decider.linear2.bias: 0.00869255606085062 0.057290952652692795
decider.linear3.weight: -0.010574794374406338 0.06009408459067345
decider.linear3.bias: 0.011410608887672424 0.052272308617830276

Rewards:
206.9982
206.9982
206.9982
objective = 12.499612808227539
==== episode 10000/10000 ====
action = 0
probs = 0.8768 0.1221 0.0004 0.0007

action = 0
probs = 0.9994 0.0006 0.0000 0.0000

action = 0
probs = 0.9966 0.0034 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00011780638305936009 0.08513107150793076
encoder.encoder.weight_hh_l0: -4.569482825900195e-06 0.08701799064874649
encoder.encoder.bias_ih_l0: 0.013092625886201859 0.08853180706501007
encoder.encoder.bias_hh_l0: 0.023089703172445297 0.08665699511766434
encoder.encoder.weight_ih_l0_reverse: 0.0017422704258933663 0.08759415149688721
encoder.encoder.weight_hh_l0_reverse: 0.008574911393225193 0.08698327839374542
encoder.encoder.bias_ih_l0_reverse: 0.03425310179591179 0.08542901277542114
encoder.encoder.bias_hh_l0_reverse: 0.0261186882853508 0.08292664587497711
decider.lstm.weight_ih_l0: 0.001539929653517902 0.14825379848480225
decider.lstm.weight_hh_l0: 0.0029573000501841307 0.14797067642211914
decider.lstm.bias_ih_l0: 0.022723328322172165 0.15885025262832642
decider.lstm.bias_hh_l0: 0.003735850565135479 0.1408505141735077
decider.linear1.weight: 0.0044730850495398045 0.12141795456409454
decider.linear1.bias: 0.019245482981204987 0.11749890446662903
decider.linear2.weight: 0.005305889993906021 0.053648270666599274
decider.linear2.bias: 0.008675895631313324 0.05725031718611717
decider.linear3.weight: -0.010372927412390709 0.06000010669231415
decider.linear3.bias: 0.011768418364226818 0.05212714150547981

Rewards:
206.9982
206.9982
206.9982
objective = 9.354456901550293
[INFO] : learning runtime (h:mm:ss): 0:02:24
[INFO] : learning end time: 12/17/2023 12:34:07 PM
