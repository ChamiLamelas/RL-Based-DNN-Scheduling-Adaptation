Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 06:26:35 PM
==== episode 1/10000 ====
action = 1
probs = 0.0008 0.9992 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00023140962002798915 0.08494384586811066
encoder.encoder.weight_hh_l0: -0.0006618748884648085 0.08680932223796844
encoder.encoder.bias_ih_l0: 0.011566562578082085 0.08690503984689713
encoder.encoder.bias_hh_l0: 0.021563667804002762 0.08702169358730316
encoder.encoder.weight_ih_l0_reverse: 0.0017642407910898328 0.08676908165216446
encoder.encoder.weight_hh_l0_reverse: 0.002431642496958375 0.08436162024736404
encoder.encoder.bias_ih_l0_reverse: 0.025433216243982315 0.08584930002689362
encoder.encoder.bias_hh_l0_reverse: 0.01729864627122879 0.08481167256832123
decider.lstm.weight_ih_l0: 0.00013023063365835696 0.14818082749843597
decider.lstm.weight_hh_l0: -0.0025607477873563766 0.14712607860565186
decider.lstm.bias_ih_l0: 0.02468549832701683 0.15627220273017883
decider.lstm.bias_hh_l0: 0.005698001012206078 0.14289475977420807
decider.linear1.weight: 0.0013232333585619926 0.12226788699626923
decider.linear1.bias: 0.017908548936247826 0.11699818074703217
decider.linear2.weight: 0.005078500602394342 0.05694204568862915
decider.linear2.bias: 0.0072264461778104305 0.057661429047584534
decider.linear3.weight: -0.06820686161518097 0.12879392504692078
decider.linear3.bias: -0.0640610009431839 0.09306599944829941

Rewards:
190.8927
190.8927
190.8927
objective = 0.05177197977900505
==== episode 100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00010556571214692667 0.08534020930528641
encoder.encoder.weight_hh_l0: -0.0007347326609306037 0.08759147673845291
encoder.encoder.bias_ih_l0: 0.013883966021239758 0.08740665018558502
encoder.encoder.bias_hh_l0: 0.02388107217848301 0.08773151785135269
encoder.encoder.weight_ih_l0_reverse: 0.0018265236867591739 0.08716456592082977
encoder.encoder.weight_hh_l0_reverse: 0.002643007319420576 0.08473999798297882
encoder.encoder.bias_ih_l0_reverse: 0.027255045250058174 0.0862392857670784
encoder.encoder.bias_hh_l0_reverse: 0.0191204734146595 0.08491957932710648
decider.lstm.weight_ih_l0: 0.0003190921270288527 0.148787260055542
decider.lstm.weight_hh_l0: -0.002914328593760729 0.14769650995731354
decider.lstm.bias_ih_l0: 0.027191154658794403 0.15686114132404327
decider.lstm.bias_hh_l0: 0.008203668519854546 0.14351575076580048
decider.linear1.weight: 0.0011791674187406898 0.1227060928940773
decider.linear1.bias: 0.019318901002407074 0.11672463268041611
decider.linear2.weight: 0.005706341005861759 0.05723656341433525
decider.linear2.bias: 0.007969710975885391 0.05816589668393135
decider.linear3.weight: -0.06862545013427734 0.1295243501663208
decider.linear3.bias: -0.06495881080627441 0.09520336240530014

Rewards:
190.8927
190.8927
190.8927
objective = 0.001213674433529377
==== episode 200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -5.342069925973192e-05 0.08540371060371399
encoder.encoder.weight_hh_l0: -0.000722980999853462 0.08775907009840012
encoder.encoder.bias_ih_l0: 0.014401590451598167 0.08747132122516632
encoder.encoder.bias_hh_l0: 0.024398701265454292 0.08782608062028885
encoder.encoder.weight_ih_l0_reverse: 0.0018167966045439243 0.0872037410736084
encoder.encoder.weight_hh_l0_reverse: 0.002695986069738865 0.08481162786483765
encoder.encoder.bias_ih_l0_reverse: 0.027621593326330185 0.08632440119981766
encoder.encoder.bias_hh_l0_reverse: 0.01948702149093151 0.0849151611328125
decider.lstm.weight_ih_l0: 0.00037875224370509386 0.14889349043369293
decider.lstm.weight_hh_l0: -0.0030107456259429455 0.14779366552829742
decider.lstm.bias_ih_l0: 0.027634618803858757 0.15697284042835236
decider.lstm.bias_hh_l0: 0.008647135458886623 0.1435883492231369
decider.linear1.weight: 0.0010903665097430348 0.12289221584796906
decider.linear1.bias: 0.019977344200015068 0.11647951602935791
decider.linear2.weight: 0.006012631580233574 0.057378437370061874
decider.linear2.bias: 0.008247291669249535 0.058257389813661575
decider.linear3.weight: -0.06863640248775482 0.12964710593223572
decider.linear3.bias: -0.06497768312692642 0.09553514420986176

Rewards:
190.8927
190.8927
190.8927
objective = 0.00040961249032989144
==== episode 300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -2.1323821783880703e-05 0.08544354885816574
encoder.encoder.weight_hh_l0: -0.0007053096196614206 0.08786514401435852
encoder.encoder.bias_ih_l0: 0.014716084115207195 0.08750850707292557
encoder.encoder.bias_hh_l0: 0.02471318654716015 0.0878787413239479
encoder.encoder.weight_ih_l0_reverse: 0.0018150957766920328 0.08722203969955444
encoder.encoder.weight_hh_l0_reverse: 0.002732191700488329 0.08485713601112366
encoder.encoder.bias_ih_l0_reverse: 0.027851955965161324 0.08637350797653198
encoder.encoder.bias_hh_l0_reverse: 0.01971738040447235 0.08489967882633209
decider.lstm.weight_ih_l0: 0.0004227833414915949 0.14895471930503845
decider.lstm.weight_hh_l0: -0.003070365870371461 0.14784768223762512
decider.lstm.bias_ih_l0: 0.027873042970895767 0.15703415870666504
decider.lstm.bias_hh_l0: 0.008885559625923634 0.14362072944641113
decider.linear1.weight: 0.0010270995553582907 0.12301874905824661
decider.linear1.bias: 0.0203876756131649 0.11635497212409973
decider.linear2.weight: 0.006209602579474449 0.05748194083571434
decider.linear2.bias: 0.008408281952142715 0.05830824375152588
decider.linear3.weight: -0.06863906979560852 0.12971988320350647
decider.linear3.bias: -0.06498199701309204 0.09570714831352234

Rewards:
190.8927
190.8927
190.8927
objective = 0.00020859860524069518
==== episode 400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.1176242651345092e-06 0.08547357469797134
encoder.encoder.weight_hh_l0: -0.0006863194284960628 0.08794520050287247
encoder.encoder.bias_ih_l0: 0.014942316338419914 0.08753583580255508
encoder.encoder.bias_hh_l0: 0.02493942156434059 0.08791634440422058
encoder.encoder.weight_ih_l0_reverse: 0.001815592055208981 0.08723287284374237
encoder.encoder.weight_hh_l0_reverse: 0.002761130454018712 0.08489178121089935
encoder.encoder.bias_ih_l0_reverse: 0.028022481128573418 0.08640669286251068
encoder.encoder.bias_hh_l0_reverse: 0.019887905567884445 0.08488006144762039
decider.lstm.weight_ih_l0: 0.00045869010500609875 0.14899800717830658
decider.lstm.weight_hh_l0: -0.003113191109150648 0.14788414537906647
decider.lstm.bias_ih_l0: 0.0280299074947834 0.15707576274871826
decider.lstm.bias_hh_l0: 0.00904242042452097 0.14363861083984375
decider.linear1.weight: 0.0009784719441086054 0.12311539798974991
decider.linear1.bias: 0.020678384229540825 0.11627669632434845
decider.linear2.weight: 0.0063545797020196915 0.05756493657827377
decider.linear2.bias: 0.008518447168171406 0.05834345519542694
decider.linear3.weight: -0.06864005327224731 0.12977169454097748
decider.linear3.bias: -0.06498347222805023 0.0958176925778389

Rewards:
190.8927
190.8927
190.8927
objective = 0.00012895179679617286
==== episode 500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.7774253137758933e-05 0.0854983776807785
encoder.encoder.weight_hh_l0: -0.0006671171286143363 0.08801054954528809
encoder.encoder.bias_ih_l0: 0.015118924900889397 0.08755849301815033
encoder.encoder.bias_hh_l0: 0.025116033852100372 0.08794607222080231
encoder.encoder.weight_ih_l0_reverse: 0.0018172776326537132 0.0872412919998169
encoder.encoder.weight_hh_l0_reverse: 0.002785542281344533 0.08492039889097214
encoder.encoder.bias_ih_l0_reverse: 0.028159022331237793 0.08643175661563873
encoder.encoder.bias_hh_l0_reverse: 0.02002444677054882 0.0848596841096878
decider.lstm.weight_ih_l0: 0.0004895552410744131 0.14903177320957184
decider.lstm.weight_hh_l0: -0.0031463196501135826 0.1479111909866333
decider.lstm.bias_ih_l0: 0.028143785893917084 0.15710681676864624
decider.lstm.bias_hh_l0: 0.009156300686299801 0.1436498910188675
decider.linear1.weight: 0.0009355193469673395 0.12319505214691162
decider.linear1.bias: 0.020941399037837982 0.11621420085430145
decider.linear2.weight: 0.006474869325757027 0.05763731151819229
decider.linear2.bias: 0.00859939493238926 0.05836984142661095
decider.linear3.weight: -0.06864051520824432 0.12981176376342773
decider.linear3.bias: -0.06498415023088455 0.09589654207229614

Rewards:
190.8927
190.8927
190.8927
objective = 8.723208156879991e-05
==== episode 600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.99069652101025e-05 0.0855187326669693
encoder.encoder.weight_hh_l0: -0.000649231777060777 0.0880625769495964
encoder.encoder.bias_ih_l0: 0.015254298225045204 0.0875772088766098
encoder.encoder.bias_hh_l0: 0.025251401588320732 0.087970070540905
encoder.encoder.weight_ih_l0_reverse: 0.0018199054757133126 0.0872478038072586
encoder.encoder.weight_hh_l0_reverse: 0.0028055692091584206 0.08494365215301514
encoder.encoder.bias_ih_l0_reverse: 0.028266191482543945 0.08645104616880417
encoder.encoder.bias_hh_l0_reverse: 0.020131615921854973 0.08484116196632385
decider.lstm.weight_ih_l0: 0.0005151919322088361 0.14905786514282227
decider.lstm.weight_hh_l0: -0.0031714094802737236 0.1479310393333435
decider.lstm.bias_ih_l0: 0.028225893154740334 0.15712952613830566
decider.lstm.bias_hh_l0: 0.009238417260348797 0.14365696907043457
decider.linear1.weight: 0.000884014880284667 0.12329979985952377
decider.linear1.bias: 0.021352112293243408 0.11618421971797943
decider.linear2.weight: 0.006642784457653761 0.057749394327402115
decider.linear2.bias: 0.008657794445753098 0.05838850140571594
decider.linear3.weight: -0.06864073127508163 0.12984202802181244
decider.linear3.bias: -0.06498446315526962 0.09595189988613129

Rewards:
190.8927
190.8927
190.8927
objective = 5.689047247869894e-05
==== episode 700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.816477692453191e-05 0.08553435653448105
encoder.encoder.weight_hh_l0: -0.0006343335844576359 0.08810128271579742
encoder.encoder.bias_ih_l0: 0.015351740643382072 0.08759166300296783
encoder.encoder.bias_hh_l0: 0.0253488440066576 0.08798819035291672
encoder.encoder.weight_ih_l0_reverse: 0.0018224298255518079 0.08725254237651825
encoder.encoder.weight_hh_l0_reverse: 0.0028208147268742323 0.08496126532554626
encoder.encoder.bias_ih_l0_reverse: 0.028344783931970596 0.08646504580974579
encoder.encoder.bias_hh_l0_reverse: 0.020210199058055878 0.08482607454061508
decider.lstm.weight_ih_l0: 0.0005348770064301789 0.1490769237279892
decider.lstm.weight_hh_l0: -0.003189253620803356 0.147944837808609
decider.lstm.bias_ih_l0: 0.02828216552734375 0.15714523196220398
decider.lstm.bias_hh_l0: 0.00929468497633934 0.1436612606048584
decider.linear1.weight: 0.000849219155497849 0.12340034544467926
decider.linear1.bias: 0.021615147590637207 0.11619539558887482
decider.linear2.weight: 0.006755111739039421 0.05785359814763069
decider.linear2.bias: 0.008697856217622757 0.05840068310499191
decider.linear3.weight: -0.0686408132314682 0.1298636943101883
decider.linear3.bias: -0.06498458236455917 0.09598866105079651

Rewards:
190.8927
190.8927
190.8927
objective = 3.792697680182755e-05
==== episode 800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.397563679958694e-05 0.08554672449827194
encoder.encoder.weight_hh_l0: -0.0006219466449692845 0.0881311446428299
encoder.encoder.bias_ih_l0: 0.015424828045070171 0.08760321885347366
encoder.encoder.bias_hh_l0: 0.025421928614377975 0.08800223469734192
encoder.encoder.weight_ih_l0_reverse: 0.0018245941027998924 0.08725626766681671
encoder.encoder.weight_hh_l0_reverse: 0.0028326816391199827 0.08497495949268341
encoder.encoder.bias_ih_l0_reverse: 0.028404420241713524 0.08647563308477402
encoder.encoder.bias_hh_l0_reverse: 0.020269839093089104 0.08481381088495255
decider.lstm.weight_ih_l0: 0.0005503809079527855 0.14909148216247559
decider.lstm.weight_hh_l0: -0.0032024800311774015 0.14795491099357605
decider.lstm.bias_ih_l0: 0.028322771191596985 0.15715663135051727
decider.lstm.bias_hh_l0: 0.009335294365882874 0.14366407692432404
decider.linear1.weight: 0.0008237194269895554 0.12348690629005432
decider.linear1.bias: 0.02180291712284088 0.11621735990047455
decider.linear2.weight: 0.006831168197095394 0.057942505925893784
decider.linear2.bias: 0.008718712255358696 0.05841999500989914
decider.linear3.weight: -0.0686408281326294 0.1298799067735672
decider.linear3.bias: -0.06498466432094574 0.09601451456546783

Rewards:
190.8927
190.8927
190.8927
objective = 3.0341578167281114e-05
==== episode 900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.824567440664396e-05 0.08555688709020615
encoder.encoder.weight_hh_l0: -0.0006114274146966636 0.0881553590297699
encoder.encoder.bias_ih_l0: 0.015482575632631779 0.0876128152012825
encoder.encoder.bias_hh_l0: 0.025479678064584732 0.08801349252462387
encoder.encoder.weight_ih_l0_reverse: 0.0018264359096065164 0.087259441614151
encoder.encoder.weight_hh_l0_reverse: 0.002842259593307972 0.08498602360486984
encoder.encoder.bias_ih_l0_reverse: 0.028451794758439064 0.08648408949375153
encoder.encoder.bias_hh_l0_reverse: 0.020317217335104942 0.08480361849069595
decider.lstm.weight_ih_l0: 0.0005631088279187679 0.14910311996936798
decider.lstm.weight_hh_l0: -0.0032128160819411278 0.14796267449855804
decider.lstm.bias_ih_l0: 0.028353888541460037 0.15716534852981567
decider.lstm.bias_hh_l0: 0.00936642661690712 0.14366617798805237
decider.linear1.weight: 0.0008038374944590032 0.12356118857860565
decider.linear1.bias: 0.021946169435977936 0.11624141782522202
decider.linear2.weight: 0.0068913111463189125 0.058018170297145844
decider.linear2.bias: 0.0087346863001585 0.05843488872051239
decider.linear3.weight: -0.06864083558320999 0.1298927217721939
decider.linear3.bias: -0.06498466432094574 0.09603389352560043

Rewards:
190.8927
190.8927
190.8927
objective = 2.6548881578492e-05
==== episode 1000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.154788232175633e-05 0.08556559681892395
encoder.encoder.weight_hh_l0: -0.000602254003752023 0.08817566931247711
encoder.encoder.bias_ih_l0: 0.01553002092987299 0.08762110024690628
encoder.encoder.bias_hh_l0: 0.025527119636535645 0.08802292495965958
encoder.encoder.weight_ih_l0_reverse: 0.0018280138028785586 0.08726216852664948
encoder.encoder.weight_hh_l0_reverse: 0.0028502647764980793 0.08499529957771301
encoder.encoder.bias_ih_l0_reverse: 0.028490910306572914 0.08649107068777084
encoder.encoder.bias_hh_l0_reverse: 0.020356332883238792 0.08479492366313934
decider.lstm.weight_ih_l0: 0.0005738948239013553 0.14911285042762756
decider.lstm.weight_hh_l0: -0.0032212287187576294 0.14796893298625946
decider.lstm.bias_ih_l0: 0.028378810733556747 0.15717236697673798
decider.lstm.bias_hh_l0: 0.009391319006681442 0.1436677724123001
decider.linear1.weight: 0.000787592027336359 0.12362674623727798
decider.linear1.bias: 0.022062059491872787 0.11626647412776947
decider.linear2.weight: 0.00693375151604414 0.058085501194000244
decider.linear2.bias: 0.008736907504498959 0.058443356305360794
decider.linear3.weight: -0.06864083558320999 0.12990324199199677
decider.linear3.bias: -0.06498465687036514 0.09604915231466293

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.415163832367398e-05 0.08557313680648804
encoder.encoder.weight_hh_l0: -0.0005942059797234833 0.08819299191236496
encoder.encoder.bias_ih_l0: 0.015569686889648438 0.08762829005718231
encoder.encoder.bias_hh_l0: 0.025566793978214264 0.08803094178438187
encoder.encoder.weight_ih_l0_reverse: 0.001829368993639946 0.08726455271244049
encoder.encoder.weight_hh_l0_reverse: 0.0028570357244461775 0.08500317484140396
encoder.encoder.bias_ih_l0_reverse: 0.02852371707558632 0.08649691939353943
encoder.encoder.bias_hh_l0_reverse: 0.020389139652252197 0.08478743582963943
decider.lstm.weight_ih_l0: 0.0005831514135934412 0.14912107586860657
decider.lstm.weight_hh_l0: -0.0032282061874866486 0.14797410368919373
decider.lstm.bias_ih_l0: 0.028399227187037468 0.15717816352844238
decider.lstm.bias_hh_l0: 0.009411714971065521 0.14366896450519562
decider.linear1.weight: 0.0007740465807728469 0.12368475645780563
decider.linear1.bias: 0.022157903760671616 0.11629118770360947
decider.linear2.weight: 0.00697708036750555 0.05814296752214432
decider.linear2.bias: 0.008750955574214458 0.05844784155488014
decider.linear3.weight: -0.06864084303379059 0.12991204857826233
decider.linear3.bias: -0.06498466432094574 0.09606144577264786

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6235567171825096e-05 0.08557972311973572
encoder.encoder.weight_hh_l0: -0.000587127055041492 0.08820789307355881
encoder.encoder.bias_ih_l0: 0.015603235922753811 0.08763459324836731
encoder.encoder.bias_hh_l0: 0.025600342079997063 0.08803782612085342
encoder.encoder.weight_ih_l0_reverse: 0.0018305297708138824 0.08726663887500763
encoder.encoder.weight_hh_l0_reverse: 0.002862806199118495 0.08500991761684418
encoder.encoder.bias_ih_l0_reverse: 0.028551515191793442 0.08650186657905579
encoder.encoder.bias_hh_l0_reverse: 0.02041693590581417 0.0847809836268425
decider.lstm.weight_ih_l0: 0.0005911567131988704 0.14912813901901245
decider.lstm.weight_hh_l0: -0.0032340576872229576 0.14797841012477875
decider.lstm.bias_ih_l0: 0.0284161064773798 0.15718290209770203
decider.lstm.bias_hh_l0: 0.009428635239601135 0.1436699777841568
decider.linear1.weight: 0.0007626257138326764 0.12373614311218262
decider.linear1.bias: 0.02223826013505459 0.11631481349468231
decider.linear2.weight: 0.007013482972979546 0.05819375067949295
decider.linear2.bias: 0.008762533776462078 0.05845155194401741
decider.linear3.weight: -0.06864084303379059 0.12991948425769806
decider.linear3.bias: -0.06498465687036514 0.0960715264081955

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 10000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.6320317526115105e-05 0.0855799987912178
encoder.encoder.weight_hh_l0: -0.0005868255393579602 0.08820851147174835
encoder.encoder.bias_ih_l0: 0.015604633837938309 0.0876348540186882
encoder.encoder.bias_hh_l0: 0.025601739063858986 0.08803810924291611
encoder.encoder.weight_ih_l0_reverse: 0.0018305785488337278 0.08726672828197479
encoder.encoder.weight_hh_l0_reverse: 0.002863047644495964 0.08501018583774567
encoder.encoder.bias_ih_l0_reverse: 0.028552673757076263 0.0865020751953125
encoder.encoder.bias_hh_l0_reverse: 0.020418094471096992 0.08478070050477982
decider.lstm.weight_ih_l0: 0.000591492629610002 0.14912842214107513
decider.lstm.weight_hh_l0: -0.0032343007624149323 0.14797857403755188
decider.lstm.bias_ih_l0: 0.028416786342859268 0.15718308091163635
decider.lstm.bias_hh_l0: 0.009429320693016052 0.143669992685318
decider.linear1.weight: 0.0007621467811986804 0.1237383484840393
decider.linear1.bias: 0.022241612896323204 0.11631585657596588
decider.linear2.weight: 0.007015005219727755 0.058195922523736954
decider.linear2.bias: 0.008763009682297707 0.05845170468091965
decider.linear3.weight: -0.06864084303379059 0.12991979718208313
decider.linear3.bias: -0.06498465687036514 0.09607193619012833

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
[INFO] : learning runtime (h:mm:ss): 0:02:23
[INFO] : learning end time: 12/17/2023 06:28:58 PM
