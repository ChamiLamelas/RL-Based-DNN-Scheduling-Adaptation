Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 03:48:36 PM
==== episode 1/10000 ====
action = 0
probs = 0.2502 0.2499 0.2499 0.2499

action = 0
probs = 0.2502 0.2499 0.2499 0.2499

action = 0
probs = 0.2502 0.2499 0.2499 0.2499

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000519445922691375 0.08475905656814575
encoder.encoder.weight_hh_l0: 0.0008231043466366827 0.08828096091747284
encoder.encoder.bias_ih_l0: 0.018489211797714233 0.08797113597393036
encoder.encoder.bias_hh_l0: 0.02848631702363491 0.08873667567968369
encoder.encoder.weight_ih_l0_reverse: 0.0015785142313688993 0.08688624948263168
encoder.encoder.weight_hh_l0_reverse: -0.00142571865580976 0.08629428595304489
encoder.encoder.bias_ih_l0_reverse: 0.031778570264577866 0.08633296936750412
encoder.encoder.bias_hh_l0_reverse: 0.023644139990210533 0.084590844810009
decider.lstm.weight_ih_l0: -0.0017141090938821435 0.14881294965744019
decider.lstm.weight_hh_l0: -0.006261611357331276 0.14818450808525085
decider.lstm.bias_ih_l0: 0.0261369775980711 0.16163958609104156
decider.lstm.bias_hh_l0: 0.007149904500693083 0.13842341303825378
decider.linear1.weight: -0.0002065448061330244 0.12212902307510376
decider.linear1.bias: 0.019336771219968796 0.11891421675682068
decider.linear2.weight: 0.005843466613441706 0.053939469158649445
decider.linear2.bias: 0.009084168821573257 0.05626849830150604
decider.linear3.weight: -0.007790869101881981 0.060598041862249374
decider.linear3.bias: 0.017614925280213356 0.04956243559718132

Rewards:
211.9920
211.9920
211.9920
objective = 293.72430419921875
==== episode 100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006947912042960525 0.08530496060848236
encoder.encoder.weight_hh_l0: 0.0010563945397734642 0.08924589306116104
encoder.encoder.bias_ih_l0: 0.02125546894967556 0.08864542841911316
encoder.encoder.bias_hh_l0: 0.03125257045030594 0.0894743800163269
encoder.encoder.weight_ih_l0_reverse: 0.00161143415607512 0.08747166395187378
encoder.encoder.weight_hh_l0_reverse: -0.0014286426594480872 0.08638607710599899
encoder.encoder.bias_ih_l0_reverse: 0.03334122151136398 0.08677704632282257
encoder.encoder.bias_hh_l0_reverse: 0.025206787511706352 0.08485982567071915
decider.lstm.weight_ih_l0: -0.0016097649931907654 0.1492699533700943
decider.lstm.weight_hh_l0: -0.006720803678035736 0.14859695732593536
decider.lstm.bias_ih_l0: 0.02797694504261017 0.16240176558494568
decider.lstm.bias_hh_l0: 0.008989867754280567 0.1387132704257965
decider.linear1.weight: -0.000828895135782659 0.12308085709810257
decider.linear1.bias: 0.0220753513276577 0.11970231682062149
decider.linear2.weight: 0.00700621772557497 0.05443170666694641
decider.linear2.bias: 0.010744169354438782 0.057019103318452835
decider.linear3.weight: -0.008787193335592747 0.061722565442323685
decider.linear3.bias: 0.01585209183394909 0.04506281763315201

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649270843714476 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949826657772064
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050043299794197 0.13872340321540833
decider.linear1.weight: -0.0008541700663045049 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054902613162994 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 1000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 1100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 1200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 1300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 1400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 1500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 1600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 1700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 1800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 1900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 2000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 2100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 2200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 2300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 2400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 2500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 2600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 2700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 2800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 2900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 3000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 3100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 3200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 3300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 3400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 3500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 3600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 3700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 3800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 3900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 4000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 4100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 4200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 4300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 4400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 4500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 4600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 4700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 4800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 4900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 5000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 5100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 5200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 5300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 5400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 5500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 5600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 5700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 5800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 5900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 6000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 6100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 6200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 6300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 6400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 6500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 6600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 6700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 6800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 6900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 7000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 7100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 7200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 7300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 7400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 7500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 7600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 7700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 7800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 7900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 8000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 8100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 8200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 8300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 8400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 8500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 8600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 8700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 8800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 8900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 9000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 9100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 9200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 9300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 9400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 9500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 9600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 9700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 9800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 9900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
==== episode 10000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0007026433595456183 0.0853249728679657
encoder.encoder.weight_hh_l0: 0.0010649273172020912 0.08928065001964569
encoder.encoder.bias_ih_l0: 0.021349063143134117 0.08866695314645767
encoder.encoder.bias_hh_l0: 0.031346164643764496 0.08949825912714005
encoder.encoder.weight_ih_l0_reverse: 0.0016132104210555553 0.0874948501586914
encoder.encoder.weight_hh_l0_reverse: -0.0014287260128185153 0.0863894671201706
encoder.encoder.bias_ih_l0_reverse: 0.03339972347021103 0.08679201453924179
encoder.encoder.bias_hh_l0_reverse: 0.025265293195843697 0.08486998081207275
decider.lstm.weight_ih_l0: -0.0016058292239904404 0.14928628504276276
decider.lstm.weight_hh_l0: -0.006735870148986578 0.1486114114522934
decider.lstm.bias_ih_l0: 0.028037112206220627 0.16242675483226776
decider.lstm.bias_hh_l0: 0.009050045162439346 0.13872340321540833
decider.linear1.weight: -0.0008541701245121658 0.12311621010303497
decider.linear1.bias: 0.02217978984117508 0.11972274631261826
decider.linear2.weight: 0.007054903078824282 0.05445103347301483
decider.linear2.bias: 0.010812610387802124 0.057049885392189026
decider.linear3.weight: -0.008826358243823051 0.0617716945707798
decider.linear3.bias: 0.015783945098519325 0.044907815754413605

Rewards:
211.9920
211.9920
211.9920
objective = 2.5271416234318167e-05
[INFO] : learning runtime (h:mm:ss): 0:02:24
[INFO] : learning end time: 12/17/2023 03:51:00 PM
