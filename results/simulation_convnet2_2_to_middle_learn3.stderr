Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(18, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/18/2023 12:12:26 AM
==== episode 1/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 5.922429045313038e-05 0.0855882540345192
encoder.encoder.weight_hh_l0: -0.0005867620347999036 0.08821997791528702
encoder.encoder.bias_ih_l0: 0.015645897015929222 0.08764412999153137
encoder.encoder.bias_hh_l0: 0.02564300037920475 0.08805668354034424
encoder.encoder.weight_ih_l0_reverse: 0.001831084256991744 0.08727473020553589
encoder.encoder.weight_hh_l0_reverse: 0.0028641039971262217 0.08501221984624863
encoder.encoder.bias_ih_l0_reverse: 0.028580287471413612 0.08651160448789597
encoder.encoder.bias_hh_l0_reverse: 0.02044570818543434 0.08478790521621704
decider.lstm.weight_ih_l0: 0.0005949310143478215 0.1491369605064392
decider.lstm.weight_hh_l0: -0.0032390006817877293 0.14798882603645325
decider.lstm.bias_ih_l0: 0.02846382185816765 0.15719690918922424
decider.lstm.bias_hh_l0: 0.00947635993361473 0.14368273317813873
decider.linear1.weight: 0.000758431269787252 0.12375425547361374
decider.linear1.bias: 0.02228587493300438 0.11631406098604202
decider.linear2.weight: 0.007037417031824589 0.0582050122320652
decider.linear2.bias: 0.008795319125056267 0.05846386402845383
decider.linear3.weight: -0.06864083558320999 0.12992878258228302
decider.linear3.bias: -0.06498465687036514 0.09611964225769043

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.723089220235124e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.01596539467573166 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.02596249431371689 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320985836908221 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.028781099244952202 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.000620843144133687 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759318128228188 0.14807309210300446
decider.lstm.bias_ih_l0: 0.028860490769147873 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873034432530403 0.14378611743450165
decider.linear1.weight: 0.0007244722219184041 0.12390006333589554
decider.linear1.bias: 0.022689213976264 0.11630132794380188
decider.linear2.weight: 0.007235204800963402 0.05828726664185524
decider.linear2.bias: 0.009088496677577496 0.0585782416164875
decider.linear3.weight: -0.06864084303379059 0.13001272082328796
decider.linear3.bias: -0.06498466432094574 0.09656188637018204

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 10000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 7.72306666476652e-05 0.08565041422843933
encoder.encoder.weight_hh_l0: -0.0005865058628842235 0.08830206096172333
encoder.encoder.bias_ih_l0: 0.015965400263667107 0.08771871775388718
encoder.encoder.bias_hh_l0: 0.025962499901652336 0.08821031451225281
encoder.encoder.weight_ih_l0_reverse: 0.0018320984672755003 0.08733552694320679
encoder.encoder.weight_hh_l0_reverse: 0.00287045631557703 0.08502434939146042
encoder.encoder.bias_ih_l0_reverse: 0.02878110110759735 0.08659277111291885
encoder.encoder.bias_hh_l0_reverse: 0.02064651995897293 0.0848446637392044
decider.lstm.weight_ih_l0: 0.0006208430277183652 0.14920325577259064
decider.lstm.weight_hh_l0: -0.0032759327441453934 0.14807309210300446
decider.lstm.bias_ih_l0: 0.02886049449443817 0.1573198139667511
decider.lstm.bias_hh_l0: 0.009873039089143276 0.14378611743450165
decider.linear1.weight: 0.0007244713488034904 0.12390006333589554
decider.linear1.bias: 0.022689219564199448 0.11630132794380188
decider.linear2.weight: 0.007235209457576275 0.05828726664185524
decider.linear2.bias: 0.009088506922125816 0.0585782416164875
decider.linear3.weight: -0.06864083558320999 0.13001272082328796
decider.linear3.bias: -0.06498465687036514 0.09656189382076263

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
[INFO] : learning runtime (h:mm:ss): 0:02:23
[INFO] : learning end time: 12/18/2023 12:14:48 AM
