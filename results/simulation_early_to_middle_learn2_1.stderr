Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 12:18:57 PM
==== episode 1/10000 ====
action = 1
probs = 0.0722 0.9265 0.0011 0.0002

action = 1
probs = 0.0049 0.9951 0.0000 0.0000

action = 1
probs = 0.0038 0.9962 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003013516834471375 0.08384420722723007
encoder.encoder.weight_hh_l0: -0.0004405351064633578 0.08496366441249847
encoder.encoder.bias_ih_l0: 0.006847985088825226 0.08571060001850128
encoder.encoder.bias_hh_l0: 0.01684507168829441 0.08574730902910233
encoder.encoder.weight_ih_l0_reverse: 0.0016394412377849221 0.08584519475698471
encoder.encoder.weight_hh_l0_reverse: 0.0022808504290878773 0.08398615568876266
encoder.encoder.bias_ih_l0_reverse: 0.02245916798710823 0.0851297453045845
encoder.encoder.bias_hh_l0_reverse: 0.014324602670967579 0.08351638913154602
decider.lstm.weight_ih_l0: -0.0003597323375288397 0.1469128131866455
decider.lstm.weight_hh_l0: -0.0014507584273815155 0.14600831270217896
decider.lstm.bias_ih_l0: 0.017580755054950714 0.1530824452638626
decider.lstm.bias_hh_l0: -0.0014067837037146091 0.14340944588184357
decider.linear1.weight: 0.0018384283175691962 0.12069481611251831
decider.linear1.bias: 0.013299520127475262 0.11646382510662079
decider.linear2.weight: 0.003776389639824629 0.055143099278211594
decider.linear2.bias: 0.004311008844524622 0.05697672441601753
decider.linear3.weight: -0.030956953763961792 0.08705604076385498
decider.linear3.bias: -0.018916931003332138 0.053772564977407455

Rewards:
190.8927
190.8927
190.8927
objective = 5.411221981048584
==== episode 100/10000 ====
action = 1
probs = 0.0306 0.9691 0.0002 0.0000

action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0003 0.9997 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031147158006206155 0.08399930596351624
encoder.encoder.weight_hh_l0: -0.0004856795712839812 0.08517475426197052
encoder.encoder.bias_ih_l0: 0.007519583683460951 0.08591362088918686
encoder.encoder.bias_hh_l0: 0.017516670748591423 0.08593476563692093
encoder.encoder.weight_ih_l0_reverse: 0.001662946306169033 0.08599399775266647
encoder.encoder.weight_hh_l0_reverse: 0.0023401693906635046 0.08409518748521805
encoder.encoder.bias_ih_l0_reverse: 0.022899175062775612 0.08526098728179932
encoder.encoder.bias_hh_l0_reverse: 0.014764608815312386 0.08361247181892395
decider.lstm.weight_ih_l0: -0.00027161382604390383 0.1471128612756729
decider.lstm.weight_hh_l0: -0.0015908412169665098 0.14617808163166046
decider.lstm.bias_ih_l0: 0.018771352246403694 0.1533251851797104
decider.lstm.bias_hh_l0: -0.00021618325263261795 0.14366135001182556
decider.linear1.weight: 0.0017986416351050138 0.1207624152302742
decider.linear1.bias: 0.013758797198534012 0.11646094918251038
decider.linear2.weight: 0.004006651230156422 0.055323854088783264
decider.linear2.bias: 0.004518931731581688 0.05727110058069229
decider.linear3.weight: -0.033084969967603683 0.08903201669454575
decider.linear3.bias: -0.02272125519812107 0.055813442915678024

Rewards:
190.8927
190.8927
190.8927
objective = 2.0479516983032227
==== episode 200/10000 ====
action = 1
probs = 0.0112 0.9887 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032079004449769855 0.08410315215587616
encoder.encoder.weight_hh_l0: -0.0004980065859854221 0.08540261536836624
encoder.encoder.bias_ih_l0: 0.008341801352798939 0.08600573241710663
encoder.encoder.bias_hh_l0: 0.0183388851583004 0.08602821826934814
encoder.encoder.weight_ih_l0_reverse: 0.0016897020395845175 0.0860544741153717
encoder.encoder.weight_hh_l0_reverse: 0.002416635863482952 0.0841510146856308
encoder.encoder.bias_ih_l0_reverse: 0.02342095598578453 0.08536558598279953
encoder.encoder.bias_hh_l0_reverse: 0.015286387875676155 0.08362046629190445
decider.lstm.weight_ih_l0: -0.00016894670261535794 0.14731352031230927
decider.lstm.weight_hh_l0: -0.0017999353585764766 0.14634324610233307
decider.lstm.bias_ih_l0: 0.019932609051465988 0.15351355075836182
decider.lstm.bias_hh_l0: 0.0009450842626392841 0.14389705657958984
decider.linear1.weight: 0.0016866647638380527 0.12095195800065994
decider.linear1.bias: 0.014674747362732887 0.11638201028108597
decider.linear2.weight: 0.0045843059197068214 0.05558793246746063
decider.linear2.bias: 0.005151987075805664 0.05750322341918945
decider.linear3.weight: -0.03403525426983833 0.08997967839241028
decider.linear3.bias: -0.024302702397108078 0.05727383494377136

Rewards:
190.8927
190.8927
190.8927
objective = 0.7249970436096191
==== episode 300/10000 ====
action = 1
probs = 0.0050 0.9949 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003199505736120045 0.08415283262729645
encoder.encoder.weight_hh_l0: -0.0004951203009113669 0.08560066670179367
encoder.encoder.bias_ih_l0: 0.009022611193358898 0.08599796891212463
encoder.encoder.bias_hh_l0: 0.019019700586795807 0.08598989993333817
encoder.encoder.weight_ih_l0_reverse: 0.0017319153994321823 0.08610699325799942
encoder.encoder.weight_hh_l0_reverse: 0.0025211682077497244 0.08424515277147293
encoder.encoder.bias_ih_l0_reverse: 0.023982876911759377 0.08542812615633011
encoder.encoder.bias_hh_l0_reverse: 0.015848308801651 0.08362702280282974
decider.lstm.weight_ih_l0: -0.00010684601875254884 0.14744944870471954
decider.lstm.weight_hh_l0: -0.0020075105130672455 0.14644671976566315
decider.lstm.bias_ih_l0: 0.02067852020263672 0.15361200273036957
decider.lstm.bias_hh_l0: 0.0016909968107938766 0.14401300251483917
decider.linear1.weight: 0.0015600871993228793 0.12115044891834259
decider.linear1.bias: 0.015377367846667767 0.11636855453252792
decider.linear2.weight: 0.005035606678575277 0.055831003934144974
decider.linear2.bias: 0.005610638298094273 0.057677850127220154
decider.linear3.weight: -0.03434985876083374 0.09035000205039978
decider.linear3.bias: -0.024722296744585037 0.05792790651321411

Rewards:
190.8927
190.8927
190.8927
objective = 0.32365521788597107
==== episode 400/10000 ====
action = 1
probs = 0.0026 0.9973 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003132697893306613 0.08419372886419296
encoder.encoder.weight_hh_l0: -0.0004899902269244194 0.0857924371957779
encoder.encoder.bias_ih_l0: 0.009610330685973167 0.08596468716859818
encoder.encoder.bias_hh_l0: 0.01960742101073265 0.08587466925382614
encoder.encoder.weight_ih_l0_reverse: 0.0017753911670297384 0.08617476373910904
encoder.encoder.weight_hh_l0_reverse: 0.00264782109297812 0.08437886834144592
encoder.encoder.bias_ih_l0_reverse: 0.024548249319195747 0.08544957637786865
encoder.encoder.bias_hh_l0_reverse: 0.016413681209087372 0.0836382806301117
decider.lstm.weight_ih_l0: -6.472084351116791e-05 0.14755508303642273
decider.lstm.weight_hh_l0: -0.002191327279433608 0.1465177685022354
decider.lstm.bias_ih_l0: 0.021181227639317513 0.15368109941482544
decider.lstm.bias_hh_l0: 0.002193700522184372 0.14406339824199677
decider.linear1.weight: 0.001442705630324781 0.12131474167108536
decider.linear1.bias: 0.01587594486773014 0.11637955904006958
decider.linear2.weight: 0.005369812250137329 0.05603693798184395
decider.linear2.bias: 0.005919392220675945 0.05781730264425278
decider.linear3.weight: -0.03448030352592468 0.09054916352033615
decider.linear3.bias: -0.024866927415132523 0.05828241631388664

Rewards:
190.8927
190.8927
190.8927
objective = 0.1691506803035736
==== episode 500/10000 ====
action = 1
probs = 0.0015 0.9985 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030382946715690196 0.08424331992864609
encoder.encoder.weight_hh_l0: -0.00048311628052033484 0.08599665760993958
encoder.encoder.bias_ih_l0: 0.01013870257884264 0.0859425738453865
encoder.encoder.bias_hh_l0: 0.020135793834924698 0.08573179692029953
encoder.encoder.weight_ih_l0_reverse: 0.0018120297463610768 0.08624748885631561
encoder.encoder.weight_hh_l0_reverse: 0.002782980212941766 0.08453472703695297
encoder.encoder.bias_ih_l0_reverse: 0.025083141401410103 0.08543577790260315
encoder.encoder.bias_hh_l0_reverse: 0.016948571428656578 0.08363834768533707
decider.lstm.weight_ih_l0: -3.04673048958648e-05 0.14764507114887238
decider.lstm.weight_hh_l0: -0.0023495242930948734 0.14656883478164673
decider.lstm.bias_ih_l0: 0.021535461768507957 0.1537364423274994
decider.lstm.bias_hh_l0: 0.0025479309260845184 0.14408081769943237
decider.linear1.weight: 0.0013375820126384497 0.12145394086837769
decider.linear1.bias: 0.01624135486781597 0.11639630794525146
decider.linear2.weight: 0.005635124631226063 0.05620941147208214
decider.linear2.bias: 0.006151645444333553 0.05791567265987396
decider.linear3.weight: -0.03454388678073883 0.09067846089601517
decider.linear3.bias: -0.024928012862801552 0.058500900864601135

Rewards:
190.8927
190.8927
190.8927
objective = 0.09795714914798737
==== episode 600/10000 ====
action = 1
probs = 0.0010 0.9990 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029616354731842875 0.08430321514606476
encoder.encoder.weight_hh_l0: -0.0004737800336442888 0.0862179771065712
encoder.encoder.bias_ih_l0: 0.01060575246810913 0.08594926446676254
encoder.encoder.bias_hh_l0: 0.020602840930223465 0.08560403436422348
encoder.encoder.weight_ih_l0_reverse: 0.0018423213623464108 0.08631762862205505
encoder.encoder.weight_hh_l0_reverse: 0.0029153209179639816 0.0846959725022316
encoder.encoder.bias_ih_l0_reverse: 0.025562280789017677 0.0853949561715126
encoder.encoder.bias_hh_l0_reverse: 0.017427708953619003 0.08363096415996552
decider.lstm.weight_ih_l0: -1.1280551461823052e-06 0.14772455394268036
decider.lstm.weight_hh_l0: -0.002485298551619053 0.14660637080669403
decider.lstm.bias_ih_l0: 0.021793251857161522 0.15378135442733765
decider.lstm.bias_hh_l0: 0.0028057266026735306 0.1440814882516861
decider.linear1.weight: 0.001243834150955081 0.12157049030065536
decider.linear1.bias: 0.01651575230062008 0.11641411483287811
decider.linear2.weight: 0.005840924568474293 0.05635456368327141
decider.linear2.bias: 0.006321980617940426 0.05799242481589317
decider.linear3.weight: -0.0345781184732914 0.09077032655477524
decider.linear3.bias: -0.02495749108493328 0.05864546447992325

Rewards:
190.8927
190.8927
190.8927
objective = 0.061224572360515594
==== episode 700/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029272015672177076 0.08436521142721176
encoder.encoder.weight_hh_l0: -0.0004633963981177658 0.08644505590200424
encoder.encoder.bias_ih_l0: 0.011002625338733196 0.08598264306783676
encoder.encoder.bias_hh_l0: 0.020999712869524956 0.08551225811243057
encoder.encoder.weight_ih_l0_reverse: 0.0018673209706321359 0.08638188242912292
encoder.encoder.weight_hh_l0_reverse: 0.003040134906768799 0.08485517650842667
encoder.encoder.bias_ih_l0_reverse: 0.025982677936553955 0.08533627539873123
encoder.encoder.bias_hh_l0_reverse: 0.017848102375864983 0.08361899107694626
decider.lstm.weight_ih_l0: 2.1560117602348328e-05 0.14779701828956604
decider.lstm.weight_hh_l0: -0.002605002373456955 0.1466347724199295
decider.lstm.bias_ih_l0: 0.0219898521900177 0.15381920337677002
decider.lstm.bias_hh_l0: 0.0030023199506103992 0.14407292008399963
decider.linear1.weight: 0.0011585860047489405 0.12167089432477951
decider.linear1.bias: 0.01672983169555664 0.11643186211585999
decider.linear2.weight: 0.006006139330565929 0.05647783353924751
decider.linear2.bias: 0.006452319212257862 0.0580533966422081
decider.linear3.weight: -0.0345982164144516 0.09084039181470871
decider.linear3.bias: -0.024973362684249878 0.05874793604016304

Rewards:
190.8927
190.8927
190.8927
objective = 0.04060237854719162
==== episode 800/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002925342705566436 0.08442119508981705
encoder.encoder.weight_hh_l0: -0.0004547593998722732 0.08666212111711502
encoder.encoder.bias_ih_l0: 0.011327175423502922 0.08602908253669739
encoder.encoder.bias_hh_l0: 0.021324262022972107 0.08545426279306412
encoder.encoder.weight_ih_l0_reverse: 0.0018878995906561613 0.08643891662359238
encoder.encoder.weight_hh_l0_reverse: 0.0031547388061881065 0.08500797301530838
encoder.encoder.bias_ih_l0_reverse: 0.026345014572143555 0.08526743203401566
encoder.encoder.bias_hh_l0_reverse: 0.018210439011454582 0.08360511809587479
decider.lstm.weight_ih_l0: 3.612205182434991e-05 0.14786362648010254
decider.lstm.weight_hh_l0: -0.0027128132060170174 0.14665669202804565
decider.lstm.bias_ih_l0: 0.022145461291074753 0.15385150909423828
decider.lstm.bias_hh_l0: 0.003157929517328739 0.1440592259168625
decider.linear1.weight: 0.001080117654055357 0.12175806611776352
decider.linear1.bias: 0.016901658847928047 0.1164473220705986
decider.linear2.weight: 0.00614201882854104 0.05658372864127159
decider.linear2.bias: 0.006555277854204178 0.058102551847696304
decider.linear3.weight: -0.034610815346241 0.09089623391628265
decider.linear3.bias: -0.024982638657093048 0.05882425233721733

Rewards:
190.8927
190.8927
190.8927
objective = 0.028371896594762802
==== episode 900/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002938433026429266 0.08446978032588959
encoder.encoder.weight_hh_l0: -0.0004490455612540245 0.08686400949954987
encoder.encoder.bias_ih_l0: 0.011592283844947815 0.0860777422785759
encoder.encoder.bias_hh_l0: 0.02158936858177185 0.08541835099458694
encoder.encoder.weight_ih_l0_reverse: 0.0019042232306674123 0.08648951351642609
encoder.encoder.weight_hh_l0_reverse: 0.0032601524144411087 0.08515683561563492
encoder.encoder.bias_ih_l0_reverse: 0.02666214480996132 0.08519396185874939
encoder.encoder.bias_hh_l0_reverse: 0.018527569249272346 0.08358773589134216
decider.lstm.weight_ih_l0: 4.366494613350369e-05 0.14792592823505402
decider.lstm.weight_hh_l0: -0.002811926882714033 0.14667387306690216
decider.lstm.bias_ih_l0: 0.02227294072508812 0.15388044714927673
decider.lstm.bias_hh_l0: 0.0032854140736162663 0.14404113590717316
decider.linear1.weight: 0.0010082662338390946 0.12183462083339691
decider.linear1.bias: 0.01704167015850544 0.11646082252264023
decider.linear2.weight: 0.006255005486309528 0.05667648836970329
decider.linear2.bias: 0.006638479884713888 0.058143600821495056
decider.linear3.weight: -0.03461919724941254 0.09094230830669403
decider.linear3.bias: -0.024988451972603798 0.0588834248483181

Rewards:
190.8927
190.8927
190.8927
objective = 0.020643200725317
==== episode 1000/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000295517296763137 0.08451157063245773
encoder.encoder.weight_hh_l0: -0.0004462676006369293 0.0870499387383461
encoder.encoder.bias_ih_l0: 0.011811165139079094 0.08612345159053802
encoder.encoder.bias_hh_l0: 0.02180825173854828 0.08539557456970215
encoder.encoder.weight_ih_l0_reverse: 0.001917182351462543 0.08653492480516434
encoder.encoder.weight_hh_l0_reverse: 0.003357303561642766 0.08530306816101074
encoder.encoder.bias_ih_l0_reverse: 0.02694227360188961 0.08511938899755478
encoder.encoder.bias_hh_l0_reverse: 0.018807699903845787 0.08356855809688568
decider.lstm.weight_ih_l0: 4.6295783249661326e-05 0.14798487722873688
decider.lstm.weight_hh_l0: -0.0029051057063043118 0.14668767154216766
decider.lstm.bias_ih_l0: 0.022380832582712173 0.15390703082084656
decider.lstm.bias_hh_l0: 0.0033933091908693314 0.14401979744434357
decider.linear1.weight: 0.0009416318498551846 0.12190300971269608
decider.linear1.bias: 0.01715846359729767 0.11647269129753113
decider.linear2.weight: 0.00634556170552969 0.05675939843058586
decider.linear2.bias: 0.006699388846755028 0.058179646730422974
decider.linear3.weight: -0.03462506830692291 0.0909799262881279
decider.linear3.bias: -0.024992328137159348 0.058930784463882446

Rewards:
190.8927
190.8927
190.8927
objective = 0.015514018945395947
==== episode 1100/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002970414643641561 0.08454738557338715
encoder.encoder.weight_hh_l0: -0.0004459067131392658 0.08721917867660522
encoder.encoder.bias_ih_l0: 0.011992771178483963 0.0861639603972435
encoder.encoder.bias_hh_l0: 0.021989859640598297 0.0853806734085083
encoder.encoder.weight_ih_l0_reverse: 0.0019275745144113898 0.08657634258270264
encoder.encoder.weight_hh_l0_reverse: 0.0034462737385183573 0.08544640988111496
encoder.encoder.bias_ih_l0_reverse: 0.02719009853899479 0.08504694700241089
encoder.encoder.bias_hh_l0_reverse: 0.019055526703596115 0.08354908972978592
decider.lstm.weight_ih_l0: 4.591416291077621e-05 0.14804083108901978
decider.lstm.weight_hh_l0: -0.0029938442166894674 0.14669905602931976
decider.lstm.bias_ih_l0: 0.022474009543657303 0.15393184125423431
decider.lstm.bias_hh_l0: 0.0034864810295403004 0.14399607479572296
decider.linear1.weight: 0.0008796569891273975 0.1219644695520401
decider.linear1.bias: 0.017256876453757286 0.11648310720920563
decider.linear2.weight: 0.006420014891773462 0.056833576411008835
decider.linear2.bias: 0.006745548453181982 0.058211445808410645
decider.linear3.weight: -0.03462931141257286 0.09101135283708572
decider.linear3.bias: -0.02499501407146454 0.05896933004260063

Rewards:
190.8927
190.8927
190.8927
objective = 0.012001222930848598
==== episode 1200/10000 ====
action = 1
probs = 0.0005 0.9995 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031681236578151584 0.08445027470588684
encoder.encoder.weight_hh_l0: -0.00038483133539557457 0.08700381219387054
encoder.encoder.bias_ih_l0: 0.01124486792832613 0.08598444610834122
encoder.encoder.bias_hh_l0: 0.02124195732176304 0.08518680185079575
encoder.encoder.weight_ih_l0_reverse: 0.0018702482338994741 0.08644112944602966
encoder.encoder.weight_hh_l0_reverse: 0.0033894823864102364 0.0853356420993805
encoder.encoder.bias_ih_l0_reverse: 0.026607584208250046 0.08481679856777191
encoder.encoder.bias_hh_l0_reverse: 0.018473010510206223 0.08337147533893585
decider.lstm.weight_ih_l0: -7.2089023888111115e-06 0.14791643619537354
decider.lstm.weight_hh_l0: -0.0029102214612066746 0.14655616879463196
decider.lstm.bias_ih_l0: 0.02166767790913582 0.15373195707798004
decider.lstm.bias_hh_l0: 0.0026801573112607002 0.14388863742351532
decider.linear1.weight: 0.0009084005723707378 0.12177374213933945
decider.linear1.bias: 0.01654425449669361 0.11643706262111664
decider.linear2.weight: 0.006168427877128124 0.05673307925462723
decider.linear2.bias: 0.006374967284500599 0.05808143690228462
decider.linear3.weight: -0.03463270887732506 0.09088651835918427
decider.linear3.bias: -0.024997055530548096 0.0580301508307457

Rewards:
190.8927
190.8927
190.8927
objective = 0.03316818177700043
==== episode 1300/10000 ====
action = 1
probs = 0.0009 0.9991 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003296507056802511 0.0844215676188469
encoder.encoder.weight_hh_l0: -0.0003608521947171539 0.08689375966787338
encoder.encoder.bias_ih_l0: 0.010947314091026783 0.0859251469373703
encoder.encoder.bias_hh_l0: 0.02094440348446369 0.08513950556516647
encoder.encoder.weight_ih_l0_reverse: 0.001849295455031097 0.08639560639858246
encoder.encoder.weight_hh_l0_reverse: 0.003336588153615594 0.08527161180973053
encoder.encoder.bias_ih_l0_reverse: 0.026320988312363625 0.08477753400802612
encoder.encoder.bias_hh_l0_reverse: 0.0181864146143198 0.08335506170988083
decider.lstm.weight_ih_l0: -2.580795444373507e-05 0.14786562323570251
decider.lstm.weight_hh_l0: -0.00284965755417943 0.1465080976486206
decider.lstm.bias_ih_l0: 0.021370097994804382 0.15365156531333923
decider.lstm.bias_hh_l0: 0.002382585546001792 0.14387646317481995
decider.linear1.weight: 0.0009424807503819466 0.1216868981719017
decider.linear1.bias: 0.016253242269158363 0.1164185181260109
decider.linear2.weight: 0.006050119176506996 0.056677091866731644
decider.linear2.bias: 0.006223732605576515 0.058030031621456146
decider.linear3.weight: -0.034664712846279144 0.09084668010473251
decider.linear3.bias: -0.02501983940601349 0.05769985541701317

Rewards:
190.8927
190.8927
190.8927
objective = 0.05435734987258911
==== episode 1400/10000 ====
action = 1
probs = 0.0061 0.9939 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002868198789656162 0.08416332304477692
encoder.encoder.weight_hh_l0: -0.0002797007036861032 0.08626887202262878
encoder.encoder.bias_ih_l0: 0.00928330235183239 0.08547588437795639
encoder.encoder.bias_hh_l0: 0.019280394539237022 0.08466403931379318
encoder.encoder.weight_ih_l0_reverse: 0.00172176375053823 0.08613951504230499
encoder.encoder.weight_hh_l0_reverse: 0.0031698173843324184 0.08493390679359436
encoder.encoder.bias_ih_l0_reverse: 0.02534625492990017 0.08457724004983902
encoder.encoder.bias_hh_l0_reverse: 0.017211681231856346 0.08289530873298645
decider.lstm.weight_ih_l0: -0.0001235856325365603 0.14752447605133057
decider.lstm.weight_hh_l0: -0.0026434180326759815 0.1462445706129074
decider.lstm.bias_ih_l0: 0.019643228501081467 0.1533101350069046
decider.lstm.bias_hh_l0: 0.0006557083688676357 0.14352397620677948
decider.linear1.weight: 0.0009825690649449825 0.12137137353420258
decider.linear1.bias: 0.015167535282671452 0.11638519167900085
decider.linear2.weight: 0.005624471232295036 0.056466925889253616
decider.linear2.bias: 0.005590041633695364 0.057781536132097244
decider.linear3.weight: -0.03475346788764 0.09067974239587784
decider.linear3.bias: -0.025090668350458145 0.05571544170379639

Rewards:
190.8927
190.8927
190.8927
objective = 0.39153701066970825
==== episode 1500/10000 ====
action = 1
probs = 0.0041 0.9959 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030834120116196573 0.08425015956163406
encoder.encoder.weight_hh_l0: -0.0002875789359677583 0.08640002459287643
encoder.encoder.bias_ih_l0: 0.009615250863134861 0.08557489514350891
encoder.encoder.bias_hh_l0: 0.01961234211921692 0.08477704972028732
encoder.encoder.weight_ih_l0_reverse: 0.0017384072998538613 0.08617697656154633
encoder.encoder.weight_hh_l0_reverse: 0.0031639509834349155 0.08497263491153717
encoder.encoder.bias_ih_l0_reverse: 0.025339236482977867 0.08456791192293167
encoder.encoder.bias_hh_l0_reverse: 0.017204662784934044 0.08301672339439392
decider.lstm.weight_ih_l0: -9.037552081281319e-05 0.14762887358665466
decider.lstm.weight_hh_l0: -0.0026565161533653736 0.14630170166492462
decider.lstm.bias_ih_l0: 0.020068367943167686 0.15336935222148895
decider.lstm.bias_hh_l0: 0.001080851536244154 0.14370228350162506
decider.linear1.weight: 0.0009596277959644794 0.12140840291976929
decider.linear1.bias: 0.015363462269306183 0.1164010688662529
decider.linear2.weight: 0.005713129881769419 0.056508876383304596
decider.linear2.bias: 0.005689867772161961 0.05782821774482727
decider.linear3.weight: -0.035211458802223206 0.09100040048360825
decider.linear3.bias: -0.025510186329483986 0.05626401677727699

Rewards:
190.8927
190.8927
190.8927
objective = 0.26504063606262207
==== episode 1600/10000 ====
action = 1
probs = 0.0064 0.9936 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029728273511864245 0.08419331163167953
encoder.encoder.weight_hh_l0: -0.0002715411246754229 0.08626362681388855
encoder.encoder.bias_ih_l0: 0.00923216063529253 0.08547510206699371
encoder.encoder.bias_hh_l0: 0.019229253754019737 0.08466672897338867
encoder.encoder.weight_ih_l0_reverse: 0.0017114023212343454 0.08612605929374695
encoder.encoder.weight_hh_l0_reverse: 0.0031261786352843046 0.08490482717752457
encoder.encoder.bias_ih_l0_reverse: 0.025111330673098564 0.08452895283699036
encoder.encoder.bias_hh_l0_reverse: 0.016976764425635338 0.08292704820632935
decider.lstm.weight_ih_l0: -0.00011375516623957083 0.14755527675151825
decider.lstm.weight_hh_l0: -0.0026146001182496548 0.14623978734016418
decider.lstm.bias_ih_l0: 0.019665639847517014 0.1532956063747406
decider.lstm.bias_hh_l0: 0.0006781262345612049 0.1436333805322647
decider.linear1.weight: 0.000937262549996376 0.12134217470884323
decider.linear1.bias: 0.01518107671290636 0.1163976639509201
decider.linear2.weight: 0.005643594078719616 0.05647984519600868
decider.linear2.bias: 0.005542183294892311 0.05778386443853378
decider.linear3.weight: -0.03560667112469673 0.09124422818422318
decider.linear3.bias: -0.02589866891503334 0.05586914345622063

Rewards:
190.8927
190.8927
190.8927
objective = 0.40800929069519043
==== episode 1700/10000 ====
action = 1
probs = 0.0040 0.9960 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031477250740863383 0.08428092300891876
encoder.encoder.weight_hh_l0: -0.00028385964105837047 0.08641186356544495
encoder.encoder.bias_ih_l0: 0.009624133817851543 0.08558881282806396
encoder.encoder.bias_hh_l0: 0.0196212287992239 0.08479161560535431
encoder.encoder.weight_ih_l0_reverse: 0.0017335268203169107 0.08617690205574036
encoder.encoder.weight_hh_l0_reverse: 0.0031411421950906515 0.08496298640966415
encoder.encoder.bias_ih_l0_reverse: 0.025222141295671463 0.08454404771327972
encoder.encoder.bias_hh_l0_reverse: 0.01708756946027279 0.0830405205488205
decider.lstm.weight_ih_l0: -7.951469888212159e-05 0.147661492228508
decider.lstm.weight_hh_l0: -0.002639379817992449 0.14631277322769165
decider.lstm.bias_ih_l0: 0.020145419985055923 0.15337051451206207
decider.lstm.bias_hh_l0: 0.001157896127551794 0.14378225803375244
decider.linear1.weight: 0.0009149700636044145 0.12140057235956192
decider.linear1.bias: 0.015423551201820374 0.11639300733804703
decider.linear2.weight: 0.005744754336774349 0.05653904750943184
decider.linear2.bias: 0.005665211006999016 0.0578174963593483
decider.linear3.weight: -0.03595763444900513 0.09157019853591919
decider.linear3.bias: -0.026259858161211014 0.05650397762656212

Rewards:
190.8927
190.8927
190.8927
objective = 0.2565142512321472
==== episode 1800/10000 ====
action = 1
probs = 0.0028 0.9971 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032553679193370044 0.08433935791254044
encoder.encoder.weight_hh_l0: -0.00029378922772593796 0.08652110397815704
encoder.encoder.bias_ih_l0: 0.00991269201040268 0.08567127585411072
encoder.encoder.bias_hh_l0: 0.01990978978574276 0.0848827064037323
encoder.encoder.weight_ih_l0_reverse: 0.001752610900439322 0.08621978759765625
encoder.encoder.weight_hh_l0_reverse: 0.003162182169035077 0.08501426130533218
encoder.encoder.bias_ih_l0_reverse: 0.025352587923407555 0.08457178622484207
encoder.encoder.bias_hh_l0_reverse: 0.017218023538589478 0.08311811089515686
decider.lstm.weight_ih_l0: -5.759589112130925e-05 0.1477314829826355
decider.lstm.weight_hh_l0: -0.002664032159373164 0.1463661640882492
decider.lstm.bias_ih_l0: 0.02047763764858246 0.15342533588409424
decider.lstm.bias_hh_l0: 0.0014901156537234783 0.14386926591396332
decider.linear1.weight: 0.000899122329428792 0.12144976854324341
decider.linear1.bias: 0.015611785463988781 0.11639580875635147
decider.linear2.weight: 0.005828695371747017 0.056583158671855927
decider.linear2.bias: 0.00577397458255291 0.05785875394940376
decider.linear3.weight: -0.03613962233066559 0.0917578935623169
decider.linear3.bias: -0.02644246816635132 0.0569341666996479

Rewards:
190.8927
190.8927
190.8927
objective = 0.18186096847057343
==== episode 1900/10000 ====
action = 1
probs = 0.0091 0.9909 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029559864196926355 0.08416740596294403
encoder.encoder.weight_hh_l0: -0.00025330943753942847 0.08614911139011383
encoder.encoder.bias_ih_l0: 0.008877591229975224 0.08540146797895432
encoder.encoder.bias_hh_l0: 0.018874691799283028 0.08457819372415543
encoder.encoder.weight_ih_l0_reverse: 0.001681106979958713 0.08608020097017288
encoder.encoder.weight_hh_l0_reverse: 0.003070082515478134 0.08483665436506271
encoder.encoder.bias_ih_l0_reverse: 0.0247908104211092 0.08447520434856415
encoder.encoder.bias_hh_l0_reverse: 0.016656246036291122 0.08287046104669571
decider.lstm.weight_ih_l0: -0.00012785485887434334 0.1475105583667755
decider.lstm.weight_hh_l0: -0.0025558117777109146 0.14618439972400665
decider.lstm.bias_ih_l0: 0.01932445913553238 0.15322457253932953
decider.lstm.bias_hh_l0: 0.00033692712895572186 0.1436377614736557
decider.linear1.weight: 0.000878060469403863 0.1212804988026619
decider.linear1.bias: 0.0150967538356781 0.11636552214622498
decider.linear2.weight: 0.005651719868183136 0.056485459208488464
decider.linear2.bias: 0.005442355293780565 0.05782715603709221
decider.linear3.weight: -0.036668214946985245 0.09206870943307877
decider.linear3.bias: -0.02700737491250038 0.055740196257829666

Rewards:
190.8927
190.8927
190.8927
objective = 0.5861430764198303
==== episode 2000/10000 ====
action = 1
probs = 0.0033 0.9967 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031604283140040934 0.08425820618867874
encoder.encoder.weight_hh_l0: -0.0002648410154506564 0.08629752695560455
encoder.encoder.bias_ih_l0: 0.009254244156181812 0.08551962673664093
encoder.encoder.bias_hh_l0: 0.019251342862844467 0.08468814939260483
encoder.encoder.weight_ih_l0_reverse: 0.0016947969561442733 0.0861205905675888
encoder.encoder.weight_hh_l0_reverse: 0.0030839317478239536 0.08488820493221283
encoder.encoder.bias_ih_l0_reverse: 0.024863773956894875 0.08447185903787613
encoder.encoder.bias_hh_l0_reverse: 0.016729207709431648 0.08297355473041534
decider.lstm.weight_ih_l0: -8.931092452257872e-05 0.14762315154075623
decider.lstm.weight_hh_l0: -0.002577227307483554 0.14626239240169525
decider.lstm.bias_ih_l0: 0.019871562719345093 0.15332083404064178
decider.lstm.bias_hh_l0: 0.0008840262889862061 0.1437685340642929
decider.linear1.weight: 0.0008307736134156585 0.12145200371742249
decider.linear1.bias: 0.01566595397889614 0.11639653146266937
decider.linear2.weight: 0.006123542785644531 0.0568007230758667
decider.linear2.bias: 0.0059498208574950695 0.05851186811923981
decider.linear3.weight: -0.037216559052467346 0.09252151101827621
decider.linear3.bias: -0.027453744783997536 0.056481681764125824

Rewards:
190.8927
190.8927
190.8927
objective = 0.21338514983654022
==== episode 2100/10000 ====
action = 1
probs = 0.0016 0.9984 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003247467684559524 0.08429756760597229
encoder.encoder.weight_hh_l0: -0.00027068742201663554 0.08636979013681412
encoder.encoder.bias_ih_l0: 0.009437809698283672 0.08557630330324173
encoder.encoder.bias_hh_l0: 0.019434910267591476 0.08474119752645493
encoder.encoder.weight_ih_l0_reverse: 0.0017054397612810135 0.08614569157361984
encoder.encoder.weight_hh_l0_reverse: 0.0031002613250166178 0.0849209800362587
encoder.encoder.bias_ih_l0_reverse: 0.024943603202700615 0.0844893530011177
encoder.encoder.bias_hh_l0_reverse: 0.016809040680527687 0.08301869034767151
decider.lstm.weight_ih_l0: -7.247108442243189e-05 0.14767205715179443
decider.lstm.weight_hh_l0: -0.002595059107989073 0.14629946649074554
decider.lstm.bias_ih_l0: 0.020126692950725555 0.15336653590202332
decider.lstm.bias_hh_l0: 0.0011391565203666687 0.14381647109985352
decider.linear1.weight: 0.0008105050656013191 0.12157531827688217
decider.linear1.bias: 0.01595146767795086 0.11645861715078354
decider.linear2.weight: 0.006336521357297897 0.05707352235913277
decider.linear2.bias: 0.006170547567307949 0.05890584737062454
decider.linear3.weight: -0.037383414804935455 0.09272056072950363
decider.linear3.bias: -0.027565866708755493 0.05677212402224541

Rewards:
190.8927
190.8927
190.8927
objective = 0.1043505072593689
==== episode 2200/10000 ====
action = 1
probs = 0.0010 0.9990 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000329320493619889 0.08432075381278992
encoder.encoder.weight_hh_l0: -0.00027438445249572396 0.08641432970762253
encoder.encoder.bias_ih_l0: 0.009551825001835823 0.0856110230088234
encoder.encoder.bias_hh_l0: 0.019548924639821053 0.08477410674095154
encoder.encoder.weight_ih_l0_reverse: 0.0017138187540695071 0.08616392314434052
encoder.encoder.weight_hh_l0_reverse: 0.003113427432253957 0.08494395762681961
encoder.encoder.bias_ih_l0_reverse: 0.025009946897625923 0.08450760692358017
encoder.encoder.bias_hh_l0_reverse: 0.016875384375452995 0.08304494619369507
decider.lstm.weight_ih_l0: -6.251273589441553e-05 0.147701233625412
decider.lstm.weight_hh_l0: -0.002608329989016056 0.1463228017091751
decider.lstm.bias_ih_l0: 0.020281478762626648 0.15339282155036926
decider.lstm.bias_hh_l0: 0.0012939507141709328 0.1438436210155487
decider.linear1.weight: 0.0007970085134729743 0.12166383117437363
decider.linear1.bias: 0.016140732914209366 0.11651065200567245
decider.linear2.weight: 0.006475651636719704 0.057274963706731796
decider.linear2.bias: 0.006317916326224804 0.05918504670262337
decider.linear3.weight: -0.037461839616298676 0.09284009784460068
decider.linear3.bias: -0.02761300653219223 0.05693047121167183

Rewards:
190.8927
190.8927
190.8927
objective = 0.06268620491027832
==== episode 2300/10000 ====
action = 1
probs = 0.0022 0.9978 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030868672183714807 0.08420122414827347
encoder.encoder.weight_hh_l0: -0.00024751320597715676 0.08614519983530045
encoder.encoder.bias_ih_l0: 0.008820436894893646 0.08541940897703171
encoder.encoder.bias_hh_l0: 0.018817536532878876 0.08458402007818222
encoder.encoder.weight_ih_l0_reverse: 0.0016609576996415854 0.08605524152517319
encoder.encoder.weight_hh_l0_reverse: 0.003024944569915533 0.08480432629585266
encoder.encoder.bias_ih_l0_reverse: 0.02453284151852131 0.08439446240663528
encoder.encoder.bias_hh_l0_reverse: 0.01639827899634838 0.08288533985614777
decider.lstm.weight_ih_l0: -0.0001202844432555139 0.14753492176532745
decider.lstm.weight_hh_l0: -0.0025118764024227858 0.14618487656116486
decider.lstm.bias_ih_l0: 0.019363464787602425 0.15323880314826965
decider.lstm.bias_hh_l0: 0.0003759278915822506 0.14368435740470886
decider.linear1.weight: 0.000832632533274591 0.12152053415775299
decider.linear1.bias: 0.015492485836148262 0.11649435013532639
decider.linear2.weight: 0.006305782124400139 0.05726936459541321
decider.linear2.bias: 0.006052336655557156 0.05918927118182182
decider.linear3.weight: -0.037528038024902344 0.09280466288328171
decider.linear3.bias: -0.02765125036239624 0.05605490878224373

Rewards:
190.8927
190.8927
190.8927
objective = 0.13710562884807587
==== episode 2400/10000 ====
action = 1
probs = 0.0018 0.9982 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031601570663042367 0.08423162996768951
encoder.encoder.weight_hh_l0: -0.0002504958538338542 0.08618838340044022
encoder.encoder.bias_ih_l0: 0.008918954990804195 0.08545275777578354
encoder.encoder.bias_hh_l0: 0.018916048109531403 0.08461230993270874
encoder.encoder.weight_ih_l0_reverse: 0.00166360626462847 0.08607130497694016
encoder.encoder.weight_hh_l0_reverse: 0.0030307569541037083 0.08482130616903305
encoder.encoder.bias_ih_l0_reverse: 0.02455926313996315 0.08440094441175461
encoder.encoder.bias_hh_l0_reverse: 0.01642470248043537 0.08291531354188919
decider.lstm.weight_ih_l0: -0.00010799794836202636 0.1475747525691986
decider.lstm.weight_hh_l0: -0.002514533931389451 0.14621233940124512
decider.lstm.bias_ih_l0: 0.019541237503290176 0.15326020121574402
decider.lstm.bias_hh_l0: 0.0005536999087780714 0.1437382847070694
decider.linear1.weight: 0.0008311555720865726 0.12154484540224075
decider.linear1.bias: 0.015591501258313656 0.11649798601865768
decider.linear2.weight: 0.006335406564176083 0.05728659778833389
decider.linear2.bias: 0.0060989768244326115 0.059212349355220795
decider.linear3.weight: -0.037714987993240356 0.09296680241823196
decider.linear3.bias: -0.02777467668056488 0.05626580864191055

Rewards:
190.8927
190.8927
190.8927
objective = 0.11740493774414062
==== episode 2500/10000 ====
action = 1
probs = 0.0015 0.9985 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003229379071854055 0.08426354825496674
encoder.encoder.weight_hh_l0: -0.00025465403450652957 0.08624068647623062
encoder.encoder.bias_ih_l0: 0.009049288928508759 0.08549218624830246
encoder.encoder.bias_hh_l0: 0.01904638297855854 0.08464895188808441
encoder.encoder.weight_ih_l0_reverse: 0.0016702767461538315 0.08609217405319214
encoder.encoder.weight_hh_l0_reverse: 0.0030426073353737593 0.0848451480269432
encoder.encoder.bias_ih_l0_reverse: 0.024619709700345993 0.0844167023897171
encoder.encoder.bias_hh_l0_reverse: 0.016485149040818214 0.08294860273599625
decider.lstm.weight_ih_l0: -9.452379890717566e-05 0.147616446018219
decider.lstm.weight_hh_l0: -0.0025245018769055605 0.14624343812465668
decider.lstm.bias_ih_l0: 0.019742218777537346 0.15328733623027802
decider.lstm.bias_hh_l0: 0.0007546832785010338 0.1437898874282837
decider.linear1.weight: 0.0008269497193396091 0.12157633900642395
decider.linear1.bias: 0.015718979761004448 0.11650452017784119
decider.linear2.weight: 0.006375179626047611 0.05730800703167915
decider.linear2.bias: 0.006157909519970417 0.059239696711301804
decider.linear3.weight: -0.03784097731113434 0.09309694170951843
decider.linear3.bias: -0.02786106988787651 0.05648599565029144

Rewards:
190.8927
190.8927
190.8927
objective = 0.09674554318189621
==== episode 2600/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032843000371940434 0.08429080247879028
encoder.encoder.weight_hh_l0: -0.0002584465255495161 0.08628728985786438
encoder.encoder.bias_ih_l0: 0.009168229065835476 0.08552693575620651
encoder.encoder.bias_hh_l0: 0.019165320321917534 0.08468270301818848
encoder.encoder.weight_ih_l0_reverse: 0.0016772407107055187 0.08611153066158295
encoder.encoder.weight_hh_l0_reverse: 0.0030546707566827536 0.0848676860332489
encoder.encoder.bias_ih_l0_reverse: 0.024682652205228806 0.08443388342857361
encoder.encoder.bias_hh_l0_reverse: 0.016548091545701027 0.08297715336084366
decider.lstm.weight_ih_l0: -8.302790956804529e-05 0.1476515531539917
decider.lstm.weight_hh_l0: -0.0025353943929076195 0.14627066254615784
decider.lstm.bias_ih_l0: 0.01991565153002739 0.15331190824508667
decider.lstm.bias_hh_l0: 0.0009281111415475607 0.14383135735988617
decider.linear1.weight: 0.0008225425845012069 0.12160509079694748
decider.linear1.bias: 0.015833424404263496 0.11651075631380081
decider.linear2.weight: 0.0064110103994607925 0.05732715129852295
decider.linear2.bias: 0.006210666615515947 0.059264034032821655
decider.linear3.weight: -0.03793039917945862 0.09319758415222168
decider.linear3.bias: -0.02792259305715561 0.056671835482120514

Rewards:
190.8927
190.8927
190.8927
objective = 0.08146613836288452
==== episode 2700/10000 ====
action = 1
probs = 0.0030 0.9970 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003085624484810978 0.08418163657188416
encoder.encoder.weight_hh_l0: -0.00023422171943821013 0.08605408668518066
encoder.encoder.bias_ih_l0: 0.008514697663486004 0.08536411076784134
encoder.encoder.bias_hh_l0: 0.018511788919568062 0.08451513200998306
encoder.encoder.weight_ih_l0_reverse: 0.001633950392715633 0.08602002263069153
encoder.encoder.weight_hh_l0_reverse: 0.002977421274408698 0.08475086838006973
encoder.encoder.bias_ih_l0_reverse: 0.024267131462693214 0.08433607965707779
encoder.encoder.bias_hh_l0_reverse: 0.016132572665810585 0.08284413814544678
decider.lstm.weight_ih_l0: -0.00013367360224947333 0.14750263094902039
decider.lstm.weight_hh_l0: -0.002455032430589199 0.14614614844322205
decider.lstm.bias_ih_l0: 0.01908443495631218 0.15317465364933014
decider.lstm.bias_hh_l0: 9.689689613878727e-05 0.14368779957294464
decider.linear1.weight: 0.00085259455954656 0.12145484983921051
decider.linear1.bias: 0.01524357870221138 0.11648399382829666
decider.linear2.weight: 0.006215959787368774 0.05723641812801361
decider.linear2.bias: 0.005921516567468643 0.05914871767163277
decider.linear3.weight: -0.03812621161341667 0.09329341351985931
decider.linear3.bias: -0.028073839843273163 0.055888913571834564

Rewards:
190.8927
190.8927
190.8927
objective = 0.19169054925441742
==== episode 2800/10000 ====
action = 1
probs = 0.0023 0.9977 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003178980841767043 0.08423062413930893
encoder.encoder.weight_hh_l0: -0.00024021038552746177 0.08612678200006485
encoder.encoder.bias_ih_l0: 0.008694395422935486 0.0854174941778183
encoder.encoder.bias_hh_l0: 0.01869148388504982 0.08456198871135712
encoder.encoder.weight_ih_l0_reverse: 0.0016401730244979262 0.08604883402585983
encoder.encoder.weight_hh_l0_reverse: 0.0029919687658548355 0.08478176593780518
encoder.encoder.bias_ih_l0_reverse: 0.024338550865650177 0.08435212075710297
encoder.encoder.bias_hh_l0_reverse: 0.0162039902061224 0.08288907259702682
decider.lstm.weight_ih_l0: -0.00011235346755711362 0.14756959676742554
decider.lstm.weight_hh_l0: -0.002462286502122879 0.1461956948041916
decider.lstm.bias_ih_l0: 0.019395355135202408 0.15321460366249084
decider.lstm.bias_hh_l0: 0.00040781451389193535 0.14376868307590485
decider.linear1.weight: 0.0008475580252707005 0.12149669975042343
decider.linear1.bias: 0.015414641238749027 0.11648687720298767
decider.linear2.weight: 0.006274468265473843 0.05726683884859085
decider.linear2.bias: 0.006008136086165905 0.05918540433049202
decider.linear3.weight: -0.03834041208028793 0.09354543685913086
decider.linear3.bias: -0.02825075574219227 0.05625593662261963

Rewards:
190.8927
190.8927
190.8927
objective = 0.1461029350757599
==== episode 2900/10000 ====
action = 1
probs = 0.0018 0.9982 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003248606517445296 0.08427004516124725
encoder.encoder.weight_hh_l0: -0.0002454877831041813 0.08618893474340439
encoder.encoder.bias_ih_l0: 0.008855044841766357 0.0854623019695282
encoder.encoder.bias_hh_l0: 0.01885213516652584 0.08460580557584763
encoder.encoder.weight_ih_l0_reverse: 0.0016478056786581874 0.08607470244169235
encoder.encoder.weight_hh_l0_reverse: 0.00300742220133543 0.08481059223413467
encoder.encoder.bias_ih_l0_reverse: 0.024418136104941368 0.08437302708625793
encoder.encoder.bias_hh_l0_reverse: 0.01628357172012329 0.08292539417743683
decider.lstm.weight_ih_l0: -9.556250734021887e-05 0.14762131869792938
decider.lstm.weight_hh_l0: -0.0024732109159231186 0.14623577892780304
decider.lstm.bias_ih_l0: 0.019645318388938904 0.15324930846691132
decider.lstm.bias_hh_l0: 0.0006577814929187298 0.14382876455783844
decider.linear1.weight: 0.0008419485529884696 0.12153385579586029
decider.linear1.bias: 0.015563193708658218 0.11649051308631897
decider.linear2.weight: 0.006325069814920425 0.05729316547513008
decider.linear2.bias: 0.006082743406295776 0.05921681597828865
decider.linear3.weight: -0.03847258910536766 0.09371380507946014
decider.linear3.bias: -0.02835998684167862 0.05654146522283554

Rewards:
190.8927
190.8927
190.8927
objective = 0.11607886850833893
==== episode 3000/10000 ====
action = 1
probs = 0.0015 0.9985 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003302831028122455 0.084302619099617
encoder.encoder.weight_hh_l0: -0.00025019192253239453 0.08624332398176193
encoder.encoder.bias_ih_l0: 0.008998965844511986 0.08550100773572922
encoder.encoder.bias_hh_l0: 0.01899605616927147 0.08464577794075012
encoder.encoder.weight_ih_l0_reverse: 0.0016557564958930016 0.08609791100025177
encoder.encoder.weight_hh_l0_reverse: 0.003022699384018779 0.08483722060918808
encoder.encoder.bias_ih_l0_reverse: 0.024498457089066505 0.08439505845308304
encoder.encoder.bias_hh_l0_reverse: 0.016363896429538727 0.08295606821775436
decider.lstm.weight_ih_l0: -8.181480370694771e-05 0.1476631909608841
decider.lstm.weight_hh_l0: -0.0024855565279722214 0.14626933634281158
decider.lstm.bias_ih_l0: 0.01985422894358635 0.15328003466129303
decider.lstm.bias_hh_l0: 0.0008666929788887501 0.14387527108192444
decider.linear1.weight: 0.0008361141080968082 0.12156740576028824
decider.linear1.bias: 0.01569495163857937 0.11649449169635773
decider.linear2.weight: 0.006369846407324076 0.0573163777589798
decider.linear2.bias: 0.006148461252450943 0.059244461357593536
decider.linear3.weight: -0.03856336325407028 0.09383668750524521
decider.linear3.bias: -0.02843412011861801 0.05677580460906029

Rewards:
190.8927
190.8927
190.8927
objective = 0.09492990374565125
==== episode 3100/10000 ====
action = 1
probs = 0.0012 0.9988 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003346021694596857 0.08432991057634354
encoder.encoder.weight_hh_l0: -0.00025441418983973563 0.08629141002893448
encoder.encoder.bias_ih_l0: 0.009127706289291382 0.0855349600315094
encoder.encoder.bias_hh_l0: 0.019124796614050865 0.08468165993690491
encoder.encoder.weight_ih_l0_reverse: 0.0016636222135275602 0.08611871302127838
encoder.encoder.weight_hh_l0_reverse: 0.0030373213812708855 0.08486168086528778
encoder.encoder.bias_ih_l0_reverse: 0.0245760940015316 0.08441656082868576
encoder.encoder.bias_hh_l0_reverse: 0.016441531479358673 0.08298257738351822
decider.lstm.weight_ih_l0: -7.031844870653003e-05 0.14769800007343292
decider.lstm.weight_hh_l0: -0.0024983049370348454 0.1462979018688202
decider.lstm.bias_ih_l0: 0.02003243751823902 0.1533072590827942
decider.lstm.bias_hh_l0: 0.0010449010878801346 0.143912211060524
decider.linear1.weight: 0.0008302663336507976 0.12159781157970428
decider.linear1.bias: 0.015813495963811874 0.1164989098906517
decider.linear2.weight: 0.006409748923033476 0.05733690410852432
decider.linear2.bias: 0.0062068793922662735 0.05926905572414398
decider.linear3.weight: -0.03862923011183739 0.09393071383237839
decider.linear3.bias: -0.028487181290984154 0.05697326362133026

Rewards:
190.8927
190.8927
190.8927
objective = 0.07942308485507965
==== episode 3200/10000 ====
action = 1
probs = 0.0011 0.9989 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003381349379196763 0.08435344696044922
encoder.encoder.weight_hh_l0: -0.0002582984743639827 0.08633501082658768
encoder.encoder.bias_ih_l0: 0.009245200082659721 0.08556554466485977
encoder.encoder.bias_hh_l0: 0.019242294132709503 0.08471433073282242
encoder.encoder.weight_ih_l0_reverse: 0.0016713482327759266 0.08613776415586472
encoder.encoder.weight_hh_l0_reverse: 0.0030513680540025234 0.08488453924655914
encoder.encoder.bias_ih_l0_reverse: 0.024651050567626953 0.0844373032450676
encoder.encoder.bias_hh_l0_reverse: 0.016516489908099174 0.08300622552633286
decider.lstm.weight_ih_l0: -6.0369296988938004e-05 0.1477280706167221
decider.lstm.weight_hh_l0: -0.002511196304112673 0.14632302522659302
decider.lstm.bias_ih_l0: 0.020189493894577026 0.1533319652080536
decider.lstm.bias_hh_l0: 0.0012019544374197721 0.14394260942935944
decider.linear1.weight: 0.0008242660551331937 0.12162598967552185
decider.linear1.bias: 0.015923157334327698 0.11650367081165314
decider.linear2.weight: 0.006446496583521366 0.05735582858324051
decider.linear2.bias: 0.006260090507566929 0.05929150804877281
decider.linear3.weight: -0.03867967426776886 0.09400632977485657
decider.linear3.bias: -0.02852725237607956 0.05714566260576248

Rewards:
190.8927
190.8927
190.8927
objective = 0.06750406324863434
==== episode 3300/10000 ====
action = 1
probs = 0.0009 0.9991 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003410280332900584 0.08437404781579971
encoder.encoder.weight_hh_l0: -0.00026191698270849884 0.08637502044439316
encoder.encoder.bias_ih_l0: 0.009353493340313435 0.0855933353304863
encoder.encoder.bias_hh_l0: 0.019350586459040642 0.08474434912204742
encoder.encoder.weight_ih_l0_reverse: 0.0016788234934210777 0.08615532517433167
encoder.encoder.weight_hh_l0_reverse: 0.003064823104068637 0.0849059596657753
encoder.encoder.bias_ih_l0_reverse: 0.024723147973418236 0.08445718139410019
encoder.encoder.bias_hh_l0_reverse: 0.01658858172595501 0.08302760124206543
decider.lstm.weight_ih_l0: -5.1611361413961276e-05 0.1477544903755188
decider.lstm.weight_hh_l0: -0.002524035517126322 0.14634552597999573
decider.lstm.bias_ih_l0: 0.020330052822828293 0.15335482358932495
decider.lstm.bias_hh_l0: 0.001342517789453268 0.14396794140338898
decider.linear1.weight: 0.0008187920320779085 0.12165230512619019
decider.linear1.bias: 0.016023686155676842 0.11650879681110382
decider.linear2.weight: 0.0064799590036273 0.05737265199422836
decider.linear2.bias: 0.006309087388217449 0.05931223928928375
decider.linear3.weight: -0.0387195385992527 0.0940689668059349
decider.linear3.bias: -0.02855849824845791 0.057298947125673294

Rewards:
190.8927
190.8927
190.8927
objective = 0.058107875287532806
==== episode 3400/10000 ====
action = 1
probs = 0.0008 0.9992 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034340110141783953 0.08439227938652039
encoder.encoder.weight_hh_l0: -0.0002653214323800057 0.08641205728054047
encoder.encoder.bias_ih_l0: 0.009454024024307728 0.08561883866786957
encoder.encoder.bias_hh_l0: 0.019451119005680084 0.08477206528186798
encoder.encoder.weight_ih_l0_reverse: 0.001686041709035635 0.08617166429758072
encoder.encoder.weight_hh_l0_reverse: 0.00307770655490458 0.08492615073919296
encoder.encoder.bias_ih_l0_reverse: 0.024792376905679703 0.08447613567113876
encoder.encoder.bias_hh_l0_reverse: 0.016657814383506775 0.08304715901613235
decider.lstm.weight_ih_l0: -4.3796710087917745e-05 0.14777807891368866
decider.lstm.weight_hh_l0: -0.0025367271155118942 0.1463659405708313
decider.lstm.bias_ih_l0: 0.02045748569071293 0.15337616205215454
decider.lstm.bias_hh_l0: 0.001469956710934639 0.14398938417434692
decider.linear1.weight: 0.0008132766815833747 0.12167713791131973
decider.linear1.bias: 0.016117636114358902 0.11651386320590973
decider.linear2.weight: 0.006511325482279062 0.05738842487335205
decider.linear2.bias: 0.006354602985084057 0.05933155119419098
decider.linear3.weight: -0.03875182196497917 0.0941220223903656
decider.linear3.bias: -0.028583478182554245 0.05743717402219772

Rewards:
190.8927
190.8927
190.8927
objective = 0.05052739009261131
==== episode 3500/10000 ====
action = 1
probs = 0.0007 0.9993 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003452359524089843 0.08440876007080078
encoder.encoder.weight_hh_l0: -0.0002685659273993224 0.08644679188728333
encoder.encoder.bias_ih_l0: 0.00954877957701683 0.08564254641532898
encoder.encoder.bias_hh_l0: 0.019545869901776314 0.08479811996221542
encoder.encoder.weight_ih_l0_reverse: 0.001693120226264 0.08618726581335068
encoder.encoder.weight_hh_l0_reverse: 0.0030902368016541004 0.08494546264410019
encoder.encoder.bias_ih_l0_reverse: 0.024860253557562828 0.08449512720108032
encoder.encoder.bias_hh_l0_reverse: 0.016725687310099602 0.0830652117729187
decider.lstm.weight_ih_l0: -3.66812564607244e-05 0.14779964089393616
decider.lstm.weight_hh_l0: -0.002549289958551526 0.14638499915599823
decider.lstm.bias_ih_l0: 0.020574744790792465 0.15339593589305878
decider.lstm.bias_hh_l0: 0.001587206730619073 0.14400801062583923
decider.linear1.weight: 0.000807211734354496 0.12170115113258362
decider.linear1.bias: 0.016210133209824562 0.11652012914419174
decider.linear2.weight: 0.006541739217936993 0.05740338936448097
decider.linear2.bias: 0.006398176774382591 0.059350356459617615
decider.linear3.weight: -0.03877846524119377 0.0941678136587143
decider.linear3.bias: -0.028603848069906235 0.05756327509880066

Rewards:
190.8927
190.8927
190.8927
objective = 0.044359661638736725
==== episode 3600/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003466807829681784 0.08442353457212448
encoder.encoder.weight_hh_l0: -0.00027164016501046717 0.08647914975881577
encoder.encoder.bias_ih_l0: 0.009637140668928623 0.08566445112228394
encoder.encoder.bias_hh_l0: 0.01963423378765583 0.08482225984334946
encoder.encoder.weight_ih_l0_reverse: 0.0016999102663248777 0.08620188385248184
encoder.encoder.weight_hh_l0_reverse: 0.00310215400531888 0.08496368676424026
encoder.encoder.bias_ih_l0_reverse: 0.024925049394369125 0.08451317250728607
encoder.encoder.bias_hh_l0_reverse: 0.0167904794216156 0.08308189362287521
decider.lstm.weight_ih_l0: -3.0255801902967505e-05 0.14781920611858368
decider.lstm.weight_hh_l0: -0.002561532659456134 0.1464024782180786
decider.lstm.bias_ih_l0: 0.020682189613580704 0.15341442823410034
decider.lstm.bias_hh_l0: 0.0016946559771895409 0.144024059176445
decider.linear1.weight: 0.0008010208839550614 0.12172397971153259
decider.linear1.bias: 0.01629793457686901 0.11652644723653793
decider.linear2.weight: 0.006570631638169289 0.05741756036877632
decider.linear2.bias: 0.006439079064875841 0.059368111193180084
decider.linear3.weight: -0.03880058228969574 0.0942075178027153
decider.linear3.bias: -0.028620555996894836 0.05767832696437836

Rewards:
190.8927
190.8927
190.8927
objective = 0.03926651552319527
==== episode 3700/10000 ====
action = 1
probs = 0.0005 0.9995 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034783242153935134 0.08443698287010193
encoder.encoder.weight_hh_l0: -0.00027459891862235963 0.08650973439216614
encoder.encoder.bias_ih_l0: 0.00972063560038805 0.08568498492240906
encoder.encoder.bias_hh_l0: 0.019717726856470108 0.08484485745429993
encoder.encoder.weight_ih_l0_reverse: 0.0017064794665202498 0.08621571213006973
encoder.encoder.weight_hh_l0_reverse: 0.0031135869212448597 0.08498108386993408
encoder.encoder.bias_ih_l0_reverse: 0.024987326934933662 0.08453027904033661
encoder.encoder.bias_hh_l0_reverse: 0.016852758824825287 0.08309760689735413
decider.lstm.weight_ih_l0: -2.4357103029615246e-05 0.14783723652362823
decider.lstm.weight_hh_l0: -0.0025735727977007627 0.14641878008842468
decider.lstm.bias_ih_l0: 0.02078232169151306 0.15343208611011505
decider.lstm.bias_hh_l0: 0.0017947801388800144 0.14403808116912842
decider.linear1.weight: 0.0007947765989229083 0.12174587696790695
decider.linear1.bias: 0.016381582245230675 0.11653256416320801
decider.linear2.weight: 0.006598317995667458 0.057431191205978394
decider.linear2.bias: 0.006477839313447475 0.05938498675823212
decider.linear3.weight: -0.03881938382983208 0.09424276649951935
decider.linear3.bias: -0.028634607791900635 0.05778523534536362

Rewards:
190.8927
190.8927
190.8927
objective = 0.03495929390192032
==== episode 3800/10000 ====
action = 1
probs = 0.0005 0.9995 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034872631658799946 0.08444927632808685
encoder.encoder.weight_hh_l0: -0.00027745880652219057 0.08653879910707474
encoder.encoder.bias_ih_l0: 0.00979984737932682 0.08570429682731628
encoder.encoder.bias_hh_l0: 0.019796935841441154 0.08486609160900116
encoder.encoder.weight_ih_l0_reverse: 0.0017128449399024248 0.0862288549542427
encoder.encoder.weight_hh_l0_reverse: 0.003124577458947897 0.0849977359175682
encoder.encoder.bias_ih_l0_reverse: 0.025047292932868004 0.08454650640487671
encoder.encoder.bias_hh_l0_reverse: 0.016912728548049927 0.0831124559044838
decider.lstm.weight_ih_l0: -1.8904655007645488e-05 0.14785397052764893
decider.lstm.weight_hh_l0: -0.0025854110717773438 0.146434023976326
decider.lstm.bias_ih_l0: 0.02087617851793766 0.15344902873039246
decider.lstm.bias_hh_l0: 0.0018886392936110497 0.14405038952827454
decider.linear1.weight: 0.0007885016384534538 0.12176696211099625
decider.linear1.bias: 0.016461502760648727 0.11653845757246017
decider.linear2.weight: 0.006624930072575808 0.05744434520602226
decider.linear2.bias: 0.0065147047862410545 0.059401076287031174
decider.linear3.weight: -0.0388355515897274 0.09427439421415329
decider.linear3.bias: -0.028646554797887802 0.05788518488407135

Rewards:
190.8927
190.8927
190.8927
objective = 0.03128226101398468
==== episode 3900/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003493919793982059 0.08446059376001358
encoder.encoder.weight_hh_l0: -0.000280234293313697 0.0865665003657341
encoder.encoder.bias_ih_l0: 0.009875276125967503 0.08572254329919815
encoder.encoder.bias_hh_l0: 0.019872361794114113 0.0848861113190651
encoder.encoder.weight_ih_l0_reverse: 0.0017190256621688604 0.08624140173196793
encoder.encoder.weight_hh_l0_reverse: 0.0031351677607744932 0.0850137323141098
encoder.encoder.bias_ih_l0_reverse: 0.025105170905590057 0.08456195145845413
encoder.encoder.bias_hh_l0_reverse: 0.016970600932836533 0.08312655985355377
decider.lstm.weight_ih_l0: -1.3832934200763702e-05 0.14786961674690247
decider.lstm.weight_hh_l0: -0.0025970623828470707 0.14644840359687805
decider.lstm.bias_ih_l0: 0.02096462994813919 0.15346534550189972
decider.lstm.bias_hh_l0: 0.0019770925864577293 0.14406122267246246
decider.linear1.weight: 0.0007822082261554897 0.12178732454776764
decider.linear1.bias: 0.0165381021797657 0.11654414981603622
decider.linear2.weight: 0.006650587543845177 0.057457081973552704
decider.linear2.bias: 0.006549892947077751 0.05941646173596382
decider.linear3.weight: -0.03884957358241081 0.09430304169654846
decider.linear3.bias: -0.028656816110014915 0.057979125529527664

Rewards:
190.8927
190.8927
190.8927
objective = 0.02811387926340103
==== episode 4000/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034984832745976746 0.08447105437517166
encoder.encoder.weight_hh_l0: -0.00028293696232140064 0.08659300953149796
encoder.encoder.bias_ih_l0: 0.009947359561920166 0.08573982864618301
encoder.encoder.bias_hh_l0: 0.0199444480240345 0.08490504324436188
encoder.encoder.weight_ih_l0_reverse: 0.0017250415403395891 0.08625341206789017
encoder.encoder.weight_hh_l0_reverse: 0.0031453981064260006 0.08502914756536484
encoder.encoder.bias_ih_l0_reverse: 0.02516116574406624 0.08457668870687485
encoder.encoder.bias_hh_l0_reverse: 0.017026593908667564 0.08314000815153122
decider.lstm.weight_ih_l0: -9.087026228371542e-06 0.1478843092918396
decider.lstm.weight_hh_l0: -0.0026085355784744024 0.14646199345588684
decider.lstm.bias_ih_l0: 0.02104836143553257 0.1534811109304428
decider.lstm.bias_hh_l0: 0.002060829196125269 0.1440708339214325
decider.linear1.weight: 0.0007758862338960171 0.1218070387840271
decider.linear1.bias: 0.01661183498799801 0.11654967069625854
decider.linear2.weight: 0.00667541055008769 0.057469442486763
decider.linear2.bias: 0.006583613343536854 0.05943124741315842
decider.linear3.weight: -0.03886184096336365 0.09432919323444366
decider.linear3.bias: -0.028665713965892792 0.05806783214211464

Rewards:
190.8927
190.8927
190.8927
objective = 0.02536681294441223
==== episode 4100/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003501143946778029 0.08448067307472229
encoder.encoder.weight_hh_l0: -0.0002855524071492255 0.08661820739507675
encoder.encoder.bias_ih_l0: 0.010015794076025486 0.0857560858130455
encoder.encoder.bias_hh_l0: 0.020012883469462395 0.08492283523082733
encoder.encoder.weight_ih_l0_reverse: 0.001730848802253604 0.08626484870910645
encoder.encoder.weight_hh_l0_reverse: 0.0031552044674754143 0.08504390716552734
encoder.encoder.bias_ih_l0_reverse: 0.025214914232492447 0.08459065109491348
encoder.encoder.bias_hh_l0_reverse: 0.017080344259738922 0.08315273374319077
decider.lstm.weight_ih_l0: -4.664063453674316e-06 0.14789803326129913
decider.lstm.weight_hh_l0: -0.002619736595079303 0.14647480845451355
decider.lstm.bias_ih_l0: 0.02112720161676407 0.15349622070789337
decider.lstm.bias_hh_l0: 0.0021396614611148834 0.1440793126821518
decider.linear1.weight: 0.0007696041720919311 0.12182600796222687
decider.linear1.bias: 0.016682317480444908 0.11655501276254654
decider.linear2.weight: 0.006699251942336559 0.057481348514556885
decider.linear2.bias: 0.006615706253796816 0.059445351362228394
decider.linear3.weight: -0.03887254744768143 0.09435300529003143
decider.linear3.bias: -0.028673401102423668 0.058151114732027054

Rewards:
190.8927
190.8927
190.8927
objective = 0.022987887263298035
==== episode 4200/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003502118634060025 0.08448964357376099
encoder.encoder.weight_hh_l0: -0.0002881151158362627 0.08664248883724213
encoder.encoder.bias_ih_l0: 0.010081632062792778 0.0857715755701065
encoder.encoder.bias_hh_l0: 0.020078714936971664 0.08493977785110474
encoder.encoder.weight_ih_l0_reverse: 0.001736524049192667 0.08627588301897049
encoder.encoder.weight_hh_l0_reverse: 0.003164720954373479 0.08505820482969284
encoder.encoder.bias_ih_l0_reverse: 0.025267157703638077 0.08460403978824615
encoder.encoder.bias_hh_l0_reverse: 0.017132584005594254 0.08316495269536972
decider.lstm.weight_ih_l0: -4.818476782020298e-07 0.14791108667850494
decider.lstm.weight_hh_l0: -0.0026307892985641956 0.1464870423078537
decider.lstm.bias_ih_l0: 0.021202463656663895 0.1535108983516693
decider.lstm.bias_hh_l0: 0.00221492862328887 0.14408685266971588
decider.linear1.weight: 0.0007633016211912036 0.12184447795152664
decider.linear1.bias: 0.016750555485486984 0.116560198366642
decider.linear2.weight: 0.006722445599734783 0.05749296396970749
decider.linear2.bias: 0.006646652240306139 0.059458982199430466
decider.linear3.weight: -0.0388820543885231 0.09437508136034012
decider.linear3.bias: -0.028680168092250824 0.058230433613061905

Rewards:
190.8927
190.8927
190.8927
objective = 0.02089359611272812
==== episode 4300/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000350153015460819 0.08449805527925491
encoder.encoder.weight_hh_l0: -0.0002906326553784311 0.08666593581438065
encoder.encoder.bias_ih_l0: 0.010145123116672039 0.085786372423172
encoder.encoder.bias_hh_l0: 0.0201422069221735 0.08495596051216125
encoder.encoder.weight_ih_l0_reverse: 0.0017420771764591336 0.08628656715154648
encoder.encoder.weight_hh_l0_reverse: 0.003173971548676491 0.0850720927119255
encoder.encoder.bias_ih_l0_reverse: 0.025318006053566933 0.08461692184209824
encoder.encoder.bias_hh_l0_reverse: 0.017183436080813408 0.08317670226097107
decider.lstm.weight_ih_l0: 3.4902616334875347e-06 0.1479235142469406
decider.lstm.weight_hh_l0: -0.0026417074259370565 0.14649876952171326
decider.lstm.bias_ih_l0: 0.021274544298648834 0.15352517366409302
decider.lstm.bias_hh_l0: 0.002287011593580246 0.1440936177968979
decider.linear1.weight: 0.0007569764275103807 0.1218625083565712
decider.linear1.bias: 0.016816772520542145 0.1165652796626091
decider.linear2.weight: 0.006745051592588425 0.0575043223798275
decider.linear2.bias: 0.006676563993096352 0.05947218835353851
decider.linear3.weight: -0.038890544325113297 0.09439563751220703
decider.linear3.bias: -0.028686154633760452 0.05830618739128113

Rewards:
190.8927
190.8927
190.8927
objective = 0.01903839036822319
==== episode 4400/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034994803718291223 0.08450594544410706
encoder.encoder.weight_hh_l0: -0.0002931105555035174 0.08668861538171768
encoder.encoder.bias_ih_l0: 0.010206487029790878 0.08580053597688675
encoder.encoder.bias_hh_l0: 0.020203571766614914 0.08497142791748047
encoder.encoder.weight_ih_l0_reverse: 0.0017475177301093936 0.0862969234585762
encoder.encoder.weight_hh_l0_reverse: 0.0031829767394810915 0.08508560806512833
encoder.encoder.bias_ih_l0_reverse: 0.02536758780479431 0.08462931215763092
encoder.encoder.bias_hh_l0_reverse: 0.017233019694685936 0.08318804949522018
decider.lstm.weight_ih_l0: 7.275044936250197e-06 0.1479354202747345
decider.lstm.weight_hh_l0: -0.002652496099472046 0.1465100347995758
decider.lstm.bias_ih_l0: 0.021343769505620003 0.15353910624980927
decider.lstm.bias_hh_l0: 0.002356239128857851 0.1440996527671814
decider.linear1.weight: 0.0007506312686018646 0.12188012897968292
decider.linear1.bias: 0.016881151124835014 0.11657024174928665
decider.linear2.weight: 0.006767124403268099 0.05751543119549751
decider.linear2.bias: 0.0067055304534733295 0.05948500707745552
decider.linear3.weight: -0.038898155093193054 0.09441486746072769
decider.linear3.bias: -0.028691496700048447 0.05837876722216606

Rewards:
190.8927
190.8927
190.8927
objective = 0.01738809607923031
==== episode 4500/10000 ====
action = 1
probs = 0.0015 0.9985 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003525583306327462 0.08436721563339233
encoder.encoder.weight_hh_l0: -0.0002350138674955815 0.08625929057598114
encoder.encoder.bias_ih_l0: 0.008986926637589931 0.08553194254636765
encoder.encoder.bias_hh_l0: 0.018984006717801094 0.0846608579158783
encoder.encoder.weight_ih_l0_reverse: 0.0016387959476560354 0.08611772954463959
encoder.encoder.weight_hh_l0_reverse: 0.0030206642113626003 0.0848417729139328
encoder.encoder.bias_ih_l0_reverse: 0.0244611706584692 0.08442751318216324
encoder.encoder.bias_hh_l0_reverse: 0.016326598823070526 0.08295270055532455
decider.lstm.weight_ih_l0: -8.005996642168611e-05 0.14770182967185974
decider.lstm.weight_hh_l0: -0.0024534910917282104 0.14629797637462616
decider.lstm.bias_ih_l0: 0.01997058093547821 0.15326064825057983
decider.lstm.bias_hh_l0: 0.0009830498602241278 0.14395080506801605
decider.linear1.weight: 0.0008582207374274731 0.12156309932470322
decider.linear1.bias: 0.015682514756917953 0.11650070548057556
decider.linear2.weight: 0.006316353566944599 0.0573127456009388
decider.linear2.bias: 0.006102604325860739 0.059243831783533096
decider.linear3.weight: -0.03896879777312279 0.09430886805057526
decider.linear3.bias: -0.028749167919158936 0.05687868967652321

Rewards:
190.8927
190.8927
190.8927
objective = 0.09251799434423447
==== episode 4600/10000 ====
action = 1
probs = 0.0012 0.9988 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035870858118869364 0.08440449088811874
encoder.encoder.weight_hh_l0: -0.0002392953756498173 0.08631650358438492
encoder.encoder.bias_ih_l0: 0.009133183397352695 0.08557405322790146
encoder.encoder.bias_hh_l0: 0.01913026161491871 0.08470796793699265
encoder.encoder.weight_ih_l0_reverse: 0.0016476508462801576 0.0861441045999527
encoder.encoder.weight_hh_l0_reverse: 0.003037866437807679 0.08487237244844437
encoder.encoder.bias_ih_l0_reverse: 0.024538235738873482 0.08445466309785843
encoder.encoder.bias_hh_l0_reverse: 0.016403665766119957 0.08298715949058533
decider.lstm.weight_ih_l0: -6.471482629422098e-05 0.14774979650974274
decider.lstm.weight_hh_l0: -0.002465445315465331 0.14633625745773315
decider.lstm.bias_ih_l0: 0.020191973075270653 0.15329109132289886
decider.lstm.bias_hh_l0: 0.001204450847581029 0.14400173723697662
decider.linear1.weight: 0.0008523603319190443 0.12159521132707596
decider.linear1.bias: 0.015809407457709312 0.11650441586971283
decider.linear2.weight: 0.006364740896970034 0.05733627825975418
decider.linear2.bias: 0.00617411220446229 0.05927212908864021
decider.linear3.weight: -0.03907429426908493 0.09445904940366745
decider.linear3.bias: -0.028836170211434364 0.05713681876659393

Rewards:
190.8927
190.8927
190.8927
objective = 0.07549665868282318
==== episode 4700/10000 ====
action = 1
probs = 0.0010 0.9990 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003635731991380453 0.0844355896115303
encoder.encoder.weight_hh_l0: -0.00024320126976817846 0.08636688441038132
encoder.encoder.bias_ih_l0: 0.009263725019991398 0.08561095595359802
encoder.encoder.bias_hh_l0: 0.01926080510020256 0.08474992960691452
encoder.encoder.weight_ih_l0_reverse: 0.0016560257645323873 0.08616747707128525
encoder.encoder.weight_hh_l0_reverse: 0.00305394665338099 0.0848999097943306
encoder.encoder.bias_ih_l0_reverse: 0.02461305819451809 0.08447994291782379
encoder.encoder.bias_hh_l0_reverse: 0.016478486359119415 0.08301671594381332
decider.lstm.weight_ih_l0: -5.1978564442833886e-05 0.14778928458690643
decider.lstm.weight_hh_l0: -0.002477511065080762 0.14636856317520142
decider.lstm.bias_ih_l0: 0.02037964016199112 0.15331827104091644
decider.lstm.bias_hh_l0: 0.001392115605995059 0.14404264092445374
decider.linear1.weight: 0.0008469097665511072 0.12162469327449799
decider.linear1.bias: 0.015924036502838135 0.11650876700878143
decider.linear2.weight: 0.006408057175576687 0.05735691636800766
decider.linear2.bias: 0.006238373927772045 0.0592975839972496
decider.linear3.weight: -0.03915008530020714 0.09457223862409592
decider.linear3.bias: -0.028897859156131744 0.05735543370246887

Rewards:
190.8927
190.8927
190.8927
objective = 0.06299372017383575
==== episode 4800/10000 ====
action = 1
probs = 0.0024 0.9976 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003467602073214948 0.08430849760770798
encoder.encoder.weight_hh_l0: -0.00021080464648548514 0.08608413487672806
encoder.encoder.bias_ih_l0: 0.008451282046735287 0.085418201982975
encoder.encoder.bias_hh_l0: 0.018448365852236748 0.08452059328556061
encoder.encoder.weight_ih_l0_reverse: 0.001594883855432272 0.08605175465345383
encoder.encoder.weight_hh_l0_reverse: 0.002948012202978134 0.0847456082701683
encoder.encoder.bias_ih_l0_reverse: 0.02405950427055359 0.08433711528778076
encoder.encoder.bias_hh_l0_reverse: 0.015924936160445213 0.08286666125059128
decider.lstm.weight_ih_l0: -0.00011334323789924383 0.14760860800743103
decider.lstm.weight_hh_l0: -0.002370798494666815 0.14621418714523315
decider.lstm.bias_ih_l0: 0.019386641681194305 0.15315353870391846
decider.lstm.bias_hh_l0: 0.00039911456406116486 0.14389076828956604
decider.linear1.weight: 0.0008703349158167839 0.12141340225934982
decider.linear1.bias: 0.015408962033689022 0.11683817207813263
decider.linear2.weight: 0.006190359592437744 0.05734448879957199
decider.linear2.bias: 0.005834043957293034 0.05914536491036415
decider.linear3.weight: -0.0394270084798336 0.09480440616607666
decider.linear3.bias: -0.029154807329177856 0.05636492371559143

Rewards:
190.8927
190.8927
190.8927
objective = 0.1553942859172821
==== episode 4900/10000 ====
action = 1
probs = 0.0014 0.9986 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035267547355033457 0.08436029404401779
encoder.encoder.weight_hh_l0: -0.00021628501417580992 0.08615370094776154
encoder.encoder.bias_ih_l0: 0.008627235889434814 0.08546891063451767
encoder.encoder.bias_hh_l0: 0.01862432435154915 0.08457375317811966
encoder.encoder.weight_ih_l0_reverse: 0.001595127279870212 0.08607958257198334
encoder.encoder.weight_hh_l0_reverse: 0.0029629257041960955 0.08477318286895752
encoder.encoder.bias_ih_l0_reverse: 0.024112340062856674 0.08435442298650742
encoder.encoder.bias_hh_l0_reverse: 0.01597777009010315 0.08289892226457596
decider.lstm.weight_ih_l0: -9.324855636805296e-05 0.147671177983284
decider.lstm.weight_hh_l0: -0.0023767740931361914 0.146262064576149
decider.lstm.bias_ih_l0: 0.019673611968755722 0.15320415794849396
decider.lstm.bias_hh_l0: 0.000686093233525753 0.1439511924982071
decider.linear1.weight: 0.0008442739490419626 0.12146903574466705
decider.linear1.bias: 0.01578069105744362 0.11732304096221924
decider.linear2.weight: 0.006326294969767332 0.05759207904338837
decider.linear2.bias: 0.005915076471865177 0.059180401265621185
decider.linear3.weight: -0.03960464149713516 0.09505873918533325
decider.linear3.bias: -0.02931956946849823 0.0567157007753849

Rewards:
190.8927
190.8927
190.8927
objective = 0.09034545719623566
==== episode 5000/10000 ====
action = 1
probs = 0.0012 0.9988 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034892125404439867 0.08433935791254044
encoder.encoder.weight_hh_l0: -0.0002107715845340863 0.0861089900135994
encoder.encoder.bias_ih_l0: 0.008499141782522202 0.08544003218412399
encoder.encoder.bias_hh_l0: 0.018496232107281685 0.08454044908285141
encoder.encoder.weight_ih_l0_reverse: 0.0015894633252173662 0.08606337010860443
encoder.encoder.weight_hh_l0_reverse: 0.002949327463284135 0.08475374430418015
encoder.encoder.bias_ih_l0_reverse: 0.02403200976550579 0.08433470129966736
encoder.encoder.bias_hh_l0_reverse: 0.015897436067461967 0.0828806608915329
decider.lstm.weight_ih_l0: -0.00010151031892746687 0.14764519035816193
decider.lstm.weight_hh_l0: -0.002362443134188652 0.14623795449733734
decider.lstm.bias_ih_l0: 0.019530661404132843 0.15317024290561676
decider.lstm.bias_hh_l0: 0.0005431408062577248 0.14392609894275665
decider.linear1.weight: 0.0008370744762942195 0.12148233503103256
decider.linear1.bias: 0.015819981694221497 0.11762499064207077
decider.linear2.weight: 0.006332513876259327 0.0577395036816597
decider.linear2.bias: 0.005852203816175461 0.05916662886738777
decider.linear3.weight: -0.03967922553420067 0.09513543546199799
decider.linear3.bias: -0.029385507106781006 0.05657181888818741

Rewards:
190.8927
190.8927
190.8927
objective = 0.07542072236537933
==== episode 5100/10000 ====
action = 1
probs = 0.0024 0.9976 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003363710129633546 0.08426149189472198
encoder.encoder.weight_hh_l0: -0.00019073051225859672 0.0859423503279686
encoder.encoder.bias_ih_l0: 0.007989010773599148 0.08532649278640747
encoder.encoder.bias_hh_l0: 0.017986100167036057 0.08439979702234268
encoder.encoder.weight_ih_l0_reverse: 0.0015695481561124325 0.08600538223981857
encoder.encoder.weight_hh_l0_reverse: 0.0028952958527952433 0.08468662947416306
encoder.encoder.bias_ih_l0_reverse: 0.02373535744845867 0.08426602929830551
encoder.encoder.bias_hh_l0_reverse: 0.015600784681737423 0.08281742036342621
decider.lstm.weight_ih_l0: -0.0001319885195698589 0.1475515216588974
decider.lstm.weight_hh_l0: -0.0023055300116539 0.14615526795387268
decider.lstm.bias_ih_l0: 0.01897834613919258 0.15305215120315552
decider.lstm.bias_hh_l0: -9.174225851893425e-06 0.14383505284786224
decider.linear1.weight: 0.0008564037270843983 0.1213858500123024
decider.linear1.bias: 0.01543037686496973 0.11758788675069809
decider.linear2.weight: 0.0061647058464586735 0.057670749723911285
decider.linear2.bias: 0.005606997758150101 0.0590989775955677
decider.linear3.weight: -0.03991822898387909 0.09537150710821152
decider.linear3.bias: -0.02961679734289646 0.05603661388158798

Rewards:
190.8927
190.8927
190.8927
objective = 0.1523832231760025
==== episode 5200/10000 ====
action = 1
probs = 0.0019 0.9981 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003428717900533229 0.08431369066238403
encoder.encoder.weight_hh_l0: -0.00019516282191034406 0.08600888401269913
encoder.encoder.bias_ih_l0: 0.00815515872091055 0.08537379652261734
encoder.encoder.bias_hh_l0: 0.018152251839637756 0.08444599062204361
encoder.encoder.weight_ih_l0_reverse: 0.0015696121845394373 0.08603330701589584
encoder.encoder.weight_hh_l0_reverse: 0.002909525530412793 0.08471217006444931
encoder.encoder.bias_ih_l0_reverse: 0.023793034255504608 0.08428468555212021
encoder.encoder.bias_hh_l0_reverse: 0.015658462420105934 0.0828433707356453
decider.lstm.weight_ih_l0: -0.00010907676187343895 0.1476152539253235
decider.lstm.weight_hh_l0: -0.0023072538897395134 0.1462060511112213
decider.lstm.bias_ih_l0: 0.01926898956298828 0.15310852229595184
decider.lstm.bias_hh_l0: 0.00028146011754870415 0.14390139281749725
decider.linear1.weight: 0.0008529149927198887 0.12141839414834976
decider.linear1.bias: 0.01555376872420311 0.1175924614071846
decider.linear2.weight: 0.006221223156899214 0.05769751965999603
decider.linear2.bias: 0.005693793762475252 0.05911967158317566
decider.linear3.weight: -0.040100909769535065 0.09564075618982315
decider.linear3.bias: -0.029793722555041313 0.05639556050300598

Rewards:
190.8927
190.8927
190.8927
objective = 0.11950242519378662
==== episode 5300/10000 ====
action = 1
probs = 0.0015 0.9985 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003479558799881488 0.08435623347759247
encoder.encoder.weight_hh_l0: -0.00019901897758245468 0.08606614172458649
encoder.encoder.bias_ih_l0: 0.008305936120450497 0.08541413396596909
encoder.encoder.bias_hh_l0: 0.018303027376532555 0.0844898447394371
encoder.encoder.weight_ih_l0_reverse: 0.0015714934561401606 0.08605773001909256
encoder.encoder.weight_hh_l0_reverse: 0.002923561492934823 0.08473511040210724
encoder.encoder.bias_ih_l0_reverse: 0.023856887593865395 0.08430503308773041
encoder.encoder.bias_hh_l0_reverse: 0.01572231389582157 0.08286421000957489
decider.lstm.weight_ih_l0: -9.073726687347516e-05 0.14766480028629303
decider.lstm.weight_hh_l0: -0.0023125335574150085 0.14624656736850739
decider.lstm.bias_ih_l0: 0.01950334757566452 0.15315483510494232
decider.lstm.bias_hh_l0: 0.0005158241838216782 0.14395402371883392
decider.linear1.weight: 0.0008498397073708475 0.12144768238067627
decider.linear1.bias: 0.015663815662264824 0.11759933084249496
decider.linear2.weight: 0.006270165555179119 0.057720158249139786
decider.linear2.bias: 0.0057693952694535255 0.059139106422662735
decider.linear3.weight: -0.04022165760397911 0.09582634270191193
decider.linear3.bias: -0.02990875393152237 0.056681130081415176

Rewards:
190.8927
190.8927
190.8927
objective = 0.09697344899177551
==== episode 5400/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003520823083817959 0.08439183980226517
encoder.encoder.weight_hh_l0: -0.00020250196394044906 0.08611667156219482
encoder.encoder.bias_ih_l0: 0.008443091996014118 0.08544954657554626
encoder.encoder.bias_hh_l0: 0.018440183252096176 0.0845305323600769
encoder.encoder.weight_ih_l0_reverse: 0.0015742199029773474 0.08607938140630722
encoder.encoder.weight_hh_l0_reverse: 0.0029370440170168877 0.08475596457719803
encoder.encoder.bias_ih_l0_reverse: 0.023921804502606392 0.08432525396347046
encoder.encoder.bias_hh_l0_reverse: 0.01578722894191742 0.08288190513849258
decider.lstm.weight_ih_l0: -7.557753269793466e-05 0.14770516753196716
decider.lstm.weight_hh_l0: -0.0023195212706923485 0.1462801843881607
decider.lstm.bias_ih_l0: 0.019700098782777786 0.15319427847862244
decider.lstm.bias_hh_l0: 0.0007125686388462782 0.1439969390630722
decider.linear1.weight: 0.0008471086621284485 0.12147440761327744
decider.linear1.bias: 0.015763461589813232 0.11760753393173218
decider.linear2.weight: 0.006313557270914316 0.05773978680372238
decider.linear2.bias: 0.005836705677211285 0.05915740504860878
decider.linear3.weight: -0.04030771926045418 0.09596391022205353
decider.linear3.bias: -0.02998938225209713 0.056919168680906296

Rewards:
190.8927
190.8927
190.8927
objective = 0.08061929047107697
==== episode 5500/10000 ====
action = 1
probs = 0.0011 0.9989 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003555057046469301 0.08442224562168121
encoder.encoder.weight_hh_l0: -0.00020573112124111503 0.08616209030151367
encoder.encoder.bias_ih_l0: 0.008568699471652508 0.08548126369714737
encoder.encoder.bias_hh_l0: 0.018565794453024864 0.084568090736866
encoder.encoder.weight_ih_l0_reverse: 0.0015773572959005833 0.0860987976193428
encoder.encoder.weight_hh_l0_reverse: 0.0029498818330466747 0.08477514237165451
encoder.encoder.bias_ih_l0_reverse: 0.023985737934708595 0.08434467762708664
encoder.encoder.bias_hh_l0_reverse: 0.015851160511374474 0.08289746940135956
decider.lstm.weight_ih_l0: -6.274733459576964e-05 0.14773918688297272
decider.lstm.weight_hh_l0: -0.002327383030205965 0.14630883932113647
decider.lstm.bias_ih_l0: 0.0198699701577425 0.15322871506214142
decider.lstm.bias_hh_l0: 0.0008824456017464399 0.14403264224529266
decider.linear1.weight: 0.0008440704550594091 0.12149930745363235
decider.linear1.bias: 0.015856314450502396 0.11761564016342163
decider.linear2.weight: 0.006353302858769894 0.057758159935474396
decider.linear2.bias: 0.005897603463381529 0.05917471647262573
decider.linear3.weight: -0.040372204035520554 0.09607098996639252
decider.linear3.bias: -0.030048836022615433 0.05712386220693588

Rewards:
190.8927
190.8927
190.8927
objective = 0.0682254433631897
==== episode 5600/10000 ====
action = 1
probs = 0.0009 0.9991 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035835563903674483 0.08444838225841522
encoder.encoder.weight_hh_l0: -0.00020875157497357577 0.08620309829711914
encoder.encoder.bias_ih_l0: 0.008683474734425545 0.08550979942083359
encoder.encoder.bias_hh_l0: 0.018680570647120476 0.0846024751663208
encoder.encoder.weight_ih_l0_reverse: 0.001580658950842917 0.0861162468791008
encoder.encoder.weight_hh_l0_reverse: 0.002961962018162012 0.08479275554418564
encoder.encoder.bias_ih_l0_reverse: 0.024047255516052246 0.0843629390001297
encoder.encoder.bias_hh_l0_reverse: 0.015912679955363274 0.08291139453649521
decider.lstm.weight_ih_l0: -5.1792430895147845e-05 0.1477683037519455
decider.lstm.weight_hh_l0: -0.0023356189485639334 0.14633359014987946
decider.lstm.bias_ih_l0: 0.0200183242559433 0.15325911343097687
decider.lstm.bias_hh_l0: 0.0010308045893907547 0.1440626084804535
decider.linear1.weight: 0.0008408364374190569 0.12152249366044998
decider.linear1.bias: 0.015942655503749847 0.11762349307537079
decider.linear2.weight: 0.006389775779098272 0.05777532234787941
decider.linear2.bias: 0.005952857434749603 0.05919100344181061
decider.linear3.weight: -0.04042185842990875 0.09615658223628998
decider.linear3.bias: -0.030093956738710403 0.05730216205120087

Rewards:
190.8927
190.8927
190.8927
objective = 0.05863933265209198
==== episode 5700/10000 ====
action = 1
probs = 0.0008 0.9992 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000360745849320665 0.0844714343547821
encoder.encoder.weight_hh_l0: -0.00021164231293369085 0.08624093234539032
encoder.encoder.bias_ih_l0: 0.008790263906121254 0.08553612232208252
encoder.encoder.bias_hh_l0: 0.018787356093525887 0.08463442325592041
encoder.encoder.weight_ih_l0_reverse: 0.0015840500127524137 0.08613232523202896
encoder.encoder.weight_hh_l0_reverse: 0.0029734920244663954 0.08480925858020782
encoder.encoder.bias_ih_l0_reverse: 0.024107102304697037 0.08438046276569366
encoder.encoder.bias_hh_l0_reverse: 0.015972532331943512 0.08292416483163834
decider.lstm.weight_ih_l0: -4.2193307308480144e-05 0.1477939933538437
decider.lstm.weight_hh_l0: -0.002344102133065462 0.14635562896728516
decider.lstm.bias_ih_l0: 0.02015148475766182 0.15328659117221832
decider.lstm.bias_hh_l0: 0.0011639553122222424 0.14408840239048004
decider.linear1.weight: 0.000837378145661205 0.12154459953308105
decider.linear1.bias: 0.016025103628635406 0.1176314577460289
decider.linear2.weight: 0.0064244503155350685 0.05779159814119339
decider.linear2.bias: 0.006004778668284416 0.05920635908842087
decider.linear3.weight: -0.040461599826812744 0.09622766077518463
decider.linear3.bias: -0.0301295705139637 0.05746181309223175

Rewards:
190.8927
190.8927
190.8927
objective = 0.05096768960356712
==== episode 5800/10000 ====
action = 1
probs = 0.0054 0.9946 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032030438887886703 0.08416925370693207
encoder.encoder.weight_hh_l0: -0.00016139537910930812 0.0857149213552475
encoder.encoder.bias_ih_l0: 0.007247119210660458 0.08518841117620468
encoder.encoder.bias_hh_l0: 0.017244216054677963 0.08420576900243759
encoder.encoder.weight_ih_l0_reverse: 0.001542643178254366 0.08592201769351959
encoder.encoder.weight_hh_l0_reverse: 0.00280558574013412 0.08459395170211792
encoder.encoder.bias_ih_l0_reverse: 0.023217976093292236 0.08416268974542618
encoder.encoder.bias_hh_l0_reverse: 0.015083403326570988 0.08277016878128052
decider.lstm.weight_ih_l0: -0.00018356065265834332 0.14743131399154663
decider.lstm.weight_hh_l0: -0.002213538158684969 0.14605699479579926
decider.lstm.bias_ih_l0: 0.01816539652645588 0.15286223590373993
decider.lstm.bias_hh_l0: -0.0008221282623708248 0.14373047649860382
decider.linear1.weight: 0.000891883100848645 0.1212402880191803
decider.linear1.bias: 0.014844081364572048 0.11755228042602539
decider.linear2.weight: 0.005889792460948229 0.057584866881370544
decider.linear2.bias: 0.005208290182054043 0.05899244174361229
decider.linear3.weight: -0.040714990347623825 0.09635375440120697
decider.linear3.bias: -0.030395831912755966 0.05539544299244881

Rewards:
190.8927
190.8927
190.8927
objective = 0.3454795777797699
==== episode 5900/10000 ====
action = 1
probs = 0.0034 0.9966 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033155560959130526 0.0842512920498848
encoder.encoder.weight_hh_l0: -0.0001666863972786814 0.08581005036830902
encoder.encoder.bias_ih_l0: 0.0074532777070999146 0.08525988459587097
encoder.encoder.bias_hh_l0: 0.017450373619794846 0.08425627648830414
encoder.encoder.weight_ih_l0_reverse: 0.0015356636140495539 0.0859588235616684
encoder.encoder.weight_hh_l0_reverse: 0.002818658482283354 0.08462527394294739
encoder.encoder.bias_ih_l0_reverse: 0.023259256035089493 0.08416568487882614
encoder.encoder.bias_hh_l0_reverse: 0.01512468047440052 0.08280288428068161
decider.lstm.weight_ih_l0: -0.00014517125964630395 0.14753688871860504
decider.lstm.weight_hh_l0: -0.0021969808731228113 0.14612461626529694
decider.lstm.bias_ih_l0: 0.018633989617228508 0.15297770500183105
decider.lstm.bias_hh_l0: -0.00035353098064661026 0.14385849237442017
decider.linear1.weight: 0.0008628798532299697 0.12133605778217316
decider.linear1.bias: 0.015277034603059292 0.1172785609960556
decider.linear2.weight: 0.006039868108928204 0.05770975351333618
decider.linear2.bias: 0.005326403304934502 0.05900515615940094
decider.linear3.weight: -0.041315093636512756 0.0972309410572052
decider.linear3.bias: -0.031102903187274933 0.056201789528131485

Rewards:
190.8927
190.8927
190.8927
objective = 0.2144624888896942
==== episode 6000/10000 ====
action = 1
probs = 0.0020 0.9980 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003369417681824416 0.08430562168359756
encoder.encoder.weight_hh_l0: -0.00017189671052619815 0.08588365465402603
encoder.encoder.bias_ih_l0: 0.007649850565940142 0.08530741184949875
encoder.encoder.bias_hh_l0: 0.017646944150328636 0.08431719243526459
encoder.encoder.weight_ih_l0_reverse: 0.0015314713818952441 0.08597689867019653
encoder.encoder.weight_hh_l0_reverse: 0.002830004785209894 0.08464536815881729
encoder.encoder.bias_ih_l0_reverse: 0.02329525351524353 0.08417116105556488
encoder.encoder.bias_hh_l0_reverse: 0.015160677954554558 0.08282480388879776
decider.lstm.weight_ih_l0: -0.00011778496264014393 0.14760364592075348
decider.lstm.weight_hh_l0: -0.0021936881821602583 0.1461707055568695
decider.lstm.bias_ih_l0: 0.01895304210484028 0.15305687487125397
decider.lstm.bias_hh_l0: -3.4489668905735016e-05 0.1439470499753952
decider.linear1.weight: 0.0008401569211855531 0.12147694826126099
decider.linear1.bias: 0.01563023217022419 0.11713319271802902
decider.linear2.weight: 0.006170045584440231 0.05787721276283264
decider.linear2.bias: 0.005425352603197098 0.05902790278196335
decider.linear3.weight: -0.04152493551373482 0.0975567027926445
decider.linear3.bias: -0.03133952617645264 0.05663762614130974

Rewards:
190.8927
190.8927
190.8927
objective = 0.12914711236953735
==== episode 6100/10000 ====
action = 1
probs = 0.0014 0.9986 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033988896757364273 0.08434083312749863
encoder.encoder.weight_hh_l0: -0.0001759484293870628 0.08593568205833435
encoder.encoder.bias_ih_l0: 0.007797810714691877 0.08533882349729538
encoder.encoder.bias_hh_l0: 0.017794908955693245 0.08436612784862518
encoder.encoder.weight_ih_l0_reverse: 0.0015293925534933805 0.08598802238702774
encoder.encoder.weight_hh_l0_reverse: 0.0028398523572832346 0.08465970307588577
encoder.encoder.bias_ih_l0_reverse: 0.02332850731909275 0.0841776505112648
encoder.encoder.bias_hh_l0_reverse: 0.015193934552371502 0.08284006267786026
decider.lstm.weight_ih_l0: -9.953621338354424e-05 0.1476466804742813
decider.lstm.weight_hh_l0: -0.0021934390533715487 0.14620111882686615
decider.lstm.bias_ih_l0: 0.019164878875017166 0.15310773253440857
decider.lstm.bias_hh_l0: 0.0001773466356098652 0.1440040022134781
decider.linear1.weight: 0.0008254420245066285 0.12159935384988785
decider.linear1.bias: 0.015864480286836624 0.11707283556461334
decider.linear2.weight: 0.0062437281012535095 0.058014947921037674
decider.linear2.bias: 0.0054743909277021885 0.059053581207990646
decider.linear3.weight: -0.0416145920753479 0.09770060330629349
decider.linear3.bias: -0.0314345546066761 0.05689353868365288

Rewards:
190.8927
190.8927
190.8927
objective = 0.08647911995649338
==== episode 6200/10000 ====
action = 1
probs = 0.0010 0.9990 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003417392435949296 0.08436665683984756
encoder.encoder.weight_hh_l0: -0.0001792882103472948 0.08597609400749207
encoder.encoder.bias_ih_l0: 0.007916530594229698 0.08536230772733688
encoder.encoder.bias_hh_l0: 0.01791362650692463 0.08440671116113663
encoder.encoder.weight_ih_l0_reverse: 0.0015285947592929006 0.08599676191806793
encoder.encoder.weight_hh_l0_reverse: 0.002848916919901967 0.08467159420251846
encoder.encoder.bias_ih_l0_reverse: 0.02336198277771473 0.08418577909469604
encoder.encoder.bias_hh_l0_reverse: 0.01522741001099348 0.08285035938024521
decider.lstm.weight_ih_l0: -8.606852497905493e-05 0.14767847955226898
decider.lstm.weight_hh_l0: -0.0021941601298749447 0.14622391760349274
decider.lstm.bias_ih_l0: 0.01932285539805889 0.15314382314682007
decider.lstm.bias_hh_l0: 0.0003353259526193142 0.14404545724391937
decider.linear1.weight: 0.0008138813427649438 0.1217055469751358
decider.linear1.bias: 0.016049284487962723 0.11704244464635849
decider.linear2.weight: 0.006314144469797611 0.05812845379114151
decider.linear2.bias: 0.005528698675334454 0.059067532420158386
decider.linear3.weight: -0.04166135564446449 0.09778336435556412
decider.linear3.bias: -0.03148169815540314 0.057069290429353714

Rewards:
190.8927
190.8927
190.8927
objective = 0.06251536309719086
==== episode 6300/10000 ====
action = 1
probs = 0.0008 0.9992 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034326445893384516 0.08438686281442642
encoder.encoder.weight_hh_l0: -0.00018212954455520958 0.08600892126560211
encoder.encoder.bias_ih_l0: 0.00801465567201376 0.08538077026605606
encoder.encoder.bias_hh_l0: 0.018011752516031265 0.08444057404994965
encoder.encoder.weight_ih_l0_reverse: 0.0015287523856386542 0.0860045775771141
encoder.encoder.weight_hh_l0_reverse: 0.00285741058178246 0.08468219637870789
encoder.encoder.bias_ih_l0_reverse: 0.023396534845232964 0.08419354259967804
encoder.encoder.bias_hh_l0_reverse: 0.01526196300983429 0.08285900950431824
decider.lstm.weight_ih_l0: -7.567478314740583e-05 0.14770343899726868
decider.lstm.weight_hh_l0: -0.002195291919633746 0.1462419033050537
decider.lstm.bias_ih_l0: 0.019447755068540573 0.15317048132419586
decider.lstm.bias_hh_l0: 0.00046022748574614525 0.14407673478126526
decider.linear1.weight: 0.0008042504778131843 0.12179792672395706
decider.linear1.bias: 0.016200754791498184 0.11703185737133026
decider.linear2.weight: 0.006373368203639984 0.058225780725479126
decider.linear2.bias: 0.0055740587413311005 0.059080060571432114
decider.linear3.weight: -0.04168868809938431 0.09783588349819183
decider.linear3.bias: -0.031508125364780426 0.05720138177275658

Rewards:
190.8927
190.8927
190.8927
objective = 0.04776417464017868
==== episode 6400/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003445478796493262 0.08440328389406204
encoder.encoder.weight_hh_l0: -0.00018462476145941764 0.08603662252426147
encoder.encoder.bias_ih_l0: 0.008097998797893524 0.08539612591266632
encoder.encoder.bias_hh_l0: 0.018095100298523903 0.0844695121049881
encoder.encoder.weight_ih_l0_reverse: 0.0015290365554392338 0.08601105213165283
encoder.encoder.weight_hh_l0_reverse: 0.002864951966330409 0.0846913754940033
encoder.encoder.bias_ih_l0_reverse: 0.02342703379690647 0.0842001736164093
encoder.encoder.bias_hh_l0_reverse: 0.015292470343410969 0.0828668549656868
decider.lstm.weight_ih_l0: -6.732340989401564e-05 0.14772377908229828
decider.lstm.weight_hh_l0: -0.0021966316271573305 0.14625665545463562
decider.lstm.bias_ih_l0: 0.019550591707229614 0.15319189429283142
decider.lstm.bias_hh_l0: 0.0005630594678223133 0.14410139620304108
decider.linear1.weight: 0.0007958868518471718 0.12188078463077545
decider.linear1.bias: 0.01632753387093544 0.1170288473367691
decider.linear2.weight: 0.006423265673220158 0.05831282213330269
decider.linear2.bias: 0.0056116944178938866 0.059090714901685715
decider.linear3.weight: -0.041705988347530365 0.09787213057279587
decider.linear3.bias: -0.03152427822351456 0.05730655789375305

Rewards:
190.8927
190.8927
190.8927
objective = 0.03764984756708145
==== episode 6500/10000 ====
action = 1
probs = 0.0005 0.9995 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003456899430602789 0.08441705256700516
encoder.encoder.weight_hh_l0: -0.0001868479885160923 0.08606058359146118
encoder.encoder.bias_ih_l0: 0.008170182816684246 0.08540947735309601
encoder.encoder.bias_hh_l0: 0.0181672852486372 0.08449479937553406
encoder.encoder.weight_ih_l0_reverse: 0.0015291159506887197 0.08601637184619904
encoder.encoder.weight_hh_l0_reverse: 0.0028717329259961843 0.08469934016466141
encoder.encoder.bias_ih_l0_reverse: 0.02345382608473301 0.08420627564191818
encoder.encoder.bias_hh_l0_reverse: 0.015319268219172955 0.08287404477596283
decider.lstm.weight_ih_l0: -6.04312117502559e-05 0.14774085581302643
decider.lstm.weight_hh_l0: -0.002198080997914076 0.14626914262771606
decider.lstm.bias_ih_l0: 0.019637446850538254 0.15321022272109985
decider.lstm.bias_hh_l0: 0.0006499146111309528 0.14412131905555725
decider.linear1.weight: 0.0007884565275162458 0.12195601314306259
decider.linear1.bias: 0.016436893492937088 0.11703063547611237
decider.linear2.weight: 0.006465821992605925 0.05839196965098381
decider.linear2.bias: 0.005643585696816444 0.05909983441233635
decider.linear3.weight: -0.041717566549777985 0.09789877384901047
decider.linear3.bias: -0.03153475746512413 0.05739329010248184

Rewards:
190.8927
190.8927
190.8927
objective = 0.030386749655008316
==== episode 6600/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034668995067477226 0.08442872017621994
encoder.encoder.weight_hh_l0: -0.00018884991004597396 0.08608146011829376
encoder.encoder.bias_ih_l0: 0.008233224041759968 0.08542107045650482
encoder.encoder.bias_hh_l0: 0.018230322748422623 0.08451694995164871
encoder.encoder.weight_ih_l0_reverse: 0.0015292349271476269 0.08602093905210495
encoder.encoder.weight_hh_l0_reverse: 0.0028778105042874813 0.08470635861158371
encoder.encoder.bias_ih_l0_reverse: 0.023477677255868912 0.08421161025762558
encoder.encoder.bias_hh_l0_reverse: 0.015343114733695984 0.08288063108921051
decider.lstm.weight_ih_l0: -5.467575101647526e-05 0.14775539934635162
decider.lstm.weight_hh_l0: -0.0021995704155415297 0.14627984166145325
decider.lstm.bias_ih_l0: 0.019711870700120926 0.15322574973106384
decider.lstm.bias_hh_l0: 0.0007243291474878788 0.14413774013519287
decider.linear1.weight: 0.0007818322628736496 0.12202434241771698
decider.linear1.bias: 0.01653156243264675 0.11703518778085709
decider.linear2.weight: 0.006502683740109205 0.05846400558948517
decider.linear2.bias: 0.005670825019478798 0.059107717126607895
decider.linear3.weight: -0.04172557592391968 0.09791912883520126
decider.linear3.bias: -0.03154182434082031 0.0574660524725914

Rewards:
190.8927
190.8927
190.8927
objective = 0.02504809945821762
==== episode 6700/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034758722176775336 0.08443889766931534
encoder.encoder.weight_hh_l0: -0.00019069542759098113 0.08610011637210846
encoder.encoder.bias_ih_l0: 0.008289642632007599 0.08543137460947037
encoder.encoder.bias_hh_l0: 0.01828674226999283 0.08453678339719772
encoder.encoder.weight_ih_l0_reverse: 0.0015294111799448729 0.08602497726678848
encoder.encoder.weight_hh_l0_reverse: 0.0028833679389208555 0.08471272885799408
encoder.encoder.bias_ih_l0_reverse: 0.023499412462115288 0.08421635627746582
encoder.encoder.bias_hh_l0_reverse: 0.015364852733910084 0.08288678526878357
decider.lstm.weight_ih_l0: -4.972984970663674e-05 0.14776818454265594
decider.lstm.weight_hh_l0: -0.0022010784596204758 0.14628924429416656
decider.lstm.bias_ih_l0: 0.019777489826083183 0.1532392054796219
decider.lstm.bias_hh_l0: 0.0007899538613855839 0.1441517025232315
decider.linear1.weight: 0.0007757907151244581 0.12208762764930725
decider.linear1.bias: 0.016615644097328186 0.11704150587320328
decider.linear2.weight: 0.006535763386636972 0.05853083357214928
decider.linear2.bias: 0.005694916471838951 0.059114739298820496
decider.linear3.weight: -0.04173139110207558 0.09793549031019211
decider.linear3.bias: -0.031546831130981445 0.05752905085682869

Rewards:
190.8927
190.8927
190.8927
objective = 0.02096947841346264
==== episode 6800/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034829191281460226 0.08444792032241821
encoder.encoder.weight_hh_l0: -0.00019244106078986079 0.08611695468425751
encoder.encoder.bias_ih_l0: 0.008341345936059952 0.08544035255908966
encoder.encoder.bias_hh_l0: 0.018338441848754883 0.08455531299114227
encoder.encoder.weight_ih_l0_reverse: 0.0015297075733542442 0.08602853119373322
encoder.encoder.weight_hh_l0_reverse: 0.0028885803185403347 0.08471869677305222
encoder.encoder.bias_ih_l0_reverse: 0.023519612848758698 0.08422096073627472
encoder.encoder.bias_hh_l0_reverse: 0.015385056845843792 0.08289271593093872
decider.lstm.weight_ih_l0: -4.536993583315052e-05 0.1477797031402588
decider.lstm.weight_hh_l0: -0.0022025350481271744 0.14629770815372467
decider.lstm.bias_ih_l0: 0.019836999475955963 0.15325085818767548
decider.lstm.bias_hh_l0: 0.0008494681678712368 0.1441635936498642
decider.linear1.weight: 0.0007702081347815692 0.12214665859937668
decider.linear1.bias: 0.016691649332642555 0.11704961210489273
decider.linear2.weight: 0.006565629504621029 0.05859335511922836
decider.linear2.bias: 0.005716416984796524 0.059121061116456985
decider.linear3.weight: -0.041735731065273285 0.09794902801513672
decider.linear3.bias: -0.03155049309134483 0.05758447200059891

Rewards:
190.8927
190.8927
190.8927
objective = 0.01776367425918579
==== episode 6900/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003489083028398454 0.08445591479539871
encoder.encoder.weight_hh_l0: -0.00019405505736358464 0.08613206446170807
encoder.encoder.bias_ih_l0: 0.008387931622564793 0.08544835448265076
encoder.encoder.bias_hh_l0: 0.0183850284665823 0.08457212895154953
encoder.encoder.weight_ih_l0_reverse: 0.0015300738159567118 0.08603173494338989
encoder.encoder.weight_hh_l0_reverse: 0.0028933966532349586 0.08472420275211334
encoder.encoder.bias_ih_l0_reverse: 0.02353830821812153 0.08422520011663437
encoder.encoder.bias_hh_l0_reverse: 0.01540374755859375 0.08289825171232224
decider.lstm.weight_ih_l0: -4.157509465585463e-05 0.14778998494148254
decider.lstm.weight_hh_l0: -0.0022039508912712336 0.14630524814128876
decider.lstm.bias_ih_l0: 0.01989021711051464 0.15326088666915894
decider.lstm.bias_hh_l0: 0.0009026932530105114 0.1441737562417984
decider.linear1.weight: 0.0007650967454537749 0.12220113724470139
decider.linear1.bias: 0.01676001027226448 0.11705835163593292
decider.linear2.weight: 0.006757458671927452 0.0586438812315464
decider.linear2.bias: 0.005958307534456253 0.05936247855424881
decider.linear3.weight: -0.0417773500084877 0.09801694750785828
decider.linear3.bias: -0.03155318647623062 0.05763285607099533

Rewards:
190.8927
190.8927
190.8927
objective = 0.013332724571228027
==== episode 7000/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003493625554256141 0.08446187525987625
encoder.encoder.weight_hh_l0: -0.00019528552365954965 0.0861433818936348
encoder.encoder.bias_ih_l0: 0.008422860875725746 0.08545450121164322
encoder.encoder.bias_hh_l0: 0.018419954925775528 0.08458476513624191
encoder.encoder.weight_ih_l0_reverse: 0.0015305007109418511 0.08603440225124359
encoder.encoder.weight_hh_l0_reverse: 0.0028971408028155565 0.08472850173711777
encoder.encoder.bias_ih_l0_reverse: 0.02355346828699112 0.0842287465929985
encoder.encoder.bias_hh_l0_reverse: 0.015418910421431065 0.08290205150842667
decider.lstm.weight_ih_l0: -3.880904841935262e-05 0.14779773354530334
decider.lstm.weight_hh_l0: -0.002205093391239643 0.1463109254837036
decider.lstm.bias_ih_l0: 0.01992996223270893 0.15326787531375885
decider.lstm.bias_hh_l0: 0.0009424383752048016 0.14418119192123413
decider.linear1.weight: 0.0007611315231770277 0.12224272638559341
decider.linear1.bias: 0.016813693568110466 0.11706508696079254
decider.linear2.weight: 0.006965640000998974 0.05877583473920822
decider.linear2.bias: 0.006225421093404293 0.05976124480366707
decider.linear3.weight: -0.04186961427330971 0.09816112369298935
decider.linear3.bias: -0.031554918736219406 0.05766725167632103

Rewards:
190.8927
190.8927
190.8927
objective = 0.008367237634956837
==== episode 7100/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003496514109428972 0.08446609973907471
encoder.encoder.weight_hh_l0: -0.00019616750068962574 0.08615139871835709
encoder.encoder.bias_ih_l0: 0.008447653613984585 0.085458904504776
encoder.encoder.bias_hh_l0: 0.018444746732711792 0.08459373563528061
encoder.encoder.weight_ih_l0_reverse: 0.0015309194568544626 0.08603654056787491
encoder.encoder.weight_hh_l0_reverse: 0.0028998893685638905 0.08473166823387146
encoder.encoder.bias_ih_l0_reverse: 0.02356516383588314 0.08423169702291489
encoder.encoder.bias_hh_l0_reverse: 0.015430601313710213 0.08290434628725052
decider.lstm.weight_ih_l0: -3.6892124626319855e-05 0.14780326187610626
decider.lstm.weight_hh_l0: -0.0022059432230889797 0.14631502330303192
decider.lstm.bias_ih_l0: 0.01995805650949478 0.15327246487140656
decider.lstm.bias_hh_l0: 0.0009705317206680775 0.14418640732765198
decider.linear1.weight: 0.0007582030957564712 0.12227233499288559
decider.linear1.bias: 0.016854126006364822 0.11706998199224472
decider.linear2.weight: 0.007079957984387875 0.058914486318826675
decider.linear2.bias: 0.00636950321495533 0.060098797082901
decider.linear3.weight: -0.04193350672721863 0.09828750789165497
decider.linear3.bias: -0.031556032598018646 0.05769024416804314

Rewards:
190.8927
190.8927
190.8927
objective = 0.005617230664938688
==== episode 7200/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00034985016100108624 0.08446929603815079
encoder.encoder.weight_hh_l0: -0.00019684157450683415 0.08615747839212418
encoder.encoder.bias_ih_l0: 0.008466473780572414 0.08546224981546402
encoder.encoder.bias_hh_l0: 0.01846356876194477 0.08460056036710739
encoder.encoder.weight_ih_l0_reverse: 0.0015313036274164915 0.08603830635547638
encoder.encoder.weight_hh_l0_reverse: 0.002902026753872633 0.08473413437604904
encoder.encoder.bias_ih_l0_reverse: 0.023574577644467354 0.08423420786857605
encoder.encoder.bias_hh_l0_reverse: 0.01544001791626215 0.0829058513045311
decider.lstm.weight_ih_l0: -3.546319931047037e-05 0.14780747890472412
decider.lstm.weight_hh_l0: -0.00220661167986691 0.14631813764572144
decider.lstm.bias_ih_l0: 0.019979320466518402 0.153275728225708
decider.lstm.bias_hh_l0: 0.0009917928837239742 0.14419031143188477
decider.linear1.weight: 0.000755907385610044 0.12229476124048233
decider.linear1.bias: 0.016886267811059952 0.11707375198602676
decider.linear2.weight: 0.007173567079007626 0.05903678014874458
decider.linear2.bias: 0.006488132290542126 0.06035333871841431
decider.linear3.weight: -0.04198041930794716 0.09839687496423721
decider.linear3.bias: -0.03155682608485222 0.05770690739154816

Rewards:
190.8927
190.8927
190.8927
objective = 0.004016592167317867
==== episode 7300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003499964077491313 0.08447183668613434
encoder.encoder.weight_hh_l0: -0.00019738099945243448 0.08616229146718979
encoder.encoder.bias_ih_l0: 0.008481449447572231 0.08546492457389832
encoder.encoder.bias_hh_l0: 0.01847854256629944 0.08460598438978195
encoder.encoder.weight_ih_l0_reverse: 0.0015316474018618464 0.08603978157043457
encoder.encoder.weight_hh_l0_reverse: 0.0029037552885711193 0.08473614603281021
encoder.encoder.bias_ih_l0_reverse: 0.023582372814416885 0.08423636853694916
encoder.encoder.bias_hh_l0_reverse: 0.01544781681150198 0.08290690928697586
decider.lstm.weight_ih_l0: -3.434058089624159e-05 0.14781083166599274
decider.lstm.weight_hh_l0: -0.0022071595303714275 0.1463206261396408
decider.lstm.bias_ih_l0: 0.019996201619505882 0.1532782018184662
decider.lstm.bias_hh_l0: 0.0010086800903081894 0.14419344067573547
decider.linear1.weight: 0.0007540317019447684 0.12231261283159256
decider.linear1.bias: 0.016912762075662613 0.11707684397697449
decider.linear2.weight: 0.007246046327054501 0.05914546176791191
decider.linear2.bias: 0.006579795852303505 0.06056741252541542
decider.linear3.weight: -0.04201696068048477 0.09849201142787933
decider.linear3.bias: -0.03155740350484848 0.0577196404337883

Rewards:
190.8927
190.8927
190.8927
objective = 0.0030114720575511456
==== episode 7400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003501081373542547 0.08447393774986267
encoder.encoder.weight_hh_l0: -0.00019782866002060473 0.08616626262664795
encoder.encoder.bias_ih_l0: 0.008493807166814804 0.0854671373963356
encoder.encoder.bias_hh_l0: 0.018490904942154884 0.0846104770898819
encoder.encoder.weight_ih_l0_reverse: 0.0015319561352953315 0.08604105561971664
encoder.encoder.weight_hh_l0_reverse: 0.00290520116686821 0.08473782241344452
encoder.encoder.bias_ih_l0_reverse: 0.023589009419083595 0.08423825353384018
encoder.encoder.bias_hh_l0_reverse: 0.015454455278813839 0.08290770649909973
decider.lstm.weight_ih_l0: -3.3425705623812973e-05 0.147813618183136
decider.lstm.weight_hh_l0: -0.00220761657692492 0.14632269740104675
decider.lstm.bias_ih_l0: 0.02001011371612549 0.15328016877174377
decider.lstm.bias_hh_l0: 0.0010225903242826462 0.14419598877429962
decider.linear1.weight: 0.0007524501415900886 0.12232732772827148
decider.linear1.bias: 0.016935249790549278 0.11707942187786102
decider.linear2.weight: 0.007304992061108351 0.05924271047115326
decider.linear2.bias: 0.0066541749984025955 0.060752227902412415
decider.linear3.weight: -0.0420466884970665 0.09857609868049622
decider.linear3.bias: -0.0315578319132328 0.057729799300432205

Rewards:
190.8927
190.8927
190.8927
objective = 0.002343929372727871
==== episode 7500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035019658389501274 0.08447571843862534
encoder.encoder.weight_hh_l0: -0.0001982095855055377 0.08616963773965836
encoder.encoder.bias_ih_l0: 0.008504300378262997 0.08546901494264603
encoder.encoder.bias_hh_l0: 0.018501395359635353 0.08461428433656693
encoder.encoder.weight_ih_l0_reverse: 0.0015322357648983598 0.08604218065738678
encoder.encoder.weight_hh_l0_reverse: 0.0029064405243843794 0.08473926782608032
encoder.encoder.bias_ih_l0_reverse: 0.02359478734433651 0.08423993736505508
encoder.encoder.bias_hh_l0_reverse: 0.015460235998034477 0.08290830999612808
decider.lstm.weight_ih_l0: -3.265749546699226e-05 0.147816002368927
decider.lstm.weight_hh_l0: -0.0022080144844949245 0.14632447063922882
decider.lstm.bias_ih_l0: 0.02002190425992012 0.1532817780971527
decider.lstm.bias_hh_l0: 0.0010343813337385654 0.14419816434383392
decider.linear1.weight: 0.0007510851137340069 0.12233979254961014
decider.linear1.bias: 0.016954785212874413 0.11708163470029831
decider.linear2.weight: 0.007354545872658491 0.059330638498067856
decider.linear2.bias: 0.006716618314385414 0.060915060341358185
decider.linear3.weight: -0.04207165166735649 0.09865148365497589
decider.linear3.bias: -0.03155820444226265 0.057738203555345535

Rewards:
190.8927
190.8927
190.8927
objective = 0.0018736196216195822
==== episode 7600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035026660771109164 0.0844772458076477
encoder.encoder.weight_hh_l0: -0.0001985379058169201 0.08617252856492996
encoder.encoder.bias_ih_l0: 0.008513316512107849 0.08547063916921616
encoder.encoder.bias_hh_l0: 0.018510404974222183 0.08461755514144897
encoder.encoder.weight_ih_l0_reverse: 0.0015324883861467242 0.08604317158460617
encoder.encoder.weight_hh_l0_reverse: 0.002907515736296773 0.08474051207304001
encoder.encoder.bias_ih_l0_reverse: 0.023599857464432716 0.08424144238233566
encoder.encoder.bias_hh_l0_reverse: 0.015465312637388706 0.08290878683328629
decider.lstm.weight_ih_l0: -3.2003092201193795e-05 0.14781804382801056
decider.lstm.weight_hh_l0: -0.0022083562798798084 0.1463259905576706
decider.lstm.bias_ih_l0: 0.020032018423080444 0.15328311920166016
decider.lstm.bias_hh_l0: 0.001044497825205326 0.14420004189014435
decider.linear1.weight: 0.0007498905761167407 0.12235048413276672
decider.linear1.bias: 0.016971923410892487 0.1170835793018341
decider.linear2.weight: 0.007396893575787544 0.059410132467746735
decider.linear2.bias: 0.006769907660782337 0.06105951592326164
decider.linear3.weight: -0.042092930525541306 0.0987192690372467
decider.linear3.bias: -0.0315585732460022 0.05774529278278351

Rewards:
190.8927
190.8927
190.8927
objective = 0.0015322677791118622
==== episode 7700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003503265033941716 0.08447859436273575
encoder.encoder.weight_hh_l0: -0.0001988293806789443 0.0861750915646553
encoder.encoder.bias_ih_l0: 0.008521285839378834 0.08547207713127136
encoder.encoder.bias_hh_l0: 0.01851837709546089 0.08462046831846237
encoder.encoder.weight_ih_l0_reverse: 0.0015327227301895618 0.086044080555439
encoder.encoder.weight_hh_l0_reverse: 0.0029084733687341213 0.08474163711071014
encoder.encoder.bias_ih_l0_reverse: 0.023604432120919228 0.0842428132891655
encoder.encoder.bias_hh_l0_reverse: 0.015469887293875217 0.08290917426347733
decider.lstm.weight_ih_l0: -3.142721834592521e-05 0.14781984686851501
decider.lstm.weight_hh_l0: -0.002208662685006857 0.14632734656333923
decider.lstm.bias_ih_l0: 0.02004094608128071 0.1532842516899109
decider.lstm.bias_hh_l0: 0.001053434330970049 0.14420166611671448
decider.linear1.weight: 0.0007488203118555248 0.12235993146896362
decider.linear1.bias: 0.01698734052479267 0.11708531528711319
decider.linear2.weight: 0.007434191182255745 0.05948345735669136
decider.linear2.bias: 0.006816779263317585 0.06119072809815407
decider.linear3.weight: -0.042111583054065704 0.0987815111875534
decider.linear3.bias: -0.03155890479683876 0.057751450687646866

Rewards:
190.8927
190.8927
190.8927
objective = 0.0012743587139993906
==== episode 7800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035037644556723535 0.08447980135679245
encoder.encoder.weight_hh_l0: -0.00019909045659005642 0.08617737144231796
encoder.encoder.bias_ih_l0: 0.008528423495590687 0.08547335863113403
encoder.encoder.bias_hh_l0: 0.018525518476963043 0.0846230611205101
encoder.encoder.weight_ih_l0_reverse: 0.001532939961180091 0.08604490756988525
encoder.encoder.weight_hh_l0_reverse: 0.0029093364719301462 0.08474264293909073
encoder.encoder.bias_ih_l0_reverse: 0.02360859327018261 0.08424409478902817
encoder.encoder.bias_hh_l0_reverse: 0.015474052168428898 0.0829094871878624
decider.lstm.weight_ih_l0: -3.0914321541786194e-05 0.14782145619392395
decider.lstm.weight_hh_l0: -0.0022089409176260233 0.14632853865623474
decider.lstm.bias_ih_l0: 0.020048948004841805 0.15328526496887207
decider.lstm.bias_hh_l0: 0.0010614097118377686 0.14420312643051147
decider.linear1.weight: 0.0007478483021259308 0.12236837297677994
decider.linear1.bias: 0.01700134575366974 0.11708689481019974
decider.linear2.weight: 0.00746750645339489 0.05955164507031441
decider.linear2.bias: 0.006858604960143566 0.06131112203001976
decider.linear3.weight: -0.042128171771764755 0.09883914142847061
decider.linear3.bias: -0.03155917301774025 0.05775688216090202

Rewards:
190.8927
190.8927
190.8927
objective = 0.0010771348606795073
==== episode 7900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000350419053575024 0.0844808965921402
encoder.encoder.weight_hh_l0: -0.0001993273908738047 0.0861794501543045
encoder.encoder.bias_ih_l0: 0.008534884080290794 0.08547451347112656
encoder.encoder.bias_hh_l0: 0.018531981855630875 0.08462540805339813
encoder.encoder.weight_ih_l0_reverse: 0.0015331405447795987 0.08604567497968674
encoder.encoder.weight_hh_l0_reverse: 0.00291012367233634 0.08474356681108475
encoder.encoder.bias_ih_l0_reverse: 0.023612407967448235 0.08424527198076248
encoder.encoder.bias_hh_l0_reverse: 0.015477864071726799 0.08290974050760269
decider.lstm.weight_ih_l0: -3.0455010346486233e-05 0.14782293140888214
decider.lstm.weight_hh_l0: -0.002209197264164686 0.1463296264410019
decider.lstm.bias_ih_l0: 0.02005617693066597 0.1532861590385437
decider.lstm.bias_hh_l0: 0.0010686460882425308 0.14420440793037415
decider.linear1.weight: 0.0007469583069905639 0.12237600982189178
decider.linear1.bias: 0.017014209181070328 0.11708831787109375
decider.linear2.weight: 0.007497647311538458 0.05961548164486885
decider.linear2.bias: 0.006896398961544037 0.06142256036400795
decider.linear3.weight: -0.0421430841088295 0.09889286756515503
decider.linear3.bias: -0.031559448689222336 0.057761743664741516

Rewards:
190.8927
190.8927
190.8927
objective = 0.0009216318721882999
==== episode 8000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000350457732565701 0.08448189496994019
encoder.encoder.weight_hh_l0: -0.0001995463971979916 0.08618134260177612
encoder.encoder.bias_ih_l0: 0.008540821261703968 0.08547560125589371
encoder.encoder.bias_hh_l0: 0.018537908792495728 0.08462757617235184
encoder.encoder.weight_ih_l0_reverse: 0.001533332746475935 0.08604639023542404
encoder.encoder.weight_hh_l0_reverse: 0.002910848241299391 0.0847444161772728
encoder.encoder.bias_ih_l0_reverse: 0.023615946993231773 0.08424636721611023
encoder.encoder.bias_hh_l0_reverse: 0.015481407754123211 0.0829099640250206
decider.lstm.weight_ih_l0: -3.0034332667128183e-05 0.14782428741455078
decider.lstm.weight_hh_l0: -0.0022094235755503178 0.14633065462112427
decider.lstm.bias_ih_l0: 0.020062819123268127 0.15328697860240936
decider.lstm.bias_hh_l0: 0.0010752798989415169 0.14420562982559204
decider.linear1.weight: 0.0007461351342499256 0.1223829910159111
decider.linear1.bias: 0.01702612265944481 0.11708962172269821
decider.linear2.weight: 0.007525165565311909 0.05967563018202782
decider.linear2.bias: 0.006930890493094921 0.06152648106217384
decider.linear3.weight: -0.042156610637903214 0.09894328564405441
decider.linear3.bias: -0.03155975416302681 0.0577661395072937

Rewards:
190.8927
190.8927
190.8927
objective = 0.0007964711985550821
==== episode 8100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035049181315116584 0.08448281139135361
encoder.encoder.weight_hh_l0: -0.0001997427607420832 0.08618306368589401
encoder.encoder.bias_ih_l0: 0.008546222932636738 0.0854765772819519
encoder.encoder.bias_hh_l0: 0.018543312326073647 0.08462954312562943
encoder.encoder.weight_ih_l0_reverse: 0.0015335133066400886 0.08604705333709717
encoder.encoder.weight_hh_l0_reverse: 0.002911514136940241 0.08474519848823547
encoder.encoder.bias_ih_l0_reverse: 0.02361920103430748 0.08424738794565201
encoder.encoder.bias_hh_l0_reverse: 0.015484669245779514 0.08291013538837433
decider.lstm.weight_ih_l0: -2.965150270028971e-05 0.14782550930976868
decider.lstm.weight_hh_l0: -0.002209637314081192 0.1463315635919571
decider.lstm.bias_ih_l0: 0.020068814978003502 0.15328767895698547
decider.lstm.bias_hh_l0: 0.0010813185945153236 0.14420685172080994
decider.linear1.weight: 0.0007453750586137176 0.12238937616348267
decider.linear1.bias: 0.01703711599111557 0.11709083616733551
decider.linear2.weight: 0.007550274487584829 0.059732016175985336
decider.linear2.bias: 0.0069623347371816635 0.06162305921316147
decider.linear3.weight: -0.04216887429356575 0.09899036586284637
decider.linear3.bias: -0.031559862196445465 0.057769984006881714

Rewards:
190.8927
190.8927
190.8927
objective = 0.0006978599121794105
==== episode 8200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003505237400531769 0.08448366075754166
encoder.encoder.weight_hh_l0: -0.00019993069872725755 0.08618468046188354
encoder.encoder.bias_ih_l0: 0.008551254868507385 0.08547746390104294
encoder.encoder.bias_hh_l0: 0.018548356369137764 0.08463138341903687
encoder.encoder.weight_ih_l0_reverse: 0.0015336836222559214 0.08604767918586731
encoder.encoder.weight_hh_l0_reverse: 0.0029121332336217165 0.08474592864513397
encoder.encoder.bias_ih_l0_reverse: 0.023622270673513412 0.0842483714222908
encoder.encoder.bias_hh_l0_reverse: 0.015487739816308022 0.08291031420230865
decider.lstm.weight_ih_l0: -2.9300450478331186e-05 0.1478266417980194
decider.lstm.weight_hh_l0: -0.002209838479757309 0.14633241295814514
decider.lstm.bias_ih_l0: 0.02007444202899933 0.15328826010227203
decider.lstm.bias_hh_l0: 0.0010869279503822327 0.14420779049396515
decider.linear1.weight: 0.0007446635281667113 0.12239530682563782
decider.linear1.bias: 0.017047453671693802 0.11709197610616684
decider.linear2.weight: 0.007573605049401522 0.059785693883895874
decider.linear2.bias: 0.006991516798734665 0.06171424314379692
decider.linear3.weight: -0.04218018800020218 0.09903506189584732
decider.linear3.bias: -0.03155995160341263 0.057773470878601074

Rewards:
190.8927
190.8927
190.8927
objective = 0.0006106270011514425
==== episode 8300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035055133048444986 0.08448446542024612
encoder.encoder.weight_hh_l0: -0.00020010762091260403 0.08618619292974472
encoder.encoder.bias_ih_l0: 0.008555963635444641 0.08547834306955338
encoder.encoder.bias_hh_l0: 0.018553053960204124 0.08463309705257416
encoder.encoder.weight_ih_l0_reverse: 0.00153384730219841 0.08604826033115387
encoder.encoder.weight_hh_l0_reverse: 0.0029127143789082766 0.08474661409854889
encoder.encoder.bias_ih_l0_reverse: 0.023625168949365616 0.08424930274486542
encoder.encoder.bias_hh_l0_reverse: 0.015490634366869926 0.0829104408621788
decider.lstm.weight_ih_l0: -2.8975418899790384e-05 0.14782771468162537
decider.lstm.weight_hh_l0: -0.002210034057497978 0.14633320271968842
decider.lstm.bias_ih_l0: 0.02007967233657837 0.15328888595104218
decider.lstm.bias_hh_l0: 0.001092198770493269 0.14420871436595917
decider.linear1.weight: 0.0007439986802637577 0.12240084260702133
decider.linear1.bias: 0.017057208344340324 0.1170930489897728
decider.linear2.weight: 0.007595394738018513 0.05983699485659599
decider.linear2.bias: 0.007018777541816235 0.06180078536272049
decider.linear3.weight: -0.04219070076942444 0.09907765686511993
decider.linear3.bias: -0.03156004473567009 0.05777670815587044

Rewards:
190.8927
190.8927
190.8927
objective = 0.0005385651020333171
==== episode 8400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035057193599641323 0.08448520302772522
encoder.encoder.weight_hh_l0: -0.00020027179562021047 0.08618760854005814
encoder.encoder.bias_ih_l0: 0.008560382761061192 0.08547914028167725
encoder.encoder.bias_hh_l0: 0.018557485193014145 0.08463471382856369
encoder.encoder.weight_ih_l0_reverse: 0.0015340055106207728 0.08604882657527924
encoder.encoder.weight_hh_l0_reverse: 0.0029132640920579433 0.08474725484848022
encoder.encoder.bias_ih_l0_reverse: 0.023627890273928642 0.08425015956163406
encoder.encoder.bias_hh_l0_reverse: 0.015493380837142467 0.08291055262088776
decider.lstm.weight_ih_l0: -2.8669443054241128e-05 0.14782872796058655
decider.lstm.weight_hh_l0: -0.002210212405771017 0.1463339626789093
decider.lstm.bias_ih_l0: 0.020084615796804428 0.15328951179981232
decider.lstm.bias_hh_l0: 0.0010971431620419025 0.14420971274375916
decider.linear1.weight: 0.0007433667196892202 0.12240604311227798
decider.linear1.bias: 0.017066454514861107 0.11709407716989517
decider.linear2.weight: 0.007615868933498859 0.05988619476556778
decider.linear2.bias: 0.0070443712174892426 0.06188322603702545
decider.linear3.weight: -0.042200520634651184 0.09911838173866272
decider.linear3.bias: -0.03156016394495964 0.0577797032892704

Rewards:
190.8927
190.8927
190.8927
objective = 0.00048167421482503414
==== episode 8500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003505926579236984 0.08448591083288193
encoder.encoder.weight_hh_l0: -0.00020042793767061085 0.08618892729282379
encoder.encoder.bias_ih_l0: 0.008564576506614685 0.08547988533973694
encoder.encoder.bias_hh_l0: 0.018561670556664467 0.08463623374700546
encoder.encoder.weight_ih_l0_reverse: 0.0015341517282649875 0.08604936301708221
encoder.encoder.weight_hh_l0_reverse: 0.0029137851670384407 0.08474787324666977
encoder.encoder.bias_ih_l0_reverse: 0.023630518466234207 0.0842510312795639
encoder.encoder.bias_hh_l0_reverse: 0.01549601275473833 0.08291066437959671
decider.lstm.weight_ih_l0: -2.838082582456991e-05 0.14782969653606415
decider.lstm.weight_hh_l0: -0.0022103837691247463 0.1463346928358078
decider.lstm.bias_ih_l0: 0.020089346915483475 0.1532900333404541
decider.lstm.bias_hh_l0: 0.0011018170043826103 0.14421063661575317
decider.linear1.weight: 0.000742762815207243 0.12241095304489136
decider.linear1.bias: 0.01707523502409458 0.11709501594305038
decider.linear2.weight: 0.007635202258825302 0.05993352085351944
decider.linear2.bias: 0.0070685106329619884 0.06196204572916031
decider.linear3.weight: -0.04220971465110779 0.09915745258331299
decider.linear3.bias: -0.031560227274894714 0.05778246372938156

Rewards:
190.8927
190.8927
190.8927
objective = 0.000432368804467842
==== episode 8600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003506136708892882 0.08448657393455505
encoder.encoder.weight_hh_l0: -0.0002005753485718742 0.08619019389152527
encoder.encoder.bias_ih_l0: 0.00856850203126669 0.08548060804605484
encoder.encoder.bias_hh_l0: 0.018565615639090538 0.08463770151138306
encoder.encoder.weight_ih_l0_reverse: 0.0015342982951551676 0.0860498771071434
encoder.encoder.weight_hh_l0_reverse: 0.0029142771381884813 0.08474845439195633
encoder.encoder.bias_ih_l0_reverse: 0.023632988333702087 0.08425183594226837
encoder.encoder.bias_hh_l0_reverse: 0.015498468652367592 0.08291079103946686
decider.lstm.weight_ih_l0: -2.8106700483476743e-05 0.14783060550689697
decider.lstm.weight_hh_l0: -0.0022105472162365913 0.1463353931903839
decider.lstm.bias_ih_l0: 0.020093759521842003 0.15329059958457947
decider.lstm.bias_hh_l0: 0.0011061741970479488 0.14421133697032928
decider.linear1.weight: 0.0007421885384246707 0.12241556495428085
decider.linear1.bias: 0.017083551734685898 0.11709586530923843
decider.linear2.weight: 0.007653350476175547 0.059978730976581573
decider.linear2.bias: 0.00709117203950882 0.06203693524003029
decider.linear3.weight: -0.04221828654408455 0.09919466078281403
decider.linear3.bias: -0.03156034275889397 0.057785119861364365

Rewards:
190.8927
190.8927
190.8927
objective = 0.00038685620529577136
==== episode 8700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003506351786199957 0.08448721468448639
encoder.encoder.weight_hh_l0: -0.00020071420294698328 0.08619140088558197
encoder.encoder.bias_ih_l0: 0.008572271093726158 0.08548132330179214
encoder.encoder.bias_hh_l0: 0.0185693446546793 0.0846390575170517
encoder.encoder.weight_ih_l0_reverse: 0.0015344376442953944 0.0860503613948822
encoder.encoder.weight_hh_l0_reverse: 0.002914746757596731 0.0847489982843399
encoder.encoder.bias_ih_l0_reverse: 0.023635344579815865 0.08425259590148926
encoder.encoder.bias_hh_l0_reverse: 0.015500832349061966 0.08291085809469223
decider.lstm.weight_ih_l0: -2.7845948352478445e-05 0.14783145487308502
decider.lstm.weight_hh_l0: -0.002210699487477541 0.14633603394031525
decider.lstm.bias_ih_l0: 0.020097915083169937 0.15329106152057648
decider.lstm.bias_hh_l0: 0.0011103260330855846 0.14421197772026062
decider.linear1.weight: 0.0007416376611217856 0.12241993844509125
decider.linear1.bias: 0.0170915387570858 0.11709672957658768
decider.linear2.weight: 0.007670621387660503 0.06002248451113701
decider.linear2.bias: 0.007112723309546709 0.06210901215672493
decider.linear3.weight: -0.04222638159990311 0.0992305725812912
decider.linear3.bias: -0.03156047314405441 0.057787586003541946

Rewards:
190.8927
190.8927
190.8927
objective = 0.0003489289665594697
==== episode 8800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003506502544041723 0.08448781818151474
encoder.encoder.weight_hh_l0: -0.00020084530115127563 0.0861925408244133
encoder.encoder.bias_ih_l0: 0.008575850166380405 0.08548195660114288
encoder.encoder.bias_hh_l0: 0.01857290416955948 0.08464036136865616
encoder.encoder.weight_ih_l0_reverse: 0.0015345701249316335 0.08605083078145981
encoder.encoder.weight_hh_l0_reverse: 0.002915196120738983 0.08474953472614288
encoder.encoder.bias_ih_l0_reverse: 0.023637626320123672 0.08425334095954895
encoder.encoder.bias_hh_l0_reverse: 0.0155031131580472 0.08291090279817581
decider.lstm.weight_ih_l0: -2.7599873646977358e-05 0.14783227443695068
decider.lstm.weight_hh_l0: -0.0022108363918960094 0.146336629986763
decider.lstm.bias_ih_l0: 0.020101869478821754 0.15329138934612274
decider.lstm.bias_hh_l0: 0.0011142846196889877 0.14421263337135315
decider.linear1.weight: 0.0007411151891574264 0.12242411822080612
decider.linear1.bias: 0.017099233344197273 0.11709752678871155
decider.linear2.weight: 0.007687118835747242 0.060064926743507385
decider.linear2.bias: 0.007133289705961943 0.06217856705188751
decider.linear3.weight: -0.04223405197262764 0.09926531463861465
decider.linear3.bias: -0.031560495495796204 0.0577898845076561

Rewards:
190.8927
190.8927
190.8927
objective = 0.00031858726288191974
==== episode 8900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000350665592122823 0.0844883993268013
encoder.encoder.weight_hh_l0: -0.00020097345986869186 0.08619362860918045
encoder.encoder.bias_ih_l0: 0.008579249493777752 0.08548255264759064
encoder.encoder.bias_hh_l0: 0.01857633702456951 0.08464159071445465
encoder.encoder.weight_ih_l0_reverse: 0.0015347045846283436 0.08605128526687622
encoder.encoder.weight_hh_l0_reverse: 0.002915630815550685 0.08475004881620407
encoder.encoder.bias_ih_l0_reverse: 0.023639826104044914 0.08425407111644745
encoder.encoder.bias_hh_l0_reverse: 0.015505337156355381 0.08291097730398178
decider.lstm.weight_ih_l0: -2.7370489988243207e-05 0.14783304929733276
decider.lstm.weight_hh_l0: -0.002210967242717743 0.14633721113204956
decider.lstm.bias_ih_l0: 0.020105645060539246 0.1532917469739914
decider.lstm.bias_hh_l0: 0.0011180927976965904 0.14421331882476807
decider.linear1.weight: 0.0007406051154248416 0.12242811918258667
decider.linear1.bias: 0.017106635496020317 0.11709828674793243
decider.linear2.weight: 0.0077029382809996605 0.06010619178414345
decider.linear2.bias: 0.007152993232011795 0.06224587559700012
decider.linear3.weight: -0.04224133491516113 0.09929897636175156
decider.linear3.bias: -0.03156057000160217 0.05779204145073891

Rewards:
190.8927
190.8927
190.8927
objective = 0.0002882455592043698
==== episode 9000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035068290890194476 0.08448895812034607
encoder.encoder.weight_hh_l0: -0.00020110122568439692 0.08619467169046402
encoder.encoder.bias_ih_l0: 0.00858253799378872 0.08548316359519958
encoder.encoder.bias_hh_l0: 0.0185796357691288 0.08464276790618896
encoder.encoder.weight_ih_l0_reverse: 0.001534829381853342 0.08605172485113144
encoder.encoder.weight_hh_l0_reverse: 0.0029160468839108944 0.08475053310394287
encoder.encoder.bias_ih_l0_reverse: 0.023641956970095634 0.08425479382276535
encoder.encoder.bias_hh_l0_reverse: 0.015507477335631847 0.08291102200746536
decider.lstm.weight_ih_l0: -2.715419941523578e-05 0.14783380925655365
decider.lstm.weight_hh_l0: -0.002211108338087797 0.14633777737617493
decider.lstm.bias_ih_l0: 0.020109260454773903 0.15329210460186005
decider.lstm.bias_hh_l0: 0.00112172681838274 0.14421404898166656
decider.linear1.weight: 0.0007401116890832782 0.12243196368217468
decider.linear1.bias: 0.017113765701651573 0.11709902435541153
decider.linear2.weight: 0.00771813141182065 0.06014637649059296
decider.linear2.bias: 0.007171929813921452 0.062311142683029175
decider.linear3.weight: -0.04224827140569687 0.09933166950941086
decider.linear3.bias: -0.03156057000160217 0.057794202119112015

Rewards:
190.8927
190.8927
190.8927
objective = 0.00026169657940045
==== episode 9100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003506921057123691 0.08448949456214905
encoder.encoder.weight_hh_l0: -0.0002012196055147797 0.08619567006826401
encoder.encoder.bias_ih_l0: 0.008585678413510323 0.08548374474048615
encoder.encoder.bias_hh_l0: 0.018582778051495552 0.08464394509792328
encoder.encoder.weight_ih_l0_reverse: 0.0015349440509453416 0.08605214953422546
encoder.encoder.weight_hh_l0_reverse: 0.002916444791480899 0.08475100994110107
encoder.encoder.bias_ih_l0_reverse: 0.023643994703888893 0.08425548672676086
encoder.encoder.bias_hh_l0_reverse: 0.0155095299705863 0.08291104435920715
decider.lstm.weight_ih_l0: -2.6943682314595208e-05 0.14783452451229095
decider.lstm.weight_hh_l0: -0.002211254555732012 0.1463383138179779
decider.lstm.bias_ih_l0: 0.02011273428797722 0.1532924920320511
decider.lstm.bias_hh_l0: 0.0011251764371991158 0.14421474933624268
decider.linear1.weight: 0.0007396438159048557 0.12243563681840897
decider.linear1.bias: 0.017120610922574997 0.11709973216056824
decider.linear2.weight: 0.007732620928436518 0.06018519774079323
decider.linear2.bias: 0.007189967669546604 0.06237392500042915
decider.linear3.weight: -0.04225483536720276 0.09936315566301346
decider.linear3.bias: -0.03156065195798874 0.05779620260000229

Rewards:
190.8927
190.8927
190.8927
objective = 0.00024273298913612962
==== episode 9200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003507049405016005 0.08449000120162964
encoder.encoder.weight_hh_l0: -0.0002013316552620381 0.08619663864374161
encoder.encoder.bias_ih_l0: 0.008588725700974464 0.08548431843519211
encoder.encoder.bias_hh_l0: 0.018585847690701485 0.08464507013559341
encoder.encoder.weight_ih_l0_reverse: 0.0015350672183558345 0.0860525593161583
encoder.encoder.weight_hh_l0_reverse: 0.0029168284963816404 0.08475145697593689
encoder.encoder.bias_ih_l0_reverse: 0.023645974695682526 0.08425615727901459
encoder.encoder.bias_hh_l0_reverse: 0.01551149319857359 0.08291108906269073
decider.lstm.weight_ih_l0: -2.6739127861219458e-05 0.14783520996570587
decider.lstm.weight_hh_l0: -0.002211385639384389 0.1463388204574585
decider.lstm.bias_ih_l0: 0.02011607214808464 0.15329286456108093
decider.lstm.bias_hh_l0: 0.0011285203509032726 0.1442154049873352
decider.linear1.weight: 0.000739184848498553 0.1224391832947731
decider.linear1.bias: 0.017127245664596558 0.11710041016340256
decider.linear2.weight: 0.007746607065200806 0.060223132371902466
decider.linear2.bias: 0.007207366172224283 0.062435027211904526
decider.linear3.weight: -0.04226110875606537 0.09939383715391159
decider.linear3.bias: -0.03156069293618202 0.05779813230037689

Rewards:
190.8927
190.8927
190.8927
objective = 0.00021997674775775522
==== episode 9300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003507161745801568 0.08449049293994904
encoder.encoder.weight_hh_l0: -0.0002014393248828128 0.08619758486747742
encoder.encoder.bias_ih_l0: 0.008591672405600548 0.08548485487699509
encoder.encoder.bias_hh_l0: 0.018588818609714508 0.08464616537094116
encoder.encoder.weight_ih_l0_reverse: 0.0015351908514276147 0.08605296909809113
encoder.encoder.weight_hh_l0_reverse: 0.002917201491072774 0.0847519114613533
encoder.encoder.bias_ih_l0_reverse: 0.023647908121347427 0.08425681293010712
encoder.encoder.bias_hh_l0_reverse: 0.015513405203819275 0.0829111635684967
decider.lstm.weight_ih_l0: -2.6539377358858474e-05 0.1478358805179596
decider.lstm.weight_hh_l0: -0.002211520681157708 0.1463393121957779
decider.lstm.bias_ih_l0: 0.0201193206012249 0.1532931625843048
decider.lstm.bias_hh_l0: 0.0011317906901240349 0.14421595633029938
decider.linear1.weight: 0.0007387373480014503 0.12244261056184769
decider.linear1.bias: 0.01713372953236103 0.11710110306739807
decider.linear2.weight: 0.0077601331286132336 0.06026026979088783
decider.linear2.bias: 0.007224174216389656 0.06249459087848663
decider.linear3.weight: -0.04226712882518768 0.09942380338907242
decider.linear3.bias: -0.03156059980392456 0.05779992789030075

Rewards:
190.8927
190.8927
190.8927
objective = 0.00020480591047089547
==== episode 9400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003507297660689801 0.08449098467826843
encoder.encoder.weight_hh_l0: -0.00020154340018052608 0.08619850873947144
encoder.encoder.bias_ih_l0: 0.008594540879130363 0.08548536896705627
encoder.encoder.bias_hh_l0: 0.01859169267117977 0.08464726060628891
encoder.encoder.weight_ih_l0_reverse: 0.0015353081980720162 0.08605337142944336
encoder.encoder.weight_hh_l0_reverse: 0.0029175670351833105 0.08475234359502792
encoder.encoder.bias_ih_l0_reverse: 0.023649787530303 0.08425744622945786
encoder.encoder.bias_hh_l0_reverse: 0.015515265986323357 0.08291125297546387
decider.lstm.weight_ih_l0: -2.6338509997003712e-05 0.14783650636672974
decider.lstm.weight_hh_l0: -0.002211642451584339 0.1463398039340973
decider.lstm.bias_ih_l0: 0.020122501999139786 0.1532934308052063
decider.lstm.bias_hh_l0: 0.0011349772103130817 0.14421644806861877
decider.linear1.weight: 0.0007383036427199841 0.12244592607021332
decider.linear1.bias: 0.017140062525868416 0.1171017587184906
decider.linear2.weight: 0.00777324428781867 0.0602966733276844
decider.linear2.bias: 0.00724045978859067 0.06255275756120682
decider.linear3.weight: -0.0422729030251503 0.09945307672023773
decider.linear3.bias: -0.031560540199279785 0.057801660150289536

Rewards:
190.8927
190.8927
190.8927
objective = 0.00018963508773595095
==== episode 9500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003507405344862491 0.08449146151542664
encoder.encoder.weight_hh_l0: -0.00020164712623227388 0.08619941025972366
encoder.encoder.bias_ih_l0: 0.008597341366112232 0.08548588305711746
encoder.encoder.bias_hh_l0: 0.018594464287161827 0.08464833348989487
encoder.encoder.weight_ih_l0_reverse: 0.0015354141360148787 0.0860537737607956
encoder.encoder.weight_hh_l0_reverse: 0.002917923964560032 0.08475276827812195
encoder.encoder.bias_ih_l0_reverse: 0.023651624098420143 0.084258072078228
encoder.encoder.bias_hh_l0_reverse: 0.015517094172537327 0.08291132003068924
decider.lstm.weight_ih_l0: -2.614367622300051e-05 0.14783714711666107
decider.lstm.weight_hh_l0: -0.0022117639891803265 0.1463402807712555
decider.lstm.bias_ih_l0: 0.020125575363636017 0.15329372882843018
decider.lstm.bias_hh_l0: 0.0011380533687770367 0.14421691000461578
decider.linear1.weight: 0.0007378828595392406 0.12244914472103119
decider.linear1.bias: 0.017146224156022072 0.11710239201784134
decider.linear2.weight: 0.007785973604768515 0.06033239886164665
decider.linear2.bias: 0.007256262470036745 0.06260964274406433
decider.linear3.weight: -0.04227844625711441 0.09948170930147171
decider.linear3.bias: -0.031560540199279785 0.057803280651569366

Rewards:
190.8927
190.8927
190.8927
objective = 0.0001744642504490912
==== episode 9600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035075104096904397 0.08449192345142365
encoder.encoder.weight_hh_l0: -0.0002017489168792963 0.08620026707649231
encoder.encoder.bias_ih_l0: 0.008600021712481976 0.08548635244369507
encoder.encoder.bias_hh_l0: 0.018597107380628586 0.08464930951595306
encoder.encoder.weight_ih_l0_reverse: 0.001535522867925465 0.08605414628982544
encoder.encoder.weight_hh_l0_reverse: 0.002918263664469123 0.08475317060947418
encoder.encoder.bias_ih_l0_reverse: 0.02365340106189251 0.08425868302583694
encoder.encoder.bias_hh_l0_reverse: 0.015518855303525925 0.08291134983301163
decider.lstm.weight_ih_l0: -2.596225567685906e-05 0.14783772826194763
decider.lstm.weight_hh_l0: -0.00221188529394567 0.1463407576084137
decider.lstm.bias_ih_l0: 0.02012852020561695 0.15329398214817047
decider.lstm.bias_hh_l0: 0.0011410107836127281 0.14421749114990234
decider.linear1.weight: 0.0007374719716608524 0.1224522590637207
decider.linear1.bias: 0.017152199521660805 0.11710303276777267
decider.linear2.weight: 0.007798228412866592 0.060367126017808914
decider.linear2.bias: 0.007271483540534973 0.06266479194164276
decider.linear3.weight: -0.04228372871875763 0.09950947761535645
decider.linear3.bias: -0.031560540199279785 0.0578048974275589

Rewards:
190.8927
190.8927
190.8927
objective = 0.0001592934422660619
==== episode 9700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035076102358289063 0.08449236303567886
encoder.encoder.weight_hh_l0: -0.0002018500817939639 0.08620110899209976
encoder.encoder.bias_ih_l0: 0.008602621965110302 0.08548680692911148
encoder.encoder.bias_hh_l0: 0.018599675968289375 0.08465024083852768
encoder.encoder.weight_ih_l0_reverse: 0.0015356290386989713 0.0860544964671135
encoder.encoder.weight_hh_l0_reverse: 0.0029185963794589043 0.08475356549024582
encoder.encoder.bias_ih_l0_reverse: 0.023655127733945847 0.08425923436880112
encoder.encoder.bias_hh_l0_reverse: 0.015520595014095306 0.08291135728359222
decider.lstm.weight_ih_l0: -2.5787669073906727e-05 0.1478383094072342
decider.lstm.weight_hh_l0: -0.0022120026405900717 0.14634117484092712
decider.lstm.bias_ih_l0: 0.020131416618824005 0.15329423546791077
decider.lstm.bias_hh_l0: 0.0011439332738518715 0.1442180573940277
decider.linear1.weight: 0.0007370710372924805 0.12245527654886246
decider.linear1.bias: 0.017158066853880882 0.1171036809682846
decider.linear2.weight: 0.007810176350176334 0.06040129065513611
decider.linear2.bias: 0.007286311127245426 0.06271885335445404
decider.linear3.weight: -0.04228881746530533 0.0995367169380188
decider.linear3.bias: -0.031560540199279785 0.05780651792883873

Rewards:
190.8927
190.8927
190.8927
objective = 0.00014791532885283232
==== episode 9800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035076795029453933 0.08449280261993408
encoder.encoder.weight_hh_l0: -0.00020194685203023255 0.08620192110538483
encoder.encoder.bias_ih_l0: 0.008605149574577808 0.0854872465133667
encoder.encoder.bias_hh_l0: 0.018602192401885986 0.0846511498093605
encoder.encoder.weight_ih_l0_reverse: 0.0015357306692749262 0.08605486154556274
encoder.encoder.weight_hh_l0_reverse: 0.0029189211782068014 0.08475394546985626
encoder.encoder.bias_ih_l0_reverse: 0.023656802251935005 0.0842597708106041
encoder.encoder.bias_hh_l0_reverse: 0.015522303059697151 0.08291133493185043
decider.lstm.weight_ih_l0: -2.5621986424084753e-05 0.14783889055252075
decider.lstm.weight_hh_l0: -0.0022121365182101727 0.14634160697460175
decider.lstm.bias_ih_l0: 0.02013421431183815 0.15329451858997345
decider.lstm.bias_hh_l0: 0.0011467589065432549 0.14421866834163666
decider.linear1.weight: 0.0007366847130469978 0.12245824187994003
decider.linear1.bias: 0.01716381497681141 0.11710431426763535
decider.linear2.weight: 0.007821821607649326 0.06043493375182152
decider.linear2.bias: 0.007300770841538906 0.06277191638946533
decider.linear3.weight: -0.0422937273979187 0.09956344962120056
decider.linear3.bias: -0.031560540199279785 0.05780813843011856

Rewards:
190.8927
190.8927
190.8927
objective = 0.00013653721543960273
==== episode 9900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00035077487700618804 0.0844932273030281
encoder.encoder.weight_hh_l0: -0.00020204090105835348 0.0862027034163475
encoder.encoder.bias_ih_l0: 0.008607632480561733 0.08548769354820251
encoder.encoder.bias_hh_l0: 0.018604686483740807 0.08465202152729034
encoder.encoder.weight_ih_l0_reverse: 0.0015358241507783532 0.0860551968216896
encoder.encoder.weight_hh_l0_reverse: 0.002919240854680538 0.0847543254494667
encoder.encoder.bias_ih_l0_reverse: 0.023658446967601776 0.08426029980182648
encoder.encoder.bias_hh_l0_reverse: 0.015523971989750862 0.08291131258010864
decider.lstm.weight_ih_l0: -2.545781353546772e-05 0.14783942699432373
decider.lstm.weight_hh_l0: -0.0022122603841125965 0.14634200930595398
decider.lstm.bias_ih_l0: 0.020136965438723564 0.15329480171203613
decider.lstm.bias_hh_l0: 0.0011495128273963928 0.14421920478343964
decider.linear1.weight: 0.0007363064214587212 0.12246111780405045
decider.linear1.bias: 0.01716945692896843 0.11710493266582489
decider.linear2.weight: 0.007833192124962807 0.06046808883547783
decider.linear2.bias: 0.007314881309866905 0.0628240630030632
decider.linear3.weight: -0.04229845851659775 0.09958971291780472
decider.linear3.bias: -0.03156059980392456 0.05780963972210884

Rewards:
190.8927
190.8927
190.8927
objective = 0.00012895179679617286
==== episode 10000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003507806977722794 0.08449362218379974
encoder.encoder.weight_hh_l0: -0.0002021350373979658 0.08620347082614899
encoder.encoder.bias_ih_l0: 0.008610057644546032 0.08548811823129654
encoder.encoder.bias_hh_l0: 0.018607132136821747 0.08465288579463959
encoder.encoder.weight_ih_l0_reverse: 0.0015359180979430676 0.08605553209781647
encoder.encoder.weight_hh_l0_reverse: 0.0029195526149123907 0.08475469797849655
encoder.encoder.bias_ih_l0_reverse: 0.02366006374359131 0.08426082134246826
encoder.encoder.bias_hh_l0_reverse: 0.015525607392191887 0.08291130512952805
decider.lstm.weight_ih_l0: -2.529773882997688e-05 0.1478399634361267
decider.lstm.weight_hh_l0: -0.0022123761009424925 0.1463424116373062
decider.lstm.bias_ih_l0: 0.02013969048857689 0.15329508483409882
decider.lstm.bias_hh_l0: 0.001152194570749998 0.14421966671943665
decider.linear1.weight: 0.0007359328446909785 0.12246394157409668
decider.linear1.bias: 0.017174988985061646 0.11710549890995026
decider.linear2.weight: 0.007844313979148865 0.06050078198313713
decider.linear2.bias: 0.0073286620900034904 0.06287533789873123
decider.linear3.weight: -0.04230303317308426 0.09961552917957306
decider.linear3.bias: -0.03156069293618202 0.057811085134744644

Rewards:
190.8927
190.8927
190.8927
objective = 0.00012136639270465821
[INFO] : learning runtime (h:mm:ss): 0:02:25
[INFO] : learning end time: 12/17/2023 12:21:22 PM
