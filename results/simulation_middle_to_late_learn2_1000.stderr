Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 04:05:11 PM
==== episode 1/10000 ====
action = 0
probs = 0.2502 0.2499 0.2499 0.2499

action = 0
probs = 0.2502 0.2499 0.2499 0.2499

action = 0
probs = 0.2502 0.2499 0.2499 0.2499

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0005181720480322838 0.08475553244352341
encoder.encoder.weight_hh_l0: 0.0008216752903535962 0.0882750079035759
encoder.encoder.bias_ih_l0: 0.018467199057340622 0.08796454966068268
encoder.encoder.bias_hh_l0: 0.02846430242061615 0.08872908353805542
encoder.encoder.weight_ih_l0_reverse: 0.0015788298333063722 0.08688253909349442
encoder.encoder.weight_hh_l0_reverse: -0.0014257087605074048 0.08629405498504639
encoder.encoder.bias_ih_l0_reverse: 0.03176718205213547 0.08632933348417282
encoder.encoder.bias_hh_l0_reverse: 0.023632749915122986 0.08458849787712097
decider.lstm.weight_ih_l0: -0.0017147044418379664 0.14881011843681335
decider.lstm.weight_hh_l0: -0.006259147077798843 0.14818255603313446
decider.lstm.bias_ih_l0: 0.026127031072974205 0.16163590550422668
decider.lstm.bias_hh_l0: 0.007139957509934902 0.13842344284057617
decider.linear1.weight: -0.0002023687120527029 0.12212665379047394
decider.linear1.bias: 0.019334113225340843 0.11891039460897446
decider.linear2.weight: 0.005839226301759481 0.053937897086143494
decider.linear2.bias: 0.009080619551241398 0.05626422539353371
decider.linear3.weight: -0.007781050633639097 0.06059654802083969
decider.linear3.bias: 0.01763097569346428 0.04957542568445206

Rewards:
147.5939
147.5939
147.5939
objective = 204.4979705810547
==== episode 100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006154795410111547 0.08498058468103409
encoder.encoder.weight_hh_l0: 0.0009441985748708248 0.08869150280952454
encoder.encoder.bias_ih_l0: 0.01999155804514885 0.08819452673196793
encoder.encoder.bias_hh_l0: 0.029988663271069527 0.08913999050855637
encoder.encoder.weight_ih_l0_reverse: 0.0015496634878218174 0.08725066483020782
encoder.encoder.weight_hh_l0_reverse: -0.0014260285533964634 0.0863080620765686
encoder.encoder.bias_ih_l0_reverse: 0.03269096836447716 0.0867108553647995
encoder.encoder.bias_hh_l0_reverse: 0.024556536227464676 0.08479942381381989
decider.lstm.weight_ih_l0: -0.0016446068184450269 0.14909645915031433
decider.lstm.weight_hh_l0: -0.0065673114731907845 0.14844796061515808
decider.lstm.bias_ih_l0: 0.027366163209080696 0.162144735455513
decider.lstm.bias_hh_l0: 0.008379094302654266 0.13864128291606903
decider.linear1.weight: -0.000540835433639586 0.12291193008422852
decider.linear1.bias: 0.021762656047940254 0.11955397576093674
decider.linear2.weight: 0.006701204925775528 0.05435994267463684
decider.linear2.bias: 0.010274527594447136 0.05682063102722168
decider.linear3.weight: -0.008494808338582516 0.06149425357580185
decider.linear3.bias: 0.016371898353099823 0.04594116657972336

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361999087036 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.0009478793945163488 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671157829463 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 1900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 2900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 3900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 4900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 5900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 6900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 7900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 8900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 9900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
==== episode 10000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0006185361417010427 0.08498700708150864
encoder.encoder.weight_hh_l0: 0.000947879278101027 0.08870349824428558
encoder.encoder.bias_ih_l0: 0.020032476633787155 0.08819974213838577
encoder.encoder.bias_hh_l0: 0.030029578134417534 0.08915022015571594
encoder.encoder.weight_ih_l0_reverse: 0.0015489151701331139 0.08726179599761963
encoder.encoder.weight_hh_l0_reverse: -0.0014260353054851294 0.08630845695734024
encoder.encoder.bias_ih_l0_reverse: 0.03271854296326637 0.08672194927930832
encoder.encoder.bias_hh_l0_reverse: 0.02458411641418934 0.08480581641197205
decider.lstm.weight_ih_l0: -0.001642698422074318 0.14910440146923065
decider.lstm.weight_hh_l0: -0.006575073581188917 0.14845505356788635
decider.lstm.bias_ih_l0: 0.02739725634455681 0.1621578484773636
decider.lstm.bias_hh_l0: 0.008410193957388401 0.13864700496196747
decider.linear1.weight: -0.0005507671739906073 0.12293299287557602
decider.linear1.bias: 0.021828895434737206 0.11957019567489624
decider.linear2.weight: 0.006727677304297686 0.05437228083610535
decider.linear2.bias: 0.01031036302447319 0.056837838143110275
decider.linear3.weight: -0.008516774512827396 0.06152128428220749
decider.linear3.bias: 0.016332905739545822 0.045842647552490234

Rewards:
147.5939
147.5939
147.5939
objective = 1.759457154548727e-05
[INFO] : learning runtime (h:mm:ss): 0:02:26
[INFO] : learning end time: 12/17/2023 04:07:36 PM
