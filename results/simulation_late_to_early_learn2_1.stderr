Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 12:29:15 PM
==== episode 1/10000 ====
action = 1
probs = 0.0663 0.7447 0.0866 0.1025

action = 0
probs = 0.0479 0.8629 0.0484 0.0408

action = 0
probs = 0.1850 0.7125 0.0516 0.0508

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001512531889602542 0.08284743130207062
encoder.encoder.weight_hh_l0: -0.00031688567833043635 0.08412010967731476
encoder.encoder.bias_ih_l0: 0.005190592259168625 0.08513332903385162
encoder.encoder.bias_hh_l0: 0.015187659300863743 0.08419201523065567
encoder.encoder.weight_ih_l0_reverse: 0.0008776130271144211 0.08485471457242966
encoder.encoder.weight_hh_l0_reverse: 0.003555304603651166 0.08352325856685638
encoder.encoder.bias_ih_l0_reverse: 0.023507103323936462 0.08349715918302536
encoder.encoder.bias_hh_l0_reverse: 0.015372681431472301 0.08234899491071701
decider.lstm.weight_ih_l0: -5.0892122089862823e-05 0.14635127782821655
decider.lstm.weight_hh_l0: 0.0019759447313845158 0.14628909528255463
decider.lstm.bias_ih_l0: 0.013864139094948769 0.1577623188495636
decider.lstm.bias_hh_l0: -0.005123306065797806 0.13943961262702942
decider.linear1.weight: 0.004124522674828768 0.11991611868143082
decider.linear1.bias: 0.012958181090652943 0.11568977683782578
decider.linear2.weight: 0.0022893333807587624 0.05232924968004227
decider.linear2.bias: 0.003867117688059807 0.05564306303858757
decider.linear3.weight: -0.004871007986366749 0.056300707161426544
decider.linear3.bias: 0.019892040640115738 0.0627780482172966

Rewards:
221.7540
221.7540
221.7540
objective = 371.1722106933594
==== episode 100/10000 ====
action = 1
probs = 0.0497 0.8536 0.0375 0.0591

action = 1
probs = 0.0362 0.9203 0.0217 0.0217

action = 1
probs = 0.1585 0.7769 0.0323 0.0323

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011300473852315918 0.08300884068012238
encoder.encoder.weight_hh_l0: -0.0003158654144499451 0.08429405093193054
encoder.encoder.bias_ih_l0: 0.005900734104216099 0.0854015126824379
encoder.encoder.bias_hh_l0: 0.015897801145911217 0.08436162769794464
encoder.encoder.weight_ih_l0_reverse: 0.0009271338349208236 0.08499696850776672
encoder.encoder.weight_hh_l0_reverse: 0.003775734221562743 0.08369280397891998
encoder.encoder.bias_ih_l0_reverse: 0.024192146956920624 0.08351422846317291
encoder.encoder.bias_hh_l0_reverse: 0.016057724133133888 0.08251272886991501
decider.lstm.weight_ih_l0: 9.595995652489364e-05 0.14652694761753082
decider.lstm.weight_hh_l0: 0.0022192602045834064 0.14642253518104553
decider.lstm.bias_ih_l0: 0.014764895662665367 0.1579890102148056
decider.lstm.bias_hh_l0: -0.004222552757710218 0.13966608047485352
decider.linear1.weight: 0.004097393248230219 0.12000155448913574
decider.linear1.bias: 0.01331845298409462 0.11568886041641235
decider.linear2.weight: 0.0024868480395525694 0.05238204449415207
decider.linear2.bias: 0.004136078059673309 0.055906735360622406
decider.linear3.weight: -0.005524653010070324 0.05654223635792732
decider.linear3.bias: 0.019323408603668213 0.062427371740341187

Rewards:
217.8160
217.8160
217.8160
objective = 35.847862243652344
==== episode 200/10000 ====
action = 1
probs = 0.0517 0.8695 0.0308 0.0480

action = 1
probs = 0.0438 0.9167 0.0211 0.0184

action = 0
probs = 0.2820 0.6401 0.0418 0.0360

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011316560267005116 0.08304761350154877
encoder.encoder.weight_hh_l0: -0.00030574400443583727 0.08434401452541351
encoder.encoder.bias_ih_l0: 0.006120443809777498 0.0854518786072731
encoder.encoder.bias_hh_l0: 0.016117511317133904 0.08445066958665848
encoder.encoder.weight_ih_l0_reverse: 0.000991293229162693 0.08505063503980637
encoder.encoder.weight_hh_l0_reverse: 0.00389946810901165 0.08378661423921585
encoder.encoder.bias_ih_l0_reverse: 0.024575138464570045 0.0835302397608757
encoder.encoder.bias_hh_l0_reverse: 0.016440710052847862 0.08242043107748032
decider.lstm.weight_ih_l0: 0.00016497584874741733 0.14659814536571503
decider.lstm.weight_hh_l0: 0.002338650170713663 0.1465003788471222
decider.lstm.bias_ih_l0: 0.015151438303291798 0.15801790356636047
decider.lstm.bias_hh_l0: -0.0038360049948096275 0.1397380232810974
decider.linear1.weight: 0.004084055311977863 0.12003001570701599
decider.linear1.bias: 0.013462658040225506 0.11579123139381409
decider.linear2.weight: 0.0024755815975368023 0.05240599811077118
decider.linear2.bias: 0.004150225780904293 0.05594239756464958
decider.linear3.weight: -0.0055829742923378944 0.056594930589199066
decider.linear3.bias: 0.019282005727291107 0.06165982037782669

Rewards:
230.1930
230.1930
230.1930
objective = 114.51812744140625
==== episode 300/10000 ====
action = 3
probs = 0.0519 0.8824 0.0272 0.0386

action = 1
probs = 0.0590 0.8959 0.0249 0.0201

action = 1
probs = 0.2905 0.6431 0.0380 0.0284

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -8.117318066069856e-05 0.0831020325422287
encoder.encoder.weight_hh_l0: -0.0003002820594701916 0.08439711481332779
encoder.encoder.bias_ih_l0: 0.006261217407882214 0.08548232167959213
encoder.encoder.bias_hh_l0: 0.016258282586932182 0.08450192958116531
encoder.encoder.weight_ih_l0_reverse: 0.0010169894667342305 0.08508668839931488
encoder.encoder.weight_hh_l0_reverse: 0.003954282961785793 0.08383749425411224
encoder.encoder.bias_ih_l0_reverse: 0.024754038080573082 0.08356871455907822
encoder.encoder.bias_hh_l0_reverse: 0.016619613394141197 0.082379549741745
decider.lstm.weight_ih_l0: 0.00019230453472118825 0.14664693176746368
decider.lstm.weight_hh_l0: 0.0023795689921826124 0.14657074213027954
decider.lstm.bias_ih_l0: 0.015285731293261051 0.1581006646156311
decider.lstm.bias_hh_l0: -0.0037017036229372025 0.13980594277381897
decider.linear1.weight: 0.0040863580070436 0.12005695700645447
decider.linear1.bias: 0.013568339869379997 0.11585821956396103
decider.linear2.weight: 0.0025090205017477274 0.052432090044021606
decider.linear2.bias: 0.004176213871687651 0.05603009834885597
decider.linear3.weight: -0.005710183177143335 0.05667498707771301
decider.linear3.bias: 0.019152924418449402 0.06100595369935036

Rewards:
202.9943
202.9943
202.9943
objective = 257.5287170410156
==== episode 400/10000 ====
action = 1
probs = 0.0533 0.8915 0.0236 0.0317

action = 1
probs = 0.0613 0.9001 0.0224 0.0162

action = 1
probs = 0.4171 0.5263 0.0322 0.0245

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -6.32725641480647e-05 0.08315981179475784
encoder.encoder.weight_hh_l0: -0.00030173733830451965 0.08447334170341492
encoder.encoder.bias_ih_l0: 0.006528367754071951 0.08556529879570007
encoder.encoder.bias_hh_l0: 0.016525430604815483 0.08455560356378555
encoder.encoder.weight_ih_l0_reverse: 0.0010515229078009725 0.08513648808002472
encoder.encoder.weight_hh_l0_reverse: 0.00402765953913331 0.08390004187822342
encoder.encoder.bias_ih_l0_reverse: 0.0249954741448164 0.08358139544725418
encoder.encoder.bias_hh_l0_reverse: 0.016861049458384514 0.08239492028951645
decider.lstm.weight_ih_l0: 0.00024456807295791805 0.14670692384243011
decider.lstm.weight_hh_l0: 0.0024627812672406435 0.14663022756576538
decider.lstm.bias_ih_l0: 0.01555436011403799 0.15817394852638245
decider.lstm.bias_hh_l0: -0.003433084115386009 0.13985894620418549
decider.linear1.weight: 0.004090606234967709 0.12008586525917053
decider.linear1.bias: 0.01372357364743948 0.11589490622282028
decider.linear2.weight: 0.002577010076493025 0.05245336517691612
decider.linear2.bias: 0.004298069979995489 0.056082192808389664
decider.linear3.weight: -0.0057884398847818375 0.056764665991067886
decider.linear3.bias: 0.01903398334980011 0.06060682609677315

Rewards:
217.8160
217.8160
217.8160
objective = 62.592098236083984
==== episode 500/10000 ====
action = 1
probs = 0.0434 0.9098 0.0235 0.0233

action = 2
probs = 0.0621 0.8917 0.0304 0.0158

action = 0
probs = 0.3838 0.5473 0.0419 0.0269

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -6.568968092324212e-05 0.08315947651863098
encoder.encoder.weight_hh_l0: -0.00028317890246398747 0.08444450795650482
encoder.encoder.bias_ih_l0: 0.006350828800350428 0.08552981168031693
encoder.encoder.bias_hh_l0: 0.016347892582416534 0.0845259428024292
encoder.encoder.weight_ih_l0_reverse: 0.001054950524121523 0.08511921763420105
encoder.encoder.weight_hh_l0_reverse: 0.003977539949119091 0.08389412611722946
encoder.encoder.bias_ih_l0_reverse: 0.024891771376132965 0.0835539847612381
encoder.encoder.bias_hh_l0_reverse: 0.016757341101765633 0.08244451880455017
decider.lstm.weight_ih_l0: 0.00022715210798196495 0.1466953456401825
decider.lstm.weight_hh_l0: 0.0024345822166651487 0.146622434258461
decider.lstm.bias_ih_l0: 0.015426037833094597 0.1581786572933197
decider.lstm.bias_hh_l0: -0.003561407094821334 0.1398307979106903
decider.linear1.weight: 0.004073154181241989 0.12006866931915283
decider.linear1.bias: 0.013636438176035881 0.11591578274965286
decider.linear2.weight: 0.002536800689995289 0.05245329812169075
decider.linear2.bias: 0.004227709025144577 0.056021321564912796
decider.linear3.weight: -0.005785610992461443 0.05674443021416664
decider.linear3.bias: 0.019048567861318588 0.06082101911306381

Rewards:
203.3164
203.3164
203.3164
objective = 308.0986328125
==== episode 600/10000 ====
action = 1
probs = 0.0490 0.8958 0.0293 0.0258

action = 1
probs = 0.0665 0.8791 0.0367 0.0177

action = 1
probs = 0.3628 0.5686 0.0425 0.0262

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -8.20286586531438e-05 0.08313510566949844
encoder.encoder.weight_hh_l0: -0.00028473447309806943 0.08441129326820374
encoder.encoder.bias_ih_l0: 0.006169566884636879 0.0854620635509491
encoder.encoder.bias_hh_l0: 0.01616663485765457 0.0844997838139534
encoder.encoder.weight_ih_l0_reverse: 0.0010270267957821488 0.08507831394672394
encoder.encoder.weight_hh_l0_reverse: 0.0038750243838876486 0.08384203910827637
encoder.encoder.bias_ih_l0_reverse: 0.02462904341518879 0.0835268571972847
encoder.encoder.bias_hh_l0_reverse: 0.016494618728756905 0.08244738727807999
decider.lstm.weight_ih_l0: 0.00017811950237955898 0.14665088057518005
decider.lstm.weight_hh_l0: 0.002340600360184908 0.14657741785049438
decider.lstm.bias_ih_l0: 0.015121109783649445 0.1581103652715683
decider.lstm.bias_hh_l0: -0.003866340033710003 0.13981878757476807
decider.linear1.weight: 0.004061070270836353 0.12004119157791138
decider.linear1.bias: 0.0135137178003788 0.11597248166799545
decider.linear2.weight: 0.0025062111672014 0.05244506523013115
decider.linear2.bias: 0.004152572713792324 0.05597083270549774
decider.linear3.weight: -0.005788734182715416 0.05668957158923149
decider.linear3.bias: 0.019038308411836624 0.0608605332672596

Rewards:
217.8160
217.8160
217.8160
objective = 58.34177780151367
==== episode 700/10000 ====
action = 1
probs = 0.0450 0.9140 0.0212 0.0198

action = 0
probs = 0.0667 0.8931 0.0255 0.0148

action = 1
probs = 0.4442 0.5011 0.0304 0.0242

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -6.99913507560268e-05 0.0832238420844078
encoder.encoder.weight_hh_l0: -0.0002912845811806619 0.08452179282903671
encoder.encoder.bias_ih_l0: 0.006612511817365885 0.08562780171632767
encoder.encoder.bias_hh_l0: 0.01660957932472229 0.08459216356277466
encoder.encoder.weight_ih_l0_reverse: 0.001050798688083887 0.08515651524066925
encoder.encoder.weight_hh_l0_reverse: 0.004004523158073425 0.08393914997577667
encoder.encoder.bias_ih_l0_reverse: 0.025026671588420868 0.08356539905071259
encoder.encoder.bias_hh_l0_reverse: 0.016892248764634132 0.08243606984615326
decider.lstm.weight_ih_l0: 0.0002625433262437582 0.1467551440000534
decider.lstm.weight_hh_l0: 0.0024762656539678574 0.14667370915412903
decider.lstm.bias_ih_l0: 0.015636920928955078 0.158262237906456
decider.lstm.bias_hh_l0: -0.0033505328465253115 0.13992105424404144
decider.linear1.weight: 0.004069801419973373 0.12008924782276154
decider.linear1.bias: 0.01373984757810831 0.11598781496286392
decider.linear2.weight: 0.0025921580381691456 0.052474018186330795
decider.linear2.bias: 0.004323769360780716 0.05609297752380371
decider.linear3.weight: -0.005861937068402767 0.056795381009578705
decider.linear3.bias: 0.01889607310295105 0.06041336432099342

Rewards:
229.4037
229.4037
229.4037
objective = 266.76641845703125
==== episode 800/10000 ====
action = 1
probs = 0.0482 0.9117 0.0197 0.0204

action = 1
probs = 0.0649 0.8881 0.0291 0.0179

action = 1
probs = 0.4238 0.4871 0.0475 0.0417

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -8.622385212220252e-05 0.08315207064151764
encoder.encoder.weight_hh_l0: -0.00027073148521594703 0.08442530035972595
encoder.encoder.bias_ih_l0: 0.0062502906657755375 0.08554654568433762
encoder.encoder.bias_hh_l0: 0.016247358173131943 0.08450943976640701
encoder.encoder.weight_ih_l0_reverse: 0.00104813976213336 0.08510444313287735
encoder.encoder.weight_hh_l0_reverse: 0.0038854803424328566 0.08390100300312042
encoder.encoder.bias_ih_l0_reverse: 0.02472270466387272 0.08348359167575836
encoder.encoder.bias_hh_l0_reverse: 0.016588281840085983 0.08244258910417557
decider.lstm.weight_ih_l0: 0.00022970594000071287 0.14670847356319427
decider.lstm.weight_hh_l0: 0.0024264068342745304 0.14661791920661926
decider.lstm.bias_ih_l0: 0.015376714989542961 0.15815621614456177
decider.lstm.bias_hh_l0: -0.003610741812735796 0.13989876210689545
decider.linear1.weight: 0.004046179354190826 0.12003123760223389
decider.linear1.bias: 0.013463832437992096 0.11592411249876022
decider.linear2.weight: 0.0024930983781814575 0.05244629085063934
decider.linear2.bias: 0.004203418269753456 0.056059472262859344
decider.linear3.weight: -0.005750145763158798 0.056695517152547836
decider.linear3.bias: 0.01908126100897789 0.06063871085643768

Rewards:
217.8160
217.8160
217.8160
objective = 67.56062316894531
==== episode 900/10000 ====
action = 1
probs = 0.0376 0.9201 0.0213 0.0210

action = 1
probs = 0.0515 0.8943 0.0339 0.0204

action = 0
probs = 0.3605 0.5173 0.0632 0.0590

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -8.319415064761415e-05 0.08311217278242111
encoder.encoder.weight_hh_l0: -0.0002546805771999061 0.08436258882284164
encoder.encoder.bias_ih_l0: 0.005979465786367655 0.08547313511371613
encoder.encoder.bias_hh_l0: 0.01597653143107891 0.08447332680225372
encoder.encoder.weight_ih_l0_reverse: 0.0010220891563221812 0.085071861743927
encoder.encoder.weight_hh_l0_reverse: 0.0038190404884517193 0.08386508375406265
encoder.encoder.bias_ih_l0_reverse: 0.02453281357884407 0.08343873918056488
encoder.encoder.bias_hh_l0_reverse: 0.016398394480347633 0.08249080181121826
decider.lstm.weight_ih_l0: 0.00019828911172226071 0.14666247367858887
decider.lstm.weight_hh_l0: 0.0023800625931471586 0.1465577632188797
decider.lstm.bias_ih_l0: 0.015176471322774887 0.1580313742160797
decider.lstm.bias_hh_l0: -0.0038109859451651573 0.13984867930412292
decider.linear1.weight: 0.004021215718239546 0.11999419331550598
decider.linear1.bias: 0.01325997058302164 0.11588869243860245
decider.linear2.weight: 0.0023966236039996147 0.05242834612727165
decider.linear2.bias: 0.004056140780448914 0.05598125606775284
decider.linear3.weight: -0.005651130806654692 0.05662817880511284
decider.linear3.bias: 0.01928533986210823 0.0614437535405159

Rewards:
230.1930
230.1930
230.1930
objective = 93.2506103515625
==== episode 1000/10000 ====
action = 1
probs = 0.0457 0.9107 0.0228 0.0207

action = 1
probs = 0.0759 0.8638 0.0391 0.0212

action = 1
probs = 0.5381 0.3622 0.0569 0.0427

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -8.705780055606738e-05 0.0831492617726326
encoder.encoder.weight_hh_l0: -0.00026591026107780635 0.08443169295787811
encoder.encoder.bias_ih_l0: 0.0062425099313259125 0.0855308398604393
encoder.encoder.bias_hh_l0: 0.016239576041698456 0.08453451842069626
encoder.encoder.weight_ih_l0_reverse: 0.001070442027412355 0.0851186215877533
encoder.encoder.weight_hh_l0_reverse: 0.0038966184947639704 0.08392904698848724
encoder.encoder.bias_ih_l0_reverse: 0.024774981662631035 0.08349978923797607
encoder.encoder.bias_hh_l0_reverse: 0.016640562564134598 0.08235681056976318
decider.lstm.weight_ih_l0: 0.00023494924244005233 0.14672866463661194
decider.lstm.weight_hh_l0: 0.0024480889551341534 0.14663578569889069
decider.lstm.bias_ih_l0: 0.015402251854538918 0.15811960399150848
decider.lstm.bias_hh_l0: -0.003585201222449541 0.13994957506656647
decider.linear1.weight: 0.004031440243124962 0.12002398818731308
decider.linear1.bias: 0.013359859585762024 0.11589084565639496
decider.linear2.weight: 0.002441330347210169 0.05245361849665642
decider.linear2.bias: 0.004129729233682156 0.055982138961553574
decider.linear3.weight: -0.005718924105167389 0.056667715311050415
decider.linear3.bias: 0.019186701625585556 0.06041986122727394

Rewards:
217.8160
217.8160
217.8160
objective = 91.16265106201172
==== episode 1100/10000 ====
action = 1
probs = 0.0307 0.9354 0.0188 0.0151

action = 1
probs = 0.0511 0.9024 0.0318 0.0147

action = 0
probs = 0.4087 0.4865 0.0647 0.0401

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.1596542915795e-05 0.08318283408880234
encoder.encoder.weight_hh_l0: -0.00025274883955717087 0.08443993330001831
encoder.encoder.bias_ih_l0: 0.006223815027624369 0.08559832721948624
encoder.encoder.bias_hh_l0: 0.016220878809690475 0.08454731851816177
encoder.encoder.weight_ih_l0_reverse: 0.0010350033408030868 0.08512880653142929
encoder.encoder.weight_hh_l0_reverse: 0.0038799415342509747 0.08392279595136642
encoder.encoder.bias_ih_l0_reverse: 0.024759706109762192 0.08347209542989731
encoder.encoder.bias_hh_l0_reverse: 0.016625287011265755 0.08252014964818954
decider.lstm.weight_ih_l0: 0.0002527125470805913 0.14674273133277893
decider.lstm.weight_hh_l0: 0.0024997368454933167 0.1466170996427536
decider.lstm.bias_ih_l0: 0.015566668473184109 0.15814542770385742
decider.lstm.bias_hh_l0: -0.0034207783173769712 0.13994579017162323
decider.linear1.weight: 0.0040283650159835815 0.12004413455724716
decider.linear1.bias: 0.013469249941408634 0.11580067127943039
decider.linear2.weight: 0.0024603831116110086 0.052464619278907776
decider.linear2.bias: 0.004143922124058008 0.055995043367147446
decider.linear3.weight: -0.005784813314676285 0.056676506996154785
decider.linear3.bias: 0.019102569669485092 0.06115107983350754

Rewards:
230.1930
230.1930
230.1930
objective = 81.65692901611328
==== episode 1200/10000 ====
action = 1
probs = 0.0342 0.9313 0.0196 0.0149

action = 1
probs = 0.0550 0.8915 0.0368 0.0167

action = 1
probs = 0.2382 0.6299 0.0880 0.0439

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00013091570872347802 0.08306287974119186
encoder.encoder.weight_hh_l0: -0.00022651307517662644 0.08426566421985626
encoder.encoder.bias_ih_l0: 0.005489549599587917 0.08542471379041672
encoder.encoder.bias_hh_l0: 0.015486614778637886 0.08444663137197495
encoder.encoder.weight_ih_l0_reverse: 0.0009776498191058636 0.0850321501493454
encoder.encoder.weight_hh_l0_reverse: 0.003698437474668026 0.08380300551652908
encoder.encoder.bias_ih_l0_reverse: 0.024200085550546646 0.08338363468647003
encoder.encoder.bias_hh_l0_reverse: 0.01606566458940506 0.08265307545661926
decider.lstm.weight_ih_l0: 0.0001523165701655671 0.14661435782909393
decider.lstm.weight_hh_l0: 0.0022980179637670517 0.1464940458536148
decider.lstm.bias_ih_l0: 0.014939342625439167 0.15793941915035248
decider.lstm.bias_hh_l0: -0.004048105329275131 0.139804407954216
decider.linear1.weight: 0.003976558335125446 0.11999541521072388
decider.linear1.bias: 0.013120285235345364 0.1156962588429451
decider.linear2.weight: 0.002328332280740142 0.05243557319045067
decider.linear2.bias: 0.0038810663390904665 0.055946920067071915
decider.linear3.weight: -0.0057649435475468636 0.05650632828474045
decider.linear3.bias: 0.019116736948490143 0.06175508350133896

Rewards:
217.8160
217.8160
217.8160
objective = 47.05805206298828
==== episode 1300/10000 ====
action = 1
probs = 0.0467 0.9250 0.0157 0.0126

action = 1
probs = 0.0648 0.8922 0.0290 0.0141

action = 1
probs = 0.2575 0.6246 0.0771 0.0408

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00014825454854872078 0.0830666646361351
encoder.encoder.weight_hh_l0: -0.00022561606601811945 0.08427339792251587
encoder.encoder.bias_ih_l0: 0.00551294069737196 0.08546940982341766
encoder.encoder.bias_hh_l0: 0.015510005876421928 0.08446083962917328
encoder.encoder.weight_ih_l0_reverse: 0.0009827181929722428 0.08504204452037811
encoder.encoder.weight_hh_l0_reverse: 0.0036924094893038273 0.08382468670606613
encoder.encoder.bias_ih_l0_reverse: 0.024206317961215973 0.08338113129138947
encoder.encoder.bias_hh_l0_reverse: 0.016071898862719536 0.08264462649822235
decider.lstm.weight_ih_l0: 0.00016240663535427302 0.14664869010448456
decider.lstm.weight_hh_l0: 0.002306792652234435 0.14653733372688293
decider.lstm.bias_ih_l0: 0.014981122687458992 0.15804214775562286
decider.lstm.bias_hh_l0: -0.004006322473287582 0.13988886773586273
decider.linear1.weight: 0.003977516666054726 0.12000653892755508
decider.linear1.bias: 0.013204308226704597 0.11560740321874619
decider.linear2.weight: 0.002423827536404133 0.05244803801178932
decider.linear2.bias: 0.004001135937869549 0.05602499097585678
decider.linear3.weight: -0.005855744704604149 0.056544676423072815
decider.linear3.bias: 0.018932398408651352 0.0610065683722496

Rewards:
217.8160
217.8160
217.8160
objective = 48.11783981323242
==== episode 1400/10000 ====
action = 1
probs = 0.0751 0.8794 0.0214 0.0242

action = 1
probs = 0.1136 0.8192 0.0396 0.0276

action = 1
probs = 0.3943 0.4797 0.0740 0.0520

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001646797318244353 0.08300141990184784
encoder.encoder.weight_hh_l0: -0.0002328298578504473 0.08421064913272858
encoder.encoder.bias_ih_l0: 0.005252714268863201 0.08533401042222977
encoder.encoder.bias_hh_l0: 0.015249781310558319 0.08438204228878021
encoder.encoder.weight_ih_l0_reverse: 0.001011233078315854 0.08498609066009521
encoder.encoder.weight_hh_l0_reverse: 0.003577424446120858 0.08377673476934433
encoder.encoder.bias_ih_l0_reverse: 0.02384379878640175 0.08340029418468475
encoder.encoder.bias_hh_l0_reverse: 0.015709377825260162 0.08244798332452774
decider.lstm.weight_ih_l0: 6.918199505889788e-05 0.14657047390937805
decider.lstm.weight_hh_l0: 0.0021256962791085243 0.1464923471212387
decider.lstm.bias_ih_l0: 0.014402970671653748 0.15795239806175232
decider.lstm.bias_hh_l0: -0.0045844740234315395 0.139924556016922
decider.linear1.weight: 0.003956842236220837 0.11995775997638702
decider.linear1.bias: 0.012867597863078117 0.11561010777950287
decider.linear2.weight: 0.0023197198752313852 0.05242633819580078
decider.linear2.bias: 0.00378849683329463 0.056027043610811234
decider.linear3.weight: -0.005763649474829435 0.0563911534845829
decider.linear3.bias: 0.01910601183772087 0.06018939986824989

Rewards:
217.8160
217.8160
217.8160
objective = 77.1454086303711
==== episode 1500/10000 ====
action = 1
probs = 0.0872 0.8639 0.0224 0.0265

action = 1
probs = 0.1538 0.7695 0.0435 0.0332

action = 1
probs = 0.4347 0.4367 0.0705 0.0580

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00015859506675042212 0.08295499533414841
encoder.encoder.weight_hh_l0: -0.00023419983335770667 0.0841556042432785
encoder.encoder.bias_ih_l0: 0.005006758961826563 0.0852520614862442
encoder.encoder.bias_hh_l0: 0.015003826469182968 0.08432875573635101
encoder.encoder.weight_ih_l0_reverse: 0.0010293014347553253 0.08495581895112991
encoder.encoder.weight_hh_l0_reverse: 0.003515237243846059 0.08374759554862976
encoder.encoder.bias_ih_l0_reverse: 0.023640312254428864 0.08341450989246368
encoder.encoder.bias_hh_l0_reverse: 0.015505884774029255 0.0823773667216301
decider.lstm.weight_ih_l0: 2.0245872292434797e-05 0.14653316140174866
decider.lstm.weight_hh_l0: 0.002035558922216296 0.14647601544857025
decider.lstm.bias_ih_l0: 0.014083496294915676 0.15792997181415558
decider.lstm.bias_hh_l0: -0.004903957713395357 0.13994379341602325
decider.linear1.weight: 0.003944552503526211 0.11993811279535294
decider.linear1.bias: 0.012730446644127369 0.1156315878033638
decider.linear2.weight: 0.0022747477050870657 0.05242306739091873
decider.linear2.bias: 0.003714023856446147 0.05604787543416023
decider.linear3.weight: -0.0057480609975755215 0.0563439205288887
decider.linear3.bias: 0.01913464441895485 0.05979108437895775

Rewards:
217.8160
217.8160
217.8160
objective = 89.8006591796875
==== episode 1600/10000 ====
action = 1
probs = 0.0856 0.8759 0.0177 0.0209

action = 1
probs = 0.1825 0.7579 0.0350 0.0246

action = 1
probs = 0.5250 0.3767 0.0568 0.0415

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00013123206736054271 0.08305352181196213
encoder.encoder.weight_hh_l0: -0.00022855184215586632 0.08426932990550995
encoder.encoder.bias_ih_l0: 0.0054355645552277565 0.08543272316455841
encoder.encoder.bias_hh_l0: 0.015432635322213173 0.0844181627035141
encoder.encoder.weight_ih_l0_reverse: 0.0010739716235548258 0.085045225918293
encoder.encoder.weight_hh_l0_reverse: 0.0036533400416374207 0.08385205268859863
encoder.encoder.bias_ih_l0_reverse: 0.02405463717877865 0.08345469832420349
encoder.encoder.bias_hh_l0_reverse: 0.015920212492346764 0.0823560506105423
decider.lstm.weight_ih_l0: 0.00012042360322084278 0.14666923880577087
decider.lstm.weight_hh_l0: 0.002217765897512436 0.1466110497713089
decider.lstm.bias_ih_l0: 0.014683853834867477 0.1581844538450241
decider.lstm.bias_hh_l0: -0.004303606227040291 0.14010481536388397
decider.linear1.weight: 0.003967111464589834 0.11999982595443726
decider.linear1.bias: 0.013007326051592827 0.11561255156993866
decider.linear2.weight: 0.0023955716751515865 0.052462778985500336
decider.linear2.bias: 0.003939866088330746 0.05614897608757019
decider.linear3.weight: -0.0058664982207119465 0.056473225355148315
decider.linear3.bias: 0.018890831619501114 0.058915574103593826

Rewards:
217.8160
217.8160
217.8160
objective = 100.63582611083984
==== episode 1700/10000 ====
action = 1
probs = 0.0521 0.9204 0.0116 0.0159

action = 1
probs = 0.1391 0.8136 0.0260 0.0213

action = 1
probs = 0.4500 0.4695 0.0441 0.0365

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00010545209079282358 0.0831470638513565
encoder.encoder.weight_hh_l0: -0.00021754225599579513 0.08435521274805069
encoder.encoder.bias_ih_l0: 0.005673393607139587 0.08556852489709854
encoder.encoder.bias_hh_l0: 0.01567046530544758 0.08451080322265625
encoder.encoder.weight_ih_l0_reverse: 0.0010761308949440718 0.08511193096637726
encoder.encoder.weight_hh_l0_reverse: 0.0037478117737919092 0.08390610665082932
encoder.encoder.bias_ih_l0_reverse: 0.024341313168406487 0.08348551392555237
encoder.encoder.bias_hh_l0_reverse: 0.01620689034461975 0.08251424878835678
decider.lstm.weight_ih_l0: 0.0001891952269943431 0.14675790071487427
decider.lstm.weight_hh_l0: 0.0023330776020884514 0.14669382572174072
decider.lstm.bias_ih_l0: 0.015093028545379639 0.15842722356319427
decider.lstm.bias_hh_l0: -0.0038944287225604057 0.1401970237493515
decider.linear1.weight: 0.003981247544288635 0.12005554884672165
decider.linear1.bias: 0.01329644676297903 0.11560977250337601
decider.linear2.weight: 0.002488455967977643 0.05249146372079849
decider.linear2.bias: 0.004075882025063038 0.056260451674461365
decider.linear3.weight: -0.005949292331933975 0.05658363550901413
decider.linear3.bias: 0.01875455304980278 0.05950896441936493

Rewards:
217.8160
217.8160
217.8160
objective = 75.9068603515625
==== episode 1800/10000 ====
action = 1
probs = 0.0716 0.8882 0.0188 0.0215

action = 1
probs = 0.2031 0.7217 0.0461 0.0290

action = 0
probs = 0.4833 0.4173 0.0625 0.0369

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000137418057420291 0.08304406702518463
encoder.encoder.weight_hh_l0: -0.0002233677514595911 0.08423135429620743
encoder.encoder.bias_ih_l0: 0.0051649510860443115 0.08538954704999924
encoder.encoder.bias_hh_l0: 0.015162021853029728 0.08443614095449448
encoder.encoder.weight_ih_l0_reverse: 0.0010507864644750953 0.08502788841724396
encoder.encoder.weight_hh_l0_reverse: 0.003587147919461131 0.08381586521863937
encoder.encoder.bias_ih_l0_reverse: 0.02386285737156868 0.08346689492464066
encoder.encoder.bias_hh_l0_reverse: 0.015728438273072243 0.08239398896694183
decider.lstm.weight_ih_l0: 7.42311603971757e-05 0.146652489900589
decider.lstm.weight_hh_l0: 0.0021344583947211504 0.14660142362117767
decider.lstm.bias_ih_l0: 0.014400791376829147 0.15824125707149506
decider.lstm.bias_hh_l0: -0.0045866635628044605 0.14016269147396088
decider.linear1.weight: 0.003958255983889103 0.11999659985303879
decider.linear1.bias: 0.012994174845516682 0.11558710038661957
decider.linear2.weight: 0.002354792319238186 0.0524730421602726
decider.linear2.bias: 0.0038108103908598423 0.056117117404937744
decider.linear3.weight: -0.005882177501916885 0.05643804371356964
decider.linear3.bias: 0.018884647637605667 0.05919812619686127

Rewards:
230.1930
230.1930
230.1930
objective = 89.91325378417969
==== episode 1900/10000 ====
action = 1
probs = 0.0606 0.9059 0.0171 0.0164

action = 0
probs = 0.1935 0.7463 0.0381 0.0221

action = 0
probs = 0.4544 0.4607 0.0529 0.0320

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00012836686801165342 0.08308257162570953
encoder.encoder.weight_hh_l0: -0.0002186159254051745 0.08427105098962784
encoder.encoder.bias_ih_l0: 0.0052902428433299065 0.08546461164951324
encoder.encoder.bias_hh_l0: 0.015287311747670174 0.08447206020355225
encoder.encoder.weight_ih_l0_reverse: 0.0010366736678406596 0.08504720032215118
encoder.encoder.weight_hh_l0_reverse: 0.003611276624724269 0.08383389562368393
encoder.encoder.bias_ih_l0_reverse: 0.023952854797244072 0.08346620947122574
encoder.encoder.bias_hh_l0_reverse: 0.015818431973457336 0.0824662521481514
decider.lstm.weight_ih_l0: 0.00011018625809811056 0.14669938385486603
decider.lstm.weight_hh_l0: 0.002184926299378276 0.14664539694786072
decider.lstm.bias_ih_l0: 0.014581836760044098 0.1583476960659027
decider.lstm.bias_hh_l0: -0.004405619576573372 0.14020991325378418
decider.linear1.weight: 0.003963721450418234 0.12001842260360718
decider.linear1.bias: 0.013117678463459015 0.11566248536109924
decider.linear2.weight: 0.0023875031620264053 0.052488330751657486
decider.linear2.bias: 0.0038971619214862585 0.0561436302959919
decider.linear3.weight: -0.005947475787252188 0.056485023349523544
decider.linear3.bias: 0.018714379519224167 0.059217676520347595

Rewards:
221.7540
221.7540
221.7540
objective = 186.9961395263672
==== episode 2000/10000 ====
action = 1
probs = 0.0451 0.9281 0.0132 0.0135

action = 0
probs = 0.1533 0.7897 0.0358 0.0211

action = 1
probs = 0.3714 0.5379 0.0566 0.0340

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00012456804688554257 0.08310702443122864
encoder.encoder.weight_hh_l0: -0.00021397702221293002 0.08427812159061432
encoder.encoder.bias_ih_l0: 0.005294472444802523 0.08548933267593384
encoder.encoder.bias_hh_l0: 0.015291541814804077 0.08450421690940857
encoder.encoder.weight_ih_l0_reverse: 0.001036511966958642 0.08506768196821213
encoder.encoder.weight_hh_l0_reverse: 0.003627728670835495 0.08384966105222702
encoder.encoder.bias_ih_l0_reverse: 0.02402454800903797 0.08345542103052139
encoder.encoder.bias_hh_l0_reverse: 0.015890125185251236 0.08259374648332596
decider.lstm.weight_ih_l0: 0.00013468842371366918 0.14672602713108063
decider.lstm.weight_hh_l0: 0.0022178315557539463 0.14666055142879486
decider.lstm.bias_ih_l0: 0.0147133469581604 0.15840716660022736
decider.lstm.bias_hh_l0: -0.004274111241102219 0.14024335145950317
decider.linear1.weight: 0.003955588676035404 0.12002936005592346
decider.linear1.bias: 0.013207950629293919 0.11564479768276215
decider.linear2.weight: 0.002407750580459833 0.05249788612127304
decider.linear2.bias: 0.003920626826584339 0.056160539388656616
decider.linear3.weight: -0.0059675066731870174 0.056517817080020905
decider.linear3.bias: 0.01870439574122429 0.05984384939074516

Rewards:
229.4037
229.4037
229.4037
objective = 196.51255798339844
==== episode 2100/10000 ====
action = 2
probs = 0.0383 0.9381 0.0118 0.0118

action = 1
probs = 0.1475 0.7977 0.0353 0.0195

action = 1
probs = 0.4055 0.5008 0.0597 0.0340

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00012050762597937137 0.0831620916724205
encoder.encoder.weight_hh_l0: -0.00021091735106892884 0.0843329131603241
encoder.encoder.bias_ih_l0: 0.005540905054658651 0.08557403087615967
encoder.encoder.bias_hh_l0: 0.015537974424660206 0.0845247432589531
encoder.encoder.weight_ih_l0_reverse: 0.0010543058160692453 0.0851084366440773
encoder.encoder.weight_hh_l0_reverse: 0.0036788282450288534 0.08390217274427414
encoder.encoder.bias_ih_l0_reverse: 0.024207353591918945 0.08345675468444824
encoder.encoder.bias_hh_l0_reverse: 0.01607293076813221 0.08257679641246796
decider.lstm.weight_ih_l0: 0.00018741810345090926 0.14678487181663513
decider.lstm.weight_hh_l0: 0.0022922924254089594 0.14670921862125397
decider.lstm.bias_ih_l0: 0.01502703595906496 0.158490389585495
decider.lstm.bias_hh_l0: -0.0039604236371815205 0.14029838144779205
decider.linear1.weight: 0.003947222605347633 0.12005070596933365
decider.linear1.bias: 0.013301257975399494 0.115604929625988
decider.linear2.weight: 0.002425607293844223 0.0525134801864624
decider.linear2.bias: 0.003975498955696821 0.05613643676042557
decider.linear3.weight: -0.005968984216451645 0.05657145753502846
decider.linear3.bias: 0.018718551844358444 0.05974450707435608

Rewards:
194.5205
194.5205
194.5205
objective = 347.3113708496094
==== episode 2200/10000 ====
action = 1
probs = 0.0283 0.9501 0.0123 0.0093

action = 1
probs = 0.0969 0.8479 0.0397 0.0155

action = 1
probs = 0.3122 0.5793 0.0743 0.0341

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011384136450942606 0.08316006511449814
encoder.encoder.weight_hh_l0: -0.00019842397887259722 0.08432428538799286
encoder.encoder.bias_ih_l0: 0.005474374163895845 0.0855768695473671
encoder.encoder.bias_hh_l0: 0.01547144167125225 0.08453194797039032
encoder.encoder.weight_ih_l0_reverse: 0.001015879213809967 0.08510290831327438
encoder.encoder.weight_hh_l0_reverse: 0.0036770589649677277 0.08389418572187424
encoder.encoder.bias_ih_l0_reverse: 0.024205345660448074 0.08341231197118759
encoder.encoder.bias_hh_l0_reverse: 0.016070924699306488 0.0827169194817543
decider.lstm.weight_ih_l0: 0.00019098026677966118 0.1467835009098053
decider.lstm.weight_hh_l0: 0.0023162909783422947 0.1466962993144989
decider.lstm.bias_ih_l0: 0.015005651861429214 0.15850874781608582
decider.lstm.bias_hh_l0: -0.003981802612543106 0.1402544528245926
decider.linear1.weight: 0.0039491597563028336 0.12003926187753677
decider.linear1.bias: 0.013340340927243233 0.11562018096446991
decider.linear2.weight: 0.0023988839238882065 0.05251096561551094
decider.linear2.bias: 0.003936692140996456 0.05603411793708801
decider.linear3.weight: -0.005961541552096605 0.056582558900117874
decider.linear3.bias: 0.01873796619474888 0.06072721257805824

Rewards:
217.8160
217.8160
217.8160
objective = 55.33186340332031
==== episode 2300/10000 ====
action = 1
probs = 0.0296 0.9507 0.0117 0.0079

action = 1
probs = 0.0938 0.8557 0.0376 0.0130

action = 1
probs = 0.3037 0.5862 0.0775 0.0326

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00013128019054420292 0.08314552158117294
encoder.encoder.weight_hh_l0: -0.0001990776800084859 0.0843113362789154
encoder.encoder.bias_ih_l0: 0.005426577292382717 0.08558114618062973
encoder.encoder.bias_hh_l0: 0.01542364526540041 0.08452888578176498
encoder.encoder.weight_ih_l0_reverse: 0.0009888444328680634 0.08509380370378494
encoder.encoder.weight_hh_l0_reverse: 0.003662543836981058 0.08388794958591461
encoder.encoder.bias_ih_l0_reverse: 0.024183686822652817 0.08341272920370102
encoder.encoder.bias_hh_l0_reverse: 0.01604926586151123 0.08272566646337509
decider.lstm.weight_ih_l0: 0.00017935682262759656 0.14678923785686493
decider.lstm.weight_hh_l0: 0.0023155068047344685 0.14669853448867798
decider.lstm.bias_ih_l0: 0.014972103759646416 0.15852276980876923
decider.lstm.bias_hh_l0: -0.004015346523374319 0.1402466744184494
decider.linear1.weight: 0.003948759287595749 0.12003299593925476
decider.linear1.bias: 0.013329507783055305 0.11564671248197556
decider.linear2.weight: 0.002408520085737109 0.052510861307382584
decider.linear2.bias: 0.0039713941514492035 0.05602641403675079
decider.linear3.weight: -0.00600711815059185 0.05659322440624237
decider.linear3.bias: 0.018652193248271942 0.06065423786640167

Rewards:
217.8160
217.8160
217.8160
objective = 53.761009216308594
==== episode 2400/10000 ====
action = 1
probs = 0.0202 0.9675 0.0074 0.0050

action = 1
probs = 0.0649 0.9075 0.0200 0.0076

action = 1
probs = 0.2291 0.7078 0.0421 0.0210

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -7.862701750127599e-05 0.08329929411411285
encoder.encoder.weight_hh_l0: -0.00019561378576327115 0.0844692513346672
encoder.encoder.bias_ih_l0: 0.00603543221950531 0.0858154296875
encoder.encoder.bias_hh_l0: 0.016032502055168152 0.08466063439846039
encoder.encoder.weight_ih_l0_reverse: 0.00102436903398484 0.08521715551614761
encoder.encoder.weight_hh_l0_reverse: 0.0038503711111843586 0.08399619162082672
encoder.encoder.bias_ih_l0_reverse: 0.024744676426053047 0.08347547054290771
encoder.encoder.bias_hh_l0_reverse: 0.01661025546491146 0.08293408155441284
decider.lstm.weight_ih_l0: 0.0003047721111215651 0.14691132307052612
decider.lstm.weight_hh_l0: 0.002473811386153102 0.14681291580200195
decider.lstm.bias_ih_l0: 0.0157691091299057 0.15875577926635742
decider.lstm.bias_hh_l0: -0.003218331141397357 0.14035966992378235
decider.linear1.weight: 0.0039687929674983025 0.12014130502939224
decider.linear1.bias: 0.013838228769600391 0.11567437648773193
decider.linear2.weight: 0.002583155408501625 0.05255070701241493
decider.linear2.bias: 0.0042552463710308075 0.05620448291301727
decider.linear3.weight: -0.00614227494224906 0.0567726194858551
decider.linear3.bias: 0.01835334673523903 0.060869019478559494

Rewards:
217.8160
217.8160
217.8160
objective = 34.53546905517578
==== episode 2500/10000 ====
action = 1
probs = 0.0206 0.9674 0.0073 0.0047

action = 1
probs = 0.0719 0.8962 0.0235 0.0084

action = 1
probs = 0.2750 0.6483 0.0523 0.0244

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00010710432979976758 0.08328911662101746
encoder.encoder.weight_hh_l0: -0.00018949800869449973 0.08445412665605545
encoder.encoder.bias_ih_l0: 0.005942009389400482 0.0857979878783226
encoder.encoder.bias_hh_l0: 0.015939082950353622 0.08464231342077255
encoder.encoder.weight_ih_l0_reverse: 0.0010274297092109919 0.08520980179309845
encoder.encoder.weight_hh_l0_reverse: 0.003815970616415143 0.08400667458772659
encoder.encoder.bias_ih_l0_reverse: 0.02468370832502842 0.08346287906169891
encoder.encoder.bias_hh_l0_reverse: 0.016549283638596535 0.08286840468645096
decider.lstm.weight_ih_l0: 0.0002967764448840171 0.14691409468650818
decider.lstm.weight_hh_l0: 0.002465318888425827 0.14681892096996307
decider.lstm.bias_ih_l0: 0.01567440666258335 0.1587708741426468
decider.lstm.bias_hh_l0: -0.0033130301162600517 0.14036433398723602
decider.linear1.weight: 0.00395225128158927 0.12012311816215515
decider.linear1.bias: 0.013754468411207199 0.11563845723867416
decider.linear2.weight: 0.002572618890553713 0.05255172401666641
decider.linear2.bias: 0.0042299251072108746 0.056162863969802856
decider.linear3.weight: -0.006136633455753326 0.056756362318992615
decider.linear3.bias: 0.018394075334072113 0.060648564249277115

Rewards:
217.8160
217.8160
217.8160
objective = 41.82772445678711
==== episode 2600/10000 ====
action = 1
probs = 0.0165 0.9745 0.0055 0.0035

action = 1
probs = 0.0696 0.9003 0.0223 0.0078

action = 0
probs = 0.3291 0.5801 0.0615 0.0293

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011317632743157446 0.08332648128271103
encoder.encoder.weight_hh_l0: -0.00017509126337245107 0.08449739217758179
encoder.encoder.bias_ih_l0: 0.0061265164986252785 0.0858849436044693
encoder.encoder.bias_hh_l0: 0.016123590990900993 0.08467182517051697
encoder.encoder.weight_ih_l0_reverse: 0.0010443604551255703 0.085248202085495
encoder.encoder.weight_hh_l0_reverse: 0.003876750124618411 0.08407215029001236
encoder.encoder.bias_ih_l0_reverse: 0.024903850629925728 0.08347973972558975
encoder.encoder.bias_hh_l0_reverse: 0.016769425943493843 0.08281547576189041
decider.lstm.weight_ih_l0: 0.000360346952220425 0.14698000252246857
decider.lstm.weight_hh_l0: 0.0025575037579983473 0.14686858654022217
decider.lstm.bias_ih_l0: 0.01598697155714035 0.15885382890701294
decider.lstm.bias_hh_l0: -0.003000472206622362 0.14040806889533997
decider.linear1.weight: 0.003936467692255974 0.12014635652303696
decider.linear1.bias: 0.013850625604391098 0.1155979335308075
decider.linear2.weight: 0.0026107430458068848 0.0525718629360199
decider.linear2.bias: 0.004303324036300182 0.056165605783462524
decider.linear3.weight: -0.006146853324025869 0.05682968348264694
decider.linear3.bias: 0.018438518047332764 0.060465555638074875

Rewards:
230.1930
230.1930
230.1930
objective = 95.31202697753906
==== episode 2700/10000 ====
action = 1
probs = 0.0123 0.9803 0.0048 0.0026

action = 1
probs = 0.0472 0.9316 0.0163 0.0049

action = 0
probs = 0.3070 0.6106 0.0572 0.0251

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00010643518908182159 0.08338889479637146
encoder.encoder.weight_hh_l0: -0.00016850318934302777 0.08457869291305542
encoder.encoder.bias_ih_l0: 0.0064334748312830925 0.0859733521938324
encoder.encoder.bias_hh_l0: 0.016430547460913658 0.08472666889429092
encoder.encoder.weight_ih_l0_reverse: 0.0010450722184032202 0.08530015498399734
encoder.encoder.weight_hh_l0_reverse: 0.003956878557801247 0.08412216603755951
encoder.encoder.bias_ih_l0_reverse: 0.02516961097717285 0.08351275324821472
encoder.encoder.bias_hh_l0_reverse: 0.01703518070280552 0.08289425075054169
decider.lstm.weight_ih_l0: 0.00042069584014825523 0.14702945947647095
decider.lstm.weight_hh_l0: 0.002648494904860854 0.14689140021800995
decider.lstm.bias_ih_l0: 0.016361521556973457 0.15889780223369598
decider.lstm.bias_hh_l0: -0.0026259301230311394 0.1404147893190384
decider.linear1.weight: 0.003947097342461348 0.1201859638094902
decider.linear1.bias: 0.014046764932572842 0.11562210321426392
decider.linear2.weight: 0.0026731016114354134 0.05258381366729736
decider.linear2.bias: 0.00444835564121604 0.05617838352918625
decider.linear3.weight: -0.006199902389198542 0.056923091411590576
decider.linear3.bias: 0.018336914479732513 0.06069746986031532

Rewards:
230.1930
230.1930
230.1930
objective = 97.57041931152344
==== episode 2800/10000 ====
action = 1
probs = 0.0160 0.9718 0.0083 0.0039

action = 2
probs = 0.0518 0.9175 0.0245 0.0063

action = 1
probs = 0.2496 0.6630 0.0621 0.0253

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011506624286994338 0.0832962766289711
encoder.encoder.weight_hh_l0: -0.00017867422138806432 0.08446923643350601
encoder.encoder.bias_ih_l0: 0.005942548159509897 0.08582312613725662
encoder.encoder.bias_hh_l0: 0.0159396231174469 0.08467280864715576
encoder.encoder.weight_ih_l0_reverse: 0.0009749988093972206 0.08520340174436569
encoder.encoder.weight_hh_l0_reverse: 0.0038034599274396896 0.08400283008813858
encoder.encoder.bias_ih_l0_reverse: 0.02468298375606537 0.0834442526102066
encoder.encoder.bias_hh_l0_reverse: 0.016548560932278633 0.08289116621017456
decider.lstm.weight_ih_l0: 0.0002930574701167643 0.1469300240278244
decider.lstm.weight_hh_l0: 0.0024999596644192934 0.14681866765022278
decider.lstm.bias_ih_l0: 0.015666130930185318 0.15879607200622559
decider.lstm.bias_hh_l0: -0.003321324475109577 0.14033646881580353
decider.linear1.weight: 0.003945558797568083 0.12010982632637024
decider.linear1.bias: 0.013681208714842796 0.11568653583526611
decider.linear2.weight: 0.0025354826357215643 0.05254203826189041
decider.linear2.bias: 0.004232901614159346 0.05608910694718361
decider.linear3.weight: -0.006136620417237282 0.05676912143826485
decider.linear3.bias: 0.018432460725307465 0.061135753989219666

Rewards:
204.5318
204.5318
204.5318
objective = 282.9708251953125
==== episode 2900/10000 ====
action = 1
probs = 0.0164 0.9733 0.0069 0.0034

action = 1
probs = 0.0389 0.9438 0.0133 0.0040

action = 1
probs = 0.1473 0.8121 0.0274 0.0132

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -5.3875817684456706e-05 0.08339085429906845
encoder.encoder.weight_hh_l0: -0.00020041834795847535 0.08456921577453613
encoder.encoder.bias_ih_l0: 0.0063116298988461494 0.08593291789293289
encoder.encoder.bias_hh_l0: 0.016308708116412163 0.08477254211902618
encoder.encoder.weight_ih_l0_reverse: 0.0009765187278389931 0.0852634608745575
encoder.encoder.weight_hh_l0_reverse: 0.003884646575897932 0.0840107724070549
encoder.encoder.bias_ih_l0_reverse: 0.024892982095479965 0.08348780125379562
encoder.encoder.bias_hh_l0_reverse: 0.016758564859628677 0.08308800309896469
decider.lstm.weight_ih_l0: 0.0003232535964343697 0.146957665681839
decider.lstm.weight_hh_l0: 0.0025194650515913963 0.14683428406715393
decider.lstm.bias_ih_l0: 0.01598873734474182 0.15886206924915314
decider.lstm.bias_hh_l0: -0.002998721320182085 0.1403474509716034
decider.linear1.weight: 0.003986836411058903 0.12017849832773209
decider.linear1.bias: 0.013985206373035908 0.1158311665058136
decider.linear2.weight: 0.00264945812523365 0.052563607692718506
decider.linear2.bias: 0.004422304220497608 0.05627315118908882
decider.linear3.weight: -0.006277953740209341 0.056854505091905594
decider.linear3.bias: 0.018100354820489883 0.0613059476017952

Rewards:
217.8160
217.8160
217.8160
objective = 21.27566146850586
==== episode 3000/10000 ====
action = 1
probs = 0.0157 0.9762 0.0055 0.0026

action = 0
probs = 0.0511 0.9328 0.0126 0.0035

action = 1
probs = 0.1998 0.7655 0.0237 0.0110

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -4.8454177886014804e-05 0.08345666527748108
encoder.encoder.weight_hh_l0: -0.00019597518257796764 0.08464588224887848
encoder.encoder.bias_ih_l0: 0.006553147919476032 0.08604198694229126
encoder.encoder.bias_hh_l0: 0.016550226137042046 0.08483535051345825
encoder.encoder.weight_ih_l0_reverse: 0.0010265079326927662 0.08532920479774475
encoder.encoder.weight_hh_l0_reverse: 0.003988596145063639 0.08408798277378082
encoder.encoder.bias_ih_l0_reverse: 0.02518661506474018 0.08355890959501266
encoder.encoder.bias_hh_l0_reverse: 0.017052197828888893 0.08301257342100143
decider.lstm.weight_ih_l0: 0.00038897356716915965 0.14703533053398132
decider.lstm.weight_hh_l0: 0.0025694421492516994 0.14690756797790527
decider.lstm.bias_ih_l0: 0.01631845533847809 0.1590195596218109
decider.lstm.bias_hh_l0: -0.002669004490599036 0.1404324769973755
decider.linear1.weight: 0.003979102708399296 0.12023452669382095
decider.linear1.bias: 0.014212162233889103 0.11577987670898438
decider.linear2.weight: 0.0027819881215691566 0.052601754665374756
decider.linear2.bias: 0.004610494710505009 0.056315794587135315
decider.linear3.weight: -0.006393220741301775 0.05698026344180107
decider.linear3.bias: 0.017891336232423782 0.060524649918079376

Rewards:
229.4037
229.4037
229.4037
objective = 249.62765502929688
==== episode 3100/10000 ====
action = 1
probs = 0.0139 0.9799 0.0043 0.0019

action = 1
probs = 0.0534 0.9343 0.0096 0.0026

action = 1
probs = 0.2252 0.7484 0.0181 0.0083

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -2.1984054910717532e-05 0.08352866768836975
encoder.encoder.weight_hh_l0: -0.00019678236276376992 0.08474071323871613
encoder.encoder.bias_ih_l0: 0.006917554419487715 0.08616754412651062
encoder.encoder.bias_hh_l0: 0.01691463403403759 0.08490106463432312
encoder.encoder.weight_ih_l0_reverse: 0.0010701884748414159 0.0854087844491005
encoder.encoder.weight_hh_l0_reverse: 0.004126382526010275 0.08416833728551865
encoder.encoder.bias_ih_l0_reverse: 0.025559768080711365 0.08363416790962219
encoder.encoder.bias_hh_l0_reverse: 0.01742534711956978 0.08299959450960159
decider.lstm.weight_ih_l0: 0.000471303123049438 0.147109717130661
decider.lstm.weight_hh_l0: 0.0026221643202006817 0.1469675749540329
decider.lstm.bias_ih_l0: 0.016784939914941788 0.15908433496952057
decider.lstm.bias_hh_l0: -0.0022025182843208313 0.14050748944282532
decider.linear1.weight: 0.003979355096817017 0.12030860036611557
decider.linear1.bias: 0.014504862949252129 0.11577362567186356
decider.linear2.weight: 0.0029064854606986046 0.05263784900307655
decider.linear2.bias: 0.004810011945664883 0.056380465626716614
decider.linear3.weight: -0.006506157107651234 0.05711599811911583
decider.linear3.bias: 0.017696496099233627 0.06008743494749069

Rewards:
217.8160
217.8160
217.8160
objective = 27.44977378845215
==== episode 3200/10000 ====
action = 1
probs = 0.0150 0.9785 0.0043 0.0023

action = 1
probs = 0.0607 0.9279 0.0086 0.0028

action = 0
probs = 0.2560 0.7215 0.0150 0.0075

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -1.93997475435026e-05 0.0835430771112442
encoder.encoder.weight_hh_l0: -0.00020279432646930218 0.08476655185222626
encoder.encoder.bias_ih_l0: 0.006989268586039543 0.08618438243865967
encoder.encoder.bias_hh_l0: 0.016986344009637833 0.08491858839988708
encoder.encoder.weight_ih_l0_reverse: 0.0010831969557330012 0.0854211300611496
encoder.encoder.weight_hh_l0_reverse: 0.004127833992242813 0.08417445421218872
encoder.encoder.bias_ih_l0_reverse: 0.025575751438736916 0.08365945518016815
encoder.encoder.bias_hh_l0_reverse: 0.017441334202885628 0.08296637237071991
decider.lstm.weight_ih_l0: 0.0004785456112585962 0.14711998403072357
decider.lstm.weight_hh_l0: 0.002625572495162487 0.1469736546278
decider.lstm.bias_ih_l0: 0.01684785820543766 0.15908180177211761
decider.lstm.bias_hh_l0: -0.002139601856470108 0.14052988588809967
decider.linear1.weight: 0.003985269460827112 0.12032797932624817
decider.linear1.bias: 0.014535072259604931 0.11576193571090698
decider.linear2.weight: 0.0029228036291897297 0.052647531032562256
decider.linear2.bias: 0.004837914370000362 0.056404437869787216
decider.linear3.weight: -0.006515969522297382 0.05710197612643242
decider.linear3.bias: 0.017654750496149063 0.05977678298950195

Rewards:
230.1930
230.1930
230.1930
objective = 111.97350311279297
==== episode 3300/10000 ====
action = 1
probs = 0.0126 0.9819 0.0037 0.0018

action = 1
probs = 0.0584 0.9308 0.0083 0.0025

action = 1
probs = 0.2194 0.7606 0.0138 0.0062

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -1.2371911907393951e-05 0.08357752859592438
encoder.encoder.weight_hh_l0: -0.00019481680647004396 0.08479130268096924
encoder.encoder.bias_ih_l0: 0.007046279963105917 0.08622477948665619
encoder.encoder.bias_hh_l0: 0.017043359577655792 0.08495957404375076
encoder.encoder.weight_ih_l0_reverse: 0.0010958409402519464 0.08545125275850296
encoder.encoder.weight_hh_l0_reverse: 0.004182782489806414 0.08419958502054214
encoder.encoder.bias_ih_l0_reverse: 0.025705184787511826 0.08366895467042923
encoder.encoder.bias_hh_l0_reverse: 0.01757076568901539 0.08302618563175201
decider.lstm.weight_ih_l0: 0.0005011988105252385 0.1471397429704666
decider.lstm.weight_hh_l0: 0.0026421365328133106 0.1469893455505371
decider.lstm.bias_ih_l0: 0.01695062220096588 0.1591348648071289
decider.lstm.bias_hh_l0: -0.002036852529272437 0.1405421644449234
decider.linear1.weight: 0.003983724862337112 0.12035275250673294
decider.linear1.bias: 0.014675412327051163 0.11576157063245773
decider.linear2.weight: 0.002983258804306388 0.05267921835184097
decider.linear2.bias: 0.004889997653663158 0.056434113532304764
decider.linear3.weight: -0.006569460965692997 0.0571645051240921
decider.linear3.bias: 0.017567500472068787 0.059959929436445236

Rewards:
217.8160
217.8160
217.8160
objective = 26.40070343017578
==== episode 3400/10000 ====
action = 1
probs = 0.0061 0.9913 0.0018 0.0008

action = 1
probs = 0.0258 0.9694 0.0036 0.0011

action = 1
probs = 0.0979 0.8924 0.0066 0.0031

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 7.374182314379141e-05 0.08375442028045654
encoder.encoder.weight_hh_l0: -0.0002054489013971761 0.08498910814523697
encoder.encoder.bias_ih_l0: 0.007884821854531765 0.08644755184650421
encoder.encoder.bias_hh_l0: 0.017881903797388077 0.08509235084056854
encoder.encoder.weight_ih_l0_reverse: 0.0011664271587505937 0.08562351763248444
encoder.encoder.weight_hh_l0_reverse: 0.004582070279866457 0.08435826748609543
encoder.encoder.bias_ih_l0_reverse: 0.026558587327599525 0.08373155444860458
encoder.encoder.bias_hh_l0_reverse: 0.01842416822910309 0.08329594135284424
decider.lstm.weight_ih_l0: 0.0006526251090690494 0.14725938439369202
decider.lstm.weight_hh_l0: 0.0027036776300519705 0.14706085622310638
decider.lstm.bias_ih_l0: 0.017902648076415062 0.15915460884571075
decider.lstm.bias_hh_l0: -0.0010848219972103834 0.14061737060546875
decider.linear1.weight: 0.003997333813458681 0.12048976123332977
decider.linear1.bias: 0.015302255749702454 0.11583763360977173
decider.linear2.weight: 0.003170326352119446 0.05274588242173195
decider.linear2.bias: 0.00514343474060297 0.05665383115410805
decider.linear3.weight: -0.006701882928609848 0.057372141629457474
decider.linear3.bias: 0.017365839332342148 0.0609360933303833

Rewards:
217.8160
217.8160
217.8160
objective = 11.152236938476562
==== episode 3500/10000 ====
action = 1
probs = 0.0056 0.9919 0.0017 0.0008

action = 1
probs = 0.0269 0.9676 0.0043 0.0013

action = 1
probs = 0.1121 0.8755 0.0085 0.0039

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.49735123058781e-05 0.08374341577291489
encoder.encoder.weight_hh_l0: -0.00018098895088769495 0.08496265113353729
encoder.encoder.bias_ih_l0: 0.0077269491739571095 0.08644207566976547
encoder.encoder.bias_hh_l0: 0.01772402971982956 0.08509496599435806
encoder.encoder.weight_ih_l0_reverse: 0.0011553382501006126 0.08560528606176376
encoder.encoder.weight_hh_l0_reverse: 0.004518304020166397 0.08434896916151047
encoder.encoder.bias_ih_l0_reverse: 0.026453685015439987 0.08371597528457642
encoder.encoder.bias_hh_l0_reverse: 0.01831926591694355 0.0832778662443161
decider.lstm.weight_ih_l0: 0.000657035387121141 0.1472480446100235
decider.lstm.weight_hh_l0: 0.002708125626668334 0.14705894887447357
decider.lstm.bias_ih_l0: 0.017839692533016205 0.1591789722442627
decider.lstm.bias_hh_l0: -0.0011477889493107796 0.14060078561306
decider.linear1.weight: 0.003980578389018774 0.12046930938959122
decider.linear1.bias: 0.01523195393383503 0.1158003881573677
decider.linear2.weight: 0.0031608303543180227 0.052756551653146744
decider.linear2.bias: 0.0051060691475868225 0.056604523211717606
decider.linear3.weight: -0.006671915762126446 0.057351481169462204
decider.linear3.bias: 0.017436956986784935 0.0609063096344471

Rewards:
217.8160
217.8160
217.8160
objective = 12.634378433227539
==== episode 3600/10000 ====
action = 1
probs = 0.0065 0.9911 0.0017 0.0008

action = 1
probs = 0.0384 0.9553 0.0048 0.0014

action = 1
probs = 0.1309 0.8565 0.0087 0.0039

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.5610067900270224e-05 0.08373234421014786
encoder.encoder.weight_hh_l0: -0.00016913184663280845 0.08494307100772858
encoder.encoder.bias_ih_l0: 0.007597789634019136 0.0864398404955864
encoder.encoder.bias_hh_l0: 0.017594873905181885 0.08511018753051758
encoder.encoder.weight_ih_l0_reverse: 0.001153207733295858 0.08558904379606247
encoder.encoder.weight_hh_l0_reverse: 0.004460872616618872 0.0843328908085823
encoder.encoder.bias_ih_l0_reverse: 0.026347627863287926 0.08372354507446289
encoder.encoder.bias_hh_l0_reverse: 0.01821320690214634 0.08323438465595245
decider.lstm.weight_ih_l0: 0.0006465082988142967 0.14724315702915192
decider.lstm.weight_hh_l0: 0.002702107187360525 0.1470666080713272
decider.lstm.bias_ih_l0: 0.01772015355527401 0.15921013057231903
decider.lstm.bias_hh_l0: -0.001267323736101389 0.1406027227640152
decider.linear1.weight: 0.003972399979829788 0.1204686239361763
decider.linear1.bias: 0.015222670510411263 0.11577398329973221
decider.linear2.weight: 0.0031666141003370285 0.05278662592172623
decider.linear2.bias: 0.005085217300802469 0.05659862980246544
decider.linear3.weight: -0.006722644437104464 0.057363640516996384
decider.linear3.bias: 0.017361339181661606 0.06052425876259804

Rewards:
217.8160
217.8160
217.8160
objective = 15.214346885681152
==== episode 3700/10000 ====
action = 1
probs = 0.0049 0.9932 0.0013 0.0006

action = 1
probs = 0.0306 0.9641 0.0041 0.0012

action = 1
probs = 0.0986 0.8912 0.0068 0.0034

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 7.197596278274432e-05 0.08379004150629044
encoder.encoder.weight_hh_l0: -0.00016723349108360708 0.08500315994024277
encoder.encoder.bias_ih_l0: 0.007814925163984299 0.08651727437973022
encoder.encoder.bias_hh_l0: 0.017812013626098633 0.08515854924917221
encoder.encoder.weight_ih_l0_reverse: 0.0011689143721014261 0.08563780039548874
encoder.encoder.weight_hh_l0_reverse: 0.004563665948808193 0.08437797427177429
encoder.encoder.bias_ih_l0_reverse: 0.026575667783617973 0.08373658359050751
encoder.encoder.bias_hh_l0_reverse: 0.018441252410411835 0.08330794423818588
decider.lstm.weight_ih_l0: 0.0006791445193812251 0.14727607369422913
decider.lstm.weight_hh_l0: 0.0027274801395833492 0.14708887040615082
decider.lstm.bias_ih_l0: 0.017907559871673584 0.15927258133888245
decider.lstm.bias_hh_l0: -0.001079917885363102 0.1406058669090271
decider.linear1.weight: 0.0039759436622262 0.12050876021385193
decider.linear1.bias: 0.015398485586047173 0.11578100919723511
decider.linear2.weight: 0.003218500642105937 0.05282082036137581
decider.linear2.bias: 0.005138271953910589 0.056669384241104126
decider.linear3.weight: -0.0067308759316802025 0.0574258416891098
decider.linear3.bias: 0.017357274889945984 0.06094801798462868

Rewards:
217.8160
217.8160
217.8160
objective = 11.516807556152344
==== episode 3800/10000 ====
action = 1
probs = 0.0057 0.9925 0.0012 0.0006

action = 1
probs = 0.0443 0.9501 0.0042 0.0013

action = 1
probs = 0.1204 0.8703 0.0062 0.0032

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 7.110967999324203e-05 0.08379508554935455
encoder.encoder.weight_hh_l0: -0.00016322221199516207 0.08500822633504868
encoder.encoder.bias_ih_l0: 0.007786180824041367 0.08653060346841812
encoder.encoder.bias_hh_l0: 0.01778326742351055 0.08517710864543915
encoder.encoder.weight_ih_l0_reverse: 0.0011841270606964827 0.08564231544733047
encoder.encoder.weight_hh_l0_reverse: 0.0045587653294205666 0.08438196033239365
encoder.encoder.bias_ih_l0_reverse: 0.026578053832054138 0.08376577496528625
encoder.encoder.bias_hh_l0_reverse: 0.0184436347335577 0.08324836194515228
decider.lstm.weight_ih_l0: 0.000681473349686712 0.14728643000125885
decider.lstm.weight_hh_l0: 0.002724902704358101 0.1471073031425476
decider.lstm.bias_ih_l0: 0.01788421906530857 0.15930861234664917
decider.lstm.bias_hh_l0: -0.0011032545007765293 0.14061801135540009
decider.linear1.weight: 0.003971566446125507 0.1205286756157875
decider.linear1.bias: 0.015452011488378048 0.11575857549905777
decider.linear2.weight: 0.0032703345641493797 0.05287637934088707
decider.linear2.bias: 0.005184642970561981 0.05669808387756348
decider.linear3.weight: -0.0068069761618971825 0.05747587978839874
decider.linear3.bias: 0.01723356731235981 0.060411132872104645

Rewards:
217.8160
217.8160
217.8160
objective = 14.35511589050293
==== episode 3900/10000 ====
action = 1
probs = 0.0086 0.9884 0.0021 0.0009

action = 1
probs = 0.0726 0.9163 0.0089 0.0022

action = 1
probs = 0.1974 0.7852 0.0125 0.0049

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 8.122026883938815e-06 0.08367229253053665
encoder.encoder.weight_hh_l0: -0.00015140947652980685 0.08485251665115356
encoder.encoder.bias_ih_l0: 0.007164398208260536 0.08636440336704254
encoder.encoder.bias_hh_l0: 0.017161481082439423 0.08507084846496582
encoder.encoder.weight_ih_l0_reverse: 0.0011263542110100389 0.08551813662052155
encoder.encoder.weight_hh_l0_reverse: 0.004288756288588047 0.08428529649972916
encoder.encoder.bias_ih_l0_reverse: 0.02595619112253189 0.0836988314986229
encoder.encoder.bias_hh_l0_reverse: 0.017821770161390305 0.08312729001045227
decider.lstm.weight_ih_l0: 0.0005966948810964823 0.14720652997493744
decider.lstm.weight_hh_l0: 0.0026530795730650425 0.14706261456012726
decider.lstm.bias_ih_l0: 0.017339006066322327 0.15922223031520844
decider.lstm.bias_hh_l0: -0.001648469129577279 0.14057640731334686
decider.linear1.weight: 0.0039444598369300365 0.12043392658233643
decider.linear1.bias: 0.015012621879577637 0.11569862812757492
decider.linear2.weight: 0.0031564366072416306 0.05286933854222298
decider.linear2.bias: 0.004970870912075043 0.05648714303970337
decider.linear3.weight: -0.006903979927301407 0.057316724210977554
decider.linear3.bias: 0.017370272427797318 0.059865932911634445

Rewards:
217.8160
217.8160
217.8160
objective = 24.746124267578125
==== episode 4000/10000 ====
action = 1
probs = 0.0167 0.9794 0.0027 0.0011

action = 1
probs = 0.1426 0.8438 0.0109 0.0027

action = 1
probs = 0.3017 0.6808 0.0128 0.0047

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -1.6026348021114245e-05 0.08361311256885529
encoder.encoder.weight_hh_l0: -0.0001551204768475145 0.08479338884353638
encoder.encoder.bias_ih_l0: 0.006898616440594196 0.08628581464290619
encoder.encoder.bias_hh_l0: 0.016895702108740807 0.08503001928329468
encoder.encoder.weight_ih_l0_reverse: 0.001117561710998416 0.08545826375484467
encoder.encoder.weight_hh_l0_reverse: 0.004160595592111349 0.08423309773206711
encoder.encoder.bias_ih_l0_reverse: 0.025653094053268433 0.08371235430240631
encoder.encoder.bias_hh_l0_reverse: 0.017518674954771996 0.08296923339366913
decider.lstm.weight_ih_l0: 0.0005431795143522322 0.14717279374599457
decider.lstm.weight_hh_l0: 0.0026061751414090395 0.1470576822757721
decider.lstm.bias_ih_l0: 0.017036527395248413 0.1591811627149582
decider.lstm.bias_hh_l0: -0.0019509498961269855 0.14058250188827515
decider.linear1.weight: 0.003941419534385204 0.12041331082582474
decider.linear1.bias: 0.014856846071779728 0.1157216802239418
decider.linear2.weight: 0.003151119453832507 0.05287812650203705
decider.linear2.bias: 0.004965558648109436 0.05651050806045532
decider.linear3.weight: -0.007094656117260456 0.0573265366256237
decider.linear3.bias: 0.01719256490468979 0.058622095733881

Rewards:
217.8160
217.8160
217.8160
objective = 41.76530456542969
==== episode 4100/10000 ====
action = 1
probs = 0.0264 0.9655 0.0061 0.0020

action = 0
probs = 0.2097 0.7665 0.0200 0.0038

action = 0
probs = 0.3489 0.6281 0.0178 0.0051

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -4.438541873241775e-05 0.08347642421722412
encoder.encoder.weight_hh_l0: -0.00017196893168147653 0.08464279770851135
encoder.encoder.bias_ih_l0: 0.006311467848718166 0.08608194440603256
encoder.encoder.bias_hh_l0: 0.016308553516864777 0.08489974588155746
encoder.encoder.weight_ih_l0_reverse: 0.0010688849724829197 0.08533535897731781
encoder.encoder.weight_hh_l0_reverse: 0.003942536190152168 0.08411907404661179
encoder.encoder.bias_ih_l0_reverse: 0.02507600747048855 0.08365767449140549
encoder.encoder.bias_hh_l0_reverse: 0.01694158837199211 0.08282999694347382
decider.lstm.weight_ih_l0: 0.0004018500621896237 0.14705955982208252
decider.lstm.weight_hh_l0: 0.0024773520417511463 0.14697839319705963
decider.lstm.bias_ih_l0: 0.01629694364964962 0.15906056761741638
decider.lstm.bias_hh_l0: -0.0026905303820967674 0.1405351459980011
decider.linear1.weight: 0.0039407918229699135 0.12033639848232269
decider.linear1.bias: 0.01445282343775034 0.11573591083288193
decider.linear2.weight: 0.003006857354193926 0.05284936726093292
decider.linear2.bias: 0.00474973488599062 0.05639496073126793
decider.linear3.weight: -0.007034246809780598 0.05724099278450012
decider.linear3.bias: 0.017308808863162994 0.05835627019405365

Rewards:
221.7540
221.7540
221.7540
objective = 195.8897705078125
==== episode 4200/10000 ====
action = 1
probs = 0.0252 0.9665 0.0061 0.0022

action = 1
probs = 0.2012 0.7803 0.0151 0.0033

action = 1
probs = 0.3821 0.6003 0.0131 0.0044

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -3.0861643608659506e-05 0.08353248983621597
encoder.encoder.weight_hh_l0: -0.00017686895444057882 0.084718719124794
encoder.encoder.bias_ih_l0: 0.006592205725610256 0.08615930378437042
encoder.encoder.bias_hh_l0: 0.016589287668466568 0.08494385331869125
encoder.encoder.weight_ih_l0_reverse: 0.001081387628801167 0.08537262678146362
encoder.encoder.weight_hh_l0_reverse: 0.003992714453488588 0.08414778858423233
encoder.encoder.bias_ih_l0_reverse: 0.025220295414328575 0.08369898796081543
encoder.encoder.bias_hh_l0_reverse: 0.01708587445318699 0.08283674716949463
decider.lstm.weight_ih_l0: 0.00044214254012331367 0.14709343016147614
decider.lstm.weight_hh_l0: 0.0025246101431548595 0.14699679613113403
decider.lstm.bias_ih_l0: 0.016581648960709572 0.15907050669193268
decider.lstm.bias_hh_l0: -0.002405822277069092 0.1405499428510666
decider.linear1.weight: 0.003951829858124256 0.12036808580160141
decider.linear1.bias: 0.01452859677374363 0.11578866094350815
decider.linear2.weight: 0.0030248723924160004 0.0528591088950634
decider.linear2.bias: 0.004830644465982914 0.0564664788544178
decider.linear3.weight: -0.00705100828781724 0.05726063624024391
decider.linear3.bias: 0.017255768179893494 0.0581851564347744

Rewards:
217.8160
217.8160
217.8160
objective = 57.531219482421875
==== episode 4300/10000 ====
action = 1
probs = 0.0199 0.9724 0.0058 0.0019

action = 1
probs = 0.2233 0.7491 0.0232 0.0043

action = 3
probs = 0.4274 0.5463 0.0208 0.0055

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -2.6110708859050646e-05 0.08351396024227142
encoder.encoder.weight_hh_l0: -0.0001648847828619182 0.08467919379472733
encoder.encoder.bias_ih_l0: 0.006407332140952349 0.08612696081399918
encoder.encoder.bias_hh_l0: 0.016404414549469948 0.08493416011333466
encoder.encoder.weight_ih_l0_reverse: 0.0011085005244240165 0.08537955582141876
encoder.encoder.weight_hh_l0_reverse: 0.004022035747766495 0.08417904376983643
encoder.encoder.bias_ih_l0_reverse: 0.025291267782449722 0.08368731290102005
encoder.encoder.bias_hh_l0_reverse: 0.017156844958662987 0.08280466496944427
decider.lstm.weight_ih_l0: 0.00046491067041642964 0.14711245894432068
decider.lstm.weight_hh_l0: 0.002542231697589159 0.14702361822128296
decider.lstm.bias_ih_l0: 0.016579966992139816 0.15911994874477386
decider.lstm.bias_hh_l0: -0.0024074995890259743 0.14057140052318573
decider.linear1.weight: 0.0039337328635156155 0.1203533485531807
decider.linear1.bias: 0.014455731958150864 0.11567950993776321
decider.linear2.weight: 0.00298461620695889 0.05287201330065727
decider.linear2.bias: 0.004721042700111866 0.05634739249944687
decider.linear3.weight: -0.006991446018218994 0.05724351480603218
decider.linear3.bias: 0.017437856644392014 0.05830290541052818

Rewards:
209.9372
209.9372
209.9372
objective = 385.873779296875
==== episode 4400/10000 ====
action = 1
probs = 0.0258 0.9668 0.0053 0.0021

action = 1
probs = 0.2883 0.6864 0.0202 0.0051

action = 0
probs = 0.4848 0.4926 0.0166 0.0060

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -3.2875908800633624e-05 0.08350309729576111
encoder.encoder.weight_hh_l0: -0.0001634907239349559 0.08466585725545883
encoder.encoder.bias_ih_l0: 0.0063352738507092 0.08612631261348724
encoder.encoder.bias_hh_l0: 0.0163323562592268 0.08491460978984833
encoder.encoder.weight_ih_l0_reverse: 0.0011048858286812901 0.08537037670612335
encoder.encoder.weight_hh_l0_reverse: 0.003980986773967743 0.08417166769504547
encoder.encoder.bias_ih_l0_reverse: 0.025198480114340782 0.0836997702717781
encoder.encoder.bias_hh_l0_reverse: 0.017064055427908897 0.08274443447589874
decider.lstm.weight_ih_l0: 0.0004512796876952052 0.1471092253923416
decider.lstm.weight_hh_l0: 0.002519122790545225 0.1470353603363037
decider.lstm.bias_ih_l0: 0.01649082452058792 0.15914961695671082
decider.lstm.bias_hh_l0: -0.002496645087376237 0.14059875905513763
decider.linear1.weight: 0.0039295414462685585 0.12035732716321945
decider.linear1.bias: 0.014449378475546837 0.11568119376897812
decider.linear2.weight: 0.0029884553514420986 0.0528876967728138
decider.linear2.bias: 0.004718447104096413 0.056419216096401215
decider.linear3.weight: -0.007012226153165102 0.05720578506588936
decider.linear3.bias: 0.01740269362926483 0.05765669792890549

Rewards:
230.1930
230.1930
230.1930
objective = 87.01103210449219
==== episode 4500/10000 ====
action = 1
probs = 0.0351 0.9545 0.0072 0.0032

action = 1
probs = 0.2485 0.7235 0.0221 0.0059

action = 1
probs = 0.3784 0.5987 0.0164 0.0065

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -4.159331365372054e-05 0.08340051025152206
encoder.encoder.weight_hh_l0: -0.00018304164404980838 0.08455505967140198
encoder.encoder.bias_ih_l0: 0.005893380381166935 0.08595366775989532
encoder.encoder.bias_hh_l0: 0.015890462324023247 0.0848097950220108
encoder.encoder.weight_ih_l0_reverse: 0.0010445138905197382 0.08526164293289185
encoder.encoder.weight_hh_l0_reverse: 0.003775813616812229 0.08404944837093353
encoder.encoder.bias_ih_l0_reverse: 0.024604491889476776 0.0836159735918045
encoder.encoder.bias_hh_l0_reverse: 0.016470063477754593 0.08278780430555344
decider.lstm.weight_ih_l0: 0.0002949609770439565 0.14696845412254333
decider.lstm.weight_hh_l0: 0.002357372548431158 0.14691075682640076
decider.lstm.bias_ih_l0: 0.01573491469025612 0.15898707509040833
decider.lstm.bias_hh_l0: -0.003252559108659625 0.14047379791736603
decider.linear1.weight: 0.003934087697416544 0.12027525156736374
decider.linear1.bias: 0.014132728800177574 0.1157425120472908
decider.linear2.weight: 0.0028714733198285103 0.05284321308135986
decider.linear2.bias: 0.004494815599173307 0.056398890912532806
decider.linear3.weight: -0.006964609958231449 0.05704653635621071
decider.linear3.bias: 0.017479434609413147 0.05817827954888344

Rewards:
217.8160
217.8160
217.8160
objective = 64.12484741210938
==== episode 4600/10000 ====
action = 1
probs = 0.0340 0.9573 0.0061 0.0026

action = 1
probs = 0.2522 0.7264 0.0170 0.0045

action = 0
probs = 0.3507 0.6334 0.0114 0.0045

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -2.0533054339466617e-05 0.08345790952444077
encoder.encoder.weight_hh_l0: -0.00018455022654961795 0.08461257070302963
encoder.encoder.bias_ih_l0: 0.0060696727596223354 0.08603797107934952
encoder.encoder.bias_hh_l0: 0.01606675609946251 0.08486459404230118
encoder.encoder.weight_ih_l0_reverse: 0.001062874449416995 0.08531206846237183
encoder.encoder.weight_hh_l0_reverse: 0.0038355491124093533 0.08408454805612564
encoder.encoder.bias_ih_l0_reverse: 0.024770593270659447 0.08365761488676071
encoder.encoder.bias_hh_l0_reverse: 0.016636162996292114 0.08285082131624222
decider.lstm.weight_ih_l0: 0.00033642997732385993 0.1470232903957367
decider.lstm.weight_hh_l0: 0.002404808299615979 0.14697009325027466
decider.lstm.bias_ih_l0: 0.015947375446558 0.15912556648254395
decider.lstm.bias_hh_l0: -0.0030400981195271015 0.14051996171474457
decider.linear1.weight: 0.0039510419592261314 0.1203257367014885
decider.linear1.bias: 0.014391262084245682 0.11579595506191254
decider.linear2.weight: 0.0029646940529346466 0.05287349969148636
decider.linear2.bias: 0.004658032674342394 0.05650369077920914
decider.linear3.weight: -0.007105669472366571 0.05717162415385246
decider.linear3.bias: 0.01717250794172287 0.0579434372484684

Rewards:
230.1930
230.1930
230.1930
objective = 108.26616668701172
==== episode 4700/10000 ====
action = 1
probs = 0.0441 0.9468 0.0065 0.0026

action = 1
probs = 0.2527 0.7269 0.0165 0.0038

action = 1
probs = 0.3616 0.6228 0.0115 0.0040

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -2.9082297260174528e-05 0.08344557881355286
encoder.encoder.weight_hh_l0: -0.00019022567721549422 0.08460483700037003
encoder.encoder.bias_ih_l0: 0.006043114699423313 0.08600731939077377
encoder.encoder.bias_hh_l0: 0.016040191054344177 0.08484261482954025
encoder.encoder.weight_ih_l0_reverse: 0.00105754763353616 0.0852864682674408
encoder.encoder.weight_hh_l0_reverse: 0.0037789756897836924 0.084056556224823
encoder.encoder.bias_ih_l0_reverse: 0.02461761236190796 0.08364282548427582
encoder.encoder.bias_hh_l0_reverse: 0.016483178362250328 0.08284196257591248
decider.lstm.weight_ih_l0: 0.000299615174299106 0.14698854088783264
decider.lstm.weight_hh_l0: 0.002372590359300375 0.14693455398082733
decider.lstm.bias_ih_l0: 0.01579182967543602 0.15906375646591187
decider.lstm.bias_hh_l0: -0.0031956504099071026 0.14047828316688538
decider.linear1.weight: 0.003952005412429571 0.12031552940607071
decider.linear1.bias: 0.014330104924738407 0.11583004891872406
decider.linear2.weight: 0.002965188818052411 0.05286774784326553
decider.linear2.bias: 0.00464562838897109 0.05649816617369652
decider.linear3.weight: -0.0071950675919651985 0.057168539613485336
decider.linear3.bias: 0.01699741743505001 0.057685427367687225

Rewards:
217.8160
217.8160
217.8160
objective = 61.49726486206055
==== episode 4800/10000 ====
action = 1
probs = 0.0500 0.9423 0.0054 0.0022

action = 0
probs = 0.2185 0.7672 0.0114 0.0028

action = 1
probs = 0.2564 0.7327 0.0080 0.0030

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -1.5579313185298815e-05 0.08345211297273636
encoder.encoder.weight_hh_l0: -0.00019266142044216394 0.08461356163024902
encoder.encoder.bias_ih_l0: 0.006033006124198437 0.08600824326276779
encoder.encoder.bias_hh_l0: 0.0160300824791193 0.08487316220998764
encoder.encoder.weight_ih_l0_reverse: 0.0010249861516058445 0.08527816832065582
encoder.encoder.weight_hh_l0_reverse: 0.0037338274996727705 0.08402473479509354
encoder.encoder.bias_ih_l0_reverse: 0.024485401809215546 0.083623506128788
encoder.encoder.bias_hh_l0_reverse: 0.016350969672203064 0.08295460790395737
decider.lstm.weight_ih_l0: 0.00026135551161132753 0.14696860313415527
decider.lstm.weight_hh_l0: 0.002344155218452215 0.14692556858062744
decider.lstm.bias_ih_l0: 0.015602575615048409 0.1591067761182785
decider.lstm.bias_hh_l0: -0.0033849128521978855 0.14044620096683502
decider.linear1.weight: 0.003964313771575689 0.12032797932624817
decider.linear1.bias: 0.01442839577794075 0.11590878665447235
decider.linear2.weight: 0.003009894397109747 0.052877116948366165
decider.linear2.bias: 0.004727431572973728 0.05663787201046944
decider.linear3.weight: -0.007349133491516113 0.05723227933049202
decider.linear3.bias: 0.016673846170306206 0.05771808326244354

Rewards:
229.4037
229.4037
229.4037
objective = 144.62318420410156
==== episode 4900/10000 ====
action = 1
probs = 0.0614 0.9308 0.0056 0.0022

action = 1
probs = 0.2095 0.7799 0.0085 0.0021

action = 1
probs = 0.2719 0.7198 0.0060 0.0022

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -1.16756555144093e-05 0.0834658071398735
encoder.encoder.weight_hh_l0: -0.0002090962661895901 0.08464745432138443
encoder.encoder.bias_ih_l0: 0.006178852170705795 0.08604831993579865
encoder.encoder.bias_hh_l0: 0.016175927594304085 0.08487799763679504
encoder.encoder.weight_ih_l0_reverse: 0.0010302979499101639 0.08527936041355133
encoder.encoder.weight_hh_l0_reverse: 0.0037118529435247183 0.08401679247617722
encoder.encoder.bias_ih_l0_reverse: 0.024434557184576988 0.08364603668451309
encoder.encoder.bias_hh_l0_reverse: 0.016300126910209656 0.08295132219791412
decider.lstm.weight_ih_l0: 0.00025494396686553955 0.14696121215820312
decider.lstm.weight_hh_l0: 0.002350620226934552 0.1469101756811142
decider.lstm.bias_ih_l0: 0.015668470412492752 0.15903113782405853
decider.lstm.bias_hh_l0: -0.003319013863801956 0.140442356467247
decider.linear1.weight: 0.003974828403443098 0.12035612761974335
decider.linear1.bias: 0.014498497359454632 0.11601273715496063
decider.linear2.weight: 0.00300755281932652 0.052886489778757095
decider.linear2.bias: 0.004728597588837147 0.05670420452952385
decider.linear3.weight: -0.007466047070920467 0.05726243555545807
decider.linear3.bias: 0.016422132030129433 0.057395998388528824

Rewards:
217.8160
217.8160
217.8160
objective = 47.13158416748047
==== episode 5000/10000 ====
action = 1
probs = 0.0764 0.9164 0.0050 0.0022

action = 1
probs = 0.3000 0.6899 0.0080 0.0022

action = 1
probs = 0.3495 0.6432 0.0052 0.0021

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.1457672119140625e-06 0.08349042385816574
encoder.encoder.weight_hh_l0: -0.00020561317796818912 0.0846625566482544
encoder.encoder.bias_ih_l0: 0.006175864953547716 0.0860639289021492
encoder.encoder.bias_hh_l0: 0.01617293618619442 0.08490558713674545
encoder.encoder.weight_ih_l0_reverse: 0.001044415752403438 0.08530189841985703
encoder.encoder.weight_hh_l0_reverse: 0.0037400168366730213 0.08404267579317093
encoder.encoder.bias_ih_l0_reverse: 0.02451956272125244 0.08368413895368576
encoder.encoder.bias_hh_l0_reverse: 0.01638513244688511 0.08287505805492401
decider.lstm.weight_ih_l0: 0.0002857940271496773 0.14700472354888916
decider.lstm.weight_hh_l0: 0.002369149588048458 0.14697428047657013
decider.lstm.bias_ih_l0: 0.01576860062777996 0.15918932855129242
decider.lstm.bias_hh_l0: -0.003218891564756632 0.1404978632926941
decider.linear1.weight: 0.003971565514802933 0.12037400156259537
decider.linear1.bias: 0.014572268351912498 0.11596763879060745
decider.linear2.weight: 0.0030971746891736984 0.05291973426938057
decider.linear2.bias: 0.004884009249508381 0.056734684854745865
decider.linear3.weight: -0.0075516365468502045 0.05732683837413788
decider.linear3.bias: 0.016255030408501625 0.05651432275772095

Rewards:
217.8160
217.8160
217.8160
objective = 65.33198547363281
==== episode 5100/10000 ====
action = 1
probs = 0.1530 0.8381 0.0062 0.0027

action = 0
probs = 0.5141 0.4759 0.0079 0.0021

action = 1
probs = 0.5430 0.4498 0.0053 0.0019

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -1.0935217460428248e-06 0.08344973623752594
encoder.encoder.weight_hh_l0: -0.00021064848988316953 0.08460815250873566
encoder.encoder.bias_ih_l0: 0.005954955704510212 0.08598890155553818
encoder.encoder.bias_hh_l0: 0.01595202460885048 0.08485249429941177
encoder.encoder.weight_ih_l0_reverse: 0.0010545433033257723 0.08527836203575134
encoder.encoder.weight_hh_l0_reverse: 0.0036931533832103014 0.08402886986732483
encoder.encoder.bias_ih_l0_reverse: 0.024395890533924103 0.08371545374393463
encoder.encoder.bias_hh_l0_reverse: 0.01626145839691162 0.08269669860601425
decider.lstm.weight_ih_l0: 0.000257357518421486 0.14697906374931335
decider.lstm.weight_hh_l0: 0.0023399873171001673 0.1469869762659073
decider.lstm.bias_ih_l0: 0.015557592734694481 0.15923526883125305
decider.lstm.bias_hh_l0: -0.003429894335567951 0.1405176818370819
decider.linear1.weight: 0.003966127522289753 0.12037678062915802
decider.linear1.bias: 0.014473272487521172 0.11588214337825775
decider.linear2.weight: 0.003155163489282131 0.052946630865335464
decider.linear2.bias: 0.005000748205929995 0.05670981481671333
decider.linear3.weight: -0.007650678977370262 0.05735800415277481
decider.linear3.bias: 0.016089394688606262 0.05489994212985039

Rewards:
229.4037
229.4037
229.4037
objective = 125.4767074584961
==== episode 5200/10000 ====
action = 1
probs = 0.2153 0.7764 0.0057 0.0026

action = 1
probs = 0.5864 0.4058 0.0060 0.0018

action = 0
probs = 0.6306 0.3635 0.0042 0.0017

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.1335015187796671e-05 0.08348210901021957
encoder.encoder.weight_hh_l0: -0.00020926451543346047 0.08464392274618149
encoder.encoder.bias_ih_l0: 0.006091763731092215 0.08601904660463333
encoder.encoder.bias_hh_l0: 0.016088834032416344 0.08485627919435501
encoder.encoder.weight_ih_l0_reverse: 0.0010616735089570284 0.08528558164834976
encoder.encoder.weight_hh_l0_reverse: 0.003692247672006488 0.0840381309390068
encoder.encoder.bias_ih_l0_reverse: 0.024391526356339455 0.08372832834720612
encoder.encoder.bias_hh_l0_reverse: 0.016257094219326973 0.0826432853937149
decider.lstm.weight_ih_l0: 0.00027002484421245754 0.14699770510196686
decider.lstm.weight_hh_l0: 0.002359093865379691 0.14700132608413696
decider.lstm.bias_ih_l0: 0.0156552717089653 0.15925464034080505
decider.lstm.bias_hh_l0: -0.0033322146628051996 0.14053890109062195
decider.linear1.weight: 0.003963611554354429 0.12040276825428009
decider.linear1.bias: 0.014551165513694286 0.11588579416275024
decider.linear2.weight: 0.0031947921961545944 0.05297341197729111
decider.linear2.bias: 0.005061093717813492 0.05676652118563652
decider.linear3.weight: -0.007830179296433926 0.05736749991774559
decider.linear3.bias: 0.015963872894644737 0.05416245758533478

Rewards:
230.1930
230.1930
230.1930
objective = 124.00360107421875
==== episode 5300/10000 ====
action = 1
probs = 0.1258 0.8690 0.0035 0.0017

action = 1
probs = 0.4907 0.5021 0.0056 0.0016

action = 1
probs = 0.5777 0.4171 0.0037 0.0015

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.9565299226087518e-05 0.08358629047870636
encoder.encoder.weight_hh_l0: -0.00018436284153722227 0.08476360142230988
encoder.encoder.bias_ih_l0: 0.006484905257821083 0.08618365228176117
encoder.encoder.bias_hh_l0: 0.016481976956129074 0.08500239998102188
encoder.encoder.weight_ih_l0_reverse: 0.0010952248703688383 0.08538328856229782
encoder.encoder.weight_hh_l0_reverse: 0.0038468320854008198 0.08413457870483398
encoder.encoder.bias_ih_l0_reverse: 0.024836042895913124 0.08378759771585464
encoder.encoder.bias_hh_l0_reverse: 0.01670161262154579 0.08273131400346756
decider.lstm.weight_ih_l0: 0.0004072604642715305 0.14713627099990845
decider.lstm.weight_hh_l0: 0.002500138245522976 0.147111177444458
decider.lstm.bias_ih_l0: 0.01631150022149086 0.1594235748052597
decider.lstm.bias_hh_l0: -0.0026759873144328594 0.14062516391277313
decider.linear1.weight: 0.003963682800531387 0.12044471502304077
decider.linear1.bias: 0.014788487926125526 0.11586446315050125
decider.linear2.weight: 0.0032600201666355133 0.05300227180123329
decider.linear2.bias: 0.005170834716409445 0.056771840900182724
decider.linear3.weight: -0.00797782652080059 0.05750546604394913
decider.linear3.bias: 0.015792232006788254 0.05467953905463219

Rewards:
217.8160
217.8160
217.8160
objective = 123.70965576171875
==== episode 5400/10000 ====
action = 0
probs = 0.1937 0.8000 0.0044 0.0019

action = 1
probs = 0.5974 0.3958 0.0054 0.0014

action = 0
probs = 0.5924 0.4018 0.0042 0.0016

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.736529156914912e-05 0.08350031822919846
encoder.encoder.weight_hh_l0: -0.00020346452947705984 0.08464735746383667
encoder.encoder.bias_ih_l0: 0.006042809225618839 0.08605668693780899
encoder.encoder.bias_hh_l0: 0.016039878129959106 0.08489957451820374
encoder.encoder.weight_ih_l0_reverse: 0.001052513369359076 0.08531074225902557
encoder.encoder.weight_hh_l0_reverse: 0.0036893882788717747 0.08405931293964386
encoder.encoder.bias_ih_l0_reverse: 0.024430643767118454 0.08374423533678055
encoder.encoder.bias_hh_l0_reverse: 0.016296207904815674 0.0827094316482544
decider.lstm.weight_ih_l0: 0.00030311450245790184 0.14704924821853638
decider.lstm.weight_hh_l0: 0.0023907553404569626 0.14705708622932434
decider.lstm.bias_ih_l0: 0.015783309936523438 0.15935444831848145
decider.lstm.bias_hh_l0: -0.003204166889190674 0.1405966430902481
decider.linear1.weight: 0.003954277839511633 0.12040802836418152
decider.linear1.bias: 0.014590119011700153 0.11586608737707138
decider.linear2.weight: 0.0032339231111109257 0.052992478013038635
decider.linear2.bias: 0.005138978362083435 0.05678210034966469
decider.linear3.weight: -0.008042015135288239 0.05746707692742348
decider.linear3.bias: 0.015730878338217735 0.05412575602531433

Rewards:
221.5682
221.5682
221.5682
objective = 228.35826110839844
==== episode 5500/10000 ====
action = 2
probs = 0.1460 0.8480 0.0043 0.0017

action = 1
probs = 0.5764 0.4149 0.0070 0.0017

action = 1
probs = 0.5946 0.3979 0.0058 0.0018

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.0617077350616455e-07 0.08350416272878647
encoder.encoder.weight_hh_l0: -0.00019470913684926927 0.08464563637971878
encoder.encoder.bias_ih_l0: 0.006024870555847883 0.08607494086027145
encoder.encoder.bias_hh_l0: 0.01602194458246231 0.08493009209632874
encoder.encoder.weight_ih_l0_reverse: 0.0010612925980240107 0.0853358581662178
encoder.encoder.weight_hh_l0_reverse: 0.0037451705429702997 0.08409953862428665
encoder.encoder.bias_ih_l0_reverse: 0.024604452773928642 0.0837593600153923
encoder.encoder.bias_hh_l0_reverse: 0.01647002249956131 0.08270713686943054
decider.lstm.weight_ih_l0: 0.00035714078694581985 0.14710426330566406
decider.lstm.weight_hh_l0: 0.002446044934913516 0.1471080183982849
decider.lstm.bias_ih_l0: 0.01598840206861496 0.15941272675991058
decider.lstm.bias_hh_l0: -0.00299907848238945 0.14064981043338776
decider.linear1.weight: 0.003939839079976082 0.12039166688919067
decider.linear1.bias: 0.014509550295770168 0.11580642312765121
decider.linear2.weight: 0.003197156358510256 0.05298607796430588
decider.linear2.bias: 0.005130244884639978 0.056658659130334854
decider.linear3.weight: -0.008007477037608624 0.05746575444936752
decider.linear3.bias: 0.015889395028352737 0.054467156529426575

Rewards:
194.5205
194.5205
194.5205
objective = 469.67425537109375
==== episode 5600/10000 ====
action = 1
probs = 0.1450 0.8490 0.0043 0.0017

action = 0
probs = 0.5320 0.4602 0.0062 0.0016

action = 1
probs = 0.5519 0.4416 0.0048 0.0017

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.1452882972662337e-05 0.08352189511060715
encoder.encoder.weight_hh_l0: -0.0001997377403313294 0.08467145264148712
encoder.encoder.bias_ih_l0: 0.006104032974690199 0.08608348667621613
encoder.encoder.bias_hh_l0: 0.016101105138659477 0.08497706055641174
encoder.encoder.weight_ih_l0_reverse: 0.001054583815857768 0.08532852679491043
encoder.encoder.weight_hh_l0_reverse: 0.0037206008564680815 0.08408354222774506
encoder.encoder.bias_ih_l0_reverse: 0.02454746700823307 0.0837639644742012
encoder.encoder.bias_hh_l0_reverse: 0.01641303487122059 0.08272752910852432
decider.lstm.weight_ih_l0: 0.0003366669116076082 0.1471015065908432
decider.lstm.weight_hh_l0: 0.002424896229058504 0.14710336923599243
decider.lstm.bias_ih_l0: 0.015936411917209625 0.15940293669700623
decider.lstm.bias_hh_l0: -0.0030510572250932455 0.14062225818634033
decider.linear1.weight: 0.003945574630051851 0.12039948254823685
decider.linear1.bias: 0.01453149039298296 0.11583822965621948
decider.linear2.weight: 0.0031978844199329615 0.052984967827796936
decider.linear2.bias: 0.0051170759834349155 0.056722212582826614
decider.linear3.weight: -0.008070120587944984 0.057472486048936844
decider.linear3.bias: 0.015761572867631912 0.05459653586149216

Rewards:
229.4037
229.4037
229.4037
objective = 123.28590393066406
==== episode 5700/10000 ====
action = 1
probs = 0.1626 0.8320 0.0038 0.0017

action = 0
probs = 0.5507 0.4428 0.0050 0.0014

action = 0
probs = 0.5945 0.4002 0.0038 0.0015

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.302914799656719e-05 0.08355405926704407
encoder.encoder.weight_hh_l0: -0.00020038832735735923 0.08470998704433441
encoder.encoder.bias_ih_l0: 0.006238150876015425 0.08611680567264557
encoder.encoder.bias_hh_l0: 0.016235223039984703 0.08500087261199951
encoder.encoder.weight_ih_l0_reverse: 0.0010665778536349535 0.0853419080376625
encoder.encoder.weight_hh_l0_reverse: 0.003734657308086753 0.08409691601991653
encoder.encoder.bias_ih_l0_reverse: 0.024583926424384117 0.08377747982740402
encoder.encoder.bias_hh_l0_reverse: 0.016449498012661934 0.08270958811044693
decider.lstm.weight_ih_l0: 0.00035256639239378273 0.14711911976337433
decider.lstm.weight_hh_l0: 0.0024487029295414686 0.14711490273475647
decider.lstm.bias_ih_l0: 0.01604524254798889 0.15941159427165985
decider.lstm.bias_hh_l0: -0.002942232647910714 0.1406308263540268
decider.linear1.weight: 0.003951248712837696 0.12042093276977539
decider.linear1.bias: 0.014596646651625633 0.1158670112490654
decider.linear2.weight: 0.003255626652389765 0.053006649017333984
decider.linear2.bias: 0.005188316572457552 0.056794337928295135
decider.linear3.weight: -0.008164527826011181 0.05751616880297661
decider.linear3.bias: 0.015579949133098125 0.05417049676179886

Rewards:
221.7540
221.7540
221.7540
objective = 96.132568359375
==== episode 5800/10000 ====
action = 0
probs = 0.2358 0.7582 0.0040 0.0019

action = 0
probs = 0.5913 0.4036 0.0040 0.0012

action = 0
probs = 0.5856 0.4092 0.0035 0.0017

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.2637395886704326e-05 0.08350372314453125
encoder.encoder.weight_hh_l0: -0.00021654822921846062 0.08465366065502167
encoder.encoder.bias_ih_l0: 0.006019826512783766 0.08602827042341232
encoder.encoder.bias_hh_l0: 0.016016898676753044 0.08493451029062271
encoder.encoder.weight_ih_l0_reverse: 0.0010325604816898704 0.08527778089046478
encoder.encoder.weight_hh_l0_reverse: 0.0036073317751288414 0.08402267843484879
encoder.encoder.bias_ih_l0_reverse: 0.0242320466786623 0.08374438434839249
encoder.encoder.bias_hh_l0_reverse: 0.01609761454164982 0.08269510418176651
decider.lstm.weight_ih_l0: 0.0002547122130636126 0.14703276753425598
decider.lstm.weight_hh_l0: 0.0023498861119151115 0.1470445841550827
decider.lstm.bias_ih_l0: 0.015597880817949772 0.15930858254432678
decider.lstm.bias_hh_l0: -0.003389583434909582 0.14056286215782166
decider.linear1.weight: 0.003953517880290747 0.1204107329249382
decider.linear1.bias: 0.01453007385134697 0.11590323597192764
decider.linear2.weight: 0.0032453848980367184 0.05301004275679588
decider.linear2.bias: 0.005145407281816006 0.05688661336898804
decider.linear3.weight: -0.008255098015069962 0.05750523880124092
decider.linear3.bias: 0.015403090044856071 0.053693775087594986

Rewards:
211.9920
211.9920
211.9920
objective = 177.03140258789062
==== episode 5900/10000 ====
action = 1
probs = 0.1764 0.8196 0.0027 0.0013

action = 3
probs = 0.5251 0.4705 0.0033 0.0011

action = 1
probs = 0.5304 0.4658 0.0027 0.0012

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.0770002922508866e-05 0.08358590304851532
encoder.encoder.weight_hh_l0: -0.0001970815210370347 0.084746815264225
encoder.encoder.bias_ih_l0: 0.006322124041616917 0.08616820722818375
encoder.encoder.bias_hh_l0: 0.01631920039653778 0.08506735414266586
encoder.encoder.weight_ih_l0_reverse: 0.001048484817147255 0.08535836637020111
encoder.encoder.weight_hh_l0_reverse: 0.003723264904692769 0.08409315347671509
encoder.encoder.bias_ih_l0_reverse: 0.024575915187597275 0.08379258215427399
encoder.encoder.bias_hh_l0_reverse: 0.016441477462649345 0.08277466893196106
decider.lstm.weight_ih_l0: 0.00036241684574633837 0.14715059101581573
decider.lstm.weight_hh_l0: 0.0024460661225020885 0.14714568853378296
decider.lstm.bias_ih_l0: 0.016099540516734123 0.15947136282920837
decider.lstm.bias_hh_l0: -0.002887920243665576 0.14066796004772186
decider.linear1.weight: 0.003948648925870657 0.12045110017061234
decider.linear1.bias: 0.014763243496418 0.11589016765356064
decider.linear2.weight: 0.0033213328570127487 0.053032469004392624
decider.linear2.bias: 0.005291000008583069 0.05695844814181328
decider.linear3.weight: -0.008378539234399796 0.05763847008347511
decider.linear3.bias: 0.015158192254602909 0.054013922810554504

Rewards:
202.8335
202.8335
202.8335
objective = 526.1717529296875
==== episode 6000/10000 ====
action = 1
probs = 0.1725 0.8235 0.0027 0.0014

action = 0
probs = 0.5521 0.4428 0.0038 0.0013

action = 0
probs = 0.5168 0.4789 0.0029 0.0014

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.7271211365587078e-05 0.08355432748794556
encoder.encoder.weight_hh_l0: -0.00020035462512169033 0.08469738066196442
encoder.encoder.bias_ih_l0: 0.006093764211982489 0.08612290769815445
encoder.encoder.bias_hh_l0: 0.016090836375951767 0.08503085374832153
encoder.encoder.weight_ih_l0_reverse: 0.001038519199937582 0.08535005897283554
encoder.encoder.weight_hh_l0_reverse: 0.003688420867547393 0.08408377319574356
encoder.encoder.bias_ih_l0_reverse: 0.02448152005672455 0.08378685265779495
encoder.encoder.bias_hh_l0_reverse: 0.016347086057066917 0.08278679102659225
decider.lstm.weight_ih_l0: 0.0003461910819169134 0.14714395999908447
decider.lstm.weight_hh_l0: 0.00243043783120811 0.14715474843978882
decider.lstm.bias_ih_l0: 0.015982044860720634 0.15950791537761688
decider.lstm.bias_hh_l0: -0.003005421021953225 0.14068330824375153
decider.linear1.weight: 0.0039452738128602505 0.12042977660894394
decider.linear1.bias: 0.0146713275462389 0.11581062525510788
decider.linear2.weight: 0.003321527037769556 0.05303097516298294
decider.linear2.bias: 0.0052750203758478165 0.05694129317998886
decider.linear3.weight: -0.008334245532751083 0.05762126296758652
decider.linear3.bias: 0.015261964872479439 0.05408142879605293

Rewards:
221.7540
221.7540
221.7540
objective = 107.0667724609375
==== episode 6100/10000 ====
action = 0
probs = 0.1913 0.8050 0.0025 0.0012

action = 0
probs = 0.6592 0.3364 0.0034 0.0010

action = 1
probs = 0.5822 0.4134 0.0029 0.0015

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.795551285496913e-05 0.083598293364048
encoder.encoder.weight_hh_l0: -0.0001933632156578824 0.08473482728004456
encoder.encoder.bias_ih_l0: 0.006220671348273754 0.08619268238544464
encoder.encoder.bias_hh_l0: 0.01621774211525917 0.08502839505672455
encoder.encoder.weight_ih_l0_reverse: 0.0010551806772127748 0.08540307730436325
encoder.encoder.weight_hh_l0_reverse: 0.003769216127693653 0.08414214104413986
encoder.encoder.bias_ih_l0_reverse: 0.024690179154276848 0.08382420986890793
encoder.encoder.bias_hh_l0_reverse: 0.016555745154619217 0.08273706585168839
decider.lstm.weight_ih_l0: 0.0004048424889333546 0.14719581604003906
decider.lstm.weight_hh_l0: 0.002487228950485587 0.147213876247406
decider.lstm.bias_ih_l0: 0.01621868461370468 0.15961430966854095
decider.lstm.bias_hh_l0: -0.0027687856927514076 0.14074665307998657
decider.linear1.weight: 0.003947017714381218 0.12045538425445557
decider.linear1.bias: 0.014782475307583809 0.11578227579593658
decider.linear2.weight: 0.0034165331162512302 0.05306049808859825
decider.linear2.bias: 0.00545534398406744 0.05698474496603012
decider.linear3.weight: -0.008465101011097431 0.05771980062127113
decider.linear3.bias: 0.015148778446018696 0.053416479378938675

Rewards:
217.9966
217.9966
217.9966
objective = 214.65835571289062
==== episode 6200/10000 ====
action = 1
probs = 0.1501 0.8459 0.0025 0.0015

action = 0
probs = 0.5156 0.4790 0.0038 0.0016

action = 1
probs = 0.4592 0.5366 0.0027 0.0016

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.0732153390999883e-05 0.08354226499795914
encoder.encoder.weight_hh_l0: -0.0002050551847787574 0.08468140661716461
encoder.encoder.bias_ih_l0: 0.00600482989102602 0.08612045645713806
encoder.encoder.bias_hh_l0: 0.016001898795366287 0.08503574877977371
encoder.encoder.weight_ih_l0_reverse: 0.0010144209954887629 0.08533889800310135
encoder.encoder.weight_hh_l0_reverse: 0.003657054854556918 0.08407368510961533
encoder.encoder.bias_ih_l0_reverse: 0.024392368271946907 0.08378802984952927
encoder.encoder.bias_hh_l0_reverse: 0.016257934272289276 0.08281975984573364
decider.lstm.weight_ih_l0: 0.00031372069497592747 0.14713247120380402
decider.lstm.weight_hh_l0: 0.00239878729917109 0.14715929329395294
decider.lstm.bias_ih_l0: 0.015810437500476837 0.15951450169086456
decider.lstm.bias_hh_l0: -0.003177026053890586 0.14065265655517578
decider.linear1.weight: 0.0039509618654847145 0.12040767073631287
decider.linear1.bias: 0.014611952006816864 0.115811288356781
decider.linear2.weight: 0.0033087676856666803 0.05302579328417778
decider.linear2.bias: 0.005240352358669043 0.056961044669151306
decider.linear3.weight: -0.008430205285549164 0.0576334111392498
decider.linear3.bias: 0.01534508541226387 0.05448073893785477

Rewards:
229.4037
229.4037
229.4037
objective = 111.04948425292969
==== episode 6300/10000 ====
action = 0
probs = 0.1346 0.8622 0.0020 0.0013

action = 1
probs = 0.4917 0.5042 0.0029 0.0013

action = 0
probs = 0.4051 0.5915 0.0021 0.0013

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.7957204767735675e-05 0.08357696980237961
encoder.encoder.weight_hh_l0: -0.000197528803255409 0.08472326397895813
encoder.encoder.bias_ih_l0: 0.00613053422421217 0.08619961142539978
encoder.encoder.bias_hh_l0: 0.016127608716487885 0.08508670330047607
encoder.encoder.weight_ih_l0_reverse: 0.001012442517094314 0.08537403494119644
encoder.encoder.weight_hh_l0_reverse: 0.0037026323843747377 0.08409807085990906
encoder.encoder.bias_ih_l0_reverse: 0.024517817422747612 0.0838218703866005
encoder.encoder.bias_hh_l0_reverse: 0.01638338342308998 0.08285898715257645
decider.lstm.weight_ih_l0: 0.00034830335061997175 0.14717461168766022
decider.lstm.weight_hh_l0: 0.0024307684507220984 0.14720311760902405
decider.lstm.bias_ih_l0: 0.015961114317178726 0.15959817171096802
decider.lstm.bias_hh_l0: -0.003026345744729042 0.1406913548707962
decider.linear1.weight: 0.003956657834351063 0.12043757736682892
decider.linear1.bias: 0.014789175242185593 0.11581180989742279
decider.linear2.weight: 0.0033711770083755255 0.053042057901620865
decider.linear2.bias: 0.005351421423256397 0.05704239010810852
decider.linear3.weight: -0.008533277548849583 0.05773322656750679
decider.linear3.bias: 0.015133141539990902 0.05460209771990776

Rewards:
221.5682
221.5682
221.5682
objective = 265.4369812011719
==== episode 6400/10000 ====
action = 1
probs = 0.1504 0.8460 0.0022 0.0014

action = 1
probs = 0.4567 0.5387 0.0032 0.0014

action = 1
probs = 0.3689 0.6278 0.0020 0.0013

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.338053647894412e-05 0.08354777097702026
encoder.encoder.weight_hh_l0: -0.00020875963673461229 0.08469434827566147
encoder.encoder.bias_ih_l0: 0.006015222053974867 0.08614017814397812
encoder.encoder.bias_hh_l0: 0.016012296080589294 0.08505724370479584
encoder.encoder.weight_ih_l0_reverse: 0.0009915023110806942 0.0853339210152626
encoder.encoder.weight_hh_l0_reverse: 0.003615383757278323 0.0840502381324768
encoder.encoder.bias_ih_l0_reverse: 0.024296121671795845 0.08379529416561127
encoder.encoder.bias_hh_l0_reverse: 0.016161689534783363 0.08287999033927917
decider.lstm.weight_ih_l0: 0.00027866207528859377 0.14711807668209076
decider.lstm.weight_hh_l0: 0.002372614573687315 0.14715120196342468
decider.lstm.bias_ih_l0: 0.01565007120370865 0.15950550138950348
decider.lstm.bias_hh_l0: -0.0033373855985701084 0.1406259834766388
decider.linear1.weight: 0.0039654504507780075 0.12042621523141861
decider.linear1.bias: 0.014743208885192871 0.11586599797010422
decider.linear2.weight: 0.0033614933490753174 0.053033825010061264
decider.linear2.bias: 0.005297557450830936 0.05706113204360008
decider.linear3.weight: -0.008578438311815262 0.05771980434656143
decider.linear3.bias: 0.015046561136841774 0.05468267574906349

Rewards:
217.8160
217.8160
217.8160
objective = 90.84848022460938
==== episode 6500/10000 ====
action = 1
probs = 0.1194 0.8780 0.0016 0.0010

action = 0
probs = 0.3858 0.6106 0.0025 0.0011

action = 1
probs = 0.2949 0.7026 0.0016 0.0010

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.138799315318465e-05 0.0836256816983223
encoder.encoder.weight_hh_l0: -0.00019451143452897668 0.08478345721960068
encoder.encoder.bias_ih_l0: 0.006342162378132343 0.08626989275217056
encoder.encoder.bias_hh_l0: 0.016339236870408058 0.08517346531152725
encoder.encoder.weight_ih_l0_reverse: 0.0010042370995506644 0.08540135622024536
encoder.encoder.weight_hh_l0_reverse: 0.0037157279439270496 0.08410045504570007
encoder.encoder.bias_ih_l0_reverse: 0.024589860811829567 0.08383693546056747
encoder.encoder.bias_hh_l0_reverse: 0.016455424949526787 0.08295276761054993
decider.lstm.weight_ih_l0: 0.00034640691592358053 0.14719490706920624
decider.lstm.weight_hh_l0: 0.002423255704343319 0.14721499383449554
decider.lstm.bias_ih_l0: 0.01599249057471752 0.15962594747543335
decider.lstm.bias_hh_l0: -0.00299496459774673 0.14069001376628876
decider.linear1.weight: 0.003965423908084631 0.1204751506447792
decider.linear1.bias: 0.015027418732643127 0.11589036136865616
decider.linear2.weight: 0.0034248349256813526 0.05305113270878792
decider.linear2.bias: 0.0054016513749957085 0.05712785944342613
decider.linear3.weight: -0.008687603287398815 0.05783028155565262
decider.linear3.bias: 0.014822796918451786 0.055038727819919586

Rewards:
229.4037
229.4037
229.4037
objective = 109.76891326904297
==== episode 6600/10000 ====
action = 1
probs = 0.1546 0.8419 0.0022 0.0012

action = 0
probs = 0.4914 0.5036 0.0036 0.0013

action = 0
probs = 0.4237 0.5729 0.0022 0.0012

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.105595533270389e-05 0.0835525393486023
encoder.encoder.weight_hh_l0: -0.00020084068819414824 0.08470983803272247
encoder.encoder.bias_ih_l0: 0.006030749063938856 0.08616535365581512
encoder.encoder.bias_hh_l0: 0.016027826815843582 0.0850657969713211
encoder.encoder.weight_ih_l0_reverse: 0.0009838497499004006 0.08533808588981628
encoder.encoder.weight_hh_l0_reverse: 0.003619283204898238 0.08407411724328995
encoder.encoder.bias_ih_l0_reverse: 0.024314817041158676 0.08380378782749176
encoder.encoder.bias_hh_l0_reverse: 0.016180386766791344 0.0828215479850769
decider.lstm.weight_ih_l0: 0.00031295951339416206 0.14716225862503052
decider.lstm.weight_hh_l0: 0.002408090513199568 0.1471947580575943
decider.lstm.bias_ih_l0: 0.01579645834863186 0.15955133736133575
decider.lstm.bias_hh_l0: -0.00319099728949368 0.14066630601882935
decider.linear1.weight: 0.003960967995226383 0.1204238012433052
decider.linear1.bias: 0.014725069515407085 0.11582791805267334
decider.linear2.weight: 0.003397292923182249 0.053049296140670776
decider.linear2.bias: 0.0053140223026275635 0.05700816214084625
decider.linear3.weight: -0.00864019151777029 0.05776602029800415
decider.linear3.bias: 0.014943432062864304 0.054285772144794464

Rewards:
221.7540
221.7540
221.7540
objective = 128.71392822265625
==== episode 6700/10000 ====
action = 1
probs = 0.1428 0.8547 0.0016 0.0009

action = 0
probs = 0.5578 0.4382 0.0029 0.0011

action = 1
probs = 0.4790 0.5181 0.0019 0.0010

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 5.467765004141256e-05 0.08365083485841751
encoder.encoder.weight_hh_l0: -0.00017714760906528682 0.08481333404779434
encoder.encoder.bias_ih_l0: 0.0063858977518975735 0.08631239831447601
encoder.encoder.bias_hh_l0: 0.0163829755038023 0.08516158908605576
encoder.encoder.weight_ih_l0_reverse: 0.0010187284788116813 0.08543584495782852
encoder.encoder.weight_hh_l0_reverse: 0.003772423369809985 0.08417056500911713
encoder.encoder.bias_ih_l0_reverse: 0.02473338134586811 0.08387622982263565
encoder.encoder.bias_hh_l0_reverse: 0.01659894920885563 0.08279280364513397
decider.lstm.weight_ih_l0: 0.0004424559301696718 0.14728598296642303
decider.lstm.weight_hh_l0: 0.002528224140405655 0.14731106162071228
decider.lstm.bias_ih_l0: 0.016374221071600914 0.15977180004119873
decider.lstm.bias_hh_l0: -0.002613225718960166 0.1407923698425293
decider.linear1.weight: 0.0039570326916873455 0.12047766894102097
decider.linear1.bias: 0.014970418065786362 0.11577136069536209
decider.linear2.weight: 0.003501246450468898 0.05309060961008072
decider.linear2.bias: 0.005519313737750053 0.05704411119222641
decider.linear3.weight: -0.008753721602261066 0.05791153758764267
decider.linear3.bias: 0.014708565548062325 0.05381716787815094

Rewards:
229.4037
229.4037
229.4037
objective = 106.93144226074219
==== episode 6800/10000 ====
action = 1
probs = 0.2255 0.7701 0.0028 0.0015

action = 0
probs = 0.6463 0.3474 0.0048 0.0015

action = 1
probs = 0.5779 0.4172 0.0034 0.0016

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3476555725210346e-05 0.08349616825580597
encoder.encoder.weight_hh_l0: -0.00021712416491936892 0.08462738990783691
encoder.encoder.bias_ih_l0: 0.005689335521310568 0.0860520452260971
encoder.encoder.bias_hh_l0: 0.015686413273215294 0.08493326604366302
encoder.encoder.weight_ih_l0_reverse: 0.0009729581652209163 0.08528589457273483
encoder.encoder.weight_hh_l0_reverse: 0.0035089224111288786 0.0840490311384201
encoder.encoder.bias_ih_l0_reverse: 0.024010390043258667 0.08377721905708313
encoder.encoder.bias_hh_l0_reverse: 0.015875959768891335 0.08267725259065628
decider.lstm.weight_ih_l0: 0.00027575387503020465 0.14713022112846375
decider.lstm.weight_hh_l0: 0.0023506260477006435 0.14715977013111115
decider.lstm.bias_ih_l0: 0.015618592500686646 0.1594773530960083
decider.lstm.bias_hh_l0: -0.003368859179317951 0.14067985117435455
decider.linear1.weight: 0.003933723084628582 0.12037517130374908
decider.linear1.bias: 0.014408012852072716 0.11576550453901291
decider.linear2.weight: 0.0033918307162821293 0.053048331290483475
decider.linear2.bias: 0.005309069994837046 0.056909721344709396
decider.linear3.weight: -0.008561333641409874 0.05772082880139351
decider.linear3.bias: 0.015189941972494125 0.05340670421719551

Rewards:
229.4037
229.4037
229.4037
objective = 120.19395446777344
==== episode 6900/10000 ====
action = 1
probs = 0.1774 0.8197 0.0019 0.0010

action = 0
probs = 0.6325 0.3625 0.0037 0.0012

action = 0
probs = 0.6029 0.3933 0.0026 0.0012

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.470378189580515e-05 0.08360207080841064
encoder.encoder.weight_hh_l0: -0.00019757288100663573 0.08474338799715042
encoder.encoder.bias_ih_l0: 0.006111857946962118 0.08623100072145462
encoder.encoder.bias_hh_l0: 0.016108937561511993 0.08504574745893478
encoder.encoder.weight_ih_l0_reverse: 0.0010107235284522176 0.08538302034139633
encoder.encoder.weight_hh_l0_reverse: 0.003663769457489252 0.08414687216281891
encoder.encoder.bias_ih_l0_reverse: 0.024449383839964867 0.08383636176586151
encoder.encoder.bias_hh_l0_reverse: 0.016314951702952385 0.08270151913166046
decider.lstm.weight_ih_l0: 0.0004182554257567972 0.14726723730564117
decider.lstm.weight_hh_l0: 0.002528292825445533 0.1472766101360321
decider.lstm.bias_ih_l0: 0.016307760030031204 0.15965405106544495
decider.lstm.bias_hh_l0: -0.002679692581295967 0.14080674946308136
decider.linear1.weight: 0.003943916410207748 0.12043588608503342
decider.linear1.bias: 0.014725849032402039 0.11575762182474136
decider.linear2.weight: 0.0034844244364649057 0.05308709293603897
decider.linear2.bias: 0.00547243794426322 0.05696429684758186
decider.linear3.weight: -0.008733417838811874 0.057923804968595505
decider.linear3.bias: 0.014893366023898125 0.05327335000038147

Rewards:
221.7540
221.7540
221.7540
objective = 85.95257568359375
==== episode 7000/10000 ====
action = 1
probs = 0.1395 0.8584 0.0014 0.0007

action = 0
probs = 0.6214 0.3746 0.0030 0.0010

action = 0
probs = 0.5799 0.4170 0.0021 0.0010

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 6.582729110959917e-05 0.08367834985256195
encoder.encoder.weight_hh_l0: -0.00017554438090883195 0.08482314646244049
encoder.encoder.bias_ih_l0: 0.0063855922780931 0.08636322617530823
encoder.encoder.bias_hh_l0: 0.016382675617933273 0.08515078574419022
encoder.encoder.weight_ih_l0_reverse: 0.001037993235513568 0.08546829223632812
encoder.encoder.weight_hh_l0_reverse: 0.0038046573754400015 0.08422039449214935
encoder.encoder.bias_ih_l0_reverse: 0.024818414822220802 0.08389748632907867
encoder.encoder.bias_hh_l0_reverse: 0.016683978959918022 0.08275242894887924
decider.lstm.weight_ih_l0: 0.000519735214766115 0.14736242592334747
decider.lstm.weight_hh_l0: 0.0026435402687639 0.14737290143966675
decider.lstm.bias_ih_l0: 0.016737043857574463 0.15984182059764862
decider.lstm.bias_hh_l0: -0.0022504045628011227 0.1408773511648178
decider.linear1.weight: 0.003947501070797443 0.12048007547855377
decider.linear1.bias: 0.014972271397709846 0.11570636928081512
decider.linear2.weight: 0.0035422155633568764 0.05311588943004608
decider.linear2.bias: 0.0056059760972857475 0.05702225863933563
decider.linear3.weight: -0.008872179314494133 0.05810486897826195
decider.linear3.bias: 0.014641286805272102 0.05332031473517418

Rewards:
221.7540
221.7540
221.7540
objective = 86.73307800292969
==== episode 7100/10000 ====
action = 1
probs = 0.1561 0.8422 0.0011 0.0006

action = 0
probs = 0.7364 0.2607 0.0022 0.0007

action = 1
probs = 0.7202 0.2776 0.0015 0.0007

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 9.759865497471765e-05 0.0837780013680458
encoder.encoder.weight_hh_l0: -0.00014871526218485087 0.08494269847869873
encoder.encoder.bias_ih_l0: 0.006821317598223686 0.08651520311832428
encoder.encoder.bias_hh_l0: 0.01681840606033802 0.08520988374948502
encoder.encoder.weight_ih_l0_reverse: 0.001099128508940339 0.08558434247970581
encoder.encoder.weight_hh_l0_reverse: 0.003968520555645227 0.08432488888502121
encoder.encoder.bias_ih_l0_reverse: 0.025290820747613907 0.0839771181344986
encoder.encoder.bias_hh_l0_reverse: 0.017156386747956276 0.08267450332641602
decider.lstm.weight_ih_l0: 0.0006624870002269745 0.14746487140655518
decider.lstm.weight_hh_l0: 0.0028155911713838577 0.1474616825580597
decider.lstm.bias_ih_l0: 0.01734447292983532 0.15995465219020844
decider.lstm.bias_hh_l0: -0.0016429673414677382 0.140975683927536
decider.linear1.weight: 0.003965733572840691 0.12056903541088104
decider.linear1.bias: 0.015352977439761162 0.11569760739803314
decider.linear2.weight: 0.0036573943216353655 0.053182195872068405
decider.linear2.bias: 0.005838177632540464 0.05706355348229408
decider.linear3.weight: -0.008993087336421013 0.05829744413495064
decider.linear3.bias: 0.014442864805459976 0.052352841943502426

Rewards:
229.4037
229.4037
229.4037
objective = 134.52703857421875
==== episode 7200/10000 ====
action = 0
probs = 0.2069 0.7911 0.0014 0.0007

action = 0
probs = 0.8180 0.1795 0.0020 0.0005

action = 0
probs = 0.7627 0.2351 0.0015 0.0007

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00010027691314462572 0.08378933370113373
encoder.encoder.weight_hh_l0: -0.0001475903409300372 0.08494745939970016
encoder.encoder.bias_ih_l0: 0.0068271406926214695 0.08652102202177048
encoder.encoder.bias_hh_l0: 0.016824230551719666 0.08517765253782272
encoder.encoder.weight_ih_l0_reverse: 0.0010996003402397037 0.08559639751911163
encoder.encoder.weight_hh_l0_reverse: 0.003946148790419102 0.08433953672647476
encoder.encoder.bias_ih_l0_reverse: 0.025255760177969933 0.08397272229194641
encoder.encoder.bias_hh_l0_reverse: 0.017121322453022003 0.08263874799013138
decider.lstm.weight_ih_l0: 0.0006581447669304907 0.14746156334877014
decider.lstm.weight_hh_l0: 0.0028002846520394087 0.1474599689245224
decider.lstm.bias_ih_l0: 0.017318936064839363 0.1599666029214859
decider.lstm.bias_hh_l0: -0.0016685142181813717 0.14099514484405518
decider.linear1.weight: 0.003967026714235544 0.12058581411838531
decider.linear1.bias: 0.01539052464067936 0.11572863906621933
decider.linear2.weight: 0.0036895601078867912 0.053200364112854004
decider.linear2.bias: 0.0058837574906647205 0.05708345025777817
decider.linear3.weight: -0.009026039391756058 0.0583958625793457
decider.linear3.bias: 0.01446313876658678 0.05179798975586891

Rewards:
211.9920
211.9920
211.9920
objective = 144.66357421875
==== episode 7300/10000 ====
action = 1
probs = 0.2360 0.7615 0.0017 0.0008

action = 0
probs = 0.8223 0.1750 0.0021 0.0005

action = 0
probs = 0.7842 0.2139 0.0014 0.0006

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 9.260899969376624e-05 0.08375543355941772
encoder.encoder.weight_hh_l0: -0.00016895518638193607 0.08490365743637085
encoder.encoder.bias_ih_l0: 0.006660059560090303 0.08648127317428589
encoder.encoder.bias_hh_l0: 0.0166571494191885 0.08511614799499512
encoder.encoder.weight_ih_l0_reverse: 0.0010793062392622232 0.08556860685348511
encoder.encoder.weight_hh_l0_reverse: 0.0038787401281297207 0.08431016653776169
encoder.encoder.bias_ih_l0_reverse: 0.025089437142014503 0.08396073430776596
encoder.encoder.bias_hh_l0_reverse: 0.016955001279711723 0.08261879533529282
decider.lstm.weight_ih_l0: 0.0005958590190857649 0.14741897583007812
decider.lstm.weight_hh_l0: 0.002720413962379098 0.1474275290966034
decider.lstm.bias_ih_l0: 0.017076337710022926 0.15992605686187744
decider.lstm.bias_hh_l0: -0.0019111039582639933 0.14099036157131195
decider.linear1.weight: 0.003967132419347763 0.12056735903024673
decider.linear1.bias: 0.01529056765139103 0.1157720685005188
decider.linear2.weight: 0.0036516787949949503 0.05318951606750488
decider.linear2.bias: 0.0058411238715052605 0.057080160826444626
decider.linear3.weight: -0.009043755941092968 0.05845313146710396
decider.linear3.bias: 0.014472831971943378 0.051668208092451096

Rewards:
221.7540
221.7540
221.7540
objective = 52.570098876953125
==== episode 7400/10000 ====
action = 1
probs = 0.2609 0.7369 0.0015 0.0007

action = 0
probs = 0.8612 0.1369 0.0015 0.0004

action = 0
probs = 0.8558 0.1430 0.0009 0.0003

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00012536495341919363 0.08385676890611649
encoder.encoder.weight_hh_l0: -0.0001370355166727677 0.08502347022294998
encoder.encoder.bias_ih_l0: 0.007145152892917395 0.0866004228591919
encoder.encoder.bias_hh_l0: 0.017142238095402718 0.08518070727586746
encoder.encoder.weight_ih_l0_reverse: 0.0011345603270456195 0.08566142618656158
encoder.encoder.weight_hh_l0_reverse: 0.004006757866591215 0.08439361304044724
encoder.encoder.bias_ih_l0_reverse: 0.025464292615652084 0.08400465548038483
encoder.encoder.bias_hh_l0_reverse: 0.017329854890704155 0.08259283751249313
decider.lstm.weight_ih_l0: 0.0007099831709638238 0.14748840034008026
decider.lstm.weight_hh_l0: 0.0028753383085131645 0.14747533202171326
decider.lstm.bias_ih_l0: 0.01758039928972721 0.15997791290283203
decider.lstm.bias_hh_l0: -0.0014070558827370405 0.14103423058986664
decider.linear1.weight: 0.003997419960796833 0.12065105140209198
decider.linear1.bias: 0.01562582701444626 0.11581651866436005
decider.linear2.weight: 0.003780018538236618 0.05323430523276329
decider.linear2.bias: 0.006020138971507549 0.05713889002799988
decider.linear3.weight: -0.009163524955511093 0.058646805584430695
decider.linear3.bias: 0.01430555060505867 0.051077358424663544

Rewards:
221.7540
221.7540
221.7540
objective = 45.12206268310547
==== episode 7500/10000 ====
action = 1
probs = 0.1962 0.8020 0.0012 0.0006

action = 0
probs = 0.8039 0.1939 0.0017 0.0005

action = 0
probs = 0.7760 0.2224 0.0011 0.0005

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00011453188926680014 0.0838213711977005
encoder.encoder.weight_hh_l0: -0.00015119447198230773 0.08497624099254608
encoder.encoder.bias_ih_l0: 0.0069120097905397415 0.08656439185142517
encoder.encoder.bias_hh_l0: 0.016909096390008926 0.08520784974098206
encoder.encoder.weight_ih_l0_reverse: 0.0011065128492191434 0.08562847226858139
encoder.encoder.weight_hh_l0_reverse: 0.0039755357429385185 0.08435770124197006
encoder.encoder.bias_ih_l0_reverse: 0.02534283883869648 0.08399427682161331
encoder.encoder.bias_hh_l0_reverse: 0.01720840111374855 0.08267006278038025
decider.lstm.weight_ih_l0: 0.000671885150950402 0.14748318493366241
decider.lstm.weight_hh_l0: 0.0028212852776050568 0.14748618006706238
decider.lstm.bias_ih_l0: 0.017399795353412628 0.16001732647418976
decider.lstm.bias_hh_l0: -0.0015876609832048416 0.14100448787212372
decider.linear1.weight: 0.003977408166974783 0.12060624361038208
decider.linear1.bias: 0.015498719178140163 0.11576295644044876
decider.linear2.weight: 0.003712685080245137 0.05321532115340233
decider.linear2.bias: 0.005939392372965813 0.05715997889637947
decider.linear3.weight: -0.00927407294511795 0.058770205825567245
decider.linear3.bias: 0.01414620503783226 0.05162704735994339

Rewards:
221.7540
221.7540
221.7540
objective = 51.18455123901367
==== episode 7600/10000 ====
action = 1
probs = 0.2013 0.7961 0.0018 0.0009

action = 0
probs = 0.8093 0.1881 0.0020 0.0006

action = 1
probs = 0.7899 0.2085 0.0011 0.0005

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00010907947580562904 0.08377529680728912
encoder.encoder.weight_hh_l0: -0.00018692531739361584 0.08491227775812149
encoder.encoder.bias_ih_l0: 0.00671569025143981 0.0864698737859726
encoder.encoder.bias_hh_l0: 0.016712771728634834 0.08513841032981873
encoder.encoder.weight_ih_l0_reverse: 0.0010994012700393796 0.08559109270572662
encoder.encoder.weight_hh_l0_reverse: 0.0038915290497243404 0.08431795984506607
encoder.encoder.bias_ih_l0_reverse: 0.025138629600405693 0.08397030830383301
encoder.encoder.bias_hh_l0_reverse: 0.01700420118868351 0.0826314240694046
decider.lstm.weight_ih_l0: 0.0005949559272266924 0.14742261171340942
decider.lstm.weight_hh_l0: 0.002732877153903246 0.14743246138095856
decider.lstm.bias_ih_l0: 0.017116563394665718 0.15992851555347443
decider.lstm.bias_hh_l0: -0.0018708901479840279 0.14095966517925262
decider.linear1.weight: 0.003981459885835648 0.12057258933782578
decider.linear1.bias: 0.015275225043296814 0.11577657610177994
decider.linear2.weight: 0.0036333915777504444 0.053191643208265305
decider.linear2.bias: 0.005790857598185539 0.05708768591284752
decider.linear3.weight: -0.00910259410738945 0.058678146451711655
decider.linear3.bias: 0.014524426311254501 0.051915492862463

Rewards:
229.4037
229.4037
229.4037
objective = 153.515625
==== episode 7700/10000 ====
action = 1
probs = 0.1399 0.8578 0.0016 0.0007

action = 0
probs = 0.7092 0.2874 0.0027 0.0007

action = 1
probs = 0.6630 0.3344 0.0018 0.0008

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 7.652595377294347e-05 0.08369733393192291
encoder.encoder.weight_hh_l0: -0.0002000648673856631 0.08482350409030914
encoder.encoder.bias_ih_l0: 0.006326459348201752 0.08639256656169891
encoder.encoder.bias_hh_l0: 0.016323542222380638 0.08512766659259796
encoder.encoder.weight_ih_l0_reverse: 0.0010570180602371693 0.08553528040647507
encoder.encoder.weight_hh_l0_reverse: 0.0038211639039218426 0.08427106589078903
encoder.encoder.bias_ih_l0_reverse: 0.024930370971560478 0.08394169807434082
encoder.encoder.bias_hh_l0_reverse: 0.016795940697193146 0.08273041993379593
decider.lstm.weight_ih_l0: 0.0005396499182097614 0.14740335941314697
decider.lstm.weight_hh_l0: 0.002655921969562769 0.1474229097366333
decider.lstm.bias_ih_l0: 0.016854485496878624 0.15989790856838226
decider.lstm.bias_hh_l0: -0.0021329782903194427 0.14092129468917847
decider.linear1.weight: 0.003950606565922499 0.12050403654575348
decider.linear1.bias: 0.01504148542881012 0.11568515747785568
decider.linear2.weight: 0.0035333456471562386 0.05315453186631203
decider.linear2.bias: 0.0056626396253705025 0.05706347897648811
decider.linear3.weight: -0.009137259796261787 0.05877130478620529
decider.linear3.bias: 0.01451906654983759 0.052860379219055176

Rewards:
229.4037
229.4037
229.4037
objective = 121.75372314453125
==== episode 7800/10000 ====
action = 1
probs = 0.0992 0.8989 0.0014 0.0006

action = 0
probs = 0.6644 0.3322 0.0027 0.0007

action = 1
probs = 0.5632 0.4342 0.0018 0.0008

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 7.3493123636581e-05 0.08371304720640182
encoder.encoder.weight_hh_l0: -0.00018426163296680897 0.08484458178281784
encoder.encoder.bias_ih_l0: 0.006366649176925421 0.08647548407316208
encoder.encoder.bias_hh_l0: 0.016363730654120445 0.08518471568822861
encoder.encoder.weight_ih_l0_reverse: 0.001039887429215014 0.08556944131851196
encoder.encoder.weight_hh_l0_reverse: 0.0038893832825124264 0.08429939299821854
encoder.encoder.bias_ih_l0_reverse: 0.025085000321269035 0.08399462699890137
encoder.encoder.bias_hh_l0_reverse: 0.016950568184256554 0.08277853578329086
decider.lstm.weight_ih_l0: 0.0005740133346989751 0.14744792878627777
decider.lstm.weight_hh_l0: 0.002687165979295969 0.14748188853263855
decider.lstm.bias_ih_l0: 0.016953065991401672 0.16001689434051514
decider.lstm.bias_hh_l0: -0.002034398727118969 0.14094839990139008
decider.linear1.weight: 0.003951565362513065 0.12051457166671753
decider.linear1.bias: 0.015159573405981064 0.1156192347407341
decider.linear2.weight: 0.0035152691416442394 0.05316072702407837
decider.linear2.bias: 0.005688095930963755 0.05708269029855728
decider.linear3.weight: -0.009171286597847939 0.05893361195921898
decider.linear3.bias: 0.014477163553237915 0.053383201360702515

Rewards:
229.4037
229.4037
229.4037
objective = 103.22212219238281
==== episode 7900/10000 ====
action = 1
probs = 0.1337 0.8642 0.0015 0.0007

action = 0
probs = 0.7232 0.2739 0.0023 0.0006

action = 0
probs = 0.6030 0.3947 0.0016 0.0007

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 7.130764424800873e-05 0.08369729667901993
encoder.encoder.weight_hh_l0: -0.0001938992936629802 0.08482740074396133
encoder.encoder.bias_ih_l0: 0.006286620162427425 0.08645422011613846
encoder.encoder.bias_hh_l0: 0.016283703967928886 0.0851777121424675
encoder.encoder.weight_ih_l0_reverse: 0.0010334011167287827 0.08554887026548386
encoder.encoder.weight_hh_l0_reverse: 0.0038232128135859966 0.08428288251161575
encoder.encoder.bias_ih_l0_reverse: 0.024925949051976204 0.08399103581905365
encoder.encoder.bias_hh_l0_reverse: 0.01679151877760887 0.08273523300886154
decider.lstm.weight_ih_l0: 0.0005447273724712431 0.14742425084114075
decider.lstm.weight_hh_l0: 0.0026541813276708126 0.14746126532554626
decider.lstm.bias_ih_l0: 0.016840860247612 0.15999355912208557
decider.lstm.bias_hh_l0: -0.00214660307392478 0.14093612134456635
decider.linear1.weight: 0.003954416140913963 0.1205160841345787
decider.linear1.bias: 0.015072663314640522 0.11565610766410828
decider.linear2.weight: 0.0035219648852944374 0.05317416042089462
decider.linear2.bias: 0.005704762414097786 0.05715618282556534
decider.linear3.weight: -0.00932316854596138 0.05904894322156906
decider.linear3.bias: 0.014250467531383038 0.05277669429779053

Rewards:
221.7540
221.7540
221.7540
objective = 72.12908935546875
==== episode 8000/10000 ====
action = 0
probs = 0.1436 0.8544 0.0014 0.0006

action = 1
probs = 0.7865 0.2113 0.0018 0.0004

action = 1
probs = 0.6850 0.3131 0.0013 0.0005

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 8.353337761946023e-05 0.08376163989305496
encoder.encoder.weight_hh_l0: -0.00017341048805974424 0.08489839732646942
encoder.encoder.bias_ih_l0: 0.006530783139169216 0.08654320240020752
encoder.encoder.bias_hh_l0: 0.016527865082025528 0.08521591126918793
encoder.encoder.weight_ih_l0_reverse: 0.0010508470004424453 0.08560281991958618
encoder.encoder.weight_hh_l0_reverse: 0.003889314131811261 0.08433744311332703
encoder.encoder.bias_ih_l0_reverse: 0.025112131610512733 0.0840197503566742
encoder.encoder.bias_hh_l0_reverse: 0.016977697610855103 0.08270838856697083
decider.lstm.weight_ih_l0: 0.0006156250601634383 0.1474785953760147
decider.lstm.weight_hh_l0: 0.0027345065027475357 0.14751030504703522
decider.lstm.bias_ih_l0: 0.017124589532613754 0.1600833386182785
decider.lstm.bias_hh_l0: -0.001862884033471346 0.14099366962909698
decider.linear1.weight: 0.003957434557378292 0.12054848670959473
decider.linear1.bias: 0.015177898108959198 0.1156540960073471
decider.linear2.weight: 0.003583768382668495 0.05320041626691818
decider.linear2.bias: 0.0058100963942706585 0.05716421455144882
decider.linear3.weight: -0.00940257403999567 0.059193480759859085
decider.linear3.bias: 0.014129825867712498 0.05229596421122551

Rewards:
229.0108
229.0108
229.0108
objective = 355.46881103515625
==== episode 8100/10000 ====
action = 0
probs = 0.1781 0.8194 0.0019 0.0007

action = 0
probs = 0.8543 0.1437 0.0017 0.0003

action = 0
probs = 0.7443 0.2537 0.0014 0.0006

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 9.40757236094214e-05 0.08380967378616333
encoder.encoder.weight_hh_l0: -0.00016369066725019366 0.08495078235864639
encoder.encoder.bias_ih_l0: 0.006737596821039915 0.08659747242927551
encoder.encoder.bias_hh_l0: 0.01673467829823494 0.08521141856908798
encoder.encoder.weight_ih_l0_reverse: 0.0010528938146308064 0.08563728630542755
encoder.encoder.weight_hh_l0_reverse: 0.00389871746301651 0.08437371999025345
encoder.encoder.bias_ih_l0_reverse: 0.025184370577335358 0.08404377847909927
encoder.encoder.bias_hh_l0_reverse: 0.017049936577677727 0.0826377272605896
decider.lstm.weight_ih_l0: 0.0006419075652956963 0.14749552309513092
decider.lstm.weight_hh_l0: 0.0027691670693457127 0.14752143621444702
decider.lstm.bias_ih_l0: 0.017248522490262985 0.16013479232788086
decider.lstm.bias_hh_l0: -0.0017389445565640926 0.14102084934711456
decider.linear1.weight: 0.003967582248151302 0.12057674676179886
decider.linear1.bias: 0.015235486440360546 0.1157168596982956
decider.linear2.weight: 0.0036111795343458652 0.05322025343775749
decider.linear2.bias: 0.005867872387170792 0.05711135268211365
decider.linear3.weight: -0.009371966123580933 0.05929237976670265
decider.linear3.bias: 0.014241339638829231 0.05169074982404709

Rewards:
211.9920
211.9920
211.9920
objective = 153.931884765625
==== episode 8200/10000 ====
action = 1
probs = 0.1124 0.8859 0.0013 0.0005

action = 0
probs = 0.7943 0.2034 0.0019 0.0004

action = 1
probs = 0.7274 0.2710 0.0012 0.0004

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00010157927317777649 0.08386918157339096
encoder.encoder.weight_hh_l0: -0.00013281829888001084 0.08502229303121567
encoder.encoder.bias_ih_l0: 0.006974280811846256 0.08670920878648758
encoder.encoder.bias_hh_l0: 0.016971362754702568 0.08533144742250443
encoder.encoder.weight_ih_l0_reverse: 0.0010785219492390752 0.08571001887321472
encoder.encoder.weight_hh_l0_reverse: 0.00405841413885355 0.08443279564380646
encoder.encoder.bias_ih_l0_reverse: 0.025585737079381943 0.0841020718216896
encoder.encoder.bias_hh_l0_reverse: 0.017451301217079163 0.08268360048532486
decider.lstm.weight_ih_l0: 0.0007439953042194247 0.14757859706878662
decider.lstm.weight_hh_l0: 0.0028909819666296244 0.1476009637117386
decider.lstm.bias_ih_l0: 0.017654938623309135 0.16026799380779266
decider.lstm.bias_hh_l0: -0.0013325298205018044 0.1410491168498993
decider.linear1.weight: 0.003964236471801996 0.12060750275850296
decider.linear1.bias: 0.015421876683831215 0.11564312875270844
decider.linear2.weight: 0.003647745819762349 0.05323490500450134
decider.linear2.bias: 0.00595005601644516 0.057166263461112976
decider.linear3.weight: -0.009481064043939114 0.05951623246073723
decider.linear3.bias: 0.014065926894545555 0.05214517191052437

Rewards:
229.4037
229.4037
229.4037
objective = 126.72911834716797
==== episode 8300/10000 ====
action = 1
probs = 0.1420 0.8551 0.0023 0.0007

action = 1
probs = 0.8152 0.1815 0.0029 0.0005

action = 0
probs = 0.7663 0.2314 0.0018 0.0005

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 7.509007991757244e-05 0.08378171920776367
encoder.encoder.weight_hh_l0: -0.0001845276274252683 0.08491747081279755
encoder.encoder.bias_ih_l0: 0.006561394780874252 0.08655031025409698
encoder.encoder.bias_hh_l0: 0.01655847765505314 0.08524201065301895
encoder.encoder.weight_ih_l0_reverse: 0.0010467011015862226 0.08562152832746506
encoder.encoder.weight_hh_l0_reverse: 0.003861786564812064 0.08436433970928192
encoder.encoder.bias_ih_l0_reverse: 0.02512224204838276 0.08405187726020813
encoder.encoder.bias_hh_l0_reverse: 0.016987808048725128 0.0826072171330452
decider.lstm.weight_ih_l0: 0.0006413289229385555 0.14748908579349518
decider.lstm.weight_hh_l0: 0.0027722897939383984 0.14750677347183228
decider.lstm.bias_ih_l0: 0.017266083508729935 0.16009774804115295
decider.lstm.bias_hh_l0: -0.0017213812097907066 0.14099305868148804
decider.linear1.weight: 0.003953908570110798 0.12053530663251877
decider.linear1.bias: 0.014996743761003017 0.11566334217786789
decider.linear2.weight: 0.003528720699250698 0.05319860577583313
decider.linear2.bias: 0.005743729881942272 0.057046614587306976
decider.linear3.weight: -0.009345825761556625 0.0594949834048748
decider.linear3.bias: 0.014413854107260704 0.05210425704717636

Rewards:
230.1930
230.1930
230.1930
objective = 163.39129638671875
==== episode 8400/10000 ====
action = 1
probs = 0.0853 0.9127 0.0016 0.0004

action = 0
probs = 0.7478 0.2483 0.0034 0.0005

action = 1
probs = 0.7022 0.2952 0.0020 0.0005

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 8.065588917816058e-05 0.08382917940616608
encoder.encoder.weight_hh_l0: -0.0001592934859218076 0.0849669948220253
encoder.encoder.bias_ih_l0: 0.006696388125419617 0.08664674311876297
encoder.encoder.bias_hh_l0: 0.016693470999598503 0.08529447764158249
encoder.encoder.weight_ih_l0_reverse: 0.0010546367848291993 0.08568717539310455
encoder.encoder.weight_hh_l0_reverse: 0.0040156845934689045 0.08442448079586029
encoder.encoder.bias_ih_l0_reverse: 0.02547471970319748 0.08408847451210022
encoder.encoder.bias_hh_l0_reverse: 0.017340293154120445 0.08270786702632904
decider.lstm.weight_ih_l0: 0.0007214397192001343 0.14756657183170319
decider.lstm.weight_hh_l0: 0.0028653470799326897 0.14758709073066711
decider.lstm.bias_ih_l0: 0.0175576601177454 0.16021545231342316
decider.lstm.bias_hh_l0: -0.0014297985471785069 0.1410340815782547
decider.linear1.weight: 0.003954852931201458 0.12055245786905289
decider.linear1.bias: 0.015184248797595501 0.11556272953748703
decider.linear2.weight: 0.0035605118609964848 0.0532054603099823
decider.linear2.bias: 0.005806358996778727 0.057027146220207214
decider.linear3.weight: -0.009402353316545486 0.05973487347364426
decider.linear3.bias: 0.014369526877999306 0.05274157598614693

Rewards:
229.4037
229.4037
229.4037
objective = 122.50289154052734
==== episode 8500/10000 ====
action = 1
probs = 0.0565 0.9422 0.0010 0.0003

action = 1
probs = 0.6384 0.3583 0.0029 0.0004

action = 0
probs = 0.6686 0.3291 0.0018 0.0005

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 9.117111039813608e-05 0.08390534669160843
encoder.encoder.weight_hh_l0: -0.0001246025349246338 0.0850590243935585
encoder.encoder.bias_ih_l0: 0.007042450364679098 0.08675320446491241
encoder.encoder.bias_hh_l0: 0.017039531841874123 0.0853690356016159
encoder.encoder.weight_ih_l0_reverse: 0.0010750064393505454 0.08576575666666031
encoder.encoder.weight_hh_l0_reverse: 0.0041817352175712585 0.08448955416679382
encoder.encoder.bias_ih_l0_reverse: 0.02588762156665325 0.08413693308830261
encoder.encoder.bias_hh_l0_reverse: 0.017753195017576218 0.08275597542524338
decider.lstm.weight_ih_l0: 0.0008167442283593118 0.14763927459716797
decider.lstm.weight_hh_l0: 0.0029747786466032267 0.14765462279319763
decider.lstm.bias_ih_l0: 0.017917130142450333 0.16030365228652954
decider.lstm.bias_hh_l0: -0.001070335740223527 0.14107342064380646
decider.linear1.weight: 0.003973664715886116 0.12059290707111359
decider.linear1.bias: 0.015464305877685547 0.11549512296915054
decider.linear2.weight: 0.0036452319473028183 0.05321621894836426
decider.linear2.bias: 0.005949866026639938 0.05705348774790764
decider.linear3.weight: -0.009527892805635929 0.05994385480880737
decider.linear3.bias: 0.014156908728182316 0.05301922932267189

Rewards:
230.1930
230.1930
230.1930
objective = 114.20062255859375
==== episode 8600/10000 ====
action = 1
probs = 0.0456 0.9527 0.0013 0.0003

action = 1
probs = 0.5295 0.4647 0.0053 0.0006

action = 0
probs = 0.5264 0.4693 0.0035 0.0008

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.28911846736446e-05 0.08377092331647873
encoder.encoder.weight_hh_l0: -0.0001552616013213992 0.0849076583981514
encoder.encoder.bias_ih_l0: 0.006404636427760124 0.08659279346466064
encoder.encoder.bias_hh_l0: 0.01640171930193901 0.08524640649557114
encoder.encoder.weight_ih_l0_reverse: 0.0010072463192045689 0.08566541224718094
encoder.encoder.weight_hh_l0_reverse: 0.0040703727863729 0.0844261646270752
encoder.encoder.bias_ih_l0_reverse: 0.0255080908536911 0.08408397436141968
encoder.encoder.bias_hh_l0_reverse: 0.017373664304614067 0.08279017359018326
decider.lstm.weight_ih_l0: 0.0006857200060039759 0.1475510597229004
decider.lstm.weight_hh_l0: 0.002814032370224595 0.14757904410362244
decider.lstm.bias_ih_l0: 0.017373155802488327 0.16018417477607727
decider.lstm.bias_hh_l0: -0.0016143133398145437 0.14099672436714172
decider.linear1.weight: 0.0039343624375760555 0.12049713730812073
decider.linear1.bias: 0.015061921440064907 0.11545275151729584
decider.linear2.weight: 0.0035067619755864143 0.05315738543868065
decider.linear2.bias: 0.0057093002833426 0.05693861097097397
decider.linear3.weight: -0.009373578242957592 0.05996324494481087
decider.linear3.bias: 0.014552563428878784 0.05412798002362251

Rewards:
230.1930
230.1930
230.1930
objective = 111.76025390625
==== episode 8700/10000 ====
action = 1
probs = 0.0334 0.9652 0.0012 0.0003

action = 1
probs = 0.3379 0.6564 0.0051 0.0005

action = 1
probs = 0.3204 0.6748 0.0040 0.0008

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -1.32732093334198e-05 0.08368457108736038
encoder.encoder.weight_hh_l0: -0.0001745707559166476 0.08482276648283005
encoder.encoder.bias_ih_l0: 0.00607004389166832 0.08648468554019928
encoder.encoder.bias_hh_l0: 0.016067124903202057 0.08514060080051422
encoder.encoder.weight_ih_l0_reverse: 0.0009759766981005669 0.08563342690467834
encoder.encoder.weight_hh_l0_reverse: 0.004089144058525562 0.08439729362726212
encoder.encoder.bias_ih_l0_reverse: 0.025452861562371254 0.0840715542435646
encoder.encoder.bias_hh_l0_reverse: 0.01731843128800392 0.08288633078336716
decider.lstm.weight_ih_l0: 0.0005748853436671197 0.14746971428394318
decider.lstm.weight_hh_l0: 0.0026841822545975447 0.14751489460468292
decider.lstm.bias_ih_l0: 0.016925565898418427 0.1600407063961029
decider.lstm.bias_hh_l0: -0.002061899285763502 0.1409444957971573
decider.linear1.weight: 0.003939707763493061 0.12046612799167633
decider.linear1.bias: 0.015045063570141792 0.11547389626502991
decider.linear2.weight: 0.003499575424939394 0.05311758816242218
decider.linear2.bias: 0.005703737027943134 0.0569649413228035
decider.linear3.weight: -0.009413089603185654 0.060082852840423584
decider.linear3.bias: 0.014555560424923897 0.05521317198872566

Rewards:
217.8160
217.8160
217.8160
objective = 61.698280334472656
==== episode 8800/10000 ====
action = 1
probs = 0.0654 0.9323 0.0018 0.0004

action = 0
probs = 0.5784 0.4148 0.0062 0.0006

action = 0
probs = 0.4828 0.5121 0.0043 0.0008

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -7.326006652874639e-06 0.08363717794418335
encoder.encoder.weight_hh_l0: -0.00019987211271654814 0.08476661145687103
encoder.encoder.bias_ih_l0: 0.005752786062657833 0.08642906695604324
encoder.encoder.bias_hh_l0: 0.015749868005514145 0.0851069837808609
encoder.encoder.weight_ih_l0_reverse: 0.0009541381150484085 0.08554662019014359
encoder.encoder.weight_hh_l0_reverse: 0.0038037672638893127 0.08431419730186462
encoder.encoder.bias_ih_l0_reverse: 0.024821147322654724 0.08404186367988586
encoder.encoder.bias_hh_l0_reverse: 0.01668671891093254 0.08275964856147766
decider.lstm.weight_ih_l0: 0.000511844758875668 0.1474403440952301
decider.lstm.weight_hh_l0: 0.0026210907381027937 0.14748188853263855
decider.lstm.bias_ih_l0: 0.01671154424548149 0.16010460257530212
decider.lstm.bias_hh_l0: -0.0022759106941521168 0.14096248149871826
decider.linear1.weight: 0.0039166356436908245 0.12043124437332153
decider.linear1.bias: 0.014648222364485264 0.11547689884901047
decider.linear2.weight: 0.003441380336880684 0.05313587188720703
decider.linear2.bias: 0.0055946181528270245 0.05695338919758797
decider.linear3.weight: -0.009526415728032589 0.060196854174137115
decider.linear3.bias: 0.014362822286784649 0.053934186697006226

Rewards:
221.7540
221.7540
221.7540
objective = 99.47526550292969
==== episode 8900/10000 ====
action = 1
probs = 0.0740 0.9227 0.0027 0.0005

action = 0
probs = 0.6230 0.3697 0.0067 0.0007

action = 0
probs = 0.4404 0.5549 0.0039 0.0007

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -1.3399421732174233e-05 0.08357580751180649
encoder.encoder.weight_hh_l0: -0.00022451288532465696 0.08470655232667923
encoder.encoder.bias_ih_l0: 0.005464920308440924 0.08638497442007065
encoder.encoder.bias_hh_l0: 0.015462002716958523 0.08505253493785858
encoder.encoder.weight_ih_l0_reverse: 0.0009563200874254107 0.0855042114853859
encoder.encoder.weight_hh_l0_reverse: 0.0037154352758079767 0.0842667818069458
encoder.encoder.bias_ih_l0_reverse: 0.024578003212809563 0.08403315395116806
encoder.encoder.bias_hh_l0_reverse: 0.01644357480108738 0.08276849240064621
decider.lstm.weight_ih_l0: 0.0004320282896514982 0.14735406637191772
decider.lstm.weight_hh_l0: 0.002537116874009371 0.14741574227809906
decider.lstm.bias_ih_l0: 0.01642165333032608 0.1599711924791336
decider.lstm.bias_hh_l0: -0.0025657927617430687 0.14092199504375458
decider.linear1.weight: 0.003923963755369186 0.12043077498674393
decider.linear1.bias: 0.01456946786493063 0.11555805802345276
decider.linear2.weight: 0.0033690929412841797 0.05313713848590851
decider.linear2.bias: 0.00549404788762331 0.05695553869009018
decider.linear3.weight: -0.009559765458106995 0.06037576496601105
decider.linear3.bias: 0.014321297407150269 0.0539960153400898

Rewards:
221.7540
221.7540
221.7540
objective = 101.5432357788086
==== episode 9000/10000 ====
action = 1
probs = 0.0645 0.9332 0.0019 0.0004

action = 0
probs = 0.6575 0.3371 0.0049 0.0005

action = 0
probs = 0.5085 0.4879 0.0031 0.0006

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.0007213354110718e-05 0.08372748643159866
encoder.encoder.weight_hh_l0: -0.00019027334928978235 0.08484712243080139
encoder.encoder.bias_ih_l0: 0.005991991609334946 0.08659147471189499
encoder.encoder.bias_hh_l0: 0.015989074483513832 0.08520925790071487
encoder.encoder.weight_ih_l0_reverse: 0.0009959953604266047 0.08561844378709793
encoder.encoder.weight_hh_l0_reverse: 0.0038855704478919506 0.08436297625303268
encoder.encoder.bias_ih_l0_reverse: 0.02505783550441265 0.08408541232347488
encoder.encoder.bias_hh_l0_reverse: 0.016923408955335617 0.08279330283403397
decider.lstm.weight_ih_l0: 0.0005858333315700293 0.14752063155174255
decider.lstm.weight_hh_l0: 0.002712543588131666 0.14756657183170319
decider.lstm.bias_ih_l0: 0.01704844832420349 0.16027335822582245
decider.lstm.bias_hh_l0: -0.0019389977678656578 0.14106886088848114
decider.linear1.weight: 0.003927091136574745 0.12049094587564468
decider.linear1.bias: 0.01484727580100298 0.11552263796329498
decider.linear2.weight: 0.0034512821584939957 0.05318035930395126
decider.linear2.bias: 0.005645551718771458 0.0570165179669857
decider.linear3.weight: -0.00974291656166315 0.06065385416150093
decider.linear3.bias: 0.01397065818309784 0.05355292186141014

Rewards:
221.7540
221.7540
221.7540
objective = 86.093994140625
==== episode 9100/10000 ====
action = 1
probs = 0.0473 0.9511 0.0013 0.0003

action = 0
probs = 0.5896 0.4060 0.0040 0.0004

action = 1
probs = 0.4382 0.5588 0.0025 0.0005

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 4.642911153496243e-05 0.08380453288555145
encoder.encoder.weight_hh_l0: -0.00016578470240347087 0.08492285013198853
encoder.encoder.bias_ih_l0: 0.00627667224034667 0.08671034872531891
encoder.encoder.bias_hh_l0: 0.016273753717541695 0.08529689908027649
encoder.encoder.weight_ih_l0_reverse: 0.0010252981446683407 0.08569507300853729
encoder.encoder.weight_hh_l0_reverse: 0.004057273734360933 0.08442633599042892
encoder.encoder.bias_ih_l0_reverse: 0.025468572974205017 0.08412108570337296
encoder.encoder.bias_hh_l0_reverse: 0.017334148287773132 0.08286287635564804
decider.lstm.weight_ih_l0: 0.0006629267008975148 0.1475963294506073
decider.lstm.weight_hh_l0: 0.0027947702910751104 0.14764614403247833
decider.lstm.bias_ih_l0: 0.017352363094687462 0.16040964424610138
decider.lstm.bias_hh_l0: -0.0016350816003978252 0.14114174246788025
decider.linear1.weight: 0.0039337147027254105 0.12053268402814865
decider.linear1.bias: 0.015100196935236454 0.11550018936395645
decider.linear2.weight: 0.0035108430311083794 0.05320171266794205
decider.linear2.bias: 0.005754506215453148 0.05710494518280029
decider.linear3.weight: -0.009892112575471401 0.06087841838598251
decider.linear3.bias: 0.013689303770661354 0.053822170943021774

Rewards:
229.4037
229.4037
229.4037
objective = 88.73409271240234
==== episode 9200/10000 ====
action = 1
probs = 0.0329 0.9661 0.0008 0.0002

action = 1
probs = 0.5277 0.4688 0.0031 0.0003

action = 1
probs = 0.4723 0.5253 0.0020 0.0004

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 8.585691102780402e-05 0.083927683532238
encoder.encoder.weight_hh_l0: -0.00012492098903749138 0.08505699783563614
encoder.encoder.bias_ih_l0: 0.0068117412738502026 0.08685872703790665
encoder.encoder.bias_hh_l0: 0.01680881902575493 0.08545685559511185
encoder.encoder.weight_ih_l0_reverse: 0.0010552611202001572 0.08579963445663452
encoder.encoder.weight_hh_l0_reverse: 0.004238983150571585 0.0845101922750473
encoder.encoder.bias_ih_l0_reverse: 0.025983639061450958 0.0841834619641304
encoder.encoder.bias_hh_l0_reverse: 0.017849210649728775 0.08286518603563309
decider.lstm.weight_ih_l0: 0.0008018892840482295 0.14771537482738495
decider.lstm.weight_hh_l0: 0.0029358661267906427 0.14775793254375458
decider.lstm.bias_ih_l0: 0.017895184457302094 0.16057562828063965
decider.lstm.bias_hh_l0: -0.001092259306460619 0.14119204878807068
decider.linear1.weight: 0.003938422538340092 0.12058793753385544
decider.linear1.bias: 0.01539536751806736 0.11544981598854065
decider.linear2.weight: 0.0035959354136139154 0.05322697386145592
decider.linear2.bias: 0.005896301940083504 0.05714154243469238
decider.linear3.weight: -0.010015584528446198 0.0610608346760273
decider.linear3.bias: 0.013461149297654629 0.05378367006778717

Rewards:
217.8160
217.8160
217.8160
objective = 104.25157165527344
==== episode 9300/10000 ====
action = 1
probs = 0.0365 0.9623 0.0010 0.0002

action = 1
probs = 0.5806 0.4160 0.0031 0.0003

action = 1
probs = 0.5413 0.4564 0.0019 0.0004

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 9.517431317362934e-05 0.08394473791122437
encoder.encoder.weight_hh_l0: -0.00012484792387112975 0.08508053421974182
encoder.encoder.bias_ih_l0: 0.006904804613441229 0.08688045293092728
encoder.encoder.bias_hh_l0: 0.016901880502700806 0.08548887073993683
encoder.encoder.weight_ih_l0_reverse: 0.0010537996422499418 0.08580297231674194
encoder.encoder.weight_hh_l0_reverse: 0.004195913206785917 0.08450926095247269
encoder.encoder.bias_ih_l0_reverse: 0.025946635752916336 0.08420423418283463
encoder.encoder.bias_hh_l0_reverse: 0.017812209203839302 0.08282043039798737
decider.lstm.weight_ih_l0: 0.0008161914302036166 0.14772655069828033
decider.lstm.weight_hh_l0: 0.002951215021312237 0.14776179194450378
decider.lstm.bias_ih_l0: 0.01795901544392109 0.16057263314723969
decider.lstm.bias_hh_l0: -0.001028427854180336 0.14119066298007965
decider.linear1.weight: 0.003943542949855328 0.120598204433918
decider.linear1.bias: 0.015394781716167927 0.1154690757393837
decider.linear2.weight: 0.003582920879125595 0.05323348939418793
decider.linear2.bias: 0.005880639888346195 0.05710292235016823
decider.linear3.weight: -0.010041461326181889 0.06114675849676132
decider.linear3.bias: 0.013430864550173283 0.05346386134624481

Rewards:
217.8160
217.8160
217.8160
objective = 123.42308044433594
==== episode 9400/10000 ====
action = 1
probs = 0.0161 0.9833 0.0005 0.0001

action = 1
probs = 0.3502 0.6473 0.0023 0.0002

action = 1
probs = 0.3221 0.6761 0.0014 0.0003

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001252830697922036 0.08407174795866013
encoder.encoder.weight_hh_l0: -6.586604285985231e-05 0.08521800488233566
encoder.encoder.bias_ih_l0: 0.007439305540174246 0.08706612139940262
encoder.encoder.bias_hh_l0: 0.017436383292078972 0.08561331033706665
encoder.encoder.weight_ih_l0_reverse: 0.0011140770511701703 0.08594467490911484
encoder.encoder.weight_hh_l0_reverse: 0.004593611694872379 0.08461352437734604
encoder.encoder.bias_ih_l0_reverse: 0.026771945878863335 0.08427006751298904
encoder.encoder.bias_hh_l0_reverse: 0.0186375230550766 0.08296029269695282
decider.lstm.weight_ih_l0: 0.0009155049920082092 0.14782458543777466
decider.lstm.weight_hh_l0: 0.003037485294044018 0.14786694943904877
decider.lstm.bias_ih_l0: 0.01832246407866478 0.1607179045677185
decider.lstm.bias_hh_l0: -0.0006649713031947613 0.14128746092319489
decider.linear1.weight: 0.003954913467168808 0.12066535651683807
decider.linear1.bias: 0.01584063097834587 0.11544215679168701
decider.linear2.weight: 0.00365253584459424 0.053249530494213104
decider.linear2.bias: 0.005997270345687866 0.057218458503484726
decider.linear3.weight: -0.01014384999871254 0.0613628514111042
decider.linear3.bias: 0.013243034482002258 0.05470352619886398

Rewards:
217.8160
217.8160
217.8160
objective = 61.21311950683594
==== episode 9500/10000 ====
action = 1
probs = 0.0254 0.9737 0.0008 0.0001

action = 0
probs = 0.5029 0.4937 0.0030 0.0003

action = 0
probs = 0.3693 0.6285 0.0019 0.0004

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 9.600937482900918e-05 0.0839911475777626
encoder.encoder.weight_hh_l0: -9.80637050815858e-05 0.08511209487915039
encoder.encoder.bias_ih_l0: 0.00692338403314352 0.08695923537015915
encoder.encoder.bias_hh_l0: 0.016920460388064384 0.08554080873727798
encoder.encoder.weight_ih_l0_reverse: 0.0010911268182098866 0.08585308492183685
encoder.encoder.weight_hh_l0_reverse: 0.004389581736177206 0.0845578983426094
encoder.encoder.bias_ih_l0_reverse: 0.02626720629632473 0.08420786261558533
encoder.encoder.bias_hh_l0_reverse: 0.018132787197828293 0.08292888849973679
decider.lstm.weight_ih_l0: 0.0008291092235594988 0.1477564126253128
decider.lstm.weight_hh_l0: 0.0029669813811779022 0.14780429005622864
decider.lstm.bias_ih_l0: 0.017988041043281555 0.1606753021478653
decider.lstm.bias_hh_l0: -0.0009993892163038254 0.1412162333726883
decider.linear1.weight: 0.003940243273973465 0.12061727046966553
decider.linear1.bias: 0.015471918508410454 0.11544746905565262
decider.linear2.weight: 0.00358630926348269 0.05324447527527809
decider.linear2.bias: 0.00589357316493988 0.05717400088906288
decider.linear3.weight: -0.01015283353626728 0.06137949973344803
decider.linear3.bias: 0.013259829953312874 0.05421048030257225

Rewards:
221.7540
221.7540
221.7540
objective = 126.40413665771484
==== episode 9600/10000 ====
action = 1
probs = 0.0158 0.9835 0.0006 0.0001

action = 0
probs = 0.4011 0.5953 0.0033 0.0003

action = 1
probs = 0.2671 0.7307 0.0019 0.0003

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00010008223034674302 0.08404941111803055
encoder.encoder.weight_hh_l0: -6.809801561757922e-05 0.08517297357320786
encoder.encoder.bias_ih_l0: 0.007132838945835829 0.08705203235149384
encoder.encoder.bias_hh_l0: 0.017129916697740555 0.08560048788785934
encoder.encoder.weight_ih_l0_reverse: 0.001120048458687961 0.08591728657484055
encoder.encoder.weight_hh_l0_reverse: 0.004608131945133209 0.08462546765804291
encoder.encoder.bias_ih_l0_reverse: 0.02668428048491478 0.08422736078500748
encoder.encoder.bias_hh_l0_reverse: 0.018549861386418343 0.08299631625413895
decider.lstm.weight_ih_l0: 0.0008796389447525144 0.14780215919017792
decider.lstm.weight_hh_l0: 0.0030115125700831413 0.14785368740558624
decider.lstm.bias_ih_l0: 0.01815906912088394 0.16075485944747925
decider.lstm.bias_hh_l0: -0.0008283609058707952 0.1412515789270401
decider.linear1.weight: 0.003943239338696003 0.1206468790769577
decider.linear1.bias: 0.01564711704850197 0.11542468518018723
decider.linear2.weight: 0.003596414579078555 0.053250547498464584
decider.linear2.bias: 0.005896822549402714 0.05716010928153992
decider.linear3.weight: -0.010129532776772976 0.06150500103831291
decider.linear3.bias: 0.013344181701540947 0.05500954017043114

Rewards:
229.4037
229.4037
229.4037
objective = 95.1259765625
==== episode 9700/10000 ====
action = 1
probs = 0.0241 0.9748 0.0009 0.0001

action = 0
probs = 0.5184 0.4765 0.0047 0.0004

action = 1
probs = 0.3158 0.6811 0.0026 0.0004

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 7.451496639987454e-05 0.08394892513751984
encoder.encoder.weight_hh_l0: -9.813513315748423e-05 0.08506342768669128
encoder.encoder.bias_ih_l0: 0.006600978318601847 0.08691827207803726
encoder.encoder.bias_hh_l0: 0.016598058864474297 0.08552013337612152
encoder.encoder.weight_ih_l0_reverse: 0.0010764228645712137 0.08581329137086868
encoder.encoder.weight_hh_l0_reverse: 0.004351883661001921 0.08454914391040802
encoder.encoder.bias_ih_l0_reverse: 0.026092760264873505 0.08417981117963791
encoder.encoder.bias_hh_l0_reverse: 0.01795833930373192 0.082972951233387
decider.lstm.weight_ih_l0: 0.0007827742374502122 0.14772425591945648
decider.lstm.weight_hh_l0: 0.002911787945777178 0.1477811485528946
decider.lstm.bias_ih_l0: 0.017782267183065414 0.16064229607582092
decider.lstm.bias_hh_l0: -0.001205163775011897 0.1411682367324829
decider.linear1.weight: 0.003925100434571505 0.12059444934129715
decider.linear1.bias: 0.015299489721655846 0.11545761674642563
decider.linear2.weight: 0.003507921937853098 0.0532381571829319
decider.linear2.bias: 0.005740348249673843 0.05709194391965866
decider.linear3.weight: -0.010130945593118668 0.06156185641884804
decider.linear3.bias: 0.013392919674515724 0.054674047976732254

Rewards:
229.4037
229.4037
229.4037
objective = 81.54954528808594
==== episode 9800/10000 ====
action = 1
probs = 0.0236 0.9755 0.0008 0.0001

action = 1
probs = 0.4984 0.4974 0.0039 0.0003

action = 1
probs = 0.3077 0.6898 0.0022 0.0004

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 8.075892401393503e-05 0.08397821336984634
encoder.encoder.weight_hh_l0: -9.639117342885584e-05 0.08509677648544312
encoder.encoder.bias_ih_l0: 0.006712769158184528 0.0869506448507309
encoder.encoder.bias_hh_l0: 0.01670985482633114 0.08555383235216141
encoder.encoder.weight_ih_l0_reverse: 0.0010787645587697625 0.08583414554595947
encoder.encoder.weight_hh_l0_reverse: 0.00438218517228961 0.08455812186002731
encoder.encoder.bias_ih_l0_reverse: 0.026188606396317482 0.08420628309249878
encoder.encoder.bias_hh_l0_reverse: 0.018054185435175896 0.08297247439622879
decider.lstm.weight_ih_l0: 0.0007975944899953902 0.14774437248706818
decider.lstm.weight_hh_l0: 0.0029304027557373047 0.14779634773731232
decider.lstm.bias_ih_l0: 0.017857227474451065 0.16067253053188324
decider.lstm.bias_hh_l0: -0.001130207208916545 0.14118728041648865
decider.linear1.weight: 0.003931030631065369 0.12060718238353729
decider.linear1.bias: 0.015367487445473671 0.11547110974788666
decider.linear2.weight: 0.003540114965289831 0.05324745923280716
decider.linear2.bias: 0.005803397856652737 0.057155877351760864
decider.linear3.weight: -0.010266626253724098 0.06171217933297157
decider.linear3.bias: 0.01313733495771885 0.054586052894592285

Rewards:
217.8160
217.8160
217.8160
objective = 79.47328186035156
==== episode 9900/10000 ====
action = 1
probs = 0.0692 0.9286 0.0018 0.0003

action = 0
probs = 0.7111 0.2840 0.0045 0.0004

action = 0
probs = 0.4552 0.5409 0.0033 0.0006

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 3.331750485813245e-05 0.08373058587312698
encoder.encoder.weight_hh_l0: -0.00015429854101967067 0.08484118431806564
encoder.encoder.bias_ih_l0: 0.0057029337622225285 0.08662949502468109
encoder.encoder.bias_hh_l0: 0.015700018033385277 0.08527803421020508
encoder.encoder.weight_ih_l0_reverse: 0.0010047353571280837 0.08561570942401886
encoder.encoder.weight_hh_l0_reverse: 0.0038773189298808575 0.0843876451253891
encoder.encoder.bias_ih_l0_reverse: 0.02491086907684803 0.08408542722463608
encoder.encoder.bias_hh_l0_reverse: 0.016776446253061295 0.0828787237405777
decider.lstm.weight_ih_l0: 0.0005591969238594174 0.14752720296382904
decider.lstm.weight_hh_l0: 0.002687100786715746 0.1475939154624939
decider.lstm.bias_ih_l0: 0.01688235253095627 0.16034896671772003
decider.lstm.bias_hh_l0: -0.0021050951909273863 0.14099593460559845
decider.linear1.weight: 0.0039057591930031776 0.12049781531095505
decider.linear1.bias: 0.014669066295027733 0.11549531668424606
decider.linear2.weight: 0.0033901131246238947 0.05320394039154053
decider.linear2.bias: 0.005572474095970392 0.05705893784761429
decider.linear3.weight: -0.010090183466672897 0.06145896390080452
decider.linear3.bias: 0.013611897826194763 0.053448986262083054

Rewards:
221.7540
221.7540
221.7540
objective = 88.855224609375
==== episode 10000/10000 ====
action = 1
probs = 0.0579 0.9401 0.0017 0.0003

action = 1
probs = 0.6733 0.3207 0.0055 0.0005

action = 1
probs = 0.4309 0.5643 0.0041 0.0007

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.58510356413899e-05 0.08370671421289444
encoder.encoder.weight_hh_l0: -0.0001559394149808213 0.08481540530920029
encoder.encoder.bias_ih_l0: 0.005541504360735416 0.08659093827009201
encoder.encoder.bias_hh_l0: 0.015538590028882027 0.0852656289935112
encoder.encoder.weight_ih_l0_reverse: 0.0010135337943211198 0.0856129452586174
encoder.encoder.weight_hh_l0_reverse: 0.00389110017567873 0.08439513295888901
encoder.encoder.bias_ih_l0_reverse: 0.0249333418905735 0.08407065272331238
encoder.encoder.bias_hh_l0_reverse: 0.016798924654722214 0.08292423188686371
decider.lstm.weight_ih_l0: 0.0005655470304191113 0.14753682911396027
decider.lstm.weight_hh_l0: 0.002692185575142503 0.14760519564151764
decider.lstm.bias_ih_l0: 0.01690053939819336 0.1603161096572876
decider.lstm.bias_hh_l0: -0.0020869108848273754 0.14100798964500427
decider.linear1.weight: 0.003894007531926036 0.12047633528709412
decider.linear1.bias: 0.01456729881465435 0.11545588076114655
decider.linear2.weight: 0.0033538746647536755 0.053193118423223495
decider.linear2.bias: 0.005498770624399185 0.05702581629157066
decider.linear3.weight: -0.010072999633848667 0.061475787311792374
decider.linear3.bias: 0.013692758046090603 0.05387706309556961

Rewards:
217.8160
217.8160
217.8160
objective = 128.60536193847656
[INFO] : learning runtime (h:mm:ss): 0:02:24
[INFO] : learning end time: 12/17/2023 12:31:38 PM
