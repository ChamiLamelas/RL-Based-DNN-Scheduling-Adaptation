Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 12:13:51 PM
==== episode 1/10000 ====
action = 0
probs = 0.9348 0.0648 0.0004 0.0000

action = 0
probs = 0.8272 0.1725 0.0002 0.0000

action = 1
probs = 0.0099 0.9901 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003024138859473169 0.08384616672992706
encoder.encoder.weight_hh_l0: -0.00043972747516818345 0.08496379107236862
encoder.encoder.bias_ih_l0: 0.00684598321095109 0.08571062982082367
encoder.encoder.bias_hh_l0: 0.016843071207404137 0.08575267344713211
encoder.encoder.weight_ih_l0_reverse: 0.0016447536181658506 0.08584695309400558
encoder.encoder.weight_hh_l0_reverse: 0.002279874635860324 0.08398735523223877
encoder.encoder.bias_ih_l0_reverse: 0.02245616912841797 0.08513110876083374
encoder.encoder.bias_hh_l0_reverse: 0.014321601018309593 0.08351603895425797
decider.lstm.weight_ih_l0: -0.00036179128801450133 0.14691057801246643
decider.lstm.weight_hh_l0: -0.0014490030007436872 0.14600369334220886
decider.lstm.bias_ih_l0: 0.017562003806233406 0.1530785858631134
decider.lstm.bias_hh_l0: -0.0014255340211093426 0.14342181384563446
decider.linear1.weight: 0.0018386237788945436 0.12069810181856155
decider.linear1.bias: 0.013321395963430405 0.11646796762943268
decider.linear2.weight: 0.0037891222164034843 0.05514511838555336
decider.linear2.bias: 0.004329759161919355 0.05696411803364754
decider.linear3.weight: -0.030962686985731125 0.08705928176641464
decider.linear3.bias: -0.01891692914068699 0.05361824855208397

Rewards:
153.4407
153.4407
153.4407
objective = 13.657819747924805
==== episode 100/10000 ====
action = 0
probs = 0.9924 0.0076 0.0000 0.0000

action = 0
probs = 0.9667 0.0332 0.0000 0.0000

action = 1
probs = 0.0019 0.9981 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030942793819122016 0.08431744575500488
encoder.encoder.weight_hh_l0: -0.0006272161263041198 0.08567003905773163
encoder.encoder.bias_ih_l0: 0.00894638430327177 0.08620715886354446
encoder.encoder.bias_hh_l0: 0.01894347183406353 0.08640971779823303
encoder.encoder.weight_ih_l0_reverse: 0.0017904501873999834 0.08624862134456635
encoder.encoder.weight_hh_l0_reverse: 0.002435704693198204 0.0842936635017395
encoder.encoder.bias_ih_l0_reverse: 0.02370627596974373 0.08567029237747192
encoder.encoder.bias_hh_l0_reverse: 0.0155717134475708 0.08388803154230118
decider.lstm.weight_ih_l0: -0.0002595122205093503 0.1473199427127838
decider.lstm.weight_hh_l0: -0.0019026134395971894 0.1463373899459839
decider.lstm.bias_ih_l0: 0.020281534641981125 0.15430666506290436
decider.lstm.bias_hh_l0: 0.00129398750141263 0.14374324679374695
decider.linear1.weight: 0.0016976948827505112 0.12120313942432404
decider.linear1.bias: 0.015525073744356632 0.11654823273420334
decider.linear2.weight: 0.0045446231961250305 0.05554895102977753
decider.linear2.bias: 0.0052220867946743965 0.0570695623755455
decider.linear3.weight: -0.032819345593452454 0.08878497779369354
decider.linear3.bias: -0.02156088314950466 0.05212501436471939

Rewards:
153.4407
153.4407
153.4407
objective = 2.219045877456665
==== episode 200/10000 ====
action = 0
probs = 0.9913 0.0087 0.0000 0.0000

action = 0
probs = 0.9673 0.0326 0.0000 0.0000

action = 1
probs = 0.0005 0.9995 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031406767084263265 0.084333635866642
encoder.encoder.weight_hh_l0: -0.0006242708186618984 0.08569122850894928
encoder.encoder.bias_ih_l0: 0.008984101936221123 0.086203433573246
encoder.encoder.bias_hh_l0: 0.01898118667304516 0.08642462641000748
encoder.encoder.weight_ih_l0_reverse: 0.0017990433843806386 0.08627572655677795
encoder.encoder.weight_hh_l0_reverse: 0.002452885266393423 0.08432148396968842
encoder.encoder.bias_ih_l0_reverse: 0.02378992736339569 0.08566330373287201
encoder.encoder.bias_hh_l0_reverse: 0.015655364841222763 0.08391711115837097
decider.lstm.weight_ih_l0: -0.0002486812009010464 0.14731746912002563
decider.lstm.weight_hh_l0: -0.0019037192687392235 0.14633919298648834
decider.lstm.bias_ih_l0: 0.020332127809524536 0.15434589982032776
decider.lstm.bias_hh_l0: 0.0013445767108350992 0.1437365859746933
decider.linear1.weight: 0.0016366394702345133 0.12131502479314804
decider.linear1.bias: 0.015900572761893272 0.11644348502159119
decider.linear2.weight: 0.004619356244802475 0.05571357533335686
decider.linear2.bias: 0.005343372467905283 0.057101596146821976
decider.linear3.weight: -0.033548466861248016 0.08942563086748123
decider.linear3.bias: -0.02264435589313507 0.05231437459588051

Rewards:
153.4407
153.4407
153.4407
objective = 2.168872594833374
==== episode 300/10000 ====
action = 0
probs = 0.9936 0.0064 0.0000 0.0000

action = 0
probs = 0.9788 0.0211 0.0000 0.0000

action = 1
probs = 0.0003 0.9997 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003098574234172702 0.0844026729464531
encoder.encoder.weight_hh_l0: -0.0006539515452459455 0.08582119643688202
encoder.encoder.bias_ih_l0: 0.009335664100944996 0.08625223487615585
encoder.encoder.bias_hh_l0: 0.019332751631736755 0.08653262257575989
encoder.encoder.weight_ih_l0_reverse: 0.001813592854887247 0.08633574098348618
encoder.encoder.weight_hh_l0_reverse: 0.002487299032509327 0.0843760222196579
encoder.encoder.bias_ih_l0_reverse: 0.024022946134209633 0.08576435595750809
encoder.encoder.bias_hh_l0_reverse: 0.015888381749391556 0.08396836370229721
decider.lstm.weight_ih_l0: -0.00023586989846080542 0.14736494421958923
decider.lstm.weight_hh_l0: -0.0019532523583620787 0.14638091623783112
decider.lstm.bias_ih_l0: 0.02062067575752735 0.15449875593185425
decider.lstm.bias_hh_l0: 0.0016331188380718231 0.14381204545497894
decider.linear1.weight: 0.0015878630802035332 0.1214192807674408
decider.linear1.bias: 0.016280394047498703 0.11638607829809189
decider.linear2.weight: 0.004766544327139854 0.055838849395513535
decider.linear2.bias: 0.005592680536210537 0.05705856531858444
decider.linear3.weight: -0.03397686406970024 0.08982191234827042
decider.linear3.bias: -0.023276805877685547 0.05197178199887276

Rewards:
153.4407
153.4407
153.4407
objective = 1.4373301267623901
==== episode 400/10000 ====
action = 0
probs = 0.9945 0.0055 0.0000 0.0000

action = 0
probs = 0.9803 0.0197 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030981050804257393 0.08442780375480652
encoder.encoder.weight_hh_l0: -0.0006653392338193953 0.08586350083351135
encoder.encoder.bias_ih_l0: 0.009457320906221867 0.08628612011671066
encoder.encoder.bias_hh_l0: 0.019454408437013626 0.08656808733940125
encoder.encoder.weight_ih_l0_reverse: 0.0018155085854232311 0.08635127544403076
encoder.encoder.weight_hh_l0_reverse: 0.002493019448593259 0.08438866585493088
encoder.encoder.bias_ih_l0_reverse: 0.024084042757749557 0.0857861340045929
encoder.encoder.bias_hh_l0_reverse: 0.01594947837293148 0.08400505036115646
decider.lstm.weight_ih_l0: -0.00023084532585926354 0.14739827811717987
decider.lstm.weight_hh_l0: -0.001986368792131543 0.1464168280363083
decider.lstm.bias_ih_l0: 0.02079913765192032 0.15455983579158783
decider.lstm.bias_hh_l0: 0.0018115737475454807 0.1438189595937729
decider.linear1.weight: 0.0015626251697540283 0.12149442732334137
decider.linear1.bias: 0.01652894914150238 0.11635173857212067
decider.linear2.weight: 0.004861751105636358 0.05593402683734894
decider.linear2.bias: 0.005709836259484291 0.057059697806835175
decider.linear3.weight: -0.034315526485443115 0.09012600779533386
decider.linear3.bias: -0.023744262754917145 0.0519302673637867

Rewards:
153.4407
153.4407
153.4407
objective = 1.3057348728179932
==== episode 500/10000 ====
action = 0
probs = 0.9971 0.0029 0.0000 0.0000

action = 0
probs = 0.9895 0.0105 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002928094763774425 0.08452528715133667
encoder.encoder.weight_hh_l0: -0.0007225298904813826 0.08606214076280594
encoder.encoder.bias_ih_l0: 0.010011413134634495 0.08639156818389893
encoder.encoder.bias_hh_l0: 0.020008500665426254 0.08673208951950073
encoder.encoder.weight_ih_l0_reverse: 0.0018304241821169853 0.086420439183712
encoder.encoder.weight_hh_l0_reverse: 0.0025314472150057554 0.0844443291425705
encoder.encoder.bias_ih_l0_reverse: 0.024392718449234962 0.0859360322356224
encoder.encoder.bias_hh_l0_reverse: 0.016258154064416885 0.08406699448823929
decider.lstm.weight_ih_l0: -0.00022004864877089858 0.14748620986938477
decider.lstm.weight_hh_l0: -0.0020843318197876215 0.14650097489356995
decider.lstm.bias_ih_l0: 0.021308643743395805 0.15478728711605072
decider.lstm.bias_hh_l0: 0.002321074716746807 0.14389044046401978
decider.linear1.weight: 0.0015258898492902517 0.12164953351020813
decider.linear1.bias: 0.01703776605427265 0.11631260067224503
decider.linear2.weight: 0.00510732876136899 0.05603582784533501
decider.linear2.bias: 0.006024262867867947 0.05702003464102745
decider.linear3.weight: -0.03459233045578003 0.09042461216449738
decider.linear3.bias: -0.024109860882163048 0.05130928009748459

Rewards:
153.4407
153.4407
153.4407
objective = 0.6939641237258911
==== episode 600/10000 ====
action = 0
probs = 0.9980 0.0020 0.0000 0.0000

action = 0
probs = 0.9897 0.0103 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029010744765400887 0.0845412015914917
encoder.encoder.weight_hh_l0: -0.0007313693640753627 0.08608756214380264
encoder.encoder.bias_ih_l0: 0.010084987618029118 0.08642198890447617
encoder.encoder.bias_hh_l0: 0.020082073286175728 0.08675523847341537
encoder.encoder.weight_ih_l0_reverse: 0.0018342988332733512 0.08643147349357605
encoder.encoder.weight_hh_l0_reverse: 0.0025363590102642775 0.0844549611210823
encoder.encoder.bias_ih_l0_reverse: 0.024442000314593315 0.08594458550214767
encoder.encoder.bias_hh_l0_reverse: 0.016307437792420387 0.08408448100090027
decider.lstm.weight_ih_l0: -0.00022028048988431692 0.14750444889068604
decider.lstm.weight_hh_l0: -0.0021088370122015476 0.14652231335639954
decider.lstm.bias_ih_l0: 0.02141467109322548 0.1548256278038025
decider.lstm.bias_hh_l0: 0.0024271016009151936 0.14388081431388855
decider.linear1.weight: 0.0015061155427247286 0.12189658731222153
decider.linear1.bias: 0.017449185252189636 0.11626331508159637
decider.linear2.weight: 0.005238160490989685 0.05616720765829086
decider.linear2.bias: 0.006075588054955006 0.05702604353427887
decider.linear3.weight: -0.034737490117549896 0.09056392312049866
decider.linear3.bias: -0.024300605058670044 0.0512973815202713

Rewards:
153.4407
153.4407
153.4407
objective = 0.6375985741615295
==== episode 700/10000 ====
action = 0
probs = 0.9992 0.0008 0.0000 0.0000

action = 0
probs = 0.9952 0.0048 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002687346423044801 0.08462650328874588
encoder.encoder.weight_hh_l0: -0.0007901056087575853 0.08626951277256012
encoder.encoder.bias_ih_l0: 0.010586517862975597 0.08653287589550018
encoder.encoder.bias_hh_l0: 0.02058359980583191 0.08688294142484665
encoder.encoder.weight_ih_l0_reverse: 0.0018546103965491056 0.08649696409702301
encoder.encoder.weight_hh_l0_reverse: 0.0025780601426959038 0.08450904488563538
encoder.encoder.bias_ih_l0_reverse: 0.024802476167678833 0.08603709936141968
encoder.encoder.bias_hh_l0_reverse: 0.016667913645505905 0.08418860286474228
decider.lstm.weight_ih_l0: -0.00021590098913293332 0.14756903052330017
decider.lstm.weight_hh_l0: -0.002208557678386569 0.14658492803573608
decider.lstm.bias_ih_l0: 0.021847261115908623 0.15501196682453156
decider.lstm.bias_hh_l0: 0.0028596881311386824 0.14388810098171234
decider.linear1.weight: 0.001463033608160913 0.1222001239657402
decider.linear1.bias: 0.01800592988729477 0.11628405004739761
decider.linear2.weight: 0.0054264673963189125 0.05633227154612541
decider.linear2.bias: 0.006285625044256449 0.056992512196302414
decider.linear3.weight: -0.034828104078769684 0.09069868177175522
decider.linear3.bias: -0.02441471815109253 0.050882093608379364

Rewards:
153.4407
153.4407
153.4407
objective = 0.2899262309074402
==== episode 800/10000 ====
action = 0
probs = 0.9996 0.0004 0.0000 0.0000

action = 0
probs = 0.9974 0.0026 0.0000 0.0000

action = 1
probs = 0.0001 0.9999 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002506726887077093 0.0846809670329094
encoder.encoder.weight_hh_l0: -0.0008360741194337606 0.0863940641283989
encoder.encoder.bias_ih_l0: 0.010925420559942722 0.08660386502742767
encoder.encoder.bias_hh_l0: 0.020922502502799034 0.0869554877281189
encoder.encoder.weight_ih_l0_reverse: 0.001865637255832553 0.08654110878705978
encoder.encoder.weight_hh_l0_reverse: 0.002617442514747381 0.08455386757850647
encoder.encoder.bias_ih_l0_reverse: 0.025096775963902473 0.0860820934176445
encoder.encoder.bias_hh_l0_reverse: 0.016962213441729546 0.08426552265882492
decider.lstm.weight_ih_l0: -0.00021614934667013586 0.14760953187942505
decider.lstm.weight_hh_l0: -0.002298529027029872 0.14662711322307587
decider.lstm.bias_ih_l0: 0.02216096967458725 0.15514612197875977
decider.lstm.bias_hh_l0: 0.0031734006479382515 0.14385300874710083
decider.linear1.weight: 0.0014213816029950976 0.12240644544363022
decider.linear1.bias: 0.018346047028899193 0.11630829423666
decider.linear2.weight: 0.005550963804125786 0.05649843439459801
decider.linear2.bias: 0.0064129820093512535 0.056976113468408585
decider.linear3.weight: -0.03486258536577225 0.09077857434749603
decider.linear3.bias: -0.024452650919556618 0.05065630003809929

Rewards:
153.4407
153.4407
153.4407
objective = 0.15859496593475342
==== episode 900/10000 ====
action = 0
probs = 0.9997 0.0003 0.0000 0.0000

action = 0
probs = 0.9984 0.0016 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002357657067477703 0.08471831679344177
encoder.encoder.weight_hh_l0: -0.000872077711392194 0.08648370206356049
encoder.encoder.bias_ih_l0: 0.011165904812514782 0.08665022999048233
encoder.encoder.bias_hh_l0: 0.021162990480661392 0.08700139820575714
encoder.encoder.weight_ih_l0_reverse: 0.0018707314739003778 0.08657214790582657
encoder.encoder.weight_hh_l0_reverse: 0.00265295896679163 0.08459161967039108
encoder.encoder.bias_ih_l0_reverse: 0.025333337485790253 0.08610121160745621
encoder.encoder.bias_hh_l0_reverse: 0.017198771238327026 0.08431239426136017
decider.lstm.weight_ih_l0: -0.0002176791022066027 0.14763802289962769
decider.lstm.weight_hh_l0: -0.0023768581449985504 0.1466582715511322
decider.lstm.bias_ih_l0: 0.0223965086042881 0.15524844825267792
decider.lstm.bias_hh_l0: 0.0034089391119778156 0.14380978047847748
decider.linear1.weight: 0.0013820880558341742 0.12256436794996262
decider.linear1.bias: 0.01859131082892418 0.1163284182548523
decider.linear2.weight: 0.005672895349562168 0.05665850266814232
decider.linear2.bias: 0.006500730291008949 0.05696869269013405
decider.linear3.weight: -0.034880027174949646 0.09083746373653412
decider.linear3.bias: -0.024470098316669464 0.050513897091150284

Rewards:
153.4407
153.4407
153.4407
objective = 0.09947638213634491
==== episode 1000/10000 ====
action = 0
probs = 0.9998 0.0002 0.0000 0.0000

action = 0
probs = 0.9989 0.0011 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002230692916782573 0.08474617451429367
encoder.encoder.weight_hh_l0: -0.0009014640818350017 0.08655329048633575
encoder.encoder.bias_ih_l0: 0.01134938932955265 0.08668317645788193
encoder.encoder.bias_hh_l0: 0.021346474066376686 0.0870334804058075
encoder.encoder.weight_ih_l0_reverse: 0.0018735608318820596 0.08659636974334717
encoder.encoder.weight_hh_l0_reverse: 0.0026856253389269114 0.08462513983249664
encoder.encoder.bias_ih_l0_reverse: 0.025536417961120605 0.08610314130783081
encoder.encoder.bias_hh_l0_reverse: 0.01740184985101223 0.084340400993824
decider.lstm.weight_ih_l0: -0.0002193755644839257 0.14765964448451996
decider.lstm.weight_hh_l0: -0.0024481769651174545 0.1466829478740692
decider.lstm.bias_ih_l0: 0.022588420659303665 0.1553332805633545
decider.lstm.bias_hh_l0: 0.0036008567549288273 0.14376237988471985
decider.linear1.weight: 0.0013452188577502966 0.12269353866577148
decider.linear1.bias: 0.018783068284392357 0.11634417623281479
decider.linear2.weight: 0.005825558677315712 0.056846488267183304
decider.linear2.bias: 0.006566754542291164 0.05696507543325424
decider.linear3.weight: -0.03489043563604355 0.09088493138551712
decider.linear3.bias: -0.02447981759905815 0.05041392892599106

Rewards:
153.4407
153.4407
153.4407
objective = 0.06812646985054016
==== episode 1100/10000 ====
action = 0
probs = 0.9999 0.0001 0.0000 0.0000

action = 0
probs = 0.9992 0.0008 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00021195683802943677 0.08476798981428146
encoder.encoder.weight_hh_l0: -0.0009260948863811791 0.08660972863435745
encoder.encoder.bias_ih_l0: 0.011495837941765785 0.08670754730701447
encoder.encoder.bias_hh_l0: 0.02149292640388012 0.08705724775791168
encoder.encoder.weight_ih_l0_reverse: 0.0018751817988231778 0.08661620318889618
encoder.encoder.weight_hh_l0_reverse: 0.0027157447766512632 0.08465522527694702
encoder.encoder.bias_ih_l0_reverse: 0.025715406984090805 0.08609329164028168
encoder.encoder.bias_hh_l0_reverse: 0.01758084073662758 0.08435558527708054
decider.lstm.weight_ih_l0: -0.00022086655371822417 0.1476769596338272
decider.lstm.weight_hh_l0: -0.002515133935958147 0.14670372009277344
decider.lstm.bias_ih_l0: 0.022752346470952034 0.1554078310728073
decider.lstm.bias_hh_l0: 0.0037647797726094723 0.14371253550052643
decider.linear1.weight: 0.0013108904240652919 0.12280282378196716
decider.linear1.bias: 0.01893874630331993 0.1163560077548027
decider.linear2.weight: 0.0059558311477303505 0.05707291513681412
decider.linear2.bias: 0.006606163457036018 0.0569487027823925
decider.linear3.weight: -0.034897465258836746 0.09092321991920471
decider.linear3.bias: -0.024485964328050613 0.05033918097615242

Rewards:
153.4407
153.4407
153.4407
objective = 0.04948385804891586
==== episode 1200/10000 ====
action = 0
probs = 0.9999 0.0001 0.0000 0.0000

action = 0
probs = 0.9994 0.0006 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002018526865867898 0.08478589355945587
encoder.encoder.weight_hh_l0: -0.0009474833495914936 0.0866575539112091
encoder.encoder.bias_ih_l0: 0.011618089862167835 0.08672649413347244
encoder.encoder.bias_hh_l0: 0.021615175530314445 0.08707603067159653
encoder.encoder.weight_ih_l0_reverse: 0.0018760606180876493 0.08663318306207657
encoder.encoder.weight_hh_l0_reverse: 0.0027438527904450893 0.08468270301818848
encoder.encoder.bias_ih_l0_reverse: 0.025877298787236214 0.0860752984881401
encoder.encoder.bias_hh_l0_reverse: 0.017742734402418137 0.08436140418052673
decider.lstm.weight_ih_l0: -0.00022198009537532926 0.14769166707992554
decider.lstm.weight_hh_l0: -0.0025800573639571667 0.1467222273349762
decider.lstm.bias_ih_l0: 0.022898389026522636 0.1554771512746811
decider.lstm.bias_hh_l0: 0.003910822328180075 0.14366088807582855
decider.linear1.weight: 0.0012771748006343842 0.12289931625127792
decider.linear1.bias: 0.01907281205058098 0.11636803299188614
decider.linear2.weight: 0.006056560203433037 0.057346343994140625
decider.linear2.bias: 0.0066488697193562984 0.05693456158041954
decider.linear3.weight: -0.03490287810564041 0.09095735102891922
decider.linear3.bias: -0.024490371346473694 0.0502801388502121

Rewards:
153.4407
153.4407
153.4407
objective = 0.037205666303634644
==== episode 1300/10000 ====
action = 0
probs = 0.9999 0.0001 0.0000 0.0000

action = 0
probs = 0.9995 0.0005 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001925049291457981 0.08480089157819748
encoder.encoder.weight_hh_l0: -0.0009663947857916355 0.086698979139328
encoder.encoder.bias_ih_l0: 0.011722613126039505 0.086741603910923
encoder.encoder.bias_hh_l0: 0.02171969786286354 0.0870915874838829
encoder.encoder.weight_ih_l0_reverse: 0.0018763416446745396 0.08664796501398087
encoder.encoder.weight_hh_l0_reverse: 0.0027699219062924385 0.08470764011144638
encoder.encoder.bias_ih_l0_reverse: 0.026024308055639267 0.0860515907406807
encoder.encoder.bias_hh_l0_reverse: 0.01788973994553089 0.084360271692276
decider.lstm.weight_ih_l0: -0.0002226661890745163 0.14770476520061493
decider.lstm.weight_hh_l0: -0.002643974032253027 0.1467394232749939
decider.lstm.bias_ih_l0: 0.023031122982501984 0.15554335713386536
decider.lstm.bias_hh_l0: 0.004043560940772295 0.14360827207565308
decider.linear1.weight: 0.001243626931682229 0.1229856014251709
decider.linear1.bias: 0.0191907100379467 0.11638235300779343
decider.linear2.weight: 0.006131886038929224 0.057643063366413116
decider.linear2.bias: 0.006672355812042952 0.05693880841135979
decider.linear3.weight: -0.03490722179412842 0.09098552912473679
decider.linear3.bias: -0.024493705481290817 0.050232212990522385

Rewards:
153.4407
153.4407
153.4407
objective = 0.02865644544363022
==== episode 1400/10000 ====
action = 0
probs = 0.9999 0.0001 0.0000 0.0000

action = 0
probs = 0.9996 0.0004 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00018384608847554773 0.08481362462043762
encoder.encoder.weight_hh_l0: -0.000983250793069601 0.08673526346683502
encoder.encoder.bias_ih_l0: 0.011813038028776646 0.08675365149974823
encoder.encoder.bias_hh_l0: 0.021810125559568405 0.08710455894470215
encoder.encoder.weight_ih_l0_reverse: 0.0018763878615573049 0.08666115999221802
encoder.encoder.weight_hh_l0_reverse: 0.0027942496817559004 0.08473038673400879
encoder.encoder.bias_ih_l0_reverse: 0.026159772649407387 0.0860229954123497
encoder.encoder.bias_hh_l0_reverse: 0.01802520453929901 0.0843537375330925
decider.lstm.weight_ih_l0: -0.00022280796838458627 0.14771685004234314
decider.lstm.weight_hh_l0: -0.002708106767386198 0.14675597846508026
decider.lstm.bias_ih_l0: 0.02315439097583294 0.15560846030712128
decider.lstm.bias_hh_l0: 0.0041668228805065155 0.14355386793613434
decider.linear1.weight: 0.0012105420464649796 0.12306345999240875
decider.linear1.bias: 0.019294973462820053 0.11639684438705444
decider.linear2.weight: 0.006203375291079283 0.057947877794504166
decider.linear2.bias: 0.00671392772346735 0.05691782012581825
decider.linear3.weight: -0.034910812973976135 0.0910135805606842
decider.linear3.bias: -0.024496324360370636 0.05019259452819824

Rewards:
153.4407
153.4407
153.4407
objective = 0.022441156208515167
==== episode 1500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 0.9997 0.0003 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00017586689500603825 0.08482448756694794
encoder.encoder.weight_hh_l0: -0.0009982777992263436 0.08676709979772568
encoder.encoder.bias_ih_l0: 0.011891507543623447 0.08676328510046005
encoder.encoder.bias_hh_l0: 0.021888596937060356 0.08711560815572739
encoder.encoder.weight_ih_l0_reverse: 0.0018763401312753558 0.08667302131652832
encoder.encoder.weight_hh_l0_reverse: 0.002816696185618639 0.08475086838006973
encoder.encoder.bias_ih_l0_reverse: 0.026283740997314453 0.08599114418029785
encoder.encoder.bias_hh_l0_reverse: 0.018149178475141525 0.0843430832028389
decider.lstm.weight_ih_l0: -0.00022226299915928394 0.14772838354110718
decider.lstm.weight_hh_l0: -0.002772676758468151 0.1467723250389099
decider.lstm.bias_ih_l0: 0.02326953411102295 0.15567338466644287
decider.lstm.bias_hh_l0: 0.004281963221728802 0.14349810779094696
decider.linear1.weight: 0.0011800340143963695 0.12313202023506165
decider.linear1.bias: 0.019383439794182777 0.11641201376914978
decider.linear2.weight: 0.006320696324110031 0.05823303014039993
decider.linear2.bias: 0.006858880165964365 0.057023756206035614
decider.linear3.weight: -0.03491717576980591 0.09118346869945526
decider.linear3.bias: -0.024498432874679565 0.05015923082828522

Rewards:
153.4407
153.4407
153.4407
objective = 0.017498061060905457
==== episode 1600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 0.9998 0.0002 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00016862977645359933 0.08483375608921051
encoder.encoder.weight_hh_l0: -0.001011575455777347 0.0867949053645134
encoder.encoder.bias_ih_l0: 0.011959247291088104 0.0867711529135704
encoder.encoder.bias_hh_l0: 0.02195633389055729 0.08712507784366608
encoder.encoder.weight_ih_l0_reverse: 0.0018764673732221127 0.08668379485607147
encoder.encoder.weight_hh_l0_reverse: 0.002837322885170579 0.08476924151182175
encoder.encoder.bias_ih_l0_reverse: 0.026396915316581726 0.08595727384090424
encoder.encoder.bias_hh_l0_reverse: 0.018262354657053947 0.08432953804731369
decider.lstm.weight_ih_l0: -0.0002208951482316479 0.14773979783058167
decider.lstm.weight_hh_l0: -0.0028375559486448765 0.14678891003131866
decider.lstm.bias_ih_l0: 0.0233770739287138 0.15573839843273163
decider.lstm.bias_hh_l0: 0.004389508627355099 0.14344167709350586
decider.linear1.weight: 0.00115601671859622 0.12318827956914902
decider.linear1.bias: 0.01945088990032673 0.1164303719997406
decider.linear2.weight: 0.006395024713128805 0.058457329869270325
decider.linear2.bias: 0.006909518502652645 0.057019516825675964
decider.linear3.weight: -0.03492795675992966 0.0913555771112442
decider.linear3.bias: -0.024500194936990738 0.05013086274266243

Rewards:
153.4407
153.4407
153.4407
objective = 0.01390602346509695
==== episode 1700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 0.9998 0.0002 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001619319518795237 0.08484183996915817
encoder.encoder.weight_hh_l0: -0.001023571123369038 0.08681969344615936
encoder.encoder.bias_ih_l0: 0.012019066140055656 0.0867774486541748
encoder.encoder.bias_hh_l0: 0.02201615273952484 0.08713328093290329
encoder.encoder.weight_ih_l0_reverse: 0.0018768204608932137 0.08669386059045792
encoder.encoder.weight_hh_l0_reverse: 0.00285677844658494 0.08478597551584244
encoder.encoder.bias_ih_l0_reverse: 0.026503395289182663 0.08592061698436737
encoder.encoder.bias_hh_l0_reverse: 0.018368832767009735 0.08431314677000046
decider.lstm.weight_ih_l0: -0.0002185287157772109 0.1477520763874054
decider.lstm.weight_hh_l0: -0.00290565169416368 0.14680743217468262
decider.lstm.bias_ih_l0: 0.023482149466872215 0.15580672025680542
decider.lstm.bias_hh_l0: 0.004494582302868366 0.14338213205337524
decider.linear1.weight: 0.001134286168962717 0.12323781102895737
decider.linear1.bias: 0.019507527351379395 0.11644893139600754
decider.linear2.weight: 0.006448432803153992 0.05865020677447319
decider.linear2.bias: 0.006944126915186644 0.056995585560798645
decider.linear3.weight: -0.03493763506412506 0.09148503839969635
decider.linear3.bias: -0.024501657113432884 0.05010645464062691

Rewards:
153.4407
153.4407
153.4407
objective = 0.01119228359311819
==== episode 1800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 0.9998 0.0002 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00015570386312901974 0.08484891802072525
encoder.encoder.weight_hh_l0: -0.001034456305205822 0.0868418961763382
encoder.encoder.bias_ih_l0: 0.012072309851646423 0.08678232133388519
encoder.encoder.bias_hh_l0: 0.022069396451115608 0.08714041858911514
encoder.encoder.weight_ih_l0_reverse: 0.0018774699419736862 0.08670340478420258
encoder.encoder.weight_hh_l0_reverse: 0.002875399310141802 0.08480125665664673
encoder.encoder.bias_ih_l0_reverse: 0.026605116203427315 0.08588074147701263
encoder.encoder.bias_hh_l0_reverse: 0.018470555543899536 0.0842939019203186
decider.lstm.weight_ih_l0: -0.00021484318131115288 0.1477663815021515
decider.lstm.weight_hh_l0: -0.0029790543485432863 0.1468297243118286
decider.lstm.bias_ih_l0: 0.023587923496961594 0.15588101744651794
decider.lstm.bias_hh_l0: 0.004600365646183491 0.14331796765327454
decider.linear1.weight: 0.001113503472879529 0.12328246980905533
decider.linear1.bias: 0.01955660805106163 0.11646688729524612
decider.linear2.weight: 0.006496846675872803 0.058824069797992706
decider.linear2.bias: 0.006982035003602505 0.05697964131832123
decider.linear3.weight: -0.03494606167078018 0.09159345924854279
decider.linear3.bias: -0.024502944201231003 0.05008542165160179

Rewards:
153.4407
153.4407
153.4407
objective = 0.009082349017262459
==== episode 1900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0001 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001499245990999043 0.08485512435436249
encoder.encoder.weight_hh_l0: -0.0010442656930536032 0.08686167746782303
encoder.encoder.bias_ih_l0: 0.012119481340050697 0.08678577095270157
encoder.encoder.bias_hh_l0: 0.02211656980216503 0.08714648336172104
encoder.encoder.weight_ih_l0_reverse: 0.00187842664308846 0.08671259880065918
encoder.encoder.weight_hh_l0_reverse: 0.0028935030568391085 0.08481524139642715
encoder.encoder.bias_ih_l0_reverse: 0.026703782379627228 0.08583693206310272
encoder.encoder.bias_hh_l0_reverse: 0.01856921799480915 0.08427164703607559
decider.lstm.weight_ih_l0: -0.0002094492519972846 0.14778435230255127
decider.lstm.weight_hh_l0: -0.003059246577322483 0.146858349442482
decider.lstm.bias_ih_l0: 0.023696530610322952 0.15596365928649902
decider.lstm.bias_hh_l0: 0.0047089653089642525 0.14324790239334106
decider.linear1.weight: 0.0010941483778879046 0.12332180887460709
decider.linear1.bias: 0.01959867775440216 0.1164853423833847
decider.linear2.weight: 0.0065279193222522736 0.05898620933294296
decider.linear2.bias: 0.007009027060121298 0.056952103972435
decider.linear3.weight: -0.03495344892144203 0.09168843179941177
decider.linear3.bias: -0.02450408786535263 0.050067201256752014

Rewards:
153.4407
153.4407
153.4407
objective = 0.007420666050165892
==== episode 2000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0001 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00014453529729507864 0.0848606675863266
encoder.encoder.weight_hh_l0: -0.001053231069818139 0.0868794396519661
encoder.encoder.bias_ih_l0: 0.01216184813529253 0.08678772300481796
encoder.encoder.bias_hh_l0: 0.02215893380343914 0.08715159446001053
encoder.encoder.weight_ih_l0_reverse: 0.0018797734519466758 0.08672173321247101
encoder.encoder.weight_hh_l0_reverse: 0.0029119951650500298 0.08482835441827774
encoder.encoder.bias_ih_l0_reverse: 0.026802925392985344 0.0857873484492302
encoder.encoder.bias_hh_l0_reverse: 0.018668366596102715 0.08424519747495651
decider.lstm.weight_ih_l0: -0.0002016217913478613 0.14780904352664948
decider.lstm.weight_hh_l0: -0.0031503369100391865 0.14689797163009644
decider.lstm.bias_ih_l0: 0.023814130574464798 0.15606071054935455
decider.lstm.bias_hh_l0: 0.0048265415243804455 0.14316792786121368
decider.linear1.weight: 0.0010746626649051905 0.12335765361785889
decider.linear1.bias: 0.01963573694229126 0.11650314182043076
decider.linear2.weight: 0.006554687395691872 0.05914117395877838
decider.linear2.bias: 0.007038111798465252 0.05693166330456734
decider.linear3.weight: -0.03495992720127106 0.09177393466234207
decider.linear3.bias: -0.02450510859489441 0.05005137622356415

Rewards:
153.4407
153.4407
153.4407
objective = 0.006091350223869085
==== episode 2100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0001 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00013956472685094923 0.08486559987068176
encoder.encoder.weight_hh_l0: -0.0010614920174703002 0.08689536154270172
encoder.encoder.bias_ih_l0: 0.012200224213302135 0.08678869903087616
encoder.encoder.bias_hh_l0: 0.022197308018803596 0.08715618401765823
encoder.encoder.weight_ih_l0_reverse: 0.0018812300404533744 0.08673083782196045
encoder.encoder.weight_hh_l0_reverse: 0.002931388793513179 0.08484096825122833
encoder.encoder.bias_ih_l0_reverse: 0.026901954784989357 0.0857335776090622
encoder.encoder.bias_hh_l0_reverse: 0.018767401576042175 0.08421619236469269
decider.lstm.weight_ih_l0: -0.00019167603750247508 0.1478424370288849
decider.lstm.weight_hh_l0: -0.0032504312694072723 0.14695200324058533
decider.lstm.bias_ih_l0: 0.02393806353211403 0.1561688333749771
decider.lstm.bias_hh_l0: 0.004950483795255423 0.14308196306228638
decider.linear1.weight: 0.0010545775294303894 0.12338994443416595
decider.linear1.bias: 0.019668040797114372 0.11652041971683502
decider.linear2.weight: 0.006577000021934509 0.059286776930093765
decider.linear2.bias: 0.00706455809995532 0.056912921369075775
decider.linear3.weight: -0.034965526312589645 0.09185104817152023
decider.linear3.bias: -0.02450600452721119 0.05003770440816879

Rewards:
153.4407
153.4407
153.4407
objective = 0.005018159747123718
==== episode 2200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0001 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001349721133010462 0.08487012982368469
encoder.encoder.weight_hh_l0: -0.0010692827636376023 0.08690991252660751
encoder.encoder.bias_ih_l0: 0.01223581563681364 0.08678899705410004
encoder.encoder.bias_hh_l0: 0.0222328994423151 0.08716046065092087
encoder.encoder.weight_ih_l0_reverse: 0.001882432377897203 0.08674008399248123
encoder.encoder.weight_hh_l0_reverse: 0.002952897222712636 0.08485426753759384
encoder.encoder.bias_ih_l0_reverse: 0.0270027294754982 0.08567637950181961
encoder.encoder.bias_hh_l0_reverse: 0.018868176266551018 0.08418530970811844
decider.lstm.weight_ih_l0: -0.00018039006681647152 0.14788486063480377
decider.lstm.weight_hh_l0: -0.0033578991424292326 0.14702250063419342
decider.lstm.bias_ih_l0: 0.024065854027867317 0.15628191828727722
decider.lstm.bias_hh_l0: 0.005078273359686136 0.14299343526363373
decider.linear1.weight: 0.001032732892781496 0.12342012673616409
decider.linear1.bias: 0.019696831703186035 0.11653678864240646
decider.linear2.weight: 0.006594034843146801 0.05942438170313835
decider.linear2.bias: 0.007083575241267681 0.0568886399269104
decider.linear3.weight: -0.03497038036584854 0.09192173182964325
decider.linear3.bias: -0.024506734684109688 0.05002570524811745

Rewards:
153.4407
153.4407
153.4407
objective = 0.004152302630245686
==== episode 2300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 0.9999 0.0001 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00013076122559141368 0.08487436920404434
encoder.encoder.weight_hh_l0: -0.0010766038903966546 0.08692330121994019
encoder.encoder.bias_ih_l0: 0.012268809601664543 0.08678903430700302
encoder.encoder.bias_hh_l0: 0.022265898063778877 0.0871644839644432
encoder.encoder.weight_ih_l0_reverse: 0.0018830647459253669 0.08674926310777664
encoder.encoder.weight_hh_l0_reverse: 0.002976620802655816 0.08486917614936829
encoder.encoder.bias_ih_l0_reverse: 0.027102963998913765 0.08561950922012329
encoder.encoder.bias_hh_l0_reverse: 0.018968410789966583 0.08415458351373672
decider.lstm.weight_ih_l0: -0.00016937546024564654 0.1479317545890808
decider.lstm.weight_hh_l0: -0.00346573768183589 0.14710478484630585
decider.lstm.bias_ih_l0: 0.024188006296753883 0.15638421475887299
decider.lstm.bias_hh_l0: 0.005200432613492012 0.14291001856327057
decider.linear1.weight: 0.0010090121068060398 0.12344931066036224
decider.linear1.bias: 0.019722573459148407 0.11655168980360031
decider.linear2.weight: 0.006608330644667149 0.059554554522037506
decider.linear2.bias: 0.007104566320776939 0.056871648877859116
decider.linear3.weight: -0.03497454151511192 0.09198690950870514
decider.linear3.bias: -0.024507373571395874 0.0500151701271534

Rewards:
153.4407
153.4407
153.4407
objective = 0.0034602347295731306
==== episode 2400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001268930354854092 0.08487825840711594
encoder.encoder.weight_hh_l0: -0.0010833034757524729 0.08693549782037735
encoder.encoder.bias_ih_l0: 0.012298760004341602 0.08678924292325974
encoder.encoder.bias_hh_l0: 0.022295845672488213 0.08716815710067749
encoder.encoder.weight_ih_l0_reverse: 0.0018830742919817567 0.08675795048475266
encoder.encoder.weight_hh_l0_reverse: 0.0030003879219293594 0.08488506823778152
encoder.encoder.bias_ih_l0_reverse: 0.027195848524570465 0.08556850999593735
encoder.encoder.bias_hh_l0_reverse: 0.019061291590332985 0.08412709087133408
decider.lstm.weight_ih_l0: -0.00016033566498663276 0.14797468483448029
decider.lstm.weight_hh_l0: -0.0035643610171973705 0.14718729257583618
decider.lstm.bias_ih_l0: 0.024291563779115677 0.15645894408226013
decider.lstm.bias_hh_l0: 0.005304005928337574 0.14284124970436096
decider.linear1.weight: 0.0009862321894615889 0.1234745979309082
decider.linear1.bias: 0.01974419318139553 0.11656691133975983
decider.linear2.weight: 0.006619825027883053 0.05967750400304794
decider.linear2.bias: 0.007121172733604908 0.05685152858495712
decider.linear3.weight: -0.03497818112373352 0.09204767644405365
decider.linear3.bias: -0.024507958441972733 0.05000586062669754

Rewards:
153.4407
153.4407
153.4407
objective = 0.0029114633798599243
==== episode 2500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0001232567010447383 0.08488186448812485
encoder.encoder.weight_hh_l0: -0.001089477096684277 0.0869467705488205
encoder.encoder.bias_ih_l0: 0.012326144613325596 0.08678963035345078
encoder.encoder.bias_hh_l0: 0.0223232414573431 0.08717155456542969
encoder.encoder.weight_ih_l0_reverse: 0.0018827453022822738 0.08676613867282867
encoder.encoder.weight_hh_l0_reverse: 0.003022907068952918 0.08490107953548431
encoder.encoder.bias_ih_l0_reverse: 0.02727978490293026 0.08552414923906326
encoder.encoder.bias_hh_l0_reverse: 0.01914522610604763 0.08410309255123138
decider.lstm.weight_ih_l0: -0.00015324130072258413 0.14801143109798431
decider.lstm.weight_hh_l0: -0.00365277286618948 0.14726504683494568
decider.lstm.bias_ih_l0: 0.024377306923270226 0.15650849044322968
decider.lstm.bias_hh_l0: 0.0053897215984761715 0.1427859514951706
decider.linear1.weight: 0.0009626246755942702 0.12349994480609894
decider.linear1.bias: 0.019764266908168793 0.11658070236444473
decider.linear2.weight: 0.006632617674767971 0.059791792184114456
decider.linear2.bias: 0.007139754481613636 0.05683695897459984
decider.linear3.weight: -0.034981418401002884 0.09210523962974548
decider.linear3.bias: -0.02450849488377571 0.04999754950404167

Rewards:
153.4407
153.4407
153.4407
objective = 0.0024815956130623817
==== episode 2600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011982004798483104 0.08488517999649048
encoder.encoder.weight_hh_l0: -0.0010951852891594172 0.08695719391107559
encoder.encoder.bias_ih_l0: 0.012351234443485737 0.08679015189409256
encoder.encoder.bias_hh_l0: 0.022348318248987198 0.0871746614575386
encoder.encoder.weight_ih_l0_reverse: 0.0018822827842086554 0.0867738351225853
encoder.encoder.weight_hh_l0_reverse: 0.0030436369124799967 0.0849166065454483
encoder.encoder.bias_ih_l0_reverse: 0.02735494077205658 0.08548571914434433
encoder.encoder.bias_hh_l0_reverse: 0.01922038197517395 0.08408219367265701
decider.lstm.weight_ih_l0: -0.00014767184620723128 0.14804236590862274
decider.lstm.weight_hh_l0: -0.0037315324880182743 0.1473361849784851
decider.lstm.bias_ih_l0: 0.024448465555906296 0.15654009580612183
decider.lstm.bias_hh_l0: 0.005460904445499182 0.14274118840694427
decider.linear1.weight: 0.0009297772194258869 0.12356612831354141
decider.linear1.bias: 0.019893115386366844 0.11665380001068115
decider.linear2.weight: 0.0066420696675777435 0.05999627709388733
decider.linear2.bias: 0.007154482416808605 0.056819818913936615
decider.linear3.weight: -0.034984245896339417 0.09215808659791946
decider.linear3.bias: -0.024508967995643616 0.04999007657170296

Rewards:
153.4407
153.4407
153.4407
objective = 0.0021309969015419483
==== episode 2700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011653810361167416 0.0848882645368576
encoder.encoder.weight_hh_l0: -0.0011005386477336287 0.08696696162223816
encoder.encoder.bias_ih_l0: 0.012374520301818848 0.08679081499576569
encoder.encoder.bias_hh_l0: 0.022371606901288033 0.08717759698629379
encoder.encoder.weight_ih_l0_reverse: 0.0018817830132320523 0.08678115904331207
encoder.encoder.weight_hh_l0_reverse: 0.003062745090574026 0.08493155241012573
encoder.encoder.bias_ih_l0_reverse: 0.027422985062003136 0.08545185625553131
encoder.encoder.bias_hh_l0_reverse: 0.019288428127765656 0.08406379818916321
decider.lstm.weight_ih_l0: -0.00014314879081211984 0.14806890487670898
decider.lstm.weight_hh_l0: -0.003802303224802017 0.14740128815174103
decider.lstm.bias_ih_l0: 0.024508973583579063 0.156560480594635
decider.lstm.bias_hh_l0: 0.005521387327462435 0.1427040547132492
decider.linear1.weight: 0.0008964468725025654 0.1236734688282013
decider.linear1.bias: 0.02006816491484642 0.11677715182304382
decider.linear2.weight: 0.006646231282502413 0.06042445823550224
decider.linear2.bias: 0.007169235497713089 0.05680513381958008
decider.linear3.weight: -0.03498566895723343 0.09218043833971024
decider.linear3.bias: -0.02450942061841488 0.04998321086168289

Rewards:
153.4407
153.4407
153.4407
objective = 0.0018383238930255175
==== episode 2800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011339783668518066 0.08489116281270981
encoder.encoder.weight_hh_l0: -0.0011055860668420792 0.08697616308927536
encoder.encoder.bias_ih_l0: 0.012396275997161865 0.08679157495498657
encoder.encoder.bias_hh_l0: 0.022393357008695602 0.08718040585517883
encoder.encoder.weight_ih_l0_reverse: 0.001881277421489358 0.08678819239139557
encoder.encoder.weight_hh_l0_reverse: 0.0030804299749433994 0.08494588732719421
encoder.encoder.bias_ih_l0_reverse: 0.027485262602567673 0.08542143553495407
encoder.encoder.bias_hh_l0_reverse: 0.019350698217749596 0.08404740691184998
decider.lstm.weight_ih_l0: -0.00013938226038590074 0.14809216558933258
decider.lstm.weight_hh_l0: -0.003866607556119561 0.14746128022670746
decider.lstm.bias_ih_l0: 0.0245613195002079 0.15657374262809753
decider.lstm.bias_hh_l0: 0.005573724862188101 0.14267264306545258
decider.linear1.weight: 0.0008785290410742164 0.12370336800813675
decider.linear1.bias: 0.020094245672225952 0.11679773032665253
decider.linear2.weight: 0.00665791891515255 0.06051208823919296
decider.linear2.bias: 0.007181406486779451 0.05678871273994446
decider.linear3.weight: -0.03498657047748566 0.09218817204236984
decider.linear3.bias: -0.024509843438863754 0.049976885318756104

Rewards:
153.4407
153.4407
153.4407
objective = 0.0016035768203437328
==== episode 2900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00011035911302315071 0.08489390462636948
encoder.encoder.weight_hh_l0: -0.001110409270040691 0.08698491752147675
encoder.encoder.bias_ih_l0: 0.012416837736964226 0.08679240942001343
encoder.encoder.bias_hh_l0: 0.022413911297917366 0.08718310296535492
encoder.encoder.weight_ih_l0_reverse: 0.0018807800952345133 0.08679500967264175
encoder.encoder.weight_hh_l0_reverse: 0.0030970752704888582 0.08495981991291046
encoder.encoder.bias_ih_l0_reverse: 0.027543362230062485 0.08539344370365143
encoder.encoder.bias_hh_l0_reverse: 0.019408801570534706 0.08403246104717255
decider.lstm.weight_ih_l0: -0.00013613510236609727 0.14811311662197113
decider.lstm.weight_hh_l0: -0.00392612349241972 0.14751744270324707
decider.lstm.bias_ih_l0: 0.024607906118035316 0.1565825194120407
decider.lstm.bias_hh_l0: 0.005620263982564211 0.14264526963233948
decider.linear1.weight: 0.0008618263527750969 0.1237257793545723
decider.linear1.bias: 0.02010771818459034 0.11680853366851807
decider.linear2.weight: 0.006669704802334309 0.06056888401508331
decider.linear2.bias: 0.007194403558969498 0.0567752830684185
decider.linear3.weight: -0.03498741239309311 0.09219472110271454
decider.linear3.bias: -0.02451024018228054 0.04997105151414871

Rewards:
153.4407
153.4407
153.4407
objective = 0.001408462761901319
==== episode 3000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00010741267033154145 0.0848965048789978
encoder.encoder.weight_hh_l0: -0.0011150407372042537 0.08699328452348709
encoder.encoder.bias_ih_l0: 0.012436370365321636 0.08679329603910446
encoder.encoder.bias_hh_l0: 0.022433456033468246 0.08718571066856384
encoder.encoder.weight_ih_l0_reverse: 0.0018802889389917254 0.08680164068937302
encoder.encoder.weight_hh_l0_reverse: 0.0031128462869673967 0.08497340977191925
encoder.encoder.bias_ih_l0_reverse: 0.02759796380996704 0.08536743372678757
encoder.encoder.bias_hh_l0_reverse: 0.01946340501308441 0.08401867747306824
decider.lstm.weight_ih_l0: -0.00013327773194760084 0.1481322944164276
decider.lstm.weight_hh_l0: -0.003981554415076971 0.14757025241851807
decider.lstm.bias_ih_l0: 0.0246498454362154 0.1565883606672287
decider.lstm.bias_hh_l0: 0.005662210751324892 0.14262111485004425
decider.linear1.weight: 0.0008449088782072067 0.12374776601791382
decider.linear1.bias: 0.020118890330195427 0.11681786179542542
decider.linear2.weight: 0.006679223850369453 0.060636602342128754
decider.linear2.bias: 0.007206758018583059 0.05676263943314552
decider.linear3.weight: -0.03498821705579758 0.09220144897699356
decider.linear3.bias: -0.024510610848665237 0.04996560886502266

Rewards:
153.4407
153.4407
153.4407
objective = 0.0012438357807695866
==== episode 3100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00010459642362548038 0.0848989486694336
encoder.encoder.weight_hh_l0: -0.001119449152611196 0.08700121939182281
encoder.encoder.bias_ih_l0: 0.012454786337912083 0.08679420500993729
encoder.encoder.bias_hh_l0: 0.02245188131928444 0.08718819916248322
encoder.encoder.weight_ih_l0_reverse: 0.0018798214150592685 0.08680806308984756
encoder.encoder.weight_hh_l0_reverse: 0.003127721603959799 0.08498658984899521
encoder.encoder.bias_ih_l0_reverse: 0.027649056166410446 0.08534331619739532
encoder.encoder.bias_hh_l0_reverse: 0.019514501094818115 0.08400604128837585
decider.lstm.weight_ih_l0: -0.00013076819595880806 0.1481497883796692
decider.lstm.weight_hh_l0: -0.004032879136502743 0.1476195603609085
decider.lstm.bias_ih_l0: 0.02468748763203621 0.15659214556217194
decider.lstm.bias_hh_l0: 0.00569987203925848 0.14259977638721466
decider.linear1.weight: 0.0008286937954835594 0.12377189099788666
decider.linear1.bias: 0.020136209204792976 0.11683209240436554
decider.linear2.weight: 0.006688037887215614 0.06069852411746979
decider.linear2.bias: 0.007216386031359434 0.056748032569885254
decider.linear3.weight: -0.03498898446559906 0.09220785647630692
decider.linear3.bias: -0.024510931223630905 0.04996059462428093

Rewards:
153.4407
153.4407
153.4407
objective = 0.0011005497071892023
==== episode 3200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00010186925646848977 0.08490129560232162
encoder.encoder.weight_hh_l0: -0.0011237040162086487 0.08700884878635406
encoder.encoder.bias_ih_l0: 0.012472378090023994 0.0867951288819313
encoder.encoder.bias_hh_l0: 0.022469470277428627 0.08719058334827423
encoder.encoder.weight_ih_l0_reverse: 0.0018793693743646145 0.08681435137987137
encoder.encoder.weight_hh_l0_reverse: 0.0031419771257787943 0.08499954640865326
encoder.encoder.bias_ih_l0_reverse: 0.027697648853063583 0.08532059192657471
encoder.encoder.bias_hh_l0_reverse: 0.0195630956441164 0.08399426937103271
decider.lstm.weight_ih_l0: -0.0001285020262002945 0.14816607534885406
decider.lstm.weight_hh_l0: -0.004081160761415958 0.1476663202047348
decider.lstm.bias_ih_l0: 0.024721937254071236 0.15659455955028534
decider.lstm.bias_hh_l0: 0.00573437474668026 0.14258050918579102
decider.linear1.weight: 0.0008130358764901757 0.12379521131515503
decider.linear1.bias: 0.020152568817138672 0.11684554070234299
decider.linear2.weight: 0.006696896627545357 0.06075740233063698
decider.linear2.bias: 0.007227533496916294 0.05673694610595703
decider.linear3.weight: -0.03498972952365875 0.09221406280994415
decider.linear3.bias: -0.024511290714144707 0.04995596781373024

Rewards:
153.4407
153.4407
153.4407
objective = 0.0009786043083295226
==== episode 3300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.922057506628335e-05 0.0849035456776619
encoder.encoder.weight_hh_l0: -0.0011278248857706785 0.08701620250940323
encoder.encoder.bias_ih_l0: 0.012489255517721176 0.08679603785276413
encoder.encoder.bias_hh_l0: 0.02248634770512581 0.08719287812709808
encoder.encoder.weight_ih_l0_reverse: 0.0018789099995046854 0.08682046085596085
encoder.encoder.weight_hh_l0_reverse: 0.0031556792091578245 0.08501233905553818
encoder.encoder.bias_ih_l0_reverse: 0.027743816375732422 0.08529919385910034
encoder.encoder.bias_hh_l0_reverse: 0.019609279930591583 0.08398306369781494
decider.lstm.weight_ih_l0: -0.00012641269131563604 0.1481814682483673
decider.lstm.weight_hh_l0: -0.004126678220927715 0.1477106213569641
decider.lstm.bias_ih_l0: 0.024753957986831665 0.15659597516059875
decider.lstm.bias_hh_l0: 0.005766421090811491 0.14256291091442108
decider.linear1.weight: 0.0007978274370543659 0.12381797283887863
decider.linear1.bias: 0.020168304443359375 0.11685845255851746
decider.linear2.weight: 0.0067037977278232574 0.06081576272845268
decider.linear2.bias: 0.007238203193992376 0.05672639235854149
decider.linear3.weight: -0.03499044477939606 0.09222010523080826
decider.linear3.bias: -0.02451157383620739 0.04995153844356537

Rewards:
153.4407
153.4407
153.4407
objective = 0.0008749508997425437
==== episode 3400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.664162644185126e-05 0.0849057212471962
encoder.encoder.weight_hh_l0: -0.0011318206088617444 0.0870233103632927
encoder.encoder.bias_ih_l0: 0.012505467049777508 0.08679694682359695
encoder.encoder.bias_hh_l0: 0.02250254526734352 0.08719505369663239
encoder.encoder.weight_ih_l0_reverse: 0.001878454815596342 0.08682643622159958
encoder.encoder.weight_hh_l0_reverse: 0.0031689023599028587 0.08502501249313354
encoder.encoder.bias_ih_l0_reverse: 0.02778795175254345 0.08527891337871552
encoder.encoder.bias_hh_l0_reverse: 0.019653411582112312 0.08397245407104492
decider.lstm.weight_ih_l0: -0.00012448683264665306 0.1481960117816925
decider.lstm.weight_hh_l0: -0.004169739782810211 0.1477527618408203
decider.lstm.bias_ih_l0: 0.024783674627542496 0.15659673511981964
decider.lstm.bias_hh_l0: 0.005796113051474094 0.14254674315452576
decider.linear1.weight: 0.0007830126560293138 0.12384071201086044
decider.linear1.bias: 0.020184285938739777 0.11687156558036804
decider.linear2.weight: 0.006710125599056482 0.06087544187903404
decider.linear2.bias: 0.007246817462146282 0.05671412870287895
decider.linear3.weight: -0.03499113768339157 0.09222610294818878
decider.linear3.bias: -0.02451193332672119 0.04994746297597885

Rewards:
153.4407
153.4407
153.4407
objective = 0.0007834920543245971
==== episode 3500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.45067367865704e-05 0.08490753173828125
encoder.encoder.weight_hh_l0: -0.0011351900175213814 0.08702915161848068
encoder.encoder.bias_ih_l0: 0.01251890603452921 0.08679745346307755
encoder.encoder.bias_hh_l0: 0.02251598797738552 0.08719682693481445
encoder.encoder.weight_ih_l0_reverse: 0.0018780323443934321 0.08683133870363235
encoder.encoder.weight_hh_l0_reverse: 0.0031797420233488083 0.085035540163517
encoder.encoder.bias_ih_l0_reverse: 0.027823470532894135 0.08526282012462616
encoder.encoder.bias_hh_l0_reverse: 0.019688932225108147 0.08396365493535995
decider.lstm.weight_ih_l0: -0.00012290693121030927 0.14820796251296997
decider.lstm.weight_hh_l0: -0.004204336553812027 0.14778679609298706
decider.lstm.bias_ih_l0: 0.024807587265968323 0.15659691393375397
decider.lstm.bias_hh_l0: 0.005820027552545071 0.1425337791442871
decider.linear1.weight: 0.0007626963779330254 0.1239936426281929
decider.linear1.bias: 0.02059703692793846 0.11739439517259598
decider.linear2.weight: 0.006817944347858429 0.06108700856566429
decider.linear2.bias: 0.00725154671818018 0.056702882051467896
decider.linear3.weight: -0.03499170392751694 0.09223412722349167
decider.linear3.bias: -0.024512160569429398 0.049944087862968445

Rewards:
153.4407
153.4407
153.4407
objective = 0.00042680403566919267
==== episode 3600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.327143197879195e-05 0.08490854501724243
encoder.encoder.weight_hh_l0: -0.0011371527798473835 0.08703247457742691
encoder.encoder.bias_ih_l0: 0.012526683509349823 0.08679758012294769
encoder.encoder.bias_hh_l0: 0.02252376265823841 0.08719783276319504
encoder.encoder.weight_ih_l0_reverse: 0.001877735834568739 0.08683419972658157
encoder.encoder.weight_hh_l0_reverse: 0.003185881767421961 0.08504152297973633
encoder.encoder.bias_ih_l0_reverse: 0.02784373238682747 0.08525357395410538
encoder.encoder.bias_hh_l0_reverse: 0.01970919594168663 0.083958700299263
decider.lstm.weight_ih_l0: -0.00012201886420371011 0.14821483194828033
decider.lstm.weight_hh_l0: -0.004224466159939766 0.14780673384666443
decider.lstm.bias_ih_l0: 0.024821190163493156 0.15659694373607635
decider.lstm.bias_hh_l0: 0.005833606235682964 0.14252634346485138
decider.linear1.weight: 0.0007538229110650718 0.1241457611322403
decider.linear1.bias: 0.020816324278712273 0.11773769557476044
decider.linear2.weight: 0.006902637891471386 0.0613393671810627
decider.linear2.bias: 0.007255860138684511 0.05669797956943512
decider.linear3.weight: -0.03499193862080574 0.09224068373441696
decider.linear3.bias: -0.02451224997639656 0.049942322075366974

Rewards:
153.4407
153.4407
153.4407
objective = 0.00022559610079042614
==== episode 3700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.25162821658887e-05 0.08490916341543198
encoder.encoder.weight_hh_l0: -0.00113836326636374 0.08703450858592987
encoder.encoder.bias_ih_l0: 0.01253146305680275 0.08679763227701187
encoder.encoder.bias_hh_l0: 0.022528542205691338 0.08719844371080399
encoder.encoder.weight_ih_l0_reverse: 0.0018775442149490118 0.08683597296476364
encoder.encoder.weight_hh_l0_reverse: 0.0031896396540105343 0.08504518866539001
encoder.encoder.bias_ih_l0_reverse: 0.027856146916747093 0.08524788171052933
encoder.encoder.bias_hh_l0_reverse: 0.019721604883670807 0.08395564556121826
decider.lstm.weight_ih_l0: -0.00012147847155574709 0.1482190489768982
decider.lstm.weight_hh_l0: -0.004236903972923756 0.14781911671161652
decider.lstm.bias_ih_l0: 0.024829570204019547 0.15659688413143158
decider.lstm.bias_hh_l0: 0.005841939710080624 0.1425217092037201
decider.linear1.weight: 0.0007485952228307724 0.12425818294286728
decider.linear1.bias: 0.020947327837347984 0.11796309798955917
decider.linear2.weight: 0.006953059695661068 0.06154387816786766
decider.linear2.bias: 0.007258635014295578 0.056695375591516495
decider.linear3.weight: -0.0349920392036438 0.09224560856819153
decider.linear3.bias: -0.024512268602848053 0.0499412901699543

Rewards:
153.4407
153.4407
153.4407
objective = 0.00013718675472773612
==== episode 3800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.199142368743196e-05 0.0849095955491066
encoder.encoder.weight_hh_l0: -0.0011392070446163416 0.08703590929508209
encoder.encoder.bias_ih_l0: 0.01253478042781353 0.08679763227701187
encoder.encoder.bias_hh_l0: 0.022531867027282715 0.08719886839389801
encoder.encoder.weight_ih_l0_reverse: 0.001877406146377325 0.08683721721172333
encoder.encoder.weight_hh_l0_reverse: 0.003192243631929159 0.08504775166511536
encoder.encoder.bias_ih_l0_reverse: 0.027864733710885048 0.08524395525455475
encoder.encoder.bias_hh_l0_reverse: 0.01973019912838936 0.08395354449748993
decider.lstm.weight_ih_l0: -0.00012110437819501385 0.148221954703331
decider.lstm.weight_hh_l0: -0.004245573654770851 0.14782768487930298
decider.lstm.bias_ih_l0: 0.024835290387272835 0.156596839427948
decider.lstm.bias_hh_l0: 0.00584767572581768 0.142518550157547
decider.linear1.weight: 0.0007450202247127891 0.1243455708026886
decider.linear1.bias: 0.021038047969341278 0.1181284487247467
decider.linear2.weight: 0.006988148204982281 0.061705250293016434
decider.linear2.bias: 0.007260573096573353 0.056693702936172485
decider.linear3.weight: -0.03499208390712738 0.09224943816661835
decider.linear3.bias: -0.024512309581041336 0.04994066432118416

Rewards:
153.4407
153.4407
153.4407
objective = 9.755499195307493e-05
==== episode 3900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.159564797300845e-05 0.08490990847349167
encoder.encoder.weight_hh_l0: -0.0011398452334105968 0.08703696727752686
encoder.encoder.bias_ih_l0: 0.012537297792732716 0.08679763972759247
encoder.encoder.bias_hh_l0: 0.022534377872943878 0.08719919621944427
encoder.encoder.weight_ih_l0_reverse: 0.0018773002084344625 0.08683815598487854
encoder.encoder.weight_hh_l0_reverse: 0.0031942061614245176 0.08504967391490936
encoder.encoder.bias_ih_l0_reverse: 0.027871202677488327 0.08524099737405777
encoder.encoder.bias_hh_l0_reverse: 0.019736677408218384 0.08395195752382278
decider.lstm.weight_ih_l0: -0.00012082248576916754 0.1482241302728653
decider.lstm.weight_hh_l0: -0.004252110607922077 0.14783421158790588
decider.lstm.bias_ih_l0: 0.02483956143260002 0.1565968096256256
decider.lstm.bias_hh_l0: 0.005851960275322199 0.1425161212682724
decider.linear1.weight: 0.0007423168863169849 0.12441718578338623
decider.linear1.bias: 0.02110738679766655 0.11825912445783615
decider.linear2.weight: 0.007014058995991945 0.06183477118611336
decider.linear2.bias: 0.00726202130317688 0.05669250339269638
decider.linear3.weight: -0.03499210625886917 0.0922524705529213
decider.linear3.bias: -0.024512309581041336 0.04994010552763939

Rewards:
153.4407
153.4407
153.4407
objective = 7.316623668884858e-05
==== episode 4000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.127754310611635e-05 0.08491016179323196
encoder.encoder.weight_hh_l0: -0.0011403561802580953 0.0870378240942955
encoder.encoder.bias_ih_l0: 0.012539293617010117 0.08679767698049545
encoder.encoder.bias_hh_l0: 0.02253636345267296 0.08719944208860397
encoder.encoder.weight_ih_l0_reverse: 0.0018772180192172527 0.08683890849351883
encoder.encoder.weight_hh_l0_reverse: 0.0031957675237208605 0.08505121618509293
encoder.encoder.bias_ih_l0_reverse: 0.027876364067196846 0.08523863554000854
encoder.encoder.bias_hh_l0_reverse: 0.019741814583539963 0.08395069092512131
decider.lstm.weight_ih_l0: -0.00012060466542607173 0.14822588860988617
decider.lstm.weight_hh_l0: -0.004257315769791603 0.14783941209316254
decider.lstm.bias_ih_l0: 0.02484297938644886 0.15659676492214203
decider.lstm.bias_hh_l0: 0.005855404771864414 0.14251422882080078
decider.linear1.weight: 0.0007401347975246608 0.12447816878557205
decider.linear1.bias: 0.021163444966077805 0.11836747080087662
decider.linear2.weight: 0.0070344749838113785 0.06194619834423065
decider.linear2.bias: 0.0072631994262337685 0.05669161304831505
decider.linear3.weight: -0.034992121160030365 0.09225506335496902
decider.linear3.bias: -0.024512233212590218 0.04993968456983566

Rewards:
153.4407
153.4407
153.4407
objective = 5.487467205966823e-05
==== episode 4100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.101774048758671e-05 0.08491037786006927
encoder.encoder.weight_hh_l0: -0.0011407731799408793 0.08703851699829102
encoder.encoder.bias_ih_l0: 0.012540941126644611 0.08679769933223724
encoder.encoder.bias_hh_l0: 0.02253798395395279 0.08719965070486069
encoder.encoder.weight_ih_l0_reverse: 0.0018771549221128225 0.08683952689170837
encoder.encoder.weight_hh_l0_reverse: 0.003197044599801302 0.08505246788263321
encoder.encoder.bias_ih_l0_reverse: 0.027880586683750153 0.08523669838905334
encoder.encoder.bias_hh_l0_reverse: 0.019746048375964165 0.08394969254732132
decider.lstm.weight_ih_l0: -0.00012042391608702019 0.14822730422019958
decider.lstm.weight_hh_l0: -0.004261595197021961 0.14784370362758636
decider.lstm.bias_ih_l0: 0.024845683947205544 0.15659676492214203
decider.lstm.bias_hh_l0: 0.005858190823346376 0.14251264929771423
decider.linear1.weight: 0.000738368253223598 0.12453075498342514
decider.linear1.bias: 0.021209929138422012 0.1184592992067337
decider.linear2.weight: 0.007051009219139814 0.0620398186147213
decider.linear2.bias: 0.007264076266437769 0.05669078230857849
decider.linear3.weight: -0.03499213606119156 0.09225721657276154
decider.linear3.bias: -0.024512140080332756 0.04993929713964462

Rewards:
153.4407
153.4407
153.4407
objective = 4.877748142462224e-05
==== episode 4200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.080774907488376e-05 0.0849105566740036
encoder.encoder.weight_hh_l0: -0.0011411081068217754 0.087039053440094
encoder.encoder.bias_ih_l0: 0.01254225242882967 0.08679768443107605
encoder.encoder.bias_hh_l0: 0.022539304569363594 0.08719980716705322
encoder.encoder.weight_ih_l0_reverse: 0.0018771025352180004 0.08684001863002777
encoder.encoder.weight_hh_l0_reverse: 0.0031980720814317465 0.08505348861217499
encoder.encoder.bias_ih_l0_reverse: 0.0278839822858572 0.08523513376712799
encoder.encoder.bias_hh_l0_reverse: 0.019749443978071213 0.08394884318113327
decider.lstm.weight_ih_l0: -0.00012028124183416367 0.1482284516096115
decider.lstm.weight_hh_l0: -0.0042650699615478516 0.14784713089466095
decider.lstm.bias_ih_l0: 0.024847883731126785 0.15659676492214203
decider.lstm.bias_hh_l0: 0.005860394332557917 0.14251142740249634
decider.linear1.weight: 0.000736293091904372 0.12457810342311859
decider.linear1.bias: 0.021249733865261078 0.11853612959384918
decider.linear2.weight: 0.007216266822069883 0.06218407303094864
decider.linear2.bias: 0.007529392838478088 0.057036321610212326
decider.linear3.weight: -0.03499291092157364 0.09233531355857849
decider.linear3.bias: -0.024512220174074173 0.0499391108751297

Rewards:
153.4407
153.4407
153.4407
objective = 2.7437330572865903e-05
==== episode 4300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.07181529328227e-05 0.08491059392690659
encoder.encoder.weight_hh_l0: -0.0011412532767280936 0.08703925460577011
encoder.encoder.bias_ih_l0: 0.012542784214019775 0.08679761737585068
encoder.encoder.bias_hh_l0: 0.022539831697940826 0.08719981461763382
encoder.encoder.weight_ih_l0_reverse: 0.0018770756432786584 0.08684022724628448
encoder.encoder.weight_hh_l0_reverse: 0.003198483493179083 0.08505387604236603
encoder.encoder.bias_ih_l0_reverse: 0.02788538858294487 0.08523447811603546
encoder.encoder.bias_hh_l0_reverse: 0.019750846549868584 0.08394848555326462
decider.lstm.weight_ih_l0: -0.00012023199087707326 0.14822888374328613
decider.lstm.weight_hh_l0: -0.004266608506441116 0.14784863591194153
decider.lstm.bias_ih_l0: 0.024848774075508118 0.15659666061401367
decider.lstm.bias_hh_l0: 0.005861329846084118 0.14251089096069336
decider.linear1.weight: 0.0007337203132919967 0.124604731798172
decider.linear1.bias: 0.02127203345298767 0.11857248842716217
decider.linear2.weight: 0.007304767612367868 0.06239033862948418
decider.linear2.bias: 0.007710607722401619 0.05736146867275238
decider.linear3.weight: -0.03499554470181465 0.09244135022163391
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 4400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067542850971222e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.001141328364610672 0.08703932911157608
encoder.encoder.bias_ih_l0: 0.012543019838631153 0.0867975577712059
encoder.encoder.bias_hh_l0: 0.022540057078003883 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770612077787519 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.0031986781395971775 0.08505406230688095
encoder.encoder.bias_ih_l0_reverse: 0.02788604237139225 0.0852341428399086
encoder.encoder.bias_hh_l0_reverse: 0.019751515239477158 0.0839482843875885
decider.lstm.weight_ih_l0: -0.00012021224392810836 0.14822909235954285
decider.lstm.weight_hh_l0: -0.0042673866264522076 0.14784936606884003
decider.lstm.bias_ih_l0: 0.024849191308021545 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861754063516855 0.14251062273979187
decider.linear1.weight: 0.000731968495529145 0.12461956590414047
decider.linear1.bias: 0.021284176036715508 0.11859124153852463
decider.linear2.weight: 0.00734463706612587 0.06253323704004288
decider.linear2.bias: 0.007805968634784222 0.05756106600165367
decider.linear3.weight: -0.03499786555767059 0.09251627326011658
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 4500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 4600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 4700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 4800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 4900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 5000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 5100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 5200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 5300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 5400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 5500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 5600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 5700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 5800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 5900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 6000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 6100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 6200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 6300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 6400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 6500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 6600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 6700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 6800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 6900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 7000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 7100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 7200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 7300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 7400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 7500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 7600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 7700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 7800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 7900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 8000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 8100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 8200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 8300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 8400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 8500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 8600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 8700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 8800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 8900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 9000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 9100/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 9200/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 9300/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 9400/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 9500/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 9600/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 9700/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 9800/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 9900/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
==== episode 10000/10000 ====
action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -9.067214705282822e-05 0.08491060137748718
encoder.encoder.weight_hh_l0: -0.0011413339525461197 0.08703933656215668
encoder.encoder.bias_ih_l0: 0.012543033808469772 0.0867975503206253
encoder.encoder.bias_hh_l0: 0.022540070116519928 0.08719979971647263
encoder.encoder.weight_ih_l0_reverse: 0.0018770599272102118 0.08684032410383224
encoder.encoder.weight_hh_l0_reverse: 0.003198693273589015 0.08505406975746155
encoder.encoder.bias_ih_l0_reverse: 0.02788608893752098 0.08523410558700562
encoder.encoder.bias_hh_l0_reverse: 0.019751565530896187 0.08394826948642731
decider.lstm.weight_ih_l0: -0.00012021067959722131 0.14822910726070404
decider.lstm.weight_hh_l0: -0.004267450887709856 0.1478494256734848
decider.lstm.bias_ih_l0: 0.024849215522408485 0.1565965861082077
decider.lstm.bias_hh_l0: 0.005861783865839243 0.14251060783863068
decider.linear1.weight: 0.0007317583076655865 0.12462127208709717
decider.linear1.bias: 0.02128588780760765 0.11859335005283356
decider.linear2.weight: 0.0073472862131893635 0.06254766881465912
decider.linear2.bias: 0.007813324220478535 0.057577263563871384
decider.linear3.weight: -0.03499807417392731 0.09252288937568665
decider.linear3.bias: -0.024512238800525665 0.04993908107280731

Rewards:
153.4407
153.4407
153.4407
objective = 1.8291553715243936e-05
[INFO] : learning runtime (h:mm:ss): 0:02:28
[INFO] : learning end time: 12/17/2023 12:16:18 PM
