Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(18, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/18/2023 12:46:26 AM
==== episode 1/10000 ====
action = 0
probs = 0.2494 0.2519 0.2494 0.2494

action = 0
probs = 0.2494 0.2519 0.2494 0.2494

action = 0
probs = 0.2494 0.2519 0.2494 0.2494

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 5.6320168368984014e-05 0.08557968586683273
encoder.encoder.weight_hh_l0: -0.0005868228035978973 0.0882081463932991
encoder.encoder.bias_ih_l0: 0.015602457337081432 0.08763407915830612
encoder.encoder.bias_hh_l0: 0.025599559769034386 0.08803631365299225
encoder.encoder.weight_ih_l0_reverse: 0.0018306460697203875 0.08726630359888077
encoder.encoder.weight_hh_l0_reverse: 0.0028630325105041265 0.08501015603542328
encoder.encoder.bias_ih_l0_reverse: 0.028551487252116203 0.08650122582912445
encoder.encoder.bias_hh_l0_reverse: 0.020416907966136932 0.08478027582168579
decider.lstm.weight_ih_l0: 0.0005913069471716881 0.14912784099578857
decider.lstm.weight_hh_l0: -0.00323411519639194 0.14797736704349518
decider.lstm.bias_ih_l0: 0.028408557176589966 0.15717950463294983
decider.lstm.bias_hh_l0: 0.009421090595424175 0.14366966485977173
decider.linear1.weight: 0.0007628611056134105 0.1237328052520752
decider.linear1.bias: 0.022224396467208862 0.11631561070680618
decider.linear2.weight: 0.007010775618255138 0.058193620294332504
decider.linear2.bias: 0.008754706010222435 0.05844859406352043
decider.linear3.weight: -0.068640798330307 0.12991215288639069
decider.linear3.bias: -0.06498450040817261 0.09603780508041382

Rewards:
61.3882
61.3882
61.3882
objective = 85.25611877441406
==== episode 100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.369077113457024e-05 0.08568133413791656
encoder.encoder.weight_hh_l0: -0.0005865986458957195 0.08833987265825272
encoder.encoder.bias_ih_l0: 0.016128476709127426 0.08775629848241806
encoder.encoder.bias_hh_l0: 0.026125583797693253 0.08828991651535034
encoder.encoder.weight_ih_l0_reverse: 0.0018307865830138326 0.08736552298069
encoder.encoder.weight_hh_l0_reverse: 0.0028724134899675846 0.08502800017595291
encoder.encoder.bias_ih_l0_reverse: 0.028874972835183144 0.0866379663348198
encoder.encoder.bias_hh_l0_reverse: 0.020740393549203873 0.08487414568662643
decider.lstm.weight_ih_l0: 0.0006334212375804782 0.14923609793186188
decider.lstm.weight_hh_l0: -0.003295276314020157 0.14811545610427856
decider.lstm.bias_ih_l0: 0.029052894562482834 0.15737590193748474
decider.lstm.bias_hh_l0: 0.010065424256026745 0.1438431590795517
decider.linear1.weight: 0.0007063671946525574 0.12396909296512604
decider.linear1.bias: 0.02288150228559971 0.11630535870790482
decider.linear2.weight: 0.007334443274885416 0.05833238363265991
decider.linear2.bias: 0.00923056248575449 0.058660656213760376
decider.linear3.weight: -0.06861478090286255 0.1300504505634308
decider.linear3.bias: -0.06491440534591675 0.09673938900232315

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 1900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 2900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 3900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 4900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 5900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 6900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 7900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 8900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 9900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
==== episode 10000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: 0.02369428612291813 0.9583032727241516
encoder.encoder.weight_ih_l0: 8.379060454899445e-05 0.08568178862333298
encoder.encoder.weight_hh_l0: -0.0005865988787263632 0.08834043145179749
encoder.encoder.bias_ih_l0: 0.016130877658724785 0.08775688707828522
encoder.encoder.bias_hh_l0: 0.02612798474729061 0.08829115331172943
encoder.encoder.weight_ih_l0_reverse: 0.0018307733116671443 0.08736597001552582
encoder.encoder.weight_hh_l0_reverse: 0.0028724486473947763 0.08502805978059769
encoder.encoder.bias_ih_l0_reverse: 0.02887638472020626 0.08663864433765411
encoder.encoder.bias_hh_l0_reverse: 0.02074180729687214 0.08487458527088165
decider.lstm.weight_ih_l0: 0.0006336112273856997 0.14923658967018127
decider.lstm.weight_hh_l0: -0.003295562230050564 0.14811614155769348
decider.lstm.bias_ih_l0: 0.029056167230010033 0.1573769748210907
decider.lstm.bias_hh_l0: 0.010068709962069988 0.14384396374225616
decider.linear1.weight: 0.0007060623611323535 0.12397042661905289
decider.linear1.bias: 0.022885143756866455 0.11630530655384064
decider.linear2.weight: 0.007336125709116459 0.058333128690719604
decider.linear2.bias: 0.009233123622834682 0.05866173282265663
decider.linear3.weight: -0.06861472129821777 0.13005124032497406
decider.linear3.bias: -0.06491423398256302 0.09674350917339325

Rewards:
58.5688
58.5688
58.5688
objective = 6.981947990425397e-06
[INFO] : learning runtime (h:mm:ss): 0:02:23
[INFO] : learning end time: 12/18/2023 12:48:48 AM
