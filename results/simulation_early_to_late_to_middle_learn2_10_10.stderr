Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 06:57:29 PM
==== episode 1/10000 ====
action = 0
probs = 0.2436 0.2692 0.2436 0.2436

action = 0
probs = 0.2436 0.2692 0.2436 0.2436

action = 0
probs = 0.2436 0.2692 0.2436 0.2436

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002343432861380279 0.08491930365562439
encoder.encoder.weight_hh_l0: -0.0006563412607647479 0.08676746487617493
encoder.encoder.bias_ih_l0: 0.011442628689110279 0.08687543123960495
encoder.encoder.bias_hh_l0: 0.02143973298370838 0.08698052167892456
encoder.encoder.weight_ih_l0_reverse: 0.001753658871166408 0.08674414455890656
encoder.encoder.weight_hh_l0_reverse: 0.0024198219180107117 0.0843406468629837
encoder.encoder.bias_ih_l0_reverse: 0.025323648005723953 0.0858338251709938
encoder.encoder.bias_hh_l0_reverse: 0.01718907430768013 0.08480538427829742
decider.lstm.weight_ih_l0: 0.00012045923358527943 0.14814651012420654
decider.lstm.weight_hh_l0: -0.0025436710566282272 0.14709366858005524
decider.lstm.bias_ih_l0: 0.024542218074202538 0.15624070167541504
decider.lstm.bias_hh_l0: 0.005554721690714359 0.14285646378993988
decider.linear1.weight: 0.0013266945024952292 0.12225484102964401
decider.linear1.bias: 0.017861150205135345 0.11701120436191559
decider.linear2.weight: 0.005063874647021294 0.05693134292960167
decider.linear2.bias: 0.007212618365883827 0.057631805539131165
decider.linear3.weight: -0.06818650662899017 0.12876415252685547
decider.linear3.bias: -0.06401704996824265 0.09295249730348587

Rewards:
206.9982
206.9982
206.9982
objective = 292.32696533203125
==== episode 100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00012998987222090364 0.08529072999954224
encoder.encoder.weight_hh_l0: -0.0007309030625037849 0.08749072253704071
encoder.encoder.bias_ih_l0: 0.013592828065156937 0.08734335005283356
encoder.encoder.bias_hh_l0: 0.023589933291077614 0.08764363080263138
encoder.encoder.weight_ih_l0_reverse: 0.0018363852286711335 0.087129607796669
encoder.encoder.weight_hh_l0_reverse: 0.0026152851060032845 0.08468664437532425
encoder.encoder.bias_ih_l0_reverse: 0.02700955420732498 0.08617832511663437
encoder.encoder.bias_hh_l0_reverse: 0.018874982371926308 0.0849098190665245
decider.lstm.weight_ih_l0: 0.0002922258572652936 0.1487094610929489
decider.lstm.weight_hh_l0: -0.0028678840026259422 0.1476229429244995
decider.lstm.bias_ih_l0: 0.02687446027994156 0.15677574276924133
decider.lstm.bias_hh_l0: 0.007886961102485657 0.1434444785118103
decider.linear1.weight: 0.0012071586679667234 0.12262316048145294
decider.linear1.bias: 0.019024552777409554 0.1168876439332962
decider.linear2.weight: 0.005554089322686195 0.05718544125556946
decider.linear2.bias: 0.007807357236742973 0.058051545172929764
decider.linear3.weight: -0.06875937432050705 0.12960536777973175
decider.linear3.bias: -0.0652509406208992 0.09492024779319763

Rewards:
190.8927
190.8927
190.8927
objective = 0.0020973957143723965
==== episode 200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -7.130704761948436e-05 0.08534812927246094
encoder.encoder.weight_hh_l0: -0.0007230238988995552 0.08767204731702805
encoder.encoder.bias_ih_l0: 0.014170162379741669 0.08741940557956696
encoder.encoder.bias_hh_l0: 0.024167267605662346 0.0877608209848404
encoder.encoder.weight_ih_l0_reverse: 0.0018221106147393584 0.08717253059148788
encoder.encoder.weight_hh_l0_reverse: 0.002673181938007474 0.08475633710622787
encoder.encoder.bias_ih_l0_reverse: 0.027362773194909096 0.08628468960523605
encoder.encoder.bias_hh_l0_reverse: 0.01922820322215557 0.08490532636642456
decider.lstm.weight_ih_l0: 0.0003515345451887697 0.1488245576620102
decider.lstm.weight_hh_l0: -0.0029741760808974504 0.1477278620004654
decider.lstm.bias_ih_l0: 0.027367210015654564 0.15689733624458313
decider.lstm.bias_hh_l0: 0.00837972853332758 0.14352406561374664
decider.linear1.weight: 0.0011093022767454386 0.12283214926719666
decider.linear1.bias: 0.019792037084698677 0.11661593616008759
decider.linear2.weight: 0.005895676091313362 0.05732240527868271
decider.linear2.bias: 0.008128209039568901 0.058113984763622284
decider.linear3.weight: -0.06877793371677399 0.12975697219371796
decider.linear3.bias: -0.0652816966176033 0.09529071301221848

Rewards:
190.8927
190.8927
190.8927
objective = 0.0006295906496234238
==== episode 300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -4.0605551475891843e-05 0.08538118004798889
encoder.encoder.weight_hh_l0: -0.0007091540028341115 0.08777573704719543
encoder.encoder.bias_ih_l0: 0.014483270235359669 0.08745729178190231
encoder.encoder.bias_hh_l0: 0.024480370804667473 0.08781871944665909
encoder.encoder.weight_ih_l0_reverse: 0.00182156206574291 0.08719140291213989
encoder.encoder.weight_hh_l0_reverse: 0.0027088390197604895 0.0848001092672348
encoder.encoder.bias_ih_l0_reverse: 0.02756056748330593 0.08634348958730698
encoder.encoder.bias_hh_l0_reverse: 0.019425993785262108 0.08489929139614105
decider.lstm.weight_ih_l0: 0.00039085265598259866 0.14888443052768707
decider.lstm.weight_hh_l0: -0.003034728579223156 0.14778107404708862
decider.lstm.bias_ih_l0: 0.02760765329003334 0.15695591270923615
decider.lstm.bias_hh_l0: 0.008620161563158035 0.14355702698230743
decider.linear1.weight: 0.0010410675313323736 0.12297902256250381
decider.linear1.bias: 0.02028314769268036 0.11641231179237366
decider.linear2.weight: 0.00611328287050128 0.0574488528072834
decider.linear2.bias: 0.008292424492537975 0.05814411863684654
decider.linear3.weight: -0.06878181546926498 0.1298382729291916
decider.linear3.bias: -0.06528738886117935 0.09545858949422836

Rewards:
190.8927
190.8927
190.8927
objective = 0.0002882455592043698
==== episode 400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -2.1312869648681954e-05 0.0854044109582901
encoder.encoder.weight_hh_l0: -0.0006949339876882732 0.08784893155097961
encoder.encoder.bias_ih_l0: 0.014692544937133789 0.08748277276754379
encoder.encoder.bias_hh_l0: 0.02468964457511902 0.08785676211118698
encoder.encoder.weight_ih_l0_reverse: 0.0018238192424178123 0.08720213919878006
encoder.encoder.weight_hh_l0_reverse: 0.0027347456198185682 0.08483176678419113
encoder.encoder.bias_ih_l0_reverse: 0.027696659788489342 0.08638261258602142
encoder.encoder.bias_hh_l0_reverse: 0.019562091678380966 0.0848911702632904
decider.lstm.weight_ih_l0: 0.00042040355037897825 0.14892370998859406
decider.lstm.weight_hh_l0: -0.003075494896620512 0.14781485497951508
decider.lstm.bias_ih_l0: 0.027755944058299065 0.1569921225309372
decider.lstm.bias_hh_l0: 0.008768454194068909 0.14357483386993408
decider.linear1.weight: 0.0009919346775859594 0.1230892539024353
decider.linear1.bias: 0.020608428865671158 0.11630118638277054
decider.linear2.weight: 0.006263689137995243 0.05754739046096802
decider.linear2.bias: 0.00839752797037363 0.058164097368717194
decider.linear3.weight: -0.06878317892551422 0.12989306449890137
decider.linear3.bias: -0.06528928875923157 0.09555815905332565

Rewards:
190.8927
190.8927
190.8927
objective = 0.00016687884635757655
==== episode 500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -7.820836799510289e-06 0.08542273193597794
encoder.encoder.weight_hh_l0: -0.0006812107749283314 0.08790627866983414
encoder.encoder.bias_ih_l0: 0.014848430640995502 0.08750250935554504
encoder.encoder.bias_hh_l0: 0.024845534935593605 0.08788543939590454
encoder.encoder.weight_ih_l0_reverse: 0.0018264433601871133 0.08720916509628296
encoder.encoder.weight_hh_l0_reverse: 0.002755436347797513 0.08485677093267441
encoder.encoder.bias_ih_l0_reverse: 0.027799716219305992 0.08641103655099869
encoder.encoder.bias_hh_l0_reverse: 0.01966514252126217 0.08488165587186813
decider.lstm.weight_ih_l0: 0.0004443425277713686 0.14895282685756683
decider.lstm.weight_hh_l0: -0.0031058266758918762 0.1478390097618103
decider.lstm.bias_ih_l0: 0.02785983309149742 0.15701806545257568
decider.lstm.bias_hh_l0: 0.00887234415858984 0.14358583092689514
decider.linear1.weight: 0.0009537517325952649 0.12317775189876556
decider.linear1.bias: 0.020848149433732033 0.11622695624828339
decider.linear2.weight: 0.0063767945393919945 0.05762915313243866
decider.linear2.bias: 0.008472074754536152 0.058178968727588654
decider.linear3.weight: -0.06878376007080078 0.1299341768026352
decider.linear3.bias: -0.06529004871845245 0.09562601894140244

Rewards:
190.8927
190.8927
190.8927
objective = 0.00010998828656738624
==== episode 600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.9867345599777764e-06 0.08543792366981506
encoder.encoder.weight_hh_l0: -0.0006683514220640063 0.08795325458049774
encoder.encoder.bias_ih_l0: 0.014970633201301098 0.08751872181892395
encoder.encoder.bias_hh_l0: 0.0249677374958992 0.08790823072195053
encoder.encoder.weight_ih_l0_reverse: 0.0018292549066245556 0.08721467852592468
encoder.encoder.weight_hh_l0_reverse: 0.0027724711690098047 0.08487733453512192
encoder.encoder.bias_ih_l0_reverse: 0.027881857007741928 0.08643313497304916
encoder.encoder.bias_hh_l0_reverse: 0.019747283309698105 0.08487235754728317
decider.lstm.weight_ih_l0: 0.00046441188897006214 0.14897572994232178
decider.lstm.weight_hh_l0: -0.003129510208964348 0.14785735309123993
decider.lstm.bias_ih_l0: 0.027937406674027443 0.15703779458999634
decider.lstm.bias_hh_l0: 0.00894990935921669 0.14359331130981445
decider.linear1.weight: 0.0009227971895597875 0.12325098365545273
decider.linear1.bias: 0.021034585312008858 0.11617349833250046
decider.linear2.weight: 0.00646569998934865 0.05769875645637512
decider.linear2.bias: 0.00852803885936737 0.05819046124815941
decider.linear3.weight: -0.06878405809402466 0.1299666315317154
decider.linear3.bias: -0.06529044359922409 0.09567564725875854

Rewards:
190.8927
190.8927
190.8927
objective = 7.964667747728527e-05
==== episode 700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 9.404420779901557e-06 0.08545099943876266
encoder.encoder.weight_hh_l0: -0.0006562914932146668 0.087992824614048
encoder.encoder.bias_ih_l0: 0.015069834887981415 0.08753249794244766
encoder.encoder.bias_hh_l0: 0.025066938251256943 0.08792735636234283
encoder.encoder.weight_ih_l0_reverse: 0.0018322011455893517 0.08721913397312164
encoder.encoder.weight_hh_l0_reverse: 0.002786936005577445 0.0848948061466217
encoder.encoder.bias_ih_l0_reverse: 0.027949770912528038 0.08645113557577133
encoder.encoder.bias_hh_l0_reverse: 0.019815199077129364 0.08486364781856537
decider.lstm.weight_ih_l0: 0.00048165148473344743 0.14899449050426483
decider.lstm.weight_hh_l0: -0.0031486304942518473 0.14787186682224274
decider.lstm.bias_ih_l0: 0.027997836470603943 0.1570533663034439
decider.lstm.bias_hh_l0: 0.009010350331664085 0.14359860122203827
decider.linear1.weight: 0.0008789831190370023 0.12333951890468597
decider.linear1.bias: 0.0214013010263443 0.11613017320632935
decider.linear2.weight: 0.006603270769119263 0.057790786027908325
decider.linear2.bias: 0.008571776561439037 0.058198750019073486
decider.linear3.weight: -0.06878422945737839 0.12999297678470612
decider.linear3.bias: -0.065290667116642 0.09571349620819092

Rewards:
190.8927
190.8927
190.8927
objective = 5.3097770432941616e-05
==== episode 800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.4396681763173547e-05 0.08546105027198792
encoder.encoder.weight_hh_l0: -0.0006464451435022056 0.08802231401205063
encoder.encoder.bias_ih_l0: 0.01514151506125927 0.08754284679889679
encoder.encoder.bias_hh_l0: 0.025138620287179947 0.08794185519218445
encoder.encoder.weight_ih_l0_reverse: 0.0018349227029830217 0.08722219616174698
encoder.encoder.weight_hh_l0_reverse: 0.002797838533297181 0.08490801602602005
encoder.encoder.bias_ih_l0_reverse: 0.027999810874462128 0.08646436780691147
encoder.encoder.bias_hh_l0_reverse: 0.019865240901708603 0.08485675603151321
decider.lstm.weight_ih_l0: 0.0004947432898916304 0.14900821447372437
decider.lstm.weight_hh_l0: -0.0031623877584934235 0.1478821188211441
decider.lstm.bias_ih_l0: 0.02804011106491089 0.15706433355808258
decider.lstm.bias_hh_l0: 0.009052617475390434 0.1436019092798233
decider.linear1.weight: 0.0008440943784080446 0.12345083802938461
decider.linear1.bias: 0.021701829507946968 0.1161450520157814
decider.linear2.weight: 0.0067231557331979275 0.05790665000677109
decider.linear2.bias: 0.008602198213338852 0.058203887194395065
decider.linear3.weight: -0.06878428161144257 0.13001203536987305
decider.linear3.bias: -0.06529077142477036 0.09573902189731598

Rewards:
190.8927
190.8927
190.8927
objective = 3.792697680182755e-05
==== episode 900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 1.7711705368128605e-05 0.0854685977101326
encoder.encoder.weight_hh_l0: -0.0006387863541021943 0.08804395794868469
encoder.encoder.bias_ih_l0: 0.015192845836281776 0.08755054324865341
encoder.encoder.bias_hh_l0: 0.025189952924847603 0.08795253932476044
encoder.encoder.weight_ih_l0_reverse: 0.0018371074693277478 0.08722440898418427
encoder.encoder.weight_hh_l0_reverse: 0.002805860247462988 0.08491777628660202
encoder.encoder.bias_ih_l0_reverse: 0.028036076575517654 0.08647393435239792
encoder.encoder.bias_hh_l0_reverse: 0.019901514053344727 0.0848514661192894
decider.lstm.weight_ih_l0: 0.0005044718855060637 0.14901816844940186
decider.lstm.weight_hh_l0: -0.003172192955389619 0.14788934588432312
decider.lstm.bias_ih_l0: 0.028069643303751945 0.15707197785377502
decider.lstm.bias_hh_l0: 0.009082162752747536 0.1436040848493576
decider.linear1.weight: 0.000820167304482311 0.12354825437068939
decider.linear1.bias: 0.021902721375226974 0.11617690324783325
decider.linear2.weight: 0.006788746453821659 0.058007340878248215
decider.linear2.bias: 0.008597150444984436 0.05822424590587616
decider.linear3.weight: -0.06878429651260376 0.1300257295370102
decider.linear3.bias: -0.06529080122709274 0.09575629979372025

Rewards:
190.8927
190.8927
190.8927
objective = 3.0341578167281114e-05
==== episode 1000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.005703754548449e-05 0.08547452837228775
encoder.encoder.weight_hh_l0: -0.000632637704256922 0.08806076645851135
encoder.encoder.bias_ih_l0: 0.015231933444738388 0.08755657076835632
encoder.encoder.bias_hh_l0: 0.025229036808013916 0.08796077221632004
encoder.encoder.weight_ih_l0_reverse: 0.00183887651655823 0.08722615987062454
encoder.encoder.weight_hh_l0_reverse: 0.002812057500705123 0.08492531627416611
encoder.encoder.bias_ih_l0_reverse: 0.028063884004950523 0.08648128807544708
encoder.encoder.bias_hh_l0_reverse: 0.019929323345422745 0.08484724909067154
decider.lstm.weight_ih_l0: 0.0005120811983942986 0.1490257978439331
decider.lstm.weight_hh_l0: -0.003179635852575302 0.14789476990699768
decider.lstm.bias_ih_l0: 0.02809171937406063 0.15707768499851227
decider.lstm.bias_hh_l0: 0.009104220196604729 0.14360566437244415
decider.linear1.weight: 0.0008023111149668694 0.12363129109144211
decider.linear1.bias: 0.0220502857118845 0.11621124297380447
decider.linear2.weight: 0.006849943194538355 0.058090753853321075
decider.linear2.bias: 0.008612087927758694 0.05822760611772537
decider.linear3.weight: -0.06878429651260376 0.13003627955913544
decider.linear3.bias: -0.06529080867767334 0.09576888382434845

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.180792398576159e-05 0.08547937124967575
encoder.encoder.weight_hh_l0: -0.000627558387350291 0.08807425945997238
encoder.encoder.bias_ih_l0: 0.015262837521731853 0.0875614732503891
encoder.encoder.bias_hh_l0: 0.025259945541620255 0.08796738088130951
encoder.encoder.weight_ih_l0_reverse: 0.00184032937977463 0.08722757548093796
encoder.encoder.weight_hh_l0_reverse: 0.002817013766616583 0.08493136614561081
encoder.encoder.bias_ih_l0_reverse: 0.02808600291609764 0.08648711442947388
encoder.encoder.bias_hh_l0_reverse: 0.01995144411921501 0.08484379202127457
decider.lstm.weight_ih_l0: 0.000518227054271847 0.1490318924188614
decider.lstm.weight_hh_l0: -0.0031855038832873106 0.14789900183677673
decider.lstm.bias_ih_l0: 0.028108933940529823 0.15708217024803162
decider.lstm.bias_hh_l0: 0.009121428243815899 0.14360685646533966
decider.linear1.weight: 0.000788240460678935 0.1237032562494278
decider.linear1.bias: 0.022165833041071892 0.11624544858932495
decider.linear2.weight: 0.006898349151015282 0.05816171318292618
decider.linear2.bias: 0.008623977191746235 0.058229658752679825
decider.linear3.weight: -0.06878430396318436 0.13004466891288757
decider.linear3.bias: -0.06529080122709274 0.09577850252389908

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.318050610483624e-05 0.08548348397016525
encoder.encoder.weight_hh_l0: -0.0006232133600860834 0.08808556944131851
encoder.encoder.bias_ih_l0: 0.015288395807147026 0.08756561577320099
encoder.encoder.bias_hh_l0: 0.025285501033067703 0.08797292411327362
encoder.encoder.weight_ih_l0_reverse: 0.0018415614031255245 0.08722876757383347
encoder.encoder.weight_hh_l0_reverse: 0.0028211420867592096 0.08493641763925552
encoder.encoder.bias_ih_l0_reverse: 0.0281043853610754 0.08649194985628128
encoder.encoder.bias_hh_l0_reverse: 0.019969822838902473 0.08484085649251938
decider.lstm.weight_ih_l0: 0.0005234010750427842 0.1490369737148285
decider.lstm.weight_hh_l0: -0.003190335351973772 0.1479025036096573
decider.lstm.bias_ih_l0: 0.028122982010245323 0.1570858359336853
decider.lstm.bias_hh_l0: 0.009135511703789234 0.14360781013965607
decider.linear1.weight: 0.0007766070775687695 0.12376714497804642
decider.linear1.bias: 0.022260937839746475 0.11627862602472305
decider.linear2.weight: 0.00693862047046423 0.0582236647605896
decider.linear2.bias: 0.008633610792458057 0.05823138728737831
decider.linear3.weight: -0.06878430396318436 0.1300516575574875
decider.linear3.bias: -0.06529080122709274 0.09578622877597809

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764856450725347e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.0006212546140886843 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421125132590532 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.0028229705058038235 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794397175312 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257083685137331 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714690873399377 0.12379668653011322
decider.linear1.bias: 0.022302843630313873 0.1162947416305542
decider.linear2.weight: 0.006956404075026512 0.05825222283601761
decider.linear2.bias: 0.008637790568172932 0.058232132345438004
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 1900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 2900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 3900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 4900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 5900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 6900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 7900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 8900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9100/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9200/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9300/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9400/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9500/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9600/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9700/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 9900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
==== episode 10000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 2.3764558136463165e-05 0.08548533171415329
encoder.encoder.weight_hh_l0: -0.000621254148427397 0.08809059113264084
encoder.encoder.bias_ih_l0: 0.015299670398235321 0.08756745606660843
encoder.encoder.bias_hh_l0: 0.02529677376151085 0.08797536790370941
encoder.encoder.weight_ih_l0_reverse: 0.0018421127460896969 0.08722930401563644
encoder.encoder.weight_hh_l0_reverse: 0.002822970738634467 0.0849386602640152
encoder.encoder.bias_ih_l0_reverse: 0.02811250649392605 0.0864940658211708
encoder.encoder.bias_hh_l0_reverse: 0.01997794583439827 0.08483952283859253
decider.lstm.weight_ih_l0: 0.0005257086595520377 0.14903920888900757
decider.lstm.weight_hh_l0: -0.00319246225990355 0.14790402352809906
decider.lstm.bias_ih_l0: 0.028129100799560547 0.15708738565444946
decider.lstm.bias_hh_l0: 0.009141654707491398 0.1436082273721695
decider.linear1.weight: 0.0007714677485637367 0.12379670143127441
decider.linear1.bias: 0.022302856668829918 0.1162947490811348
decider.linear2.weight: 0.0069564091973006725 0.058252234011888504
decider.linear2.bias: 0.008637790568172932 0.058232128620147705
decider.linear3.weight: -0.06878430396318436 0.1300547569990158
decider.linear3.bias: -0.06529079377651215 0.09578957408666611

Rewards:
190.8927
190.8927
190.8927
objective = 2.2756183170713484e-05
[INFO] : learning runtime (h:mm:ss): 0:02:24
[INFO] : learning end time: 12/17/2023 06:59:53 PM
