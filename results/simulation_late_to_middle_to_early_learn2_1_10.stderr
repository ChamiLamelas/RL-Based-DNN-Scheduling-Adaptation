Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 06:54:56 PM
==== episode 1/10000 ====
action = 0
probs = 0.2512 0.2611 0.2438 0.2438

action = 0
probs = 0.2521 0.2604 0.2437 0.2437

action = 0
probs = 0.2673 0.2454 0.2436 0.2436

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00011580906721064821 0.08513176441192627
encoder.encoder.weight_hh_l0: -4.160356638749363e-06 0.08702121675014496
encoder.encoder.bias_ih_l0: 0.013103625737130642 0.08853939175605774
encoder.encoder.bias_hh_l0: 0.023100702092051506 0.08665937185287476
encoder.encoder.weight_ih_l0_reverse: 0.0017393972957506776 0.08759302645921707
encoder.encoder.weight_hh_l0_reverse: 0.008571128360927105 0.08697651326656342
encoder.encoder.bias_ih_l0_reverse: 0.03424810245633125 0.08543713390827179
encoder.encoder.bias_hh_l0_reverse: 0.026113685220479965 0.08291249722242355
decider.lstm.weight_ih_l0: 0.00153682054951787 0.14825321733951569
decider.lstm.weight_hh_l0: 0.0029564755968749523 0.14796967804431915
decider.lstm.bias_ih_l0: 0.022714389488101006 0.15885254740715027
decider.lstm.bias_hh_l0: 0.003726907540112734 0.14087863266468048
decider.linear1.weight: 0.00447314977645874 0.12142177671194077
decider.linear1.bias: 0.01926344819366932 0.1174999475479126
decider.linear2.weight: 0.005317486822605133 0.053652629256248474
decider.linear2.bias: 0.008689959533512592 0.05725189298391342
decider.linear3.weight: -0.010411988943815231 0.06001835688948631
decider.linear3.bias: 0.011718419380486012 0.05202840641140938

Rewards:
211.9920
211.9920
211.9920
objective = 288.2076110839844
==== episode 100/10000 ====
action = 0
probs = 0.2943 0.7030 0.0009 0.0018

action = 0
probs = 0.4371 0.5625 0.0001 0.0002

action = 0
probs = 0.9601 0.0398 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000125852893688716 0.08525127917528152
encoder.encoder.weight_hh_l0: -1.1565923614398343e-06 0.08716338127851486
encoder.encoder.bias_ih_l0: 0.013493504375219345 0.08873692899942398
encoder.encoder.bias_hh_l0: 0.023490577936172485 0.08679544925689697
encoder.encoder.weight_ih_l0_reverse: 0.0017509844619780779 0.08772135525941849
encoder.encoder.weight_hh_l0_reverse: 0.008735856041312218 0.08710948377847672
encoder.encoder.bias_ih_l0_reverse: 0.03455333039164543 0.08550897240638733
encoder.encoder.bias_hh_l0_reverse: 0.026418915018439293 0.08290936052799225
decider.lstm.weight_ih_l0: 0.0016324701718986034 0.14838846027851105
decider.lstm.weight_hh_l0: 0.003008176339790225 0.14804495871067047
decider.lstm.bias_ih_l0: 0.023192763328552246 0.1588515192270279
decider.lstm.bias_hh_l0: 0.004205270670354366 0.14088228344917297
decider.linear1.weight: 0.00447418075054884 0.12145689874887466
decider.linear1.bias: 0.019402801990509033 0.11758632212877274
decider.linear2.weight: 0.005426804069429636 0.05370412394404411
decider.linear2.bias: 0.008807395584881306 0.05732891336083412
decider.linear3.weight: -0.013599025085568428 0.0614883191883564
decider.linear3.bias: 0.007430476136505604 0.04993843659758568

Rewards:
211.9920
211.9920
211.9920
objective = 147.78990173339844
==== episode 200/10000 ====
action = 1
probs = 0.2538 0.7448 0.0004 0.0009

action = 1
probs = 0.4502 0.5496 0.0001 0.0001

action = 0
probs = 0.9804 0.0196 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0001601748081156984 0.08542055636644363
encoder.encoder.weight_hh_l0: -7.185697540990077e-06 0.08737258613109589
encoder.encoder.bias_ih_l0: 0.014083163812756538 0.08899740874767303
encoder.encoder.bias_hh_l0: 0.024080241098999977 0.08700300008058548
encoder.encoder.weight_ih_l0_reverse: 0.0017626500921323895 0.08791739493608475
encoder.encoder.weight_hh_l0_reverse: 0.008785998448729515 0.08718191832304001
encoder.encoder.bias_ih_l0_reverse: 0.034864865243434906 0.08563270419836044
encoder.encoder.bias_hh_l0_reverse: 0.026730453595519066 0.0829218327999115
decider.lstm.weight_ih_l0: 0.0017667191568762064 0.14853966236114502
decider.lstm.weight_hh_l0: 0.0030939613934606314 0.1481432467699051
decider.lstm.bias_ih_l0: 0.023849450051784515 0.15894363820552826
decider.lstm.bias_hh_l0: 0.0048619601875543594 0.1408783346414566
decider.linear1.weight: 0.0044744438491761684 0.12154951691627502
decider.linear1.bias: 0.019813740625977516 0.11769149452447891
decider.linear2.weight: 0.005615120753645897 0.05380566418170929
decider.linear2.bias: 0.008966625668108463 0.05737267807126045
decider.linear3.weight: -0.015744399279356003 0.06269704550504684
decider.linear3.bias: 0.0045971954241395 0.048725634813308716

Rewards:
230.1930
230.1930
230.1930
objective = 70.05377197265625
==== episode 300/10000 ====
action = 1
probs = 0.1661 0.8332 0.0002 0.0005

action = 0
probs = 0.5493 0.4506 0.0000 0.0001

action = 0
probs = 0.9894 0.0106 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002238590968772769 0.08562501519918442
encoder.encoder.weight_hh_l0: -2.745857091213111e-05 0.08761406689882278
encoder.encoder.bias_ih_l0: 0.01478599477559328 0.08927185833454132
encoder.encoder.bias_hh_l0: 0.024783071130514145 0.08718295395374298
encoder.encoder.weight_ih_l0_reverse: 0.0018085036426782608 0.08812011033296585
encoder.encoder.weight_hh_l0_reverse: 0.008865328505635262 0.08729162812232971
encoder.encoder.bias_ih_l0_reverse: 0.03522143140435219 0.08574235439300537
encoder.encoder.bias_hh_l0_reverse: 0.02708701603114605 0.08287017047405243
decider.lstm.weight_ih_l0: 0.0018755897181108594 0.14868290722370148
decider.lstm.weight_hh_l0: 0.0031679386738687754 0.14825212955474854
decider.lstm.bias_ih_l0: 0.024407509714365005 0.15913066267967224
decider.lstm.bias_hh_l0: 0.0054200179874897 0.14082492887973785
decider.linear1.weight: 0.004454521462321281 0.12162785232067108
decider.linear1.bias: 0.020165055990219116 0.11773277074098587
decider.linear2.weight: 0.005674777552485466 0.05387122929096222
decider.linear2.bias: 0.009088592603802681 0.057395003736019135
decider.linear3.weight: -0.017179561778903008 0.06360859423875809
decider.linear3.bias: 0.0027385386638343334 0.04830962046980858

Rewards:
221.7540
221.7540
221.7540
objective = 58.566009521484375
==== episode 400/10000 ====
action = 0
probs = 0.1522 0.8472 0.0002 0.0003

action = 0
probs = 0.6789 0.3211 0.0000 0.0000

action = 0
probs = 0.9913 0.0087 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00022995802282821387 0.08564190566539764
encoder.encoder.weight_hh_l0: -2.6380443159723654e-05 0.08762948960065842
encoder.encoder.bias_ih_l0: 0.014811036176979542 0.08929089456796646
encoder.encoder.bias_hh_l0: 0.024808110669255257 0.08719740062952042
encoder.encoder.weight_ih_l0_reverse: 0.001810794579796493 0.08812172710895538
encoder.encoder.weight_hh_l0_reverse: 0.008889956399798393 0.08731618523597717
encoder.encoder.bias_ih_l0_reverse: 0.03522675856947899 0.08574819564819336
encoder.encoder.bias_hh_l0_reverse: 0.027092337608337402 0.08285818994045258
decider.lstm.weight_ih_l0: 0.0018806629814207554 0.14869876205921173
decider.lstm.weight_hh_l0: 0.0031702073756605387 0.14827336370944977
decider.lstm.bias_ih_l0: 0.024418700486421585 0.1591702103614807
decider.lstm.bias_hh_l0: 0.005431215278804302 0.14080996811389923
decider.linear1.weight: 0.0044502392411231995 0.12162300944328308
decider.linear1.bias: 0.020133469253778458 0.11765168607234955
decider.linear2.weight: 0.005645114928483963 0.053869180381298065
decider.linear2.bias: 0.009072095155715942 0.05738944560289383
decider.linear3.weight: -0.018280930817127228 0.06418967247009277
decider.linear3.bias: 0.0014565023593604565 0.04802600294351578

Rewards:
211.9920
211.9920
211.9920
objective = 161.0019989013672
==== episode 500/10000 ====
action = 1
probs = 0.1113 0.8883 0.0001 0.0002

action = 0
probs = 0.4482 0.5517 0.0000 0.0000

action = 0
probs = 0.9838 0.0161 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00024350023886654526 0.0856330618262291
encoder.encoder.weight_hh_l0: -2.4327671781065874e-05 0.08760238438844681
encoder.encoder.bias_ih_l0: 0.014744946733117104 0.08925945311784744
encoder.encoder.bias_hh_l0: 0.024742020294070244 0.08719414472579956
encoder.encoder.weight_ih_l0_reverse: 0.001833555055782199 0.08813942223787308
encoder.encoder.weight_hh_l0_reverse: 0.008923191577196121 0.08735789358615875
encoder.encoder.bias_ih_l0_reverse: 0.03533841297030449 0.08576302230358124
encoder.encoder.bias_hh_l0_reverse: 0.02720399759709835 0.0829211175441742
decider.lstm.weight_ih_l0: 0.001886871992610395 0.14870081841945648
decider.lstm.weight_hh_l0: 0.0031721177510917187 0.14828872680664062
decider.lstm.bias_ih_l0: 0.024416791275143623 0.15921470522880554
decider.lstm.bias_hh_l0: 0.005429313518106937 0.14075475931167603
decider.linear1.weight: 0.004453313536942005 0.12162502855062485
decider.linear1.bias: 0.020131021738052368 0.11767127364873886
decider.linear2.weight: 0.005632977932691574 0.053870584815740585
decider.linear2.bias: 0.00901979673653841 0.05739426612854004
decider.linear3.weight: -0.019262023270130157 0.06476888060569763
decider.linear3.bias: 0.0003211912699043751 0.04813612625002861

Rewards:
221.7540
221.7540
221.7540
objective = 69.2726821899414
==== episode 600/10000 ====
action = 1
probs = 0.0741 0.9257 0.0001 0.0002

action = 0
probs = 0.2988 0.7012 0.0000 0.0000

action = 1
probs = 0.9773 0.0227 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002554650418460369 0.08564235270023346
encoder.encoder.weight_hh_l0: -2.0739793399116024e-05 0.0875919759273529
encoder.encoder.bias_ih_l0: 0.014713053591549397 0.08922948688268661
encoder.encoder.bias_hh_l0: 0.024710126221179962 0.08720923960208893
encoder.encoder.weight_ih_l0_reverse: 0.0018551255343481898 0.08817023038864136
encoder.encoder.weight_hh_l0_reverse: 0.008960929699242115 0.0874062180519104
encoder.encoder.bias_ih_l0_reverse: 0.035472236573696136 0.08577648550271988
encoder.encoder.bias_hh_l0_reverse: 0.02733781933784485 0.08299803733825684
decider.lstm.weight_ih_l0: 0.0019169937586411834 0.1487203687429428
decider.lstm.weight_hh_l0: 0.003188741859048605 0.14831019937992096
decider.lstm.bias_ih_l0: 0.02452877163887024 0.15930207073688507
decider.lstm.bias_hh_l0: 0.005541300401091576 0.14073185622692108
decider.linear1.weight: 0.0044546229764819145 0.12163747847080231
decider.linear1.bias: 0.02016168273985386 0.11767638474702835
decider.linear2.weight: 0.0056070624850690365 0.05387277528643608
decider.linear2.bias: 0.008967895992100239 0.05741006135940552
decider.linear3.weight: -0.020044347271323204 0.06527156382799149
decider.linear3.bias: -0.0005791494622826576 0.0484747551381588

Rewards:
229.4037
229.4037
229.4037
objective = 387.7613525390625
==== episode 700/10000 ====
action = 1
probs = 0.0508 0.9491 0.0001 0.0001

action = 0
probs = 0.2020 0.7979 0.0000 0.0000

action = 0
probs = 0.9603 0.0397 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002666772052180022 0.08566747605800629
encoder.encoder.weight_hh_l0: -1.5162944691837765e-05 0.08760479092597961
encoder.encoder.bias_ih_l0: 0.014718763530254364 0.08923308551311493
encoder.encoder.bias_hh_l0: 0.024715833365917206 0.08723806589841843
encoder.encoder.weight_ih_l0_reverse: 0.001867597340606153 0.08818739652633667
encoder.encoder.weight_hh_l0_reverse: 0.009011062793433666 0.087459996342659
encoder.encoder.bias_ih_l0_reverse: 0.03559565544128418 0.08579039573669434
encoder.encoder.bias_hh_l0_reverse: 0.027461238205432892 0.0830494612455368
decider.lstm.weight_ih_l0: 0.0019503614166751504 0.14875225722789764
decider.lstm.weight_hh_l0: 0.003206229070201516 0.14834077656269073
decider.lstm.bias_ih_l0: 0.024649260565638542 0.15939651429653168
decider.lstm.bias_hh_l0: 0.00566178560256958 0.14072196185588837
decider.linear1.weight: 0.0044499533250927925 0.12163644284009933
decider.linear1.bias: 0.020127534866333008 0.11768006533384323
decider.linear2.weight: 0.005546517204493284 0.05386330187320709
decider.linear2.bias: 0.008917134255170822 0.05742409825325012
decider.linear3.weight: -0.020689737051725388 0.06567966192960739
decider.linear3.bias: -0.0013151455204933882 0.048832762986421585

Rewards:
221.7540
221.7540
221.7540
objective = 125.08016967773438
==== episode 800/10000 ====
action = 1
probs = 0.0473 0.9525 0.0001 0.0001

action = 1
probs = 0.1440 0.8559 0.0000 0.0000

action = 0
probs = 0.8781 0.1219 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00025438383454456925 0.08555170148611069
encoder.encoder.weight_hh_l0: -1.1384284334781114e-05 0.08743482828140259
encoder.encoder.bias_ih_l0: 0.014297579415142536 0.08901795744895935
encoder.encoder.bias_hh_l0: 0.024294648319482803 0.08710236102342606
encoder.encoder.weight_ih_l0_reverse: 0.0018640580819919705 0.08805638551712036
encoder.encoder.weight_hh_l0_reverse: 0.009026560932397842 0.08745801448822021
encoder.encoder.bias_ih_l0_reverse: 0.0354943573474884 0.08569198846817017
encoder.encoder.bias_hh_l0_reverse: 0.027359941974282265 0.08305910229682922
decider.lstm.weight_ih_l0: 0.0018603525822982192 0.14863289892673492
decider.lstm.weight_hh_l0: 0.0031389812938869 0.1482517570257187
decider.lstm.bias_ih_l0: 0.024171307682991028 0.15938995778560638
decider.lstm.bias_hh_l0: 0.00518382340669632 0.14058910310268402
decider.linear1.weight: 0.004447389394044876 0.12156212329864502
decider.linear1.bias: 0.019777623936533928 0.11763087660074234
decider.linear2.weight: 0.0053825462237000465 0.05379852280020714
decider.linear2.bias: 0.008750486187636852 0.057422034442424774
decider.linear3.weight: -0.021235480904579163 0.0659104734659195
decider.linear3.bias: -0.0019201883114874363 0.04911532625555992

Rewards:
230.1930
230.1930
230.1930
objective = 25.647705078125
==== episode 900/10000 ====
action = 1
probs = 0.0310 0.9689 0.0000 0.0001

action = 1
probs = 0.1107 0.8893 0.0000 0.0000

action = 0
probs = 0.9223 0.0777 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00027277335175313056 0.08570781350135803
encoder.encoder.weight_hh_l0: -7.837093107809778e-06 0.08763670921325684
encoder.encoder.bias_ih_l0: 0.014703821390867233 0.08925560861825943
encoder.encoder.bias_hh_l0: 0.024700889363884926 0.08730209618806839
encoder.encoder.weight_ih_l0_reverse: 0.0018752634059637785 0.08821263909339905
encoder.encoder.weight_hh_l0_reverse: 0.009076780639588833 0.08754201978445053
encoder.encoder.bias_ih_l0_reverse: 0.03571713715791702 0.08581580966711044
encoder.encoder.bias_hh_l0_reverse: 0.027582723647356033 0.0831262394785881
decider.lstm.weight_ih_l0: 0.0020180039573460817 0.14882241189479828
decider.lstm.weight_hh_l0: 0.003242173930630088 0.14839576184749603
decider.lstm.bias_ih_l0: 0.024911774322390556 0.15947259962558746
decider.lstm.bias_hh_l0: 0.0059242844581604 0.14075395464897156
decider.linear1.weight: 0.004444302059710026 0.12164396047592163
decider.linear1.bias: 0.02012372948229313 0.11768718808889389
decider.linear2.weight: 0.00544359814375639 0.053862668573856354
decider.linear2.bias: 0.008844037540256977 0.05743644759058952
decider.linear3.weight: -0.021698730066418648 0.06634243577718735
decider.linear3.bias: -0.0024067210033535957 0.04928174242377281

Rewards:
230.1930
230.1930
230.1930
objective = 17.635099411010742
==== episode 1000/10000 ====
action = 1
probs = 0.0320 0.9679 0.0000 0.0001

action = 1
probs = 0.1277 0.8723 0.0000 0.0000

action = 1
probs = 0.9518 0.0482 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00026577457902021706 0.0857391208410263
encoder.encoder.weight_hh_l0: -1.0509991625440307e-05 0.08768797665834427
encoder.encoder.bias_ih_l0: 0.014780623838305473 0.08932267874479294
encoder.encoder.bias_hh_l0: 0.024777693673968315 0.08736120909452438
encoder.encoder.weight_ih_l0_reverse: 0.0018734597833827138 0.08824547380208969
encoder.encoder.weight_hh_l0_reverse: 0.009064234793186188 0.08753922581672668
encoder.encoder.bias_ih_l0_reverse: 0.03570929542183876 0.08584290742874146
encoder.encoder.bias_hh_l0_reverse: 0.02757488191127777 0.08311671018600464
decider.lstm.weight_ih_l0: 0.0020454623736441135 0.14886395633220673
decider.lstm.weight_hh_l0: 0.0032648234628140926 0.1484237015247345
decider.lstm.bias_ih_l0: 0.025067199021577835 0.15946121513843536
decider.lstm.bias_hh_l0: 0.006079694256186485 0.1408032327890396
decider.linear1.weight: 0.0044460054486989975 0.1216689795255661
decider.linear1.bias: 0.020237859338521957 0.11771784722805023
decider.linear2.weight: 0.0054679992608726025 0.0538950152695179
decider.linear2.bias: 0.008872000500559807 0.057412438094615936
decider.linear3.weight: -0.022069264203310013 0.06662068516016006
decider.linear3.bias: -0.0027739370707422495 0.04904617369174957

Rewards:
217.8160
217.8160
217.8160
objective = 232.49571228027344
==== episode 1100/10000 ====
action = 1
probs = 0.0186 0.9813 0.0000 0.0000

action = 1
probs = 0.0589 0.9411 0.0000 0.0000

action = 0
probs = 0.8835 0.1165 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002793149324133992 0.08577482402324677
encoder.encoder.weight_hh_l0: -7.117080713214818e-06 0.08770475536584854
encoder.encoder.bias_ih_l0: 0.014788572676479816 0.08931008726358414
encoder.encoder.bias_hh_l0: 0.024785641580820084 0.0873999372124672
encoder.encoder.weight_ih_l0_reverse: 0.0018823094433173537 0.08826122432947159
encoder.encoder.weight_hh_l0_reverse: 0.009115064516663551 0.0875953882932663
encoder.encoder.bias_ih_l0_reverse: 0.035853251814842224 0.08583676815032959
encoder.encoder.bias_hh_l0_reverse: 0.027718838304281235 0.08319177478551865
decider.lstm.weight_ih_l0: 0.002075562486425042 0.14887893199920654
decider.lstm.weight_hh_l0: 0.0032789139077067375 0.14843975007534027
decider.lstm.bias_ih_l0: 0.025173280388116837 0.15952454507350922
decider.lstm.bias_hh_l0: 0.006185776088386774 0.14074945449829102
decider.linear1.weight: 0.004437012132257223 0.12167646735906601
decider.linear1.bias: 0.020171230658888817 0.11770825833082199
decider.linear2.weight: 0.005398042965680361 0.0538809634745121
decider.linear2.bias: 0.008792423643171787 0.05745420604944229
decider.linear3.weight: -0.022555746138095856 0.06694772839546204
decider.linear3.bias: -0.00310755823738873 0.04982896149158478

Rewards:
230.1930
230.1930
230.1930
objective = 15.609354019165039
==== episode 1200/10000 ====
action = 1
probs = 0.0276 0.9723 0.0000 0.0000

action = 1
probs = 0.1060 0.8940 0.0000 0.0000

action = 0
probs = 0.9224 0.0776 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00025155788171105087 0.08571760356426239
encoder.encoder.weight_hh_l0: -1.537418370389787e-06 0.0876438319683075
encoder.encoder.bias_ih_l0: 0.014563092961907387 0.08928117156028748
encoder.encoder.bias_hh_l0: 0.024560164660215378 0.08733733743429184
encoder.encoder.weight_ih_l0_reverse: 0.0018833020003512502 0.08818431943655014
encoder.encoder.weight_hh_l0_reverse: 0.009127076715230942 0.08759938925504684
encoder.encoder.bias_ih_l0_reverse: 0.035669825971126556 0.08581569790840149
encoder.encoder.bias_hh_l0_reverse: 0.027535418048501015 0.08312179148197174
decider.lstm.weight_ih_l0: 0.002028264570981264 0.14885038137435913
decider.lstm.weight_hh_l0: 0.0032438465859740973 0.14841558039188385
decider.lstm.bias_ih_l0: 0.02493255026638508 0.15946964919567108
decider.lstm.bias_hh_l0: 0.0059450408443808556 0.1407800167798996
decider.linear1.weight: 0.004435158800333738 0.12162507325410843
decider.linear1.bias: 0.01999063789844513 0.11769374459981918
decider.linear2.weight: 0.005353206302970648 0.05387837439775467
decider.linear2.bias: 0.008726338855922222 0.057417143136262894
decider.linear3.weight: -0.023015988990664482 0.06719990074634552
decider.linear3.bias: -0.0034509021788835526 0.04922797158360481

Rewards:
230.1930
230.1930
230.1930
objective = 16.943851470947266
==== episode 1300/10000 ====
action = 1
probs = 0.0545 0.9454 0.0000 0.0001

action = 1
probs = 0.1945 0.8055 0.0000 0.0000

action = 0
probs = 0.9542 0.0458 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000221257985685952 0.08558441698551178
encoder.encoder.weight_hh_l0: -2.5934100449376274e-06 0.0874992161989212
encoder.encoder.bias_ih_l0: 0.014182829298079014 0.08913358300924301
encoder.encoder.bias_hh_l0: 0.02417990192770958 0.08718599379062653
encoder.encoder.weight_ih_l0_reverse: 0.0018818548414856195 0.08808525651693344
encoder.encoder.weight_hh_l0_reverse: 0.009093038737773895 0.08755967766046524
encoder.encoder.bias_ih_l0_reverse: 0.035426829010248184 0.08577051013708115
encoder.encoder.bias_hh_l0_reverse: 0.027292422950267792 0.08306164294481277
decider.lstm.weight_ih_l0: 0.0019282613648101687 0.14874742925167084
decider.lstm.weight_hh_l0: 0.0031821695156395435 0.1483248472213745
decider.lstm.bias_ih_l0: 0.02446076273918152 0.159321591258049
decider.lstm.bias_hh_l0: 0.00547326123341918 0.14077222347259521
decider.linear1.weight: 0.004447780083864927 0.12157798558473587
decider.linear1.bias: 0.01978963613510132 0.11767712235450745
decider.linear2.weight: 0.005354081746190786 0.05387212336063385
decider.linear2.bias: 0.008712353184819221 0.05739675834774971
decider.linear3.weight: -0.0235416479408741 0.06754618883132935
decider.linear3.bias: -0.003988342359662056 0.04836757108569145

Rewards:
230.1930
230.1930
230.1930
objective = 24.50192642211914
==== episode 1400/10000 ====
action = 1
probs = 0.0510 0.9489 0.0001 0.0001

action = 1
probs = 0.1458 0.8542 0.0000 0.0000

action = 1
probs = 0.8370 0.1630 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00020217261044308543 0.08533353358507156
encoder.encoder.weight_hh_l0: -1.3298749763634987e-05 0.08720113337039948
encoder.encoder.bias_ih_l0: 0.013387464918196201 0.08879518508911133
encoder.encoder.bias_hh_l0: 0.023384537547826767 0.08688069880008698
encoder.encoder.weight_ih_l0_reverse: 0.0019294189987704158 0.08785644918680191
encoder.encoder.weight_hh_l0_reverse: 0.009129748679697514 0.08756588399410248
encoder.encoder.bias_ih_l0_reverse: 0.03522827476263046 0.08559207618236542
encoder.encoder.bias_hh_l0_reverse: 0.02709386497735977 0.08310523629188538
decider.lstm.weight_ih_l0: 0.0017242783214896917 0.14852610230445862
decider.lstm.weight_hh_l0: 0.003062495496124029 0.14815551042556763
decider.lstm.bias_ih_l0: 0.023447111248970032 0.15931443870067596
decider.lstm.bias_hh_l0: 0.0044596134684979916 0.14055202901363373
decider.linear1.weight: 0.004439746495336294 0.12141986191272736
decider.linear1.bias: 0.01911330036818981 0.11752442270517349
decider.linear2.weight: 0.0050017349421978 0.05375487729907036
decider.linear2.bias: 0.008188641630113125 0.0572483092546463
decider.linear3.weight: -0.023798689246177673 0.06757685542106628
decider.linear3.bias: -0.003985980991274118 0.0489114485681057

Rewards:
217.8160
217.8160
217.8160
objective = 146.96484375
==== episode 1500/10000 ====
action = 1
probs = 0.0908 0.9090 0.0001 0.0001

action = 1
probs = 0.3362 0.6637 0.0000 0.0000

action = 0
probs = 0.9380 0.0620 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00019118684576824307 0.08539333194494247
encoder.encoder.weight_hh_l0: -3.2086370538308984e-07 0.08728092908859253
encoder.encoder.bias_ih_l0: 0.01356393750756979 0.08895646035671234
encoder.encoder.bias_hh_l0: 0.023561004549264908 0.08683664351701736
encoder.encoder.weight_ih_l0_reverse: 0.001918602385558188 0.0878584235906601
encoder.encoder.weight_hh_l0_reverse: 0.009189770556986332 0.08762647956609726
encoder.encoder.bias_ih_l0_reverse: 0.03513377904891968 0.0856371819972992
encoder.encoder.bias_hh_l0_reverse: 0.026999372988939285 0.08295562118291855
decider.lstm.weight_ih_l0: 0.001771546434611082 0.1486397534608841
decider.lstm.weight_hh_l0: 0.0030855401419103146 0.14823991060256958
decider.lstm.bias_ih_l0: 0.023663125932216644 0.1592417061328888
decider.lstm.bias_hh_l0: 0.004675624426454306 0.1407930850982666
decider.linear1.weight: 0.004442296922206879 0.12142065167427063
decider.linear1.bias: 0.019183162599802017 0.1175503209233284
decider.linear2.weight: 0.005070475395768881 0.05379185453057289
decider.linear2.bias: 0.008282439783215523 0.05721507593989372
decider.linear3.weight: -0.02443937212228775 0.06812093406915665
decider.linear3.bias: -0.004438130185008049 0.0475178137421608

Rewards:
230.1930
230.1930
230.1930
objective = 43.6861572265625
==== episode 1600/10000 ====
action = 1
probs = 0.1140 0.8858 0.0001 0.0001

action = 1
probs = 0.4869 0.5130 0.0000 0.0000

action = 0
probs = 0.9684 0.0316 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00020408946147654206 0.085495725274086
encoder.encoder.weight_hh_l0: 1.5166878256422933e-05 0.08738517016172409
encoder.encoder.bias_ih_l0: 0.013843030668795109 0.08912891894578934
encoder.encoder.bias_hh_l0: 0.023840097710490227 0.08688409626483917
encoder.encoder.weight_ih_l0_reverse: 0.0019062962383031845 0.0879138931632042
encoder.encoder.weight_hh_l0_reverse: 0.009220571257174015 0.08766824007034302
encoder.encoder.bias_ih_l0_reverse: 0.0351673923432827 0.08570864051580429
encoder.encoder.bias_hh_l0_reverse: 0.02703298255801201 0.08289270848035812
decider.lstm.weight_ih_l0: 0.0018518450669944286 0.1487596184015274
decider.lstm.weight_hh_l0: 0.003120837267488241 0.14833936095237732
decider.lstm.bias_ih_l0: 0.024019332602620125 0.15936985611915588
decider.lstm.bias_hh_l0: 0.005031826440244913 0.14093969762325287
decider.linear1.weight: 0.004439567215740681 0.1214478388428688
decider.linear1.bias: 0.019336696714162827 0.11757013201713562
decider.linear2.weight: 0.005146761424839497 0.0538342222571373
decider.linear2.bias: 0.008391880430281162 0.05718982592225075
decider.linear3.weight: -0.025075212121009827 0.06873150914907455
decider.linear3.bias: -0.005005871877074242 0.04677378013730049

Rewards:
230.1930
230.1930
230.1930
objective = 62.98138427734375
==== episode 1700/10000 ====
action = 1
probs = 0.1434 0.8564 0.0001 0.0001

action = 1
probs = 0.7238 0.2762 0.0000 0.0000

action = 0
probs = 0.9886 0.0114 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002283220674144104 0.085689477622509
encoder.encoder.weight_hh_l0: 3.188744813087396e-05 0.08759868144989014
encoder.encoder.bias_ih_l0: 0.014396348968148232 0.08940130472183228
encoder.encoder.bias_hh_l0: 0.024393415078520775 0.08702770620584488
encoder.encoder.weight_ih_l0_reverse: 0.0018805342260748148 0.08802255988121033
encoder.encoder.weight_hh_l0_reverse: 0.009233090095221996 0.0877007320523262
encoder.encoder.bias_ih_l0_reverse: 0.03528144210577011 0.08580678701400757
encoder.encoder.bias_hh_l0_reverse: 0.02714703045785427 0.08275732398033142
decider.lstm.weight_ih_l0: 0.0019647234585136175 0.1489260196685791
decider.lstm.weight_hh_l0: 0.003180811647325754 0.14846934378147125
decider.lstm.bias_ih_l0: 0.02456848695874214 0.15953367948532104
decider.lstm.bias_hh_l0: 0.005580982193350792 0.14111921191215515
decider.linear1.weight: 0.004426024854183197 0.12152381241321564
decider.linear1.bias: 0.01967369206249714 0.11765346676111221
decider.linear2.weight: 0.005251850001513958 0.053917452692985535
decider.linear2.bias: 0.008601069450378418 0.05720256641507149
decider.linear3.weight: -0.025579217821359634 0.0692959800362587
decider.linear3.bias: -0.005482260137796402 0.04585173353552818

Rewards:
230.1930
230.1930
230.1930
objective = 111.49945068359375
==== episode 1800/10000 ====
action = 1
probs = 0.0761 0.9238 0.0001 0.0001

action = 1
probs = 0.5677 0.4323 0.0000 0.0000

action = 0
probs = 0.9820 0.0180 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00024147535441443324 0.085717111825943
encoder.encoder.weight_hh_l0: 3.251493035349995e-05 0.08760509639978409
encoder.encoder.bias_ih_l0: 0.01435411162674427 0.08937541395425797
encoder.encoder.bias_hh_l0: 0.024351181462407112 0.08708331733942032
encoder.encoder.weight_ih_l0_reverse: 0.0019064572406932712 0.08804391324520111
encoder.encoder.weight_hh_l0_reverse: 0.009265155531466007 0.08774638175964355
encoder.encoder.bias_ih_l0_reverse: 0.035381291061639786 0.08581159263849258
encoder.encoder.bias_hh_l0_reverse: 0.027246885001659393 0.08280792087316513
decider.lstm.weight_ih_l0: 0.0019997190684080124 0.14894838631153107
decider.lstm.weight_hh_l0: 0.0031953323632478714 0.1485106199979782
decider.lstm.bias_ih_l0: 0.024701585993170738 0.15961937606334686
decider.lstm.bias_hh_l0: 0.0057140858843922615 0.141047865152359
decider.linear1.weight: 0.004423999227583408 0.12152301520109177
decider.linear1.bias: 0.019653262570500374 0.11762766540050507
decider.linear2.weight: 0.005176536738872528 0.05392184108495712
decider.linear2.bias: 0.008493230678141117 0.05720614269375801
decider.linear3.weight: -0.026006756350398064 0.06971148401498795
decider.linear3.bias: -0.0058580609038472176 0.04657726362347603

Rewards:
230.1930
230.1930
230.1930
objective = 71.83373260498047
==== episode 1900/10000 ====
action = 1
probs = 0.0542 0.9457 0.0001 0.0000

action = 0
probs = 0.6170 0.3829 0.0000 0.0000

action = 0
probs = 0.9860 0.0140 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00027065383619628847 0.08583548665046692
encoder.encoder.weight_hh_l0: 4.212183921481483e-05 0.0877256914973259
encoder.encoder.bias_ih_l0: 0.01466407347470522 0.08951113373041153
encoder.encoder.bias_hh_l0: 0.024661144241690636 0.08717573434114456
encoder.encoder.weight_ih_l0_reverse: 0.0019027757225558162 0.08810897916555405
encoder.encoder.weight_hh_l0_reverse: 0.009273568168282509 0.08777355402708054
encoder.encoder.bias_ih_l0_reverse: 0.03548860549926758 0.08587750792503357
encoder.encoder.bias_hh_l0_reverse: 0.027354197576642036 0.0827673152089119
decider.lstm.weight_ih_l0: 0.0020660939626395702 0.14903448522090912
decider.lstm.weight_hh_l0: 0.003231924260035157 0.1485981047153473
decider.lstm.bias_ih_l0: 0.025029852986335754 0.15975113213062286
decider.lstm.bias_hh_l0: 0.006042344495654106 0.14105068147182465
decider.linear1.weight: 0.004403744824230671 0.12157345563173294
decider.linear1.bias: 0.019876297563314438 0.11761749535799026
decider.linear2.weight: 0.005212901625782251 0.053975027054548264
decider.linear2.bias: 0.00858862791210413 0.05715499818325043
decider.linear3.weight: -0.02640955150127411 0.07018676400184631
decider.linear3.bias: -0.006163949146866798 0.04660126194357872

Rewards:
221.7540
221.7540
221.7540
objective = 40.86102294921875
==== episode 2000/10000 ====
action = 1
probs = 0.0210 0.9790 0.0000 0.0000

action = 0
probs = 0.2904 0.7095 0.0000 0.0000

action = 0
probs = 0.9559 0.0441 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002906168228946626 0.08587595820426941
encoder.encoder.weight_hh_l0: 4.24621939600911e-05 0.08773009479045868
encoder.encoder.bias_ih_l0: 0.014652837999165058 0.08947324752807617
encoder.encoder.bias_hh_l0: 0.024649905040860176 0.08724381029605865
encoder.encoder.weight_ih_l0_reverse: 0.0019285588059574366 0.08813796192407608
encoder.encoder.weight_hh_l0_reverse: 0.009312799200415611 0.08782128989696503
encoder.encoder.bias_ih_l0_reverse: 0.03561120480298996 0.085851289331913
encoder.encoder.bias_hh_l0_reverse: 0.027476796880364418 0.08287721127271652
decider.lstm.weight_ih_l0: 0.0021026646718382835 0.14904308319091797
decider.lstm.weight_hh_l0: 0.0032444321550428867 0.14862465858459473
decider.lstm.bias_ih_l0: 0.02515082247555256 0.15984313189983368
decider.lstm.bias_hh_l0: 0.006163308396935463 0.14098390936851501
decider.linear1.weight: 0.004392984788864851 0.12157232314348221
decider.linear1.bias: 0.019868146628141403 0.1175817921757698
decider.linear2.weight: 0.005135165527462959 0.053942520171403885
decider.linear2.bias: 0.008479812182486057 0.057122185826301575
decider.linear3.weight: -0.026706799864768982 0.0704951286315918
decider.linear3.bias: -0.0063428934663534164 0.04796005040407181

Rewards:
221.7540
221.7540
221.7540
objective = 96.29170227050781
==== episode 2100/10000 ====
action = 1
probs = 0.0125 0.9875 0.0000 0.0000

action = 1
probs = 0.1699 0.8301 0.0000 0.0000

action = 0
probs = 0.8923 0.1077 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00030688114929944277 0.08590635657310486
encoder.encoder.weight_hh_l0: 4.688060289481655e-05 0.08774055540561676
encoder.encoder.bias_ih_l0: 0.014694001525640488 0.08946439623832703
encoder.encoder.bias_hh_l0: 0.024691075086593628 0.08726682513952255
encoder.encoder.weight_ih_l0_reverse: 0.0019441924523562193 0.08814161270856857
encoder.encoder.weight_hh_l0_reverse: 0.00934809073805809 0.08786144107580185
encoder.encoder.bias_ih_l0_reverse: 0.03570172190666199 0.08583851903676987
encoder.encoder.bias_hh_l0_reverse: 0.027567317709326744 0.08294176310300827
decider.lstm.weight_ih_l0: 0.002115516923367977 0.14904479682445526
decider.lstm.weight_hh_l0: 0.0032453821040689945 0.14863574504852295
decider.lstm.bias_ih_l0: 0.025164315477013588 0.15991239249706268
decider.lstm.bias_hh_l0: 0.006176800932735205 0.14094480872154236
decider.linear1.weight: 0.004383382387459278 0.12156353890895844
decider.linear1.bias: 0.019814539700746536 0.11752481758594513
decider.linear2.weight: 0.005077950656414032 0.05391576513648033
decider.linear2.bias: 0.008424131199717522 0.057109590619802475
decider.linear3.weight: -0.026965130120515823 0.0707813948392868
decider.linear3.bias: -0.006451009307056665 0.048771344125270844

Rewards:
230.1930
230.1930
230.1930
objective = 24.001815795898438
==== episode 2200/10000 ====
action = 1
probs = 0.0077 0.9923 0.0000 0.0000

action = 1
probs = 0.1088 0.8912 0.0000 0.0000

action = 0
probs = 0.8832 0.1168 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003230881120543927 0.08598889410495758
encoder.encoder.weight_hh_l0: 5.0173079216619954e-05 0.08783261477947235
encoder.encoder.bias_ih_l0: 0.014902316965162754 0.08953147381544113
encoder.encoder.bias_hh_l0: 0.02489939145743847 0.0873619019985199
encoder.encoder.weight_ih_l0_reverse: 0.0019403559854254127 0.08822774887084961
encoder.encoder.weight_hh_l0_reverse: 0.009345040656626225 0.08787773549556732
encoder.encoder.bias_ih_l0_reverse: 0.03582412004470825 0.08587057143449783
encoder.encoder.bias_hh_l0_reverse: 0.02768971398472786 0.08298048377037048
decider.lstm.weight_ih_l0: 0.0021807346493005753 0.1491059511899948
decider.lstm.weight_hh_l0: 0.003281765151768923 0.14868637919425964
decider.lstm.bias_ih_l0: 0.025468964129686356 0.15994524955749512
decider.lstm.bias_hh_l0: 0.006481444928795099 0.1409834623336792
decider.linear1.weight: 0.0043762726709246635 0.12161485850811005
decider.linear1.bias: 0.02001797780394554 0.1175384372472763
decider.linear2.weight: 0.005132084712386131 0.05394083634018898
decider.linear2.bias: 0.008537345565855503 0.05711048096418381
decider.linear3.weight: -0.027213992550969124 0.07115892320871353
decider.linear3.bias: -0.006519057787954807 0.049157023429870605

Rewards:
230.1930
230.1930
230.1930
objective = 18.968582153320312
==== episode 2300/10000 ====
action = 1
probs = 0.0077 0.9923 0.0000 0.0000

action = 1
probs = 0.1198 0.8802 0.0000 0.0000

action = 0
probs = 0.9519 0.0481 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00032584162545390427 0.08603738993406296
encoder.encoder.weight_hh_l0: 4.662151332013309e-05 0.08791235834360123
encoder.encoder.bias_ih_l0: 0.015050769783556461 0.08961321413516998
encoder.encoder.bias_hh_l0: 0.02504783868789673 0.0874466523528099
encoder.encoder.weight_ih_l0_reverse: 0.0019342100713402033 0.08832564204931259
encoder.encoder.weight_hh_l0_reverse: 0.00930266734212637 0.08785393834114075
encoder.encoder.bias_ih_l0_reverse: 0.03588368743658066 0.0859319269657135
encoder.encoder.bias_hh_l0_reverse: 0.027749279513955116 0.08297993242740631
decider.lstm.weight_ih_l0: 0.0022402936592698097 0.14917303621768951
decider.lstm.weight_hh_l0: 0.003322198987007141 0.14873743057250977
decider.lstm.bias_ih_l0: 0.025787023827433586 0.15992869436740875
decider.lstm.bias_hh_l0: 0.0067995041608810425 0.1410694271326065
decider.linear1.weight: 0.004379825200885534 0.12168332934379578
decider.linear1.bias: 0.020307006314396858 0.11761849373579025
decider.linear2.weight: 0.005267282947897911 0.05399540066719055
decider.linear2.bias: 0.008710907772183418 0.057118695229291916
decider.linear3.weight: -0.027413729578256607 0.07153245806694031
decider.linear3.bias: -0.0065711308270692825 0.048785656690597534

Rewards:
230.1930
230.1930
230.1930
objective = 14.167804718017578
==== episode 2400/10000 ====
action = 1
probs = 0.0075 0.9925 0.0000 0.0000

action = 1
probs = 0.1442 0.8558 0.0000 0.0000

action = 0
probs = 0.9732 0.0268 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003336300724186003 0.08609198033809662
encoder.encoder.weight_hh_l0: 4.4274780520936474e-05 0.08798740804195404
encoder.encoder.bias_ih_l0: 0.015209811739623547 0.08969888091087341
encoder.encoder.bias_hh_l0: 0.025206875056028366 0.08750216662883759
encoder.encoder.weight_ih_l0_reverse: 0.0019395019626244903 0.08838338404893875
encoder.encoder.weight_hh_l0_reverse: 0.009287811815738678 0.08785004913806915
encoder.encoder.bias_ih_l0_reverse: 0.035938672721385956 0.085968017578125
encoder.encoder.bias_hh_l0_reverse: 0.027804268524050713 0.08295734971761703
decider.lstm.weight_ih_l0: 0.0022754226811230183 0.14921234548091888
decider.lstm.weight_hh_l0: 0.003345676464959979 0.14876732230186462
decider.lstm.bias_ih_l0: 0.025975696742534637 0.15992532670497894
decider.lstm.bias_hh_l0: 0.0069881826639175415 0.1410977840423584
decider.linear1.weight: 0.004379266873002052 0.12172512710094452
decider.linear1.bias: 0.020472703501582146 0.11764338612556458
decider.linear2.weight: 0.005329652689397335 0.05403706803917885
decider.linear2.bias: 0.008784491568803787 0.05712069198489189
decider.linear3.weight: -0.027569008991122246 0.07180775701999664
decider.linear3.bias: -0.0066202133893966675 0.048550862818956375

Rewards:
230.1930
230.1930
230.1930
objective = 14.62075424194336
==== episode 2500/10000 ====
action = 1
probs = 0.0061 0.9938 0.0000 0.0000

action = 1
probs = 0.0954 0.9046 0.0000 0.0000

action = 1
probs = 0.9311 0.0689 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00032617582473903894 0.08604704588651657
encoder.encoder.weight_hh_l0: 5.1290870032971725e-05 0.08791147172451019
encoder.encoder.bias_ih_l0: 0.015007193200290203 0.0896090641617775
encoder.encoder.bias_hh_l0: 0.02500426024198532 0.08745214343070984
encoder.encoder.weight_ih_l0_reverse: 0.0019393058028072119 0.08831174671649933
encoder.encoder.weight_hh_l0_reverse: 0.009328448213636875 0.08789339661598206
encoder.encoder.bias_ih_l0_reverse: 0.03589257225394249 0.08592579513788223
encoder.encoder.bias_hh_l0_reverse: 0.027758173644542694 0.0830119177699089
decider.lstm.weight_ih_l0: 0.0022406065836548805 0.14916235208511353
decider.lstm.weight_hh_l0: 0.003317080670967698 0.14873231947422028
decider.lstm.bias_ih_l0: 0.02575596421957016 0.15993858873844147
decider.lstm.bias_hh_l0: 0.006768448278307915 0.14103472232818604
decider.linear1.weight: 0.004375515040010214 0.12167063355445862
decider.linear1.bias: 0.020225169137120247 0.11757484823465347
decider.linear2.weight: 0.005212725140154362 0.053984031081199646
decider.linear2.bias: 0.00864536501467228 0.057128701359033585
decider.linear3.weight: -0.0277475044131279 0.07197028398513794
decider.linear3.bias: -0.006675210315734148 0.049106620252132416

Rewards:
217.8160
217.8160
217.8160
objective = 201.92828369140625
==== episode 2600/10000 ====
action = 1
probs = 0.0044 0.9955 0.0000 0.0000

action = 1
probs = 0.0703 0.9297 0.0000 0.0000

action = 0
probs = 0.9285 0.0715 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003387504257261753 0.08610490709543228
encoder.encoder.weight_hh_l0: 5.0582395488163456e-05 0.08798038959503174
encoder.encoder.bias_ih_l0: 0.01517111249268055 0.08966212719678879
encoder.encoder.bias_hh_l0: 0.02516818232834339 0.08751039206981659
encoder.encoder.weight_ih_l0_reverse: 0.0019434000132605433 0.08837409317493439
encoder.encoder.weight_hh_l0_reverse: 0.009319537319242954 0.08789601922035217
encoder.encoder.bias_ih_l0_reverse: 0.03598003461956978 0.085948146879673
encoder.encoder.bias_hh_l0_reverse: 0.027845630422234535 0.0830337181687355
decider.lstm.weight_ih_l0: 0.002279849722981453 0.14919708669185638
decider.lstm.weight_hh_l0: 0.003341060131788254 0.14876161515712738
decider.lstm.bias_ih_l0: 0.025944538414478302 0.1599593609571457
decider.lstm.bias_hh_l0: 0.0069570220075547695 0.141051784157753
decider.linear1.weight: 0.004371528513729572 0.12170843034982681
decider.linear1.bias: 0.02036876231431961 0.11758560687303543
decider.linear2.weight: 0.005243713967502117 0.05400693416595459
decider.linear2.bias: 0.008705894462764263 0.057141516357660294
decider.linear3.weight: -0.02793971076607704 0.07231783866882324
decider.linear3.bias: -0.006714416667819023 0.049314916133880615

Rewards:
230.1930
230.1930
230.1930
objective = 11.62723159790039
==== episode 2700/10000 ====
action = 1
probs = 0.0036 0.9964 0.0000 0.0000

action = 1
probs = 0.0475 0.9525 0.0000 0.0000

action = 0
probs = 0.9180 0.0820 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00034998226328752935 0.08611433207988739
encoder.encoder.weight_hh_l0: 4.841720874537714e-05 0.0879887118935585
encoder.encoder.bias_ih_l0: 0.01521733496338129 0.08963734656572342
encoder.encoder.bias_hh_l0: 0.02521440014243126 0.08753404021263123
encoder.encoder.weight_ih_l0_reverse: 0.0019427131628617644 0.08841478824615479
encoder.encoder.weight_hh_l0_reverse: 0.009306640364229679 0.08788970112800598
encoder.encoder.bias_ih_l0_reverse: 0.03604807332158089 0.08595608174800873
encoder.encoder.bias_hh_l0_reverse: 0.02791367471218109 0.08307758718729019
decider.lstm.weight_ih_l0: 0.0022956186439841986 0.14920930564403534
decider.lstm.weight_hh_l0: 0.0033517449628561735 0.1487753987312317
decider.lstm.bias_ih_l0: 0.02602047473192215 0.15998119115829468
decider.lstm.bias_hh_l0: 0.007032955065369606 0.14106981456279755
decider.linear1.weight: 0.004370811861008406 0.12172922492027283
decider.linear1.bias: 0.02044656127691269 0.11760638654232025
decider.linear2.weight: 0.005268639884889126 0.054008327424526215
decider.linear2.bias: 0.008744269609451294 0.05715452507138252
decider.linear3.weight: -0.028120186179876328 0.07263307273387909
decider.linear3.bias: -0.006751033011823893 0.04960544779896736

Rewards:
230.1930
230.1930
230.1930
objective = 10.57747745513916
==== episode 2800/10000 ====
action = 1
probs = 0.0031 0.9969 0.0000 0.0000

action = 1
probs = 0.0410 0.9589 0.0000 0.0000

action = 0
probs = 0.9105 0.0895 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003513896372169256 0.08613522350788116
encoder.encoder.weight_hh_l0: 4.8976027755998075e-05 0.0880136787891388
encoder.encoder.bias_ih_l0: 0.015250738710165024 0.08966583013534546
encoder.encoder.bias_hh_l0: 0.025247802957892418 0.08756239712238312
encoder.encoder.weight_ih_l0_reverse: 0.0019463167991489172 0.0884317085146904
encoder.encoder.weight_hh_l0_reverse: 0.009312462992966175 0.0879034623503685
encoder.encoder.bias_ih_l0_reverse: 0.03607071563601494 0.08596602827310562
encoder.encoder.bias_hh_l0_reverse: 0.027936315163969994 0.08309590071439743
decider.lstm.weight_ih_l0: 0.002308758208528161 0.14921793341636658
decider.lstm.weight_hh_l0: 0.0033582537434995174 0.1487823724746704
decider.lstm.bias_ih_l0: 0.026074258610606194 0.15998008847236633
decider.lstm.bias_hh_l0: 0.007086737081408501 0.14106741547584534
decider.linear1.weight: 0.004367131274193525 0.1217372789978981
decider.linear1.bias: 0.020459018647670746 0.11759719997644424
decider.linear2.weight: 0.005252208095043898 0.05401964113116264
decider.linear2.bias: 0.00874405074864626 0.05716150254011154
decider.linear3.weight: -0.0282931849360466 0.07293553650379181
decider.linear3.bias: -0.006778249517083168 0.04972381517291069

Rewards:
230.1930
230.1930
230.1930
objective = 10.644432067871094
==== episode 2900/10000 ====
action = 1
probs = 0.0023 0.9977 0.0000 0.0000

action = 1
probs = 0.0273 0.9727 0.0000 0.0000

action = 0
probs = 0.8384 0.1616 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003652097948361188 0.08616044372320175
encoder.encoder.weight_hh_l0: 5.2238963689887896e-05 0.08802846074104309
encoder.encoder.bias_ih_l0: 0.015319089405238628 0.0896521508693695
encoder.encoder.bias_hh_l0: 0.025316154584288597 0.0875660702586174
encoder.encoder.weight_ih_l0_reverse: 0.0019447837257757783 0.08843567967414856
encoder.encoder.weight_hh_l0_reverse: 0.009330060333013535 0.08792708069086075
encoder.encoder.bias_ih_l0_reverse: 0.03613218665122986 0.08595164120197296
encoder.encoder.bias_hh_l0_reverse: 0.027997784316539764 0.08313007652759552
decider.lstm.weight_ih_l0: 0.0023129587061703205 0.14921222627162933
decider.lstm.weight_hh_l0: 0.0033572581596672535 0.14878085255622864
decider.lstm.bias_ih_l0: 0.026073189452290535 0.16001096367835999
decider.lstm.bias_hh_l0: 0.0070856716483831406 0.14103378355503082
decider.linear1.weight: 0.0043611302971839905 0.12173424661159515
decider.linear1.bias: 0.020419402047991753 0.11757484078407288
decider.linear2.weight: 0.005213594995439053 0.05400532856583595
decider.linear2.bias: 0.008694184012711048 0.05717650055885315
decider.linear3.weight: -0.028472866863012314 0.07322359830141068
decider.linear3.bias: -0.006808459758758545 0.05021541938185692

Rewards:
230.1930
230.1930
230.1930
objective = 15.818987846374512
==== episode 3000/10000 ====
action = 1
probs = 0.0025 0.9975 0.0000 0.0000

action = 0
probs = 0.0288 0.9711 0.0000 0.0000

action = 1
probs = 0.7875 0.2124 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00035862872027792037 0.08612903952598572
encoder.encoder.weight_hh_l0: 5.6954573665279895e-05 0.0879766121506691
encoder.encoder.bias_ih_l0: 0.015165458433330059 0.08961832523345947
encoder.encoder.bias_hh_l0: 0.02516251988708973 0.08754991739988327
encoder.encoder.weight_ih_l0_reverse: 0.0019448823295533657 0.08837265521287918
encoder.encoder.weight_hh_l0_reverse: 0.009365922771394253 0.08795751631259918
encoder.encoder.bias_ih_l0_reverse: 0.036085404455661774 0.0859319418668747
encoder.encoder.bias_hh_l0_reverse: 0.02795100212097168 0.08313410729169846
decider.lstm.weight_ih_l0: 0.002278192201629281 0.14917689561843872
decider.lstm.weight_hh_l0: 0.0033321853261440992 0.1487545669078827
decider.lstm.bias_ih_l0: 0.025890808552503586 0.16001032292842865
decider.lstm.bias_hh_l0: 0.00690328236669302 0.14098747074604034
decider.linear1.weight: 0.004358833655714989 0.12169259786605835
decider.linear1.bias: 0.02021700143814087 0.11754748225212097
decider.linear2.weight: 0.0051287198439240456 0.053983744233846664
decider.linear2.bias: 0.008580662310123444 0.0571579746901989
decider.linear3.weight: -0.02868029475212097 0.07352092117071152
decider.linear3.bias: -0.006838512606918812 0.05037277936935425

Rewards:
229.4037
229.4037
229.4037
objective = 389.7822265625
==== episode 3100/10000 ====
action = 1
probs = 0.0022 0.9978 0.0000 0.0000

action = 1
probs = 0.0268 0.9732 0.0000 0.0000

action = 0
probs = 0.7777 0.2223 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00035710580414161086 0.08615327626466751
encoder.encoder.weight_hh_l0: 5.620100273517892e-05 0.08800743520259857
encoder.encoder.bias_ih_l0: 0.01518868375569582 0.08964914828538895
encoder.encoder.bias_hh_l0: 0.02518574148416519 0.08757911622524261
encoder.encoder.weight_ih_l0_reverse: 0.0019439344760030508 0.08838815987110138
encoder.encoder.weight_hh_l0_reverse: 0.009369396604597569 0.0879707857966423
encoder.encoder.bias_ih_l0_reverse: 0.036090683192014694 0.08594244718551636
encoder.encoder.bias_hh_l0_reverse: 0.027956277132034302 0.08314500749111176
decider.lstm.weight_ih_l0: 0.002296128310263157 0.14919306337833405
decider.lstm.weight_hh_l0: 0.003341219387948513 0.14876672625541687
decider.lstm.bias_ih_l0: 0.025966595858335495 0.16000662744045258
decider.lstm.bias_hh_l0: 0.006979071069508791 0.14099660515785217
decider.linear1.weight: 0.004354934673756361 0.12170131504535675
decider.linear1.bias: 0.0202323105186224 0.11754205822944641
decider.linear2.weight: 0.00513827707618475 0.053989581763744354
decider.linear2.bias: 0.008597738109529018 0.0571652352809906
decider.linear3.weight: -0.02892720140516758 0.07396268099546432
decider.linear3.bias: -0.006877983920276165 0.05041186138987541

Rewards:
230.1930
230.1930
230.1930
objective = 21.55067253112793
==== episode 3200/10000 ====
action = 1
probs = 0.0020 0.9980 0.0000 0.0000

action = 1
probs = 0.0285 0.9715 0.0000 0.0000

action = 0
probs = 0.8810 0.1190 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000353596726199612 0.0862099751830101
encoder.encoder.weight_hh_l0: 4.915906174574047e-05 0.08809882402420044
encoder.encoder.bias_ih_l0: 0.015332052484154701 0.08975381404161453
encoder.encoder.bias_hh_l0: 0.0253291055560112 0.08766485750675201
encoder.encoder.weight_ih_l0_reverse: 0.0019487278768792748 0.08847040683031082
encoder.encoder.weight_hh_l0_reverse: 0.009335195645689964 0.08795245736837387
encoder.encoder.bias_ih_l0_reverse: 0.036119233816862106 0.08598966896533966
encoder.encoder.bias_hh_l0_reverse: 0.027984824031591415 0.0831429660320282
decider.lstm.weight_ih_l0: 0.002351068425923586 0.14924860000610352
decider.lstm.weight_hh_l0: 0.0033782992977648973 0.14880827069282532
decider.lstm.bias_ih_l0: 0.02624841034412384 0.15998932719230652
decider.lstm.bias_hh_l0: 0.007260885089635849 0.14105503261089325
decider.linear1.weight: 0.004353064578026533 0.12175697833299637
decider.linear1.bias: 0.020459046587347984 0.11756493151187897
decider.linear2.weight: 0.005237387493252754 0.05403614044189453
decider.linear2.bias: 0.00875068362802267 0.057175714522600174
decider.linear3.weight: -0.029140381142497063 0.07445961236953735
decider.linear3.bias: -0.006908322684466839 0.050052449107170105

Rewards:
230.1930
230.1930
230.1930
objective = 12.091696739196777
==== episode 3300/10000 ====
action = 1
probs = 0.0019 0.9981 0.0000 0.0000

action = 1
probs = 0.0261 0.9739 0.0000 0.0000

action = 0
probs = 0.8273 0.1727 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003502924519125372 0.08619613200426102
encoder.encoder.weight_hh_l0: 5.415043779066764e-05 0.08806856721639633
encoder.encoder.bias_ih_l0: 0.015245052985846996 0.08972213417291641
encoder.encoder.bias_hh_l0: 0.02524210885167122 0.08763853460550308
encoder.encoder.weight_ih_l0_reverse: 0.0019428151426836848 0.08842683583498001
encoder.encoder.weight_hh_l0_reverse: 0.009360050782561302 0.08798059821128845
encoder.encoder.bias_ih_l0_reverse: 0.0360841266810894 0.08597161620855331
encoder.encoder.bias_hh_l0_reverse: 0.02794971875846386 0.08315087109804153
decider.lstm.weight_ih_l0: 0.002330377697944641 0.14922529458999634
decider.lstm.weight_hh_l0: 0.0033615855500102043 0.14879168570041656
decider.lstm.bias_ih_l0: 0.026131436228752136 0.15999798476696014
decider.lstm.bias_hh_l0: 0.007143921684473753 0.1410188525915146
decider.linear1.weight: 0.004351095762103796 0.12172836810350418
decider.linear1.bias: 0.020325403660535812 0.11754532158374786
decider.linear2.weight: 0.005179857835173607 0.054016727954149246
decider.linear2.bias: 0.008669243194162846 0.05717169865965843
decider.linear3.weight: -0.02933674305677414 0.07478924840688705
decider.linear3.bias: -0.006935279816389084 0.05027026683092117

Rewards:
230.1930
230.1930
230.1930
objective = 16.730892181396484
==== episode 3400/10000 ====
action = 1
probs = 0.0018 0.9982 0.0000 0.0000

action = 1
probs = 0.0286 0.9714 0.0000 0.0000

action = 0
probs = 0.8900 0.1100 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003470482479315251 0.08623524755239487
encoder.encoder.weight_hh_l0: 4.927158079226501e-05 0.08812814205884933
encoder.encoder.bias_ih_l0: 0.01532837562263012 0.0897960439324379
encoder.encoder.bias_hh_l0: 0.02532542496919632 0.08770190179347992
encoder.encoder.weight_ih_l0_reverse: 0.0019471707055345178 0.0884777083992958
encoder.encoder.weight_hh_l0_reverse: 0.009342065081000328 0.08797326683998108
encoder.encoder.bias_ih_l0_reverse: 0.036097586154937744 0.0860043615102768
encoder.encoder.bias_hh_l0_reverse: 0.027963172644376755 0.08315058052539825
decider.lstm.weight_ih_l0: 0.002363654552027583 0.14925897121429443
decider.lstm.weight_hh_l0: 0.003384079784154892 0.14881737530231476
decider.lstm.bias_ih_l0: 0.0263061486184597 0.15998654067516327
decider.lstm.bias_hh_l0: 0.007318652234971523 0.14104785025119781
decider.linear1.weight: 0.004348871298134327 0.12176249921321869
decider.linear1.bias: 0.02045542560517788 0.1175558939576149
decider.linear2.weight: 0.005243848543614149 0.05404610559344292
decider.linear2.bias: 0.008764060214161873 0.05717413127422333
decider.linear3.weight: -0.029529908671975136 0.07522458583116531
decider.linear3.bias: -0.006966366432607174 0.05002722144126892

Rewards:
230.1930
230.1930
230.1930
objective = 11.307109832763672
==== episode 3500/10000 ====
action = 1
probs = 0.0015 0.9984 0.0000 0.0000

action = 1
probs = 0.0253 0.9747 0.0000 0.0000

action = 1
probs = 0.8964 0.1036 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00035321316681802273 0.08626794815063477
encoder.encoder.weight_hh_l0: 4.7078323405003175e-05 0.08816912025213242
encoder.encoder.bias_ih_l0: 0.015420707874000072 0.08983193337917328
encoder.encoder.bias_hh_l0: 0.025417756289243698 0.08773718029260635
encoder.encoder.weight_ih_l0_reverse: 0.0019508479163050652 0.08851197361946106
encoder.encoder.weight_hh_l0_reverse: 0.00933616142719984 0.08797302842140198
encoder.encoder.bias_ih_l0_reverse: 0.036141324788331985 0.08601650595664978
encoder.encoder.bias_hh_l0_reverse: 0.028006913140416145 0.08316128700971603
decider.lstm.weight_ih_l0: 0.0023837359622120857 0.14927487075328827
decider.lstm.weight_hh_l0: 0.0033968607895076275 0.14883151650428772
decider.lstm.bias_ih_l0: 0.026405587792396545 0.15999704599380493
decider.lstm.bias_hh_l0: 0.0074180918745696545 0.14105045795440674
decider.linear1.weight: 0.004346258006989956 0.12178350239992142
decider.linear1.bias: 0.020533785223960876 0.11755609512329102
decider.linear2.weight: 0.005268086679279804 0.05405969172716141
decider.linear2.bias: 0.008800218813121319 0.057184383273124695
decider.linear3.weight: -0.029705902561545372 0.0756135955452919
decider.linear3.bias: -0.006991630885750055 0.05008424445986748

Rewards:
217.8160
217.8160
217.8160
objective = 166.586669921875
==== episode 3600/10000 ====
action = 1
probs = 0.0026 0.9974 0.0000 0.0000

action = 1
probs = 0.0525 0.9475 0.0000 0.0000

action = 0
probs = 0.9435 0.0565 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000321203435305506 0.08622174710035324
encoder.encoder.weight_hh_l0: 4.9604892410570756e-05 0.08812332153320312
encoder.encoder.bias_ih_l0: 0.015198130160570145 0.08984995633363724
encoder.encoder.bias_hh_l0: 0.025195177644491196 0.08771812915802002
encoder.encoder.weight_ih_l0_reverse: 0.0019463782664388418 0.08845093101263046
encoder.encoder.weight_hh_l0_reverse: 0.009344118647277355 0.08798517286777496
encoder.encoder.bias_ih_l0_reverse: 0.035977669060230255 0.08603028208017349
encoder.encoder.bias_hh_l0_reverse: 0.027843255549669266 0.08310896158218384
decider.lstm.weight_ih_l0: 0.0023575848899781704 0.1492646336555481
decider.lstm.weight_hh_l0: 0.0033802813850343227 0.1488189697265625
decider.lstm.bias_ih_l0: 0.026290487498044968 0.1599479764699936
decider.lstm.bias_hh_l0: 0.007302996702492237 0.14105753600597382
decider.linear1.weight: 0.0043503581546247005 0.12175898253917694
decider.linear1.bias: 0.020426422357559204 0.11756537854671478
decider.linear2.weight: 0.005272563546895981 0.054062630981206894
decider.linear2.bias: 0.00880208145827055 0.057139404118061066
decider.linear3.weight: -0.02990380860865116 0.07598922401666641
decider.linear3.bias: -0.007019325625151396 0.04939514771103859

Rewards:
230.1930
230.1930
230.1930
objective = 8.798748970031738
==== episode 3700/10000 ====
action = 1
probs = 0.0038 0.9962 0.0000 0.0000

action = 1
probs = 0.1070 0.8930 0.0000 0.0000

action = 0
probs = 0.9781 0.0219 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00031856397981755435 0.08624523878097534
encoder.encoder.weight_hh_l0: 4.6769237087573856e-05 0.08816879987716675
encoder.encoder.bias_ih_l0: 0.01528566051274538 0.08994632959365845
encoder.encoder.bias_hh_l0: 0.025282708927989006 0.08775488287210464
encoder.encoder.weight_ih_l0_reverse: 0.0019463197095319629 0.0884845107793808
encoder.encoder.weight_hh_l0_reverse: 0.00931943953037262 0.08796807378530502
encoder.encoder.bias_ih_l0_reverse: 0.03595758229494095 0.0860709398984909
encoder.encoder.bias_hh_l0_reverse: 0.027823172509670258 0.08305126428604126
decider.lstm.weight_ih_l0: 0.0023756877053529024 0.14930200576782227
decider.lstm.weight_hh_l0: 0.003395846113562584 0.14884762465953827
decider.lstm.bias_ih_l0: 0.026413436979055405 0.1599428951740265
decider.lstm.bias_hh_l0: 0.007425959222018719 0.1410982757806778
decider.linear1.weight: 0.004357505589723587 0.12179122120141983
decider.linear1.bias: 0.020556718111038208 0.11759273707866669
decider.linear2.weight: 0.005366353318095207 0.054100487381219864
decider.linear2.bias: 0.008920170366764069 0.05712779238820076
decider.linear3.weight: -0.03005199134349823 0.0763007402420044
decider.linear3.bias: -0.007054398767650127 0.04856475070118904

Rewards:
230.1930
230.1930
230.1930
objective = 10.67758560180664
==== episode 3800/10000 ====
action = 1
probs = 0.0034 0.9966 0.0000 0.0000

action = 1
probs = 0.1034 0.8965 0.0000 0.0000

action = 0
probs = 0.9789 0.0211 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003226093831472099 0.08627790957689285
encoder.encoder.weight_hh_l0: 4.6828805352561176e-05 0.08820360153913498
encoder.encoder.bias_ih_l0: 0.015343284234404564 0.08998623490333557
encoder.encoder.bias_hh_l0: 0.025340337306261063 0.08779679983854294
encoder.encoder.weight_ih_l0_reverse: 0.0019475538283586502 0.08850857615470886
encoder.encoder.weight_hh_l0_reverse: 0.009318020194768906 0.0879758670926094
encoder.encoder.bias_ih_l0_reverse: 0.0359780415892601 0.08608193695545197
encoder.encoder.bias_hh_l0_reverse: 0.02784362994134426 0.08305934816598892
decider.lstm.weight_ih_l0: 0.002392672933638096 0.1493152230978012
decider.lstm.weight_hh_l0: 0.0034054075367748737 0.1488623172044754
decider.lstm.bias_ih_l0: 0.02649763971567154 0.159957617521286
decider.lstm.bias_hh_l0: 0.007510148920118809 0.14108888804912567
decider.linear1.weight: 0.004355308599770069 0.12180580198764801
decider.linear1.bias: 0.020606543868780136 0.11758580803871155
decider.linear2.weight: 0.0053755613043904305 0.05411391705274582
decider.linear2.bias: 0.008925878442823887 0.05711757391691208
decider.linear3.weight: -0.030205724760890007 0.07658782601356506
decider.linear3.bias: -0.007096145302057266 0.04862124100327492

Rewards:
230.1930
230.1930
230.1930
objective = 10.277971267700195
==== episode 3900/10000 ====
action = 1
probs = 0.0030 0.9970 0.0000 0.0000

action = 1
probs = 0.0994 0.9006 0.0000 0.0000

action = 0
probs = 0.9789 0.0211 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003301881661172956 0.08630255609750748
encoder.encoder.weight_hh_l0: 4.644443833967671e-05 0.08823034167289734
encoder.encoder.bias_ih_l0: 0.01539628952741623 0.0900171771645546
encoder.encoder.bias_hh_l0: 0.02539334073662758 0.08782912790775299
encoder.encoder.weight_ih_l0_reverse: 0.0019506934331730008 0.08852701634168625
encoder.encoder.weight_hh_l0_reverse: 0.009322640486061573 0.0879872590303421
encoder.encoder.bias_ih_l0_reverse: 0.036007028073072433 0.08609598875045776
encoder.encoder.bias_hh_l0_reverse: 0.027872612699866295 0.08307357877492905
decider.lstm.weight_ih_l0: 0.0024049815256148577 0.14932259917259216
decider.lstm.weight_hh_l0: 0.003412076737731695 0.14887210726737976
decider.lstm.bias_ih_l0: 0.026559241116046906 0.15996798872947693
decider.lstm.bias_hh_l0: 0.007571753580123186 0.14106933772563934
decider.linear1.weight: 0.004352431744337082 0.12181438505649567
decider.linear1.bias: 0.020625300705432892 0.11756930500268936
decider.linear2.weight: 0.0053861807100474834 0.05412036553025246
decider.linear2.bias: 0.008932700380682945 0.05712556093931198
decider.linear3.weight: -0.0303417406976223 0.07684291154146194
decider.linear3.bias: -0.007131505757570267 0.048701707273721695

Rewards:
230.1930
230.1930
230.1930
objective = 9.900343894958496
==== episode 4000/10000 ====
action = 1
probs = 0.0054 0.9946 0.0000 0.0000

action = 1
probs = 0.1634 0.8366 0.0000 0.0000

action = 0
probs = 0.9814 0.0186 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003080019960179925 0.0862032026052475
encoder.encoder.weight_hh_l0: 5.1817249186569825e-05 0.0881219357252121
encoder.encoder.bias_ih_l0: 0.015115665271878242 0.08993498235940933
encoder.encoder.bias_hh_l0: 0.025112710893154144 0.08771302551031113
encoder.encoder.weight_ih_l0_reverse: 0.001944211428053677 0.08843233436346054
encoder.encoder.weight_hh_l0_reverse: 0.009335038252174854 0.08800003677606583
encoder.encoder.bias_ih_l0_reverse: 0.03584408760070801 0.08607359975576401
encoder.encoder.bias_hh_l0_reverse: 0.02770967409014702 0.08304914087057114
decider.lstm.weight_ih_l0: 0.0023547951132059097 0.14928652346134186
decider.lstm.weight_hh_l0: 0.003379331436008215 0.14884227514266968
decider.lstm.bias_ih_l0: 0.02629699744284153 0.15993927419185638
decider.lstm.bias_hh_l0: 0.00730951176956296 0.14108619093894958
decider.linear1.weight: 0.004365089349448681 0.12176080793142319
decider.linear1.bias: 0.02040368877351284 0.11757208406925201
decider.linear2.weight: 0.005356115289032459 0.05409197136759758
decider.linear2.bias: 0.008892729878425598 0.057128794491291046
decider.linear3.weight: -0.030543504282832146 0.0771280974149704
decider.linear3.bias: -0.0071841576136648655 0.04828956723213196

Rewards:
230.1930
230.1930
230.1930
objective = 15.540334701538086
==== episode 4100/10000 ====
action = 1
probs = 0.0062 0.9938 0.0000 0.0000

action = 0
probs = 0.2450 0.7550 0.0000 0.0000

action = 0
probs = 0.9895 0.0105 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00031510984990745783 0.086264468729496
encoder.encoder.weight_hh_l0: 5.094406515127048e-05 0.08819565176963806
encoder.encoder.bias_ih_l0: 0.015296196565032005 0.09003827720880508
encoder.encoder.bias_hh_l0: 0.025293244048953056 0.0877717062830925
encoder.encoder.weight_ih_l0_reverse: 0.001941238297149539 0.08847378194332123
encoder.encoder.weight_hh_l0_reverse: 0.009317462332546711 0.08798667788505554
encoder.encoder.bias_ih_l0_reverse: 0.035872988402843475 0.08609992265701294
encoder.encoder.bias_hh_l0_reverse: 0.027738574892282486 0.08300547301769257
decider.lstm.weight_ih_l0: 0.002383179496973753 0.14932705461978912
decider.lstm.weight_hh_l0: 0.003399503417313099 0.14887253940105438
decider.lstm.bias_ih_l0: 0.02646372839808464 0.1599448025226593
decider.lstm.bias_hh_l0: 0.007476238068193197 0.14109565317630768
decider.linear1.weight: 0.004363087471574545 0.12179920077323914
decider.linear1.bias: 0.020561516284942627 0.11755745112895966
decider.linear2.weight: 0.005416465923190117 0.054138895124197006
decider.linear2.bias: 0.008971331641077995 0.057118818163871765
decider.linear3.weight: -0.03078174963593483 0.07758811116218567
decider.linear3.bias: -0.007249877788126469 0.04781857877969742

Rewards:
221.7540
221.7540
221.7540
objective = 105.20345306396484
==== episode 4200/10000 ====
action = 1
probs = 0.0033 0.9967 0.0000 0.0000

action = 1
probs = 0.1310 0.8690 0.0000 0.0000

action = 0
probs = 0.9808 0.0192 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00032975239446386695 0.08630535751581192
encoder.encoder.weight_hh_l0: 5.005297498428263e-05 0.08823306113481522
encoder.encoder.bias_ih_l0: 0.015343250706791878 0.09005367755889893
encoder.encoder.bias_hh_l0: 0.02534029632806778 0.0878412202000618
encoder.encoder.weight_ih_l0_reverse: 0.001949105761013925 0.08850107342004776
encoder.encoder.weight_hh_l0_reverse: 0.009335510432720184 0.08801878988742828
encoder.encoder.bias_ih_l0_reverse: 0.03594734147191048 0.08610048145055771
encoder.encoder.bias_hh_l0_reverse: 0.027812927961349487 0.08306343853473663
decider.lstm.weight_ih_l0: 0.002407188294455409 0.1493285447359085
decider.lstm.weight_hh_l0: 0.0034093642607331276 0.14888127148151398
decider.lstm.bias_ih_l0: 0.02654818817973137 0.15997296571731567
decider.lstm.bias_hh_l0: 0.007560692727565765 0.14104627072811127
decider.linear1.weight: 0.004354281350970268 0.12180737406015396
decider.linear1.bias: 0.02057737670838833 0.1175248846411705
decider.linear2.weight: 0.005374545697122812 0.054139699786901474
decider.linear2.bias: 0.008904986083507538 0.057119496166706085
decider.linear3.weight: -0.031011737883090973 0.07803025841712952
decider.linear3.bias: -0.00731388945132494 0.048536717891693115

Rewards:
230.1930
230.1930
230.1930
objective = 12.513174057006836
==== episode 4300/10000 ====
action = 1
probs = 0.0042 0.9958 0.0000 0.0000

action = 1
probs = 0.2189 0.7811 0.0000 0.0000

action = 0
probs = 0.9902 0.0098 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00033565357443876565 0.0863528624176979
encoder.encoder.weight_hh_l0: 4.82405157526955e-05 0.0882951095700264
encoder.encoder.bias_ih_l0: 0.015500049106776714 0.0901474878191948
encoder.encoder.bias_hh_l0: 0.02549709938466549 0.08788761496543884
encoder.encoder.weight_ih_l0_reverse: 0.0019483803771436214 0.08853939175605774
encoder.encoder.weight_hh_l0_reverse: 0.009315247647464275 0.08800017088651657
encoder.encoder.bias_ih_l0_reverse: 0.03596951439976692 0.08612822741270065
encoder.encoder.bias_hh_l0_reverse: 0.02783510647714138 0.08301277458667755
decider.lstm.weight_ih_l0: 0.0024298536591231823 0.14936450123786926
decider.lstm.weight_hh_l0: 0.003427383489906788 0.14891059696674347
decider.lstm.bias_ih_l0: 0.02669486403465271 0.15998408198356628
decider.lstm.bias_hh_l0: 0.007707372307777405 0.14105883240699768
decider.linear1.weight: 0.004354302771389484 0.12184476107358932
decider.linear1.bias: 0.02072793059051037 0.11752960085868835
decider.linear2.weight: 0.005450091324746609 0.05417903512716293
decider.linear2.bias: 0.00899853277951479 0.05711100250482559
decider.linear3.weight: -0.031210456043481827 0.0784476101398468
decider.linear3.bias: -0.007368260994553566 0.04796942323446274

Rewards:
230.1930
230.1930
230.1930
objective = 20.03816795349121
==== episode 4400/10000 ====
action = 1
probs = 0.0045 0.9955 0.0000 0.0000

action = 1
probs = 0.2672 0.7328 0.0000 0.0000

action = 0
probs = 0.9916 0.0084 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003295353672001511 0.08636195212602615
encoder.encoder.weight_hh_l0: 5.0308462959947065e-05 0.08830369263887405
encoder.encoder.bias_ih_l0: 0.015498974360525608 0.09018002450466156
encoder.encoder.bias_hh_l0: 0.025496019050478935 0.08789321035146713
encoder.encoder.weight_ih_l0_reverse: 0.0019457917660474777 0.08852998167276382
encoder.encoder.weight_hh_l0_reverse: 0.009317588992416859 0.08800512552261353
encoder.encoder.bias_ih_l0_reverse: 0.03593413904309273 0.08612912148237228
encoder.encoder.bias_hh_l0_reverse: 0.027799729257822037 0.08300351351499557
decider.lstm.weight_ih_l0: 0.0024323398247361183 0.14936666190624237
decider.lstm.weight_hh_l0: 0.0034281564876437187 0.14891311526298523
decider.lstm.bias_ih_l0: 0.02670704945921898 0.1599816083908081
decider.lstm.bias_hh_l0: 0.007719554007053375 0.1410328596830368
decider.linear1.weight: 0.004353348631411791 0.12185259163379669
decider.linear1.bias: 0.020742833614349365 0.11748732626438141
decider.linear2.weight: 0.0054528359323740005 0.054190538823604584
decider.linear2.bias: 0.00900096446275711 0.057111166417598724
decider.linear3.weight: -0.03140889108181 0.07883110642433167
decider.linear3.bias: -0.007423587143421173 0.04779219627380371

Rewards:
230.1930
230.1930
230.1930
objective = 24.854228973388672
==== episode 4500/10000 ====
action = 1
probs = 0.0068 0.9932 0.0000 0.0000

action = 1
probs = 0.2854 0.7146 0.0000 0.0000

action = 0
probs = 0.9932 0.0068 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00031821540324017406 0.08625760674476624
encoder.encoder.weight_hh_l0: 5.159958527656272e-05 0.08818947523832321
encoder.encoder.bias_ih_l0: 0.01525392010807991 0.09004631638526917
encoder.encoder.bias_hh_l0: 0.025250963866710663 0.08778862655162811
encoder.encoder.weight_ih_l0_reverse: 0.0019409589003771544 0.08849908411502838
encoder.encoder.weight_hh_l0_reverse: 0.009297875687479973 0.08798317611217499
encoder.encoder.bias_ih_l0_reverse: 0.03584037348628044 0.08611680567264557
encoder.encoder.bias_hh_l0_reverse: 0.02770596370100975 0.08300095051527023
decider.lstm.weight_ih_l0: 0.0023912847973406315 0.1493416428565979
decider.lstm.weight_hh_l0: 0.003402381669729948 0.14889223873615265
decider.lstm.bias_ih_l0: 0.02652759850025177 0.15996070206165314
decider.lstm.bias_hh_l0: 0.00754010584205389 0.14110107719898224
decider.linear1.weight: 0.004367890767753124 0.12181888520717621
decider.linear1.bias: 0.020631957799196243 0.11759074777364731
decider.linear2.weight: 0.0054757799953222275 0.05417207255959511
decider.linear2.bias: 0.009023637510836124 0.05711052939295769
decider.linear3.weight: -0.03161162510514259 0.07920771837234497
decider.linear3.bias: -0.007483211345970631 0.04749847203493118

Rewards:
230.1930
230.1930
230.1930
objective = 26.835952758789062
==== episode 4600/10000 ====
action = 1
probs = 0.0049 0.9951 0.0000 0.0000

action = 1
probs = 0.2397 0.7602 0.0000 0.0000

action = 0
probs = 0.9912 0.0088 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003250979061704129 0.08628939837217331
encoder.encoder.weight_hh_l0: 5.278220123727806e-05 0.08821340650320053
encoder.encoder.bias_ih_l0: 0.015260739251971245 0.09006442874670029
encoder.encoder.bias_hh_l0: 0.025257783010601997 0.08782149106264114
encoder.encoder.weight_ih_l0_reverse: 0.0019504179945215583 0.08849750459194183
encoder.encoder.weight_hh_l0_reverse: 0.00931736920028925 0.08801665902137756
encoder.encoder.bias_ih_l0_reverse: 0.0358683206140995 0.0861106589436531
encoder.encoder.bias_hh_l0_reverse: 0.02773391269147396 0.08302067220211029
decider.lstm.weight_ih_l0: 0.0024079279974102974 0.14935018122196198
decider.lstm.weight_hh_l0: 0.0034104972146451473 0.14891332387924194
decider.lstm.bias_ih_l0: 0.02657916769385338 0.16000400483608246
decider.lstm.bias_hh_l0: 0.007591669447720051 0.1410621553659439
decider.linear1.weight: 0.0043633244931697845 0.12182393670082092
decider.linear1.bias: 0.020626986399292946 0.11754459887742996
decider.linear2.weight: 0.005428760312497616 0.054182060062885284
decider.linear2.bias: 0.008973830379545689 0.05711045488715172
decider.linear3.weight: -0.03186260163784027 0.0796920582652092
decider.linear3.bias: -0.007564496248960495 0.04781152680516243

Rewards:
230.1930
230.1930
230.1930
objective = 22.086830139160156
==== episode 4700/10000 ====
action = 1
probs = 0.0050 0.9950 0.0000 0.0000

action = 1
probs = 0.1493 0.8507 0.0000 0.0000

action = 0
probs = 0.9751 0.0249 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00029517203802242875 0.08608821034431458
encoder.encoder.weight_hh_l0: 5.4149302741279826e-05 0.08796842396259308
encoder.encoder.bias_ih_l0: 0.014632247388362885 0.0897621139883995
encoder.encoder.bias_hh_l0: 0.024629291146993637 0.087605319917202
encoder.encoder.weight_ih_l0_reverse: 0.0019533196464180946 0.08833445608615875
encoder.encoder.weight_hh_l0_reverse: 0.009370015934109688 0.08806146681308746
encoder.encoder.bias_ih_l0_reverse: 0.03568100556731224 0.08602765947580338
encoder.encoder.bias_hh_l0_reverse: 0.02754659578204155 0.08309182524681091
decider.lstm.weight_ih_l0: 0.0022830951493233442 0.14918483793735504
decider.lstm.weight_hh_l0: 0.003328092163428664 0.14878138899803162
decider.lstm.bias_ih_l0: 0.02593105286359787 0.1598999947309494
decider.lstm.bias_hh_l0: 0.006943558808416128 0.1409403383731842
decider.linear1.weight: 0.004370957147330046 0.12172040343284607
decider.linear1.bias: 0.020164402201771736 0.11754153668880463
decider.linear2.weight: 0.005259878933429718 0.05409061908721924
decider.linear2.bias: 0.008774790912866592 0.057078227400779724
decider.linear3.weight: -0.032094672322273254 0.08004234731197357
decider.linear3.bias: -0.007633730303496122 0.04843050241470337

Rewards:
230.1930
230.1930
230.1930
objective = 14.732851028442383
==== episode 4800/10000 ====
action = 1
probs = 0.0044 0.9956 0.0000 0.0000

action = 0
probs = 0.1129 0.8871 0.0000 0.0000

action = 0
probs = 0.9783 0.0217 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003017228445969522 0.08609697222709656
encoder.encoder.weight_hh_l0: 5.174352918402292e-05 0.08798609673976898
encoder.encoder.bias_ih_l0: 0.014675037935376167 0.08975179493427277
encoder.encoder.bias_hh_l0: 0.02467208355665207 0.08767212182283401
encoder.encoder.weight_ih_l0_reverse: 0.0019380589947104454 0.08839263021945953
encoder.encoder.weight_hh_l0_reverse: 0.009337379597127438 0.08803961426019669
encoder.encoder.bias_ih_l0_reverse: 0.03571329638361931 0.08604918420314789
encoder.encoder.bias_hh_l0_reverse: 0.027578886598348618 0.08313091844320297
decider.lstm.weight_ih_l0: 0.0022947590332478285 0.1491830050945282
decider.lstm.weight_hh_l0: 0.0033360044471919537 0.14877741038799286
decider.lstm.bias_ih_l0: 0.02601425163447857 0.15987332165241241
decider.lstm.bias_hh_l0: 0.007026761770248413 0.14094699919223785
decider.linear1.weight: 0.004375194199383259 0.12174287438392639
decider.linear1.bias: 0.02027900516986847 0.117607481777668
decider.linear2.weight: 0.0053032441064715385 0.054106373339891434
decider.linear2.bias: 0.008825602009892464 0.05706487596035004
decider.linear3.weight: -0.03234981745481491 0.08060090988874435
decider.linear3.bias: -0.007711742538958788 0.048518091440200806

Rewards:
221.7540
221.7540
221.7540
objective = 163.17266845703125
==== episode 4900/10000 ====
action = 1
probs = 0.0041 0.9959 0.0000 0.0000

action = 1
probs = 0.1085 0.8915 0.0000 0.0000

action = 0
probs = 0.9685 0.0315 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002964460290968418 0.08608509600162506
encoder.encoder.weight_hh_l0: 5.3995594498701394e-05 0.08795978873968124
encoder.encoder.bias_ih_l0: 0.014566261321306229 0.08973173797130585
encoder.encoder.bias_hh_l0: 0.024563312530517578 0.08763905614614487
encoder.encoder.weight_ih_l0_reverse: 0.0019484013319015503 0.08834099024534225
encoder.encoder.weight_hh_l0_reverse: 0.009373137727379799 0.08807381242513657
encoder.encoder.bias_ih_l0_reverse: 0.03567908704280853 0.08602801710367203
encoder.encoder.bias_hh_l0_reverse: 0.02754468098282814 0.08313602209091187
decider.lstm.weight_ih_l0: 0.0022867522202432156 0.14918062090873718
decider.lstm.weight_hh_l0: 0.003327525220811367 0.14878009259700775
decider.lstm.bias_ih_l0: 0.025938045233488083 0.1599050909280777
decider.lstm.bias_hh_l0: 0.006950550712645054 0.14092789590358734
decider.linear1.weight: 0.004371579270809889 0.12171607464551926
decider.linear1.bias: 0.02012547291815281 0.11756336688995361
decider.linear2.weight: 0.005229143425822258 0.05408618226647377
decider.linear2.bias: 0.008733438327908516 0.05708874762058258
decider.linear3.weight: -0.03260974586009979 0.08109726011753082
decider.linear3.bias: -0.00779180321842432 0.048738960176706314

Rewards:
230.1930
230.1930
230.1930
objective = 11.586565017700195
==== episode 5000/10000 ====
action = 1
probs = 0.0039 0.9960 0.0000 0.0000

action = 1
probs = 0.0889 0.9111 0.0000 0.0000

action = 0
probs = 0.9699 0.0301 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002937906829174608 0.08605919778347015
encoder.encoder.weight_hh_l0: 5.232527109910734e-05 0.08793272823095322
encoder.encoder.bias_ih_l0: 0.014508814550936222 0.08967342972755432
encoder.encoder.bias_hh_l0: 0.024505870416760445 0.08764559775590897
encoder.encoder.weight_ih_l0_reverse: 0.001938479021191597 0.08836203068494797
encoder.encoder.weight_hh_l0_reverse: 0.009350404143333435 0.08805383741855621
encoder.encoder.bias_ih_l0_reverse: 0.03567767143249512 0.08602936565876007
encoder.encoder.bias_hh_l0_reverse: 0.027543263509869576 0.08316389471292496
decider.lstm.weight_ih_l0: 0.0022695527877658606 0.14914529025554657
decider.lstm.weight_hh_l0: 0.003317884635180235 0.14874790608882904
decider.lstm.bias_ih_l0: 0.025872930884361267 0.15984757244586945
decider.lstm.bias_hh_l0: 0.0068854400888085365 0.1409149169921875
decider.linear1.weight: 0.004376263823360205 0.1217217892408371
decider.linear1.bias: 0.020166531205177307 0.1176135390996933
decider.linear2.weight: 0.005249916575849056 0.054087862372398376
decider.linear2.bias: 0.008758296258747578 0.05706636235117912
decider.linear3.weight: -0.032865408807992935 0.08165227621793747
decider.linear3.bias: -0.00787048414349556 0.04882343113422394

Rewards:
230.1930
230.1930
230.1930
objective = 9.792449951171875
==== episode 5100/10000 ====
action = 1
probs = 0.0041 0.9959 0.0000 0.0000

action = 0
probs = 0.0820 0.9180 0.0000 0.0000

action = 0
probs = 0.9604 0.0396 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002864658017642796 0.08600577712059021
encoder.encoder.weight_hh_l0: 5.298760879668407e-05 0.0878632441163063
encoder.encoder.bias_ih_l0: 0.014319604262709618 0.08958935737609863
encoder.encoder.bias_hh_l0: 0.024316662922501564 0.08758440613746643
encoder.encoder.weight_ih_l0_reverse: 0.0019417029106989503 0.08830514550209045
encoder.encoder.weight_hh_l0_reverse: 0.009367011487483978 0.0880659744143486
encoder.encoder.bias_ih_l0_reverse: 0.03561132773756981 0.08599448204040527
encoder.encoder.bias_hh_l0_reverse: 0.027476917952299118 0.08317166566848755
decider.lstm.weight_ih_l0: 0.0022311380598694086 0.1491018831729889
decider.lstm.weight_hh_l0: 0.003292026463896036 0.14871227741241455
decider.lstm.bias_ih_l0: 0.025672849267721176 0.15983031690120697
decider.lstm.bias_hh_l0: 0.006685351952910423 0.14087630808353424
decider.linear1.weight: 0.0043752072378993034 0.1216876208782196
decider.linear1.bias: 0.019998593255877495 0.1175931841135025
decider.linear2.weight: 0.005191110540181398 0.05406380444765091
decider.linear2.bias: 0.008683961816132069 0.05706793814897537
decider.linear3.weight: -0.03314271941781044 0.0822189599275589
decider.linear3.bias: -0.007947691716253757 0.04896172508597374

Rewards:
221.7540
221.7540
221.7540
objective = 188.18060302734375
==== episode 5200/10000 ====
action = 1
probs = 0.0040 0.9960 0.0000 0.0000

action = 1
probs = 0.0990 0.9010 0.0000 0.0000

action = 0
probs = 0.9782 0.0218 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002957298420369625 0.08611465990543365
encoder.encoder.weight_hh_l0: 5.254405550658703e-05 0.08799778670072556
encoder.encoder.bias_ih_l0: 0.014627882279455662 0.08975255489349365
encoder.encoder.bias_hh_l0: 0.024624938145279884 0.08772117644548416
encoder.encoder.weight_ih_l0_reverse: 0.0019264889415353537 0.08840342611074448
encoder.encoder.weight_hh_l0_reverse: 0.00933786015957594 0.08805178105831146
encoder.encoder.bias_ih_l0_reverse: 0.03569039702415466 0.0860527902841568
encoder.encoder.bias_hh_l0_reverse: 0.02755598910152912 0.08315663039684296
decider.lstm.weight_ih_l0: 0.002317253965884447 0.14921848475933075
decider.lstm.weight_hh_l0: 0.0033450121991336346 0.14880727231502533
decider.lstm.bias_ih_l0: 0.0261196568608284 0.15988439321517944
decider.lstm.bias_hh_l0: 0.007132155355066061 0.14097361266613007
decider.linear1.weight: 0.004377327859401703 0.12174490839242935
decider.linear1.bias: 0.020261581987142563 0.11763007938861847
decider.linear2.weight: 0.005296346731483936 0.05411398783326149
decider.linear2.bias: 0.008809632621705532 0.057056814432144165
decider.linear3.weight: -0.03342713788151741 0.0828990563750267
decider.linear3.bias: -0.008036956191062927 0.04866062104701996

Rewards:
230.1930
230.1930
230.1930
objective = 9.998930931091309
==== episode 5300/10000 ====
action = 1
probs = 0.0024 0.9976 0.0000 0.0000

action = 1
probs = 0.0556 0.9444 0.0000 0.0000

action = 0
probs = 0.9725 0.0275 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00031364517053589225 0.08620454370975494
encoder.encoder.weight_hh_l0: 4.9150679842568934e-05 0.088102787733078
encoder.encoder.bias_ih_l0: 0.014868753962218761 0.0898318961262703
encoder.encoder.bias_hh_l0: 0.024865813553333282 0.08785970509052277
encoder.encoder.weight_ih_l0_reverse: 0.0019270011689513922 0.0884966254234314
encoder.encoder.weight_hh_l0_reverse: 0.009327773936092854 0.08805111050605774
encoder.encoder.bias_ih_l0_reverse: 0.0358467660844326 0.08608546853065491
encoder.encoder.bias_hh_l0_reverse: 0.02771235629916191 0.08320457488298416
decider.lstm.weight_ih_l0: 0.002378033008426428 0.1492757648229599
decider.lstm.weight_hh_l0: 0.0033829514868557453 0.14885586500167847
decider.lstm.bias_ih_l0: 0.02641487866640091 0.15993589162826538
decider.lstm.bias_hh_l0: 0.007427380420267582 0.14100059866905212
decider.linear1.weight: 0.0043729739263653755 0.12179229408502579
decider.linear1.bias: 0.020443331450223923 0.11765579134225845
decider.linear2.weight: 0.0053141918033361435 0.05413838475942612
decider.linear2.bias: 0.008829792030155659 0.05708537623286247
decider.linear3.weight: -0.03360990434885025 0.08334741741418839
decider.linear3.bias: -0.008093626238405704 0.04918351769447327

Rewards:
230.1930
230.1930
230.1930
objective = 6.717006683349609
==== episode 5400/10000 ====
action = 1
probs = 0.0012 0.9988 0.0000 0.0000

action = 1
probs = 0.0201 0.9799 0.0000 0.0000

action = 0
probs = 0.8995 0.1005 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00034116380265913904 0.08624931424856186
encoder.encoder.weight_hh_l0: 4.951619848725386e-05 0.08813454210758209
encoder.encoder.bias_ih_l0: 0.014987539499998093 0.08978750556707382
encoder.encoder.bias_hh_l0: 0.02498459257185459 0.08790474385023117
encoder.encoder.weight_ih_l0_reverse: 0.0019206448923796415 0.08850958198308945
encoder.encoder.weight_hh_l0_reverse: 0.00934575591236353 0.08807343244552612
encoder.encoder.bias_ih_l0_reverse: 0.035978320986032486 0.08603882044553757
encoder.encoder.bias_hh_l0_reverse: 0.027843911200761795 0.08327850699424744
decider.lstm.weight_ih_l0: 0.0023903129622340202 0.14926211535930634
decider.lstm.weight_hh_l0: 0.003386802040040493 0.14884892106056213
decider.lstm.bias_ih_l0: 0.026434579864144325 0.1600094437599182
decider.lstm.bias_hh_l0: 0.007447089534252882 0.1409335434436798
decider.linear1.weight: 0.004359341226518154 0.12178653478622437
decider.linear1.bias: 0.020366700366139412 0.11759897321462631
decider.linear2.weight: 0.005226481705904007 0.054108649492263794
decider.linear2.bias: 0.008728837594389915 0.05714922025799751
decider.linear3.weight: -0.03381286561489105 0.08373521268367767
decider.linear3.bias: -0.008131124079227448 0.05029430240392685

Rewards:
230.1930
230.1930
230.1930
objective = 9.772716522216797
==== episode 5500/10000 ====
action = 1
probs = 0.0011 0.9989 0.0000 0.0000

action = 1
probs = 0.0207 0.9793 0.0000 0.0000

action = 0
probs = 0.9406 0.0594 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003339210816193372 0.08630388975143433
encoder.encoder.weight_hh_l0: 4.377076402306557e-05 0.08821636438369751
encoder.encoder.bias_ih_l0: 0.015102548524737358 0.0898924320936203
encoder.encoder.bias_hh_l0: 0.02509959787130356 0.08798526972532272
encoder.encoder.weight_ih_l0_reverse: 0.0019327333429828286 0.08857972174882889
encoder.encoder.weight_hh_l0_reverse: 0.009334125556051731 0.08807314932346344
encoder.encoder.bias_ih_l0_reverse: 0.036024309694767 0.08609539270401001
encoder.encoder.bias_hh_l0_reverse: 0.027889898046851158 0.08327388018369675
decider.lstm.weight_ih_l0: 0.0024350695312023163 0.14931820333003998
decider.lstm.weight_hh_l0: 0.003416837193071842 0.14888659119606018
decider.lstm.bias_ih_l0: 0.026660114526748657 0.15998375415802002
decider.lstm.bias_hh_l0: 0.0076726339757442474 0.1410047709941864
decider.linear1.weight: 0.004362477920949459 0.12183210253715515
decider.linear1.bias: 0.020559074357151985 0.11763361096382141
decider.linear2.weight: 0.0053176721557974815 0.05415777489542961
decider.linear2.bias: 0.008894591592252254 0.05709106847643852
decider.linear3.weight: -0.03409632667899132 0.08433722704648972
decider.linear3.bias: -0.0081632100045681 0.05005408078432083

Rewards:
230.1930
230.1930
230.1930
objective = 6.382894039154053
==== episode 5600/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0125 0.9875 0.0000 0.0000

action = 0
probs = 0.9463 0.0537 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00034926910302601755 0.08637788891792297
encoder.encoder.weight_hh_l0: 3.604685116442852e-05 0.08831320703029633
encoder.encoder.bias_ih_l0: 0.015352400951087475 0.08997858315706253
encoder.encoder.bias_hh_l0: 0.0253494493663311 0.08807419240474701
encoder.encoder.weight_ih_l0_reverse: 0.0019475811859592795 0.08867572993040085
encoder.encoder.weight_hh_l0_reverse: 0.009319271892309189 0.08806495368480682
encoder.encoder.bias_ih_l0_reverse: 0.036171041429042816 0.08613839000463486
encoder.encoder.bias_hh_l0_reverse: 0.028036629781126976 0.08329541236162186
decider.lstm.weight_ih_l0: 0.0024828282184898853 0.14936266839504242
decider.lstm.weight_hh_l0: 0.003450256772339344 0.14891640841960907
decider.lstm.bias_ih_l0: 0.026896528899669647 0.15999148786067963
decider.lstm.bias_hh_l0: 0.007909052073955536 0.14104148745536804
decider.linear1.weight: 0.004363286774605513 0.12188858538866043
decider.linear1.bias: 0.02078240178525448 0.11766275018453598
decider.linear2.weight: 0.005428003147244453 0.054235901683568954
decider.linear2.bias: 0.009036141447722912 0.057084713131189346
decider.linear3.weight: -0.034374527633190155 0.08489755541086197
decider.linear3.bias: -0.008185098879039288 0.05018765106797218

Rewards:
230.1930
230.1930
230.1930
objective = 5.244296073913574
==== episode 5700/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0154 0.9846 0.0000 0.0000

action = 0
probs = 0.9774 0.0226 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00035425968235358596 0.08642062544822693
encoder.encoder.weight_hh_l0: 2.8841113817179576e-05 0.08837922662496567
encoder.encoder.bias_ih_l0: 0.015501956455409527 0.09007636457681656
encoder.encoder.bias_hh_l0: 0.025499003008008003 0.08813800662755966
encoder.encoder.weight_ih_l0_reverse: 0.001971282297745347 0.08875025063753128
encoder.encoder.weight_hh_l0_reverse: 0.009302154183387756 0.08805251121520996
encoder.encoder.bias_ih_l0_reverse: 0.03623821586370468 0.08619444072246552
encoder.encoder.bias_hh_l0_reverse: 0.02810380421578884 0.08327417075634003
decider.lstm.weight_ih_l0: 0.002514858264476061 0.14940209686756134
decider.lstm.weight_hh_l0: 0.0034749649930745363 0.14894656836986542
decider.lstm.bias_ih_l0: 0.02706950716674328 0.159988671541214
decider.lstm.bias_hh_l0: 0.008082021027803421 0.141096830368042
decider.linear1.weight: 0.004373547621071339 0.1219530701637268
decider.linear1.bias: 0.021074846386909485 0.11765013635158539
decider.linear2.weight: 0.005525211803615093 0.05433708056807518
decider.linear2.bias: 0.009120780043303967 0.05707106366753578
decider.linear3.weight: -0.03455770015716553 0.08532790094614029
decider.linear3.bias: -0.00820010993629694 0.04980137199163437

Rewards:
230.1930
230.1930
230.1930
objective = 2.995819091796875
==== episode 5800/10000 ====
action = 1
probs = 0.0009 0.9991 0.0000 0.0000

action = 1
probs = 0.0191 0.9809 0.0000 0.0000

action = 0
probs = 0.9912 0.0088 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003510144306346774 0.08635876327753067
encoder.encoder.weight_hh_l0: 2.903194399550557e-05 0.08831198513507843
encoder.encoder.bias_ih_l0: 0.015381282195448875 0.09001344442367554
encoder.encoder.bias_hh_l0: 0.025378331542015076 0.08809532225131989
encoder.encoder.weight_ih_l0_reverse: 0.0019771510269492865 0.088767409324646
encoder.encoder.weight_hh_l0_reverse: 0.009271200746297836 0.0880184918642044
encoder.encoder.bias_ih_l0_reverse: 0.03621264547109604 0.08621034771203995
encoder.encoder.bias_hh_l0_reverse: 0.02807823196053505 0.08327410370111465
decider.lstm.weight_ih_l0: 0.0025007473304867744 0.14939221739768982
decider.lstm.weight_hh_l0: 0.0034668007865548134 0.14893756806850433
decider.lstm.bias_ih_l0: 0.027035260573029518 0.15994291007518768
decider.lstm.bias_hh_l0: 0.00804777443408966 0.14118576049804688
decider.linear1.weight: 0.0043894085101783276 0.12200527638196945
decider.linear1.bias: 0.021249622106552124 0.11765068024396896
decider.linear2.weight: 0.005625083111226559 0.05449695512652397
decider.linear2.bias: 0.009183433838188648 0.057065777480602264
decider.linear3.weight: -0.034693628549575806 0.08560565859079361
decider.linear3.bias: -0.008214417845010757 0.04951297864317894

Rewards:
230.1930
230.1930
230.1930
objective = 2.224527359008789
==== episode 5900/10000 ====
action = 1
probs = 0.0008 0.9992 0.0000 0.0000

action = 1
probs = 0.0177 0.9823 0.0000 0.0000

action = 0
probs = 0.9883 0.0117 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003441166190896183 0.08634648472070694
encoder.encoder.weight_hh_l0: 3.390431447769515e-05 0.08829300850629807
encoder.encoder.bias_ih_l0: 0.01529711950570345 0.08999579399824142
encoder.encoder.bias_hh_l0: 0.025294169783592224 0.08806951344013214
encoder.encoder.weight_ih_l0_reverse: 0.0019688294269144535 0.08873526751995087
encoder.encoder.weight_hh_l0_reverse: 0.009279416874051094 0.08803319185972214
encoder.encoder.bias_ih_l0_reverse: 0.0361563041806221 0.08619903028011322
encoder.encoder.bias_hh_l0_reverse: 0.02802189067006111 0.08328127861022949
decider.lstm.weight_ih_l0: 0.0024909109342843294 0.14938108623027802
decider.lstm.weight_hh_l0: 0.0034568908158689737 0.14893020689487457
decider.lstm.bias_ih_l0: 0.026969630271196365 0.15995056927204132
decider.lstm.bias_hh_l0: 0.007982132956385612 0.1411651074886322
decider.linear1.weight: 0.004384186118841171 0.12198366224765778
decider.linear1.bias: 0.021163800731301308 0.11763687431812286
decider.linear2.weight: 0.005580431316047907 0.05448120832443237
decider.linear2.bias: 0.009130628779530525 0.05706574395298958
decider.linear3.weight: -0.034815650433301926 0.08580513298511505
decider.linear3.bias: -0.008229551836848259 0.049599628895521164

Rewards:
230.1930
230.1930
230.1930
objective = 2.3324079513549805
==== episode 6000/10000 ====
action = 1
probs = 0.0009 0.9991 0.0000 0.0000

action = 1
probs = 0.0213 0.9787 0.0000 0.0000

action = 0
probs = 0.9931 0.0069 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003515248536132276 0.08638181537389755
encoder.encoder.weight_hh_l0: 2.7670716008287854e-05 0.08834270387887955
encoder.encoder.bias_ih_l0: 0.01543919276446104 0.09006407111883163
encoder.encoder.bias_hh_l0: 0.025436243042349815 0.08812171220779419
encoder.encoder.weight_ih_l0_reverse: 0.0019871473778039217 0.08879360556602478
encoder.encoder.weight_hh_l0_reverse: 0.009264367632567883 0.08802084624767303
encoder.encoder.bias_ih_l0_reverse: 0.03622160106897354 0.08622448891401291
encoder.encoder.bias_hh_l0_reverse: 0.02808719128370285 0.08325982838869095
decider.lstm.weight_ih_l0: 0.0025195705238729715 0.14941254258155823
decider.lstm.weight_hh_l0: 0.003479626029729843 0.1489560902118683
decider.lstm.bias_ih_l0: 0.027122823521494865 0.1599646955728531
decider.lstm.bias_hh_l0: 0.008135322481393814 0.1412021517753601
decider.linear1.weight: 0.0043943519704043865 0.12202765047550201
decider.linear1.bias: 0.021328918635845184 0.11760330200195312
decider.linear2.weight: 0.005660177208483219 0.054532915353775024
decider.linear2.bias: 0.009207969531416893 0.05706370249390602
decider.linear3.weight: -0.03492245450615883 0.08606161922216415
decider.linear3.bias: -0.008243987336754799 0.04936406388878822

Rewards:
230.1930
230.1930
230.1930
objective = 2.2488574981689453
==== episode 6100/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0157 0.9843 0.0000 0.0000

action = 0
probs = 0.9943 0.0057 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000372447248082608 0.08643219619989395
encoder.encoder.weight_hh_l0: 1.8120097593055107e-05 0.08840738981962204
encoder.encoder.bias_ih_l0: 0.015629548579454422 0.09011666476726532
encoder.encoder.bias_hh_l0: 0.025626596063375473 0.08818808943033218
encoder.encoder.weight_ih_l0_reverse: 0.0020068520680069923 0.08886999636888504
encoder.encoder.weight_hh_l0_reverse: 0.009264248423278332 0.08802521973848343
encoder.encoder.bias_ih_l0_reverse: 0.03636963665485382 0.08626030385494232
encoder.encoder.bias_hh_l0_reverse: 0.02823523059487343 0.08327282220125198
decider.lstm.weight_ih_l0: 0.0025478440802544355 0.14943872392177582
decider.lstm.weight_hh_l0: 0.0035042159724980593 0.14897888898849487
decider.lstm.bias_ih_l0: 0.027278289198875427 0.1599818468093872
decider.lstm.bias_hh_l0: 0.008290782570838928 0.14122352004051208
decider.linear1.weight: 0.004403365775942802 0.12207713723182678
decider.linear1.bias: 0.02151542529463768 0.1176258847117424
decider.linear2.weight: 0.00573473796248436 0.05460737645626068
decider.linear2.bias: 0.009282859042286873 0.05707878991961479
decider.linear3.weight: -0.035007208585739136 0.0863041803240776
decider.linear3.bias: -0.008256129920482635 0.049482520669698715

Rewards:
230.1930
230.1930
230.1930
objective = 1.701188087463379
==== episode 6200/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0138 0.9862 0.0000 0.0000

action = 0
probs = 0.9931 0.0069 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003704415285028517 0.08643113076686859
encoder.encoder.weight_hh_l0: 2.111904541379772e-05 0.08840271085500717
encoder.encoder.bias_ih_l0: 0.015586053021252155 0.09010207653045654
encoder.encoder.bias_hh_l0: 0.02558310143649578 0.08818072825670242
encoder.encoder.weight_ih_l0_reverse: 0.0019983581732958555 0.08885212242603302
encoder.encoder.weight_hh_l0_reverse: 0.009269348345696926 0.08803217858076096
encoder.encoder.bias_ih_l0_reverse: 0.036346033215522766 0.08625414967536926
encoder.encoder.bias_hh_l0_reverse: 0.028211619704961777 0.083284892141819
decider.lstm.weight_ih_l0: 0.0025440051686018705 0.14943267405033112
decider.lstm.weight_hh_l0: 0.0034999412018805742 0.14897580444812775
decider.lstm.bias_ih_l0: 0.027250314131379128 0.15998971462249756
decider.lstm.bias_hh_l0: 0.008262813091278076 0.1412011682987213
decider.linear1.weight: 0.004399324767291546 0.12206821143627167
decider.linear1.bias: 0.02147519960999489 0.11762740463018417
decider.linear2.weight: 0.005711582954972982 0.05460831895470619
decider.linear2.bias: 0.009256836026906967 0.057086169719696045
decider.linear3.weight: -0.03508416563272476 0.08645694702863693
decider.linear3.bias: -0.008267320692539215 0.04961308464407921

Rewards:
230.1930
230.1930
230.1930
objective = 1.64961576461792
==== episode 6300/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0078 0.9922 0.0000 0.0000

action = 0
probs = 0.9731 0.0269 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00036699287011288106 0.0864105373620987
encoder.encoder.weight_hh_l0: 2.8983806259930134e-05 0.08835658431053162
encoder.encoder.bias_ih_l0: 0.015436314046382904 0.08998961746692657
encoder.encoder.bias_hh_l0: 0.025433361530303955 0.08811036497354507
encoder.encoder.weight_ih_l0_reverse: 0.0019555820617824793 0.08877392113208771
encoder.encoder.weight_hh_l0_reverse: 0.009287713095545769 0.08803721517324448
encoder.encoder.bias_ih_l0_reverse: 0.03626140207052231 0.08621270209550858
encoder.encoder.bias_hh_l0_reverse: 0.028126994147896767 0.08333443105220795
decider.lstm.weight_ih_l0: 0.002509454730898142 0.1493981033563614
decider.lstm.weight_hh_l0: 0.0034717905800789595 0.14895065128803253
decider.lstm.bias_ih_l0: 0.027061201632022858 0.16001029312610626
decider.lstm.bias_hh_l0: 0.00807369314134121 0.141109436750412
decider.linear1.weight: 0.004384861793369055 0.1220225989818573
decider.linear1.bias: 0.021295398473739624 0.11759541928768158
decider.linear2.weight: 0.005663939286023378 0.05453148111701012
decider.linear2.bias: 0.009175027720630169 0.057115502655506134
decider.linear3.weight: -0.03514927625656128 0.08652358502149582
decider.linear3.bias: -0.008276496082544327 0.050175879150629044

Rewards:
230.1930
230.1930
230.1930
objective = 2.7230708599090576
==== episode 6400/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0070 0.9930 0.0000 0.0000

action = 0
probs = 0.9802 0.0198 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00037249401793815196 0.08645852655172348
encoder.encoder.weight_hh_l0: 2.3947512090671808e-05 0.08842453360557556
encoder.encoder.bias_ih_l0: 0.015578744933009148 0.09006565809249878
encoder.encoder.bias_hh_l0: 0.0255757924169302 0.08817503601312637
encoder.encoder.weight_ih_l0_reverse: 0.0019754546228796244 0.08884015679359436
encoder.encoder.weight_hh_l0_reverse: 0.009284445084631443 0.08804839104413986
encoder.encoder.bias_ih_l0_reverse: 0.0363478884100914 0.08624483644962311
encoder.encoder.bias_hh_l0_reverse: 0.02821348048746586 0.08334271609783173
decider.lstm.weight_ih_l0: 0.0025388295762240887 0.14942505955696106
decider.lstm.weight_hh_l0: 0.0034917183220386505 0.14896896481513977
decider.lstm.bias_ih_l0: 0.027203086763620377 0.16000469028949738
decider.lstm.bias_hh_l0: 0.008215581066906452 0.14114567637443542
decider.linear1.weight: 0.004384268075227737 0.12205587327480316
decider.linear1.bias: 0.021428624168038368 0.11761072278022766
decider.linear2.weight: 0.005680016707628965 0.054569490253925323
decider.linear2.bias: 0.009218843653798103 0.05712117627263069
decider.linear3.weight: -0.03522178530693054 0.0867479220032692
decider.linear3.bias: -0.008285017684102058 0.050197623670101166

Rewards:
230.1930
230.1930
230.1930
objective = 2.101865291595459
==== episode 6500/10000 ====
action = 1
probs = 0.0009 0.9991 0.0000 0.0000

action = 1
probs = 0.0255 0.9745 0.0000 0.0000

action = 0
probs = 0.9948 0.0052 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003417864500079304 0.08642624318599701
encoder.encoder.weight_hh_l0: 2.7658723411150277e-05 0.08839897066354752
encoder.encoder.bias_ih_l0: 0.015455191023647785 0.09014102816581726
encoder.encoder.bias_hh_l0: 0.025452231988310814 0.08816158026456833
encoder.encoder.weight_ih_l0_reverse: 0.001992418197914958 0.08881093561649323
encoder.encoder.weight_hh_l0_reverse: 0.009248207323253155 0.08802605420351028
encoder.encoder.bias_ih_l0_reverse: 0.0361560694873333 0.08624488115310669
encoder.encoder.bias_hh_l0_reverse: 0.028021667152643204 0.0832449272274971
decider.lstm.weight_ih_l0: 0.002542227739468217 0.14943569898605347
decider.lstm.weight_hh_l0: 0.0034897152800112963 0.14897729456424713
decider.lstm.bias_ih_l0: 0.027203485369682312 0.15999539196491241
decider.lstm.bias_hh_l0: 0.008215971291065216 0.14120513200759888
decider.linear1.weight: 0.0043885838240385056 0.12203497439622879
decider.linear1.bias: 0.02133881486952305 0.11758853495121002
decider.linear2.weight: 0.0056797172874212265 0.054587848484516144
decider.linear2.bias: 0.009210665710270405 0.0570576936006546
decider.linear3.weight: -0.0352860763669014 0.08686775714159012
decider.linear3.bias: -0.008293213322758675 0.04918775334954262

Rewards:
230.1930
230.1930
230.1930
objective = 2.4535624980926514
==== episode 6600/10000 ====
action = 1
probs = 0.0017 0.9983 0.0000 0.0000

action = 1
probs = 0.0682 0.9318 0.0000 0.0000

action = 0
probs = 0.9962 0.0038 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003114078426733613 0.08638917654752731
encoder.encoder.weight_hh_l0: 3.600773561629467e-05 0.08835234493017197
encoder.encoder.bias_ih_l0: 0.015302575193345547 0.09014251083135605
encoder.encoder.bias_hh_l0: 0.025299612432718277 0.08808721601963043
encoder.encoder.weight_ih_l0_reverse: 0.0019747880287468433 0.08872753381729126
encoder.encoder.weight_hh_l0_reverse: 0.009234352968633175 0.08801261335611343
encoder.encoder.bias_ih_l0_reverse: 0.035941507667303085 0.08621840178966522
encoder.encoder.bias_hh_l0_reverse: 0.02780710719525814 0.08317988365888596
decider.lstm.weight_ih_l0: 0.0025192962493747473 0.14942486584186554
decider.lstm.weight_hh_l0: 0.0034664319828152657 0.14896558225154877
decider.lstm.bias_ih_l0: 0.027053795754909515 0.15998852252960205
decider.lstm.bias_hh_l0: 0.008066296577453613 0.14119461178779602
decider.linear1.weight: 0.004381105303764343 0.12198541313409805
decider.linear1.bias: 0.02114095166325569 0.11755483597517014
decider.linear2.weight: 0.005644315853714943 0.05455690622329712
decider.linear2.bias: 0.009161115624010563 0.057024307548999786
decider.linear3.weight: -0.03543318063020706 0.08713430166244507
decider.linear3.bias: -0.008316597901284695 0.04859260097146034

Rewards:
230.1930
230.1930
230.1930
objective = 5.8467230796813965
==== episode 6700/10000 ====
action = 1
probs = 0.0024 0.9976 0.0000 0.0000

action = 1
probs = 0.1212 0.8788 0.0000 0.0000

action = 0
probs = 0.9978 0.0022 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00030731523293070495 0.08642406761646271
encoder.encoder.weight_hh_l0: 3.334060966153629e-05 0.08839864283800125
encoder.encoder.bias_ih_l0: 0.015439078211784363 0.09022953361272812
encoder.encoder.bias_hh_l0: 0.025436121970415115 0.08811827749013901
encoder.encoder.weight_ih_l0_reverse: 0.0019817096181213856 0.08875665813684464
encoder.encoder.weight_hh_l0_reverse: 0.009216726757586002 0.08800040185451508
encoder.encoder.bias_ih_l0_reverse: 0.0359414704144001 0.08623623847961426
encoder.encoder.bias_hh_l0_reverse: 0.027807066217064857 0.08313600718975067
decider.lstm.weight_ih_l0: 0.0025360691361129284 0.14945267140865326
decider.lstm.weight_hh_l0: 0.00347905489616096 0.14898763597011566
decider.lstm.bias_ih_l0: 0.027147218585014343 0.15999552607536316
decider.lstm.bias_hh_l0: 0.00815970916301012 0.14122584462165833
decider.linear1.weight: 0.0043847812339663506 0.12199905514717102
decider.linear1.bias: 0.021193210035562515 0.11755119264125824
decider.linear2.weight: 0.005682290066033602 0.054580796509981155
decider.linear2.bias: 0.009215420112013817 0.05701344832777977
decider.linear3.weight: -0.03563324362039566 0.08766996115446091
decider.linear3.bias: -0.00834704376757145 0.04813462495803833

Rewards:
230.1930
230.1930
230.1930
objective = 10.263957977294922
==== episode 6800/10000 ====
action = 1
probs = 0.0098 0.9902 0.0000 0.0000

action = 0
probs = 0.5443 0.4557 0.0000 0.0000

action = 0
probs = 0.9994 0.0006 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002896471705753356 0.08650585263967514
encoder.encoder.weight_hh_l0: 2.6511383111937903e-05 0.08851046860218048
encoder.encoder.bias_ih_l0: 0.01586996763944626 0.0904773399233818
encoder.encoder.bias_hh_l0: 0.02586701326072216 0.08813761174678802
encoder.encoder.weight_ih_l0_reverse: 0.001996248262003064 0.08881717920303345
encoder.encoder.weight_hh_l0_reverse: 0.009156889282166958 0.08796427398920059
encoder.encoder.bias_ih_l0_reverse: 0.035890817642211914 0.08626002818346024
encoder.encoder.bias_hh_l0_reverse: 0.02775641344487667 0.08301230520009995
decider.lstm.weight_ih_l0: 0.002547453623265028 0.14947466552257538
decider.lstm.weight_hh_l0: 0.0034776560496538877 0.14897315204143524
decider.lstm.bias_ih_l0: 0.027169745415449142 0.15986572206020355
decider.lstm.bias_hh_l0: 0.008182237856090069 0.14131282269954681
decider.linear1.weight: 0.004392697941511869 0.12200862914323807
decider.linear1.bias: 0.021237101405858994 0.11751273274421692
decider.linear2.weight: 0.0057352464646101 0.05461953952908516
decider.linear2.bias: 0.009348446503281593 0.05702812969684601
decider.linear3.weight: -0.03598707169294357 0.08865445107221603
decider.linear3.bias: -0.008394526317715645 0.04658202826976776

Rewards:
221.7540
221.7540
221.7540
objective = 45.73012924194336
==== episode 6900/10000 ====
action = 1
probs = 0.0064 0.9936 0.0000 0.0000

action = 1
probs = 0.2469 0.7531 0.0000 0.0000

action = 0
probs = 0.9985 0.0015 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002484893484506756 0.08630803227424622
encoder.encoder.weight_hh_l0: 5.004999547963962e-05 0.08827053010463715
encoder.encoder.bias_ih_l0: 0.015181639231741428 0.09014412760734558
encoder.encoder.bias_hh_l0: 0.025178683921694756 0.08789829164743423
encoder.encoder.weight_ih_l0_reverse: 0.001953572267666459 0.08864771574735641
encoder.encoder.weight_hh_l0_reverse: 0.00916784256696701 0.08796581625938416
encoder.encoder.bias_ih_l0_reverse: 0.03560660406947136 0.08617705851793289
encoder.encoder.bias_hh_l0_reverse: 0.027472205460071564 0.08306560665369034
decider.lstm.weight_ih_l0: 0.0024811693001538515 0.14938153326511383
decider.lstm.weight_hh_l0: 0.003419817192479968 0.14886821806430817
decider.lstm.bias_ih_l0: 0.02674076333642006 0.15981613099575043
decider.lstm.bias_hh_l0: 0.00775326369330287 0.14131426811218262
decider.linear1.weight: 0.004403168801218271 0.12193945050239563
decider.linear1.bias: 0.020940301939845085 0.11759565025568008
decider.linear2.weight: 0.0056344373151659966 0.05456038936972618
decider.linear2.bias: 0.009156512096524239 0.05698372796177864
decider.linear3.weight: -0.03641185909509659 0.08981575816869736
decider.linear3.bias: -0.008465433493256569 0.04744532331824303

Rewards:
230.1930
230.1930
230.1930
objective = 22.369354248046875
==== episode 7000/10000 ====
action = 1
probs = 0.0053 0.9947 0.0000 0.0000

action = 1
probs = 0.1785 0.8215 0.0000 0.0000

action = 0
probs = 0.9981 0.0019 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00024034931266214699 0.08625771850347519
encoder.encoder.weight_hh_l0: 5.2899515139870346e-05 0.08820933848619461
encoder.encoder.bias_ih_l0: 0.014997622929513454 0.09004855901002884
encoder.encoder.bias_hh_l0: 0.024994665756821632 0.08785495907068253
encoder.encoder.weight_ih_l0_reverse: 0.0019431670662015676 0.08861403167247772
encoder.encoder.weight_hh_l0_reverse: 0.009169694036245346 0.0879644826054573
encoder.encoder.bias_ih_l0_reverse: 0.03555648773908615 0.08615997433662415
encoder.encoder.bias_hh_l0_reverse: 0.027422087267041206 0.08308371156454086
decider.lstm.weight_ih_l0: 0.002459340961650014 0.149352565407753
decider.lstm.weight_hh_l0: 0.003405094612389803 0.14883698523044586
decider.lstm.bias_ih_l0: 0.026628762483596802 0.1598052680492401
decider.lstm.bias_hh_l0: 0.007641260512173176 0.1413055807352066
decider.linear1.weight: 0.0044061578810215 0.12193613499403
decider.linear1.bias: 0.02090863324701786 0.11762110888957977
decider.linear2.weight: 0.005619293078780174 0.05455545708537102
decider.linear2.bias: 0.00911208800971508 0.05696675553917885
decider.linear3.weight: -0.03677518665790558 0.09081348031759262
decider.linear3.bias: -0.008538980036973953 0.04770180955529213

Rewards:
230.1930
230.1930
230.1930
objective = 15.638765335083008
==== episode 7100/10000 ====
action = 1
probs = 0.0043 0.9957 0.0000 0.0000

action = 1
probs = 0.1186 0.8814 0.0000 0.0000

action = 0
probs = 0.9974 0.0026 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00024147957446984947 0.08619862049818039
encoder.encoder.weight_hh_l0: 5.4310796258505434e-05 0.08813735842704773
encoder.encoder.bias_ih_l0: 0.014797515235841274 0.08993492275476456
encoder.encoder.bias_hh_l0: 0.0247945636510849 0.08779355138540268
encoder.encoder.weight_ih_l0_reverse: 0.0019393303664401174 0.08859115839004517
encoder.encoder.weight_hh_l0_reverse: 0.009179225191473961 0.0879681184887886
encoder.encoder.bias_ih_l0_reverse: 0.035531554371118546 0.08614407479763031
encoder.encoder.bias_hh_l0_reverse: 0.02739715576171875 0.08311991393566132
decider.lstm.weight_ih_l0: 0.00243496079929173 0.14931462705135345
decider.lstm.weight_hh_l0: 0.0033873538486659527 0.1488025188446045
decider.lstm.bias_ih_l0: 0.026493972167372704 0.15976890921592712
decider.lstm.bias_hh_l0: 0.007506468333303928 0.14129233360290527
decider.linear1.weight: 0.004408923909068108 0.1219344362616539
decider.linear1.bias: 0.020889341831207275 0.11762043833732605
decider.linear2.weight: 0.005609883926808834 0.05454772710800171
decider.linear2.bias: 0.00907108560204506 0.056970153003931046
decider.linear3.weight: -0.03711953014135361 0.09175607562065125
decider.linear3.bias: -0.008614972233772278 0.04807671904563904

Rewards:
230.1930
230.1930
230.1930
objective = 10.215133666992188
==== episode 7200/10000 ====
action = 1
probs = 0.0020 0.9980 0.0000 0.0000

action = 1
probs = 0.0459 0.9541 0.0000 0.0000

action = 0
probs = 0.9959 0.0041 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00027408613823354244 0.08624150604009628
encoder.encoder.weight_hh_l0: 4.8654961574357e-05 0.08818533271551132
encoder.encoder.bias_ih_l0: 0.01483259629458189 0.08992694318294525
encoder.encoder.bias_hh_l0: 0.024829650297760963 0.08790259063243866
encoder.encoder.weight_ih_l0_reverse: 0.001946085598319769 0.0886550173163414
encoder.encoder.weight_hh_l0_reverse: 0.009208410046994686 0.08798673003911972
encoder.encoder.bias_ih_l0_reverse: 0.03571956977248192 0.08616595715284348
encoder.encoder.bias_hh_l0_reverse: 0.027585169300436974 0.08321177959442139
decider.lstm.weight_ih_l0: 0.002480731112882495 0.14935459196567535
decider.lstm.weight_hh_l0: 0.003426539245992899 0.14886319637298584
decider.lstm.bias_ih_l0: 0.026765312999486923 0.15982110798358917
decider.lstm.bias_hh_l0: 0.007777812425047159 0.14127835631370544
decider.linear1.weight: 0.004422658588737249 0.12198752164840698
decider.linear1.bias: 0.021096501499414444 0.11761554330587387
decider.linear2.weight: 0.005631743464618921 0.054574187844991684
decider.linear2.bias: 0.00906697753816843 0.05702079087495804
decider.linear3.weight: -0.03732062503695488 0.09234629571437836
decider.linear3.bias: -0.008664024993777275 0.04890328273177147

Rewards:
230.1930
230.1930
230.1930
objective = 4.070431709289551
==== episode 7300/10000 ====
action = 1
probs = 0.0030 0.9970 0.0000 0.0000

action = 1
probs = 0.0884 0.9116 0.0000 0.0000

action = 0
probs = 0.9970 0.0030 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00025322320288978517 0.08623509109020233
encoder.encoder.weight_hh_l0: 5.417353895609267e-05 0.0881756842136383
encoder.encoder.bias_ih_l0: 0.014829392544925213 0.08996352553367615
encoder.encoder.bias_hh_l0: 0.024826444685459137 0.08785321563482285
encoder.encoder.weight_ih_l0_reverse: 0.001940306043252349 0.08861249685287476
encoder.encoder.weight_hh_l0_reverse: 0.009196427650749683 0.08798292279243469
encoder.encoder.bias_ih_l0_reverse: 0.03558410704135895 0.08616726100444794
encoder.encoder.bias_hh_l0_reverse: 0.027449702844023705 0.08314701169729233
decider.lstm.weight_ih_l0: 0.0024756374768912792 0.14937449991703033
decider.lstm.weight_hh_l0: 0.0034165075048804283 0.14887572824954987
decider.lstm.bias_ih_l0: 0.02670281007885933 0.15986131131649017
decider.lstm.bias_hh_l0: 0.007715309504419565 0.1412811577320099
decider.linear1.weight: 0.00441501010209322 0.12194997817277908
decider.linear1.bias: 0.02094252221286297 0.11760083585977554
decider.linear2.weight: 0.005623354110866785 0.05455763265490532
decider.linear2.bias: 0.009056828916072845 0.05698753148317337
decider.linear3.weight: -0.03745259717106819 0.0926390290260315
decider.linear3.bias: -0.00869790744036436 0.04834067076444626

Rewards:
230.1930
230.1930
230.1930
objective = 7.564353942871094
==== episode 7400/10000 ====
action = 1
probs = 0.0028 0.9972 0.0000 0.0000

action = 1
probs = 0.0881 0.9119 0.0000 0.0000

action = 0
probs = 0.9969 0.0031 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00025420321617275476 0.08625175058841705
encoder.encoder.weight_hh_l0: 5.5560907640028745e-05 0.08818920701742172
encoder.encoder.bias_ih_l0: 0.014816186390817165 0.08998118340969086
encoder.encoder.bias_hh_l0: 0.02481323853135109 0.08787529915571213
encoder.encoder.weight_ih_l0_reverse: 0.0019385168561711907 0.08860878646373749
encoder.encoder.weight_hh_l0_reverse: 0.009203520603477955 0.08799025416374207
encoder.encoder.bias_ih_l0_reverse: 0.03557290881872177 0.08617252111434937
encoder.encoder.bias_hh_l0_reverse: 0.027438506484031677 0.08314570039510727
decider.lstm.weight_ih_l0: 0.002493496285751462 0.14940831065177917
decider.lstm.weight_hh_l0: 0.003426043316721916 0.14891694486141205
decider.lstm.bias_ih_l0: 0.02678762376308441 0.15992221236228943
decider.lstm.bias_hh_l0: 0.007800125516951084 0.14127515256404877
decider.linear1.weight: 0.004410546272993088 0.12194991856813431
decider.linear1.bias: 0.020920541137456894 0.11758933216333389
decider.linear2.weight: 0.005618368741124868 0.05455729737877846
decider.linear2.bias: 0.009038656949996948 0.05698724091053009
decider.linear3.weight: -0.03768187761306763 0.0932578295469284
decider.linear3.bias: -0.008752560243010521 0.04841315373778343

Rewards:
230.1930
230.1930
230.1930
objective = 7.53085994720459
==== episode 7500/10000 ====
action = 1
probs = 0.0020 0.9980 0.0000 0.0000

action = 1
probs = 0.0416 0.9584 0.0000 0.0000

action = 0
probs = 0.9955 0.0045 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00026752721169032156 0.08618941903114319
encoder.encoder.weight_hh_l0: 4.9446865887148306e-05 0.08811512589454651
encoder.encoder.bias_ih_l0: 0.014635767787694931 0.08983927965164185
encoder.encoder.bias_hh_l0: 0.02463282085955143 0.08784224838018417
encoder.encoder.weight_ih_l0_reverse: 0.0019371995003893971 0.08861897885799408
encoder.encoder.weight_hh_l0_reverse: 0.009207235649228096 0.08798197656869888
encoder.encoder.bias_ih_l0_reverse: 0.03562833368778229 0.08615624904632568
encoder.encoder.bias_hh_l0_reverse: 0.027493933215737343 0.08322013914585114
decider.lstm.weight_ih_l0: 0.002453921362757683 0.1493329554796219
decider.lstm.weight_hh_l0: 0.003403398673981428 0.14885666966438293
decider.lstm.bias_ih_l0: 0.026609046384692192 0.1598474383354187
decider.lstm.bias_hh_l0: 0.007621550001204014 0.1412591189146042
decider.linear1.weight: 0.004417757038027048 0.12197131663560867
decider.linear1.bias: 0.021009473130106926 0.11761824786663055
decider.linear2.weight: 0.005626194644719362 0.05456298589706421
decider.linear2.bias: 0.00902305543422699 0.05701436847448349
decider.linear3.weight: -0.037863217294216156 0.09377606958150864
decider.linear3.bias: -0.008797976188361645 0.04900107532739639

Rewards:
230.1930
230.1930
230.1930
objective = 3.7533202171325684
==== episode 7600/10000 ====
action = 1
probs = 0.0021 0.9979 0.0000 0.0000

action = 1
probs = 0.0495 0.9505 0.0000 0.0000

action = 0
probs = 0.9968 0.0032 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00027055872487835586 0.08623220771551132
encoder.encoder.weight_hh_l0: 4.906510002911091e-05 0.08816968649625778
encoder.encoder.bias_ih_l0: 0.014761128462851048 0.0899169072508812
encoder.encoder.bias_hh_l0: 0.02475818619132042 0.08789967000484467
encoder.encoder.weight_ih_l0_reverse: 0.0019437485607340932 0.0886596292257309
encoder.encoder.weight_hh_l0_reverse: 0.009197361767292023 0.08798269927501678
encoder.encoder.bias_ih_l0_reverse: 0.03566042706370354 0.08618282526731491
encoder.encoder.bias_hh_l0_reverse: 0.02752602845430374 0.0832141861319542
decider.lstm.weight_ih_l0: 0.002487191464751959 0.149379163980484
decider.lstm.weight_hh_l0: 0.003427664516493678 0.14889582991600037
decider.lstm.bias_ih_l0: 0.02679448388516903 0.15989121794700623
decider.lstm.bias_hh_l0: 0.007806984707713127 0.141288161277771
decider.linear1.weight: 0.00442558154463768 0.12198995053768158
decider.linear1.bias: 0.021093852818012238 0.11762068420648575
decider.linear2.weight: 0.005668948870152235 0.05458913743495941
decider.linear2.bias: 0.009057280607521534 0.05700960382819176
decider.linear3.weight: -0.03799387812614441 0.09412834048271179
decider.linear3.bias: -0.008834373205900192 0.04884093999862671

Rewards:
230.1930
230.1930
230.1930
objective = 4.297720909118652
==== episode 7700/10000 ====
action = 1
probs = 0.0022 0.9978 0.0000 0.0000

action = 1
probs = 0.0596 0.9404 0.0000 0.0000

action = 0
probs = 0.9977 0.0023 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002721198834478855 0.08626878261566162
encoder.encoder.weight_hh_l0: 4.888455805485137e-05 0.08821587264537811
encoder.encoder.bias_ih_l0: 0.014868037775158882 0.0899864211678505
encoder.encoder.bias_hh_l0: 0.02486509457230568 0.08794668316841125
encoder.encoder.weight_ih_l0_reverse: 0.0019496830645948648 0.08869010210037231
encoder.encoder.weight_hh_l0_reverse: 0.009189053438603878 0.08798321336507797
encoder.encoder.bias_ih_l0_reverse: 0.035681284964084625 0.08620600402355194
encoder.encoder.bias_hh_l0_reverse: 0.02754688262939453 0.0832008644938469
decider.lstm.weight_ih_l0: 0.002514015883207321 0.149419367313385
decider.lstm.weight_hh_l0: 0.003447494236752391 0.14893019199371338
decider.lstm.bias_ih_l0: 0.02694336324930191 0.1599307656288147
decider.lstm.bias_hh_l0: 0.007955865003168583 0.1413102149963379
decider.linear1.weight: 0.004431865178048611 0.12200291454792023
decider.linear1.bias: 0.021150436252355576 0.1176246628165245
decider.linear2.weight: 0.005705178715288639 0.054610732942819595
decider.linear2.bias: 0.009085403755307198 0.05700258910655975
decider.linear3.weight: -0.03813454136252403 0.09451009333133698
decider.linear3.bias: -0.008872231468558311 0.048654697835445404

Rewards:
230.1930
230.1930
230.1930
objective = 5.070176601409912
==== episode 7800/10000 ====
action = 1
probs = 0.0016 0.9984 0.0000 0.0000

action = 1
probs = 0.0424 0.9576 0.0000 0.0000

action = 0
probs = 0.9975 0.0025 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00028828164795413613 0.08630427718162537
encoder.encoder.weight_hh_l0: 4.6294448111439124e-05 0.08825938403606415
encoder.encoder.bias_ih_l0: 0.014940332621335983 0.09001348912715912
encoder.encoder.bias_hh_l0: 0.02493739128112793 0.08801737427711487
encoder.encoder.weight_ih_l0_reverse: 0.00195693108253181 0.08873739093542099
encoder.encoder.weight_hh_l0_reverse: 0.009199948981404305 0.08799368888139725
encoder.encoder.bias_ih_l0_reverse: 0.035784509032964706 0.08623131364583969
encoder.encoder.bias_hh_l0_reverse: 0.02765011042356491 0.08324426412582397
decider.lstm.weight_ih_l0: 0.002543260343372822 0.1494496613740921
decider.lstm.weight_hh_l0: 0.003471948904916644 0.1489652842283249
decider.lstm.bias_ih_l0: 0.02711409330368042 0.15997479856014252
decider.lstm.bias_hh_l0: 0.008126595988869667 0.14130592346191406
decider.linear1.weight: 0.00443992530927062 0.12203443795442581
decider.linear1.bias: 0.02127181366086006 0.1176305040717125
decider.linear2.weight: 0.005731186829507351 0.054634712636470795
decider.linear2.bias: 0.009096302092075348 0.05702667683362961
decider.linear3.weight: -0.03827398642897606 0.0949149802327156
decider.linear3.bias: -0.008909080177545547 0.04896393418312073

Rewards:
230.1930
230.1930
230.1930
objective = 3.6392836570739746
==== episode 7900/10000 ====
action = 1
probs = 0.0024 0.9976 0.0000 0.0000

action = 1
probs = 0.0525 0.9475 0.0000 0.0000

action = 0
probs = 0.9980 0.0020 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00027212343411520123 0.08622439950704575
encoder.encoder.weight_hh_l0: 4.6622681111330166e-05 0.088160939514637
encoder.encoder.bias_ih_l0: 0.014755411073565483 0.0899132713675499
encoder.encoder.bias_hh_l0: 0.02475246787071228 0.08790148794651031
encoder.encoder.weight_ih_l0_reverse: 0.0019489278784021735 0.08869186043739319
encoder.encoder.weight_hh_l0_reverse: 0.009171273559331894 0.08796797692775726
encoder.encoder.bias_ih_l0_reverse: 0.0356515608727932 0.08620069175958633
encoder.encoder.bias_hh_l0_reverse: 0.027517160400748253 0.08322073519229889
decider.lstm.weight_ih_l0: 0.002490642014890909 0.14937648177146912
decider.lstm.weight_hh_l0: 0.0034313995856791735 0.148888498544693
decider.lstm.bias_ih_l0: 0.026837661862373352 0.15986941754817963
decider.lstm.bias_hh_l0: 0.007850158959627151 0.14133858680725098
decider.linear1.weight: 0.004441269673407078 0.1220138892531395
decider.linear1.bias: 0.021201658993959427 0.11765484511852264
decider.linear2.weight: 0.005741505417972803 0.054627977311611176
decider.linear2.bias: 0.009091297164559364 0.057000305503606796
decider.linear3.weight: -0.03841636702418327 0.09527637809515
decider.linear3.bias: -0.0089482506737113 0.04869617521762848

Rewards:
230.1930
230.1930
230.1930
objective = 4.472472190856934
==== episode 8000/10000 ====
action = 1
probs = 0.0037 0.9963 0.0000 0.0000

action = 1
probs = 0.1129 0.8871 0.0000 0.0000

action = 0
probs = 0.9989 0.0011 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0002639970916789025 0.08627057075500488
encoder.encoder.weight_hh_l0: 4.806754441233352e-05 0.08821899443864822
encoder.encoder.bias_ih_l0: 0.014924484305083752 0.09003010392189026
encoder.encoder.bias_hh_l0: 0.024921545758843422 0.08793191611766815
encoder.encoder.weight_ih_l0_reverse: 0.001954637700691819 0.08870887011289597
encoder.encoder.weight_hh_l0_reverse: 0.009151668287813663 0.08796597272157669
encoder.encoder.bias_ih_l0_reverse: 0.03561905398964882 0.08622624725103378
encoder.encoder.bias_hh_l0_reverse: 0.027484649792313576 0.08315353095531464
decider.lstm.weight_ih_l0: 0.0025204455014318228 0.14943444728851318
decider.lstm.weight_hh_l0: 0.0034516346640884876 0.14893095195293427
decider.lstm.bias_ih_l0: 0.026991093531250954 0.1599145531654358
decider.lstm.bias_hh_l0: 0.008003586903214455 0.14137813448905945
decider.linear1.weight: 0.004444170743227005 0.12200901657342911
decider.linear1.bias: 0.02119060419499874 0.11765927821397781
decider.linear2.weight: 0.005786429159343243 0.05464562401175499
decider.linear2.bias: 0.009135016240179539 0.05696975067257881
decider.linear3.weight: -0.038608722388744354 0.09579500555992126
decider.linear3.bias: -0.008998633362352848 0.048060741275548935

Rewards:
230.1930
230.1930
230.1930
objective = 9.558974266052246
==== episode 8100/10000 ====
action = 1
probs = 0.0337 0.9663 0.0000 0.0000

action = 0
probs = 0.8785 0.1215 0.0000 0.0000

action = 0
probs = 0.9999 0.0001 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.000291992851998657 0.08669739216566086
encoder.encoder.weight_hh_l0: 3.1010865768621443e-06 0.08873563259840012
encoder.encoder.bias_ih_l0: 0.016332928091287613 0.09079666435718536
encoder.encoder.bias_hh_l0: 0.02632998861372471 0.08845502138137817
encoder.encoder.weight_ih_l0_reverse: 0.0020398793276399374 0.08903667330741882
encoder.encoder.weight_hh_l0_reverse: 0.009085766971111298 0.08799461275339127
encoder.encoder.bias_ih_l0_reverse: 0.03611649572849274 0.08640339970588684
encoder.encoder.bias_hh_l0_reverse: 0.027982091531157494 0.08290909975767136
decider.lstm.weight_ih_l0: 0.002620249055325985 0.14961041510105133
decider.lstm.weight_hh_l0: 0.003549145068973303 0.1490362286567688
decider.lstm.bias_ih_l0: 0.02773006446659565 0.15974222123622894
decider.lstm.bias_hh_l0: 0.008742554113268852 0.14166362583637238
decider.linear1.weight: 0.004463659133762121 0.12208742648363113
decider.linear1.bias: 0.021689247339963913 0.11783212423324585
decider.linear2.weight: 0.005972759332507849 0.054776158183813095
decider.linear2.bias: 0.009556574746966362 0.056987784802913666
decider.linear3.weight: -0.03896341100335121 0.09682217240333557
decider.linear3.bias: -0.00908363051712513 0.04527934640645981

Rewards:
221.7540
221.7540
221.7540
objective = 12.117574691772461
==== episode 8200/10000 ====
action = 1
probs = 0.0283 0.9717 0.0000 0.0000

action = 0
probs = 0.9196 0.0804 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00032006565015763044 0.08676854521036148
encoder.encoder.weight_hh_l0: -1.655807500355877e-05 0.08882508426904678
encoder.encoder.bias_ih_l0: 0.016569362953305244 0.0908740684390068
encoder.encoder.bias_hh_l0: 0.026566429063677788 0.08857499808073044
encoder.encoder.weight_ih_l0_reverse: 0.002065950306132436 0.08911928534507751
encoder.encoder.weight_hh_l0_reverse: 0.009096448309719563 0.08801679313182831
encoder.encoder.bias_ih_l0_reverse: 0.03630867972970009 0.08644932508468628
encoder.encoder.bias_hh_l0_reverse: 0.028174277395009995 0.08288086205720901
decider.lstm.weight_ih_l0: 0.0026333904825150967 0.14966638386249542
decider.lstm.weight_hh_l0: 0.003575703129172325 0.14910569787025452
decider.lstm.bias_ih_l0: 0.02790234237909317 0.15977740287780762
decider.lstm.bias_hh_l0: 0.008914828300476074 0.1417207270860672
decider.linear1.weight: 0.004465778823941946 0.12218990176916122
decider.linear1.bias: 0.022019585594534874 0.11783964931964874
decider.linear2.weight: 0.00592110026627779 0.054876506328582764
decider.linear2.bias: 0.009593586437404156 0.05700848251581192
decider.linear3.weight: -0.03919241577386856 0.09739755839109421
decider.linear3.bias: -0.00916796550154686 0.045199230313301086

Rewards:
221.7540
221.7540
221.7540
objective = 8.31617546081543
==== episode 8300/10000 ====
action = 1
probs = 0.0387 0.9613 0.0000 0.0000

action = 1
probs = 0.9687 0.0313 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003671013400889933 0.08691060543060303
encoder.encoder.weight_hh_l0: -5.726117888116278e-05 0.08899557590484619
encoder.encoder.bias_ih_l0: 0.017034150660037994 0.09104378521442413
encoder.encoder.bias_hh_l0: 0.027031216770410538 0.08878730237483978
encoder.encoder.weight_ih_l0_reverse: 0.002105036051943898 0.08928147703409195
encoder.encoder.weight_hh_l0_reverse: 0.009131909348070621 0.08808129280805588
encoder.encoder.bias_ih_l0_reverse: 0.03668897971510887 0.08653976023197174
encoder.encoder.bias_hh_l0_reverse: 0.028554577380418777 0.08289342373609543
decider.lstm.weight_ih_l0: 0.0026720999740064144 0.14973901212215424
decider.lstm.weight_hh_l0: 0.003613756038248539 0.14918972551822662
decider.lstm.bias_ih_l0: 0.02820993959903717 0.1597662717103958
decider.lstm.bias_hh_l0: 0.009222426451742649 0.1417752355337143
decider.linear1.weight: 0.00445898249745369 0.12225855141878128
decider.linear1.bias: 0.022301752120256424 0.11789070814847946
decider.linear2.weight: 0.006007679272443056 0.05494692176580429
decider.linear2.bias: 0.009741002693772316 0.05705927684903145
decider.linear3.weight: -0.03939541429281235 0.09795275330543518
decider.linear3.bias: -0.009240495041012764 0.044751785695552826

Rewards:
230.1930
230.1930
230.1930
objective = 268.81005859375
==== episode 8400/10000 ====
action = 1
probs = 0.0241 0.9759 0.0000 0.0000

action = 0
probs = 0.9656 0.0344 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0003806986496783793 0.08693010360002518
encoder.encoder.weight_hh_l0: -6.085152563173324e-05 0.08901683241128922
encoder.encoder.bias_ih_l0: 0.017075389623641968 0.09102442860603333
encoder.encoder.bias_hh_l0: 0.02707245945930481 0.08882038295269012
encoder.encoder.weight_ih_l0_reverse: 0.0021109760273247957 0.08930527418851852
encoder.encoder.weight_hh_l0_reverse: 0.009145374409854412 0.0880928561091423
encoder.encoder.bias_ih_l0_reverse: 0.03676823526620865 0.08656617999076843
encoder.encoder.bias_hh_l0_reverse: 0.028633838519454002 0.08289428055286407
decider.lstm.weight_ih_l0: 0.0026713283732533455 0.14974702894687653
decider.lstm.weight_hh_l0: 0.0036234045401215553 0.14920151233673096
decider.lstm.bias_ih_l0: 0.028242971748113632 0.15982569754123688
decider.lstm.bias_hh_l0: 0.00925545021891594 0.14173363149166107
decider.linear1.weight: 0.004453171044588089 0.12229359149932861
decider.linear1.bias: 0.02240026369690895 0.11786773055791855
decider.linear2.weight: 0.005998176522552967 0.05498456582427025
decider.linear2.bias: 0.009732898324728012 0.05705353990197182
decider.linear3.weight: -0.03954562544822693 0.09833981841802597
decider.linear3.bias: -0.009299229830503464 0.0449659563601017

Rewards:
221.7540
221.7540
221.7540
objective = 4.394467353820801
==== episode 8500/10000 ====
action = 1
probs = 0.0371 0.9629 0.0000 0.0000

action = 0
probs = 0.9879 0.0121 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00043336368980817497 0.08705291152000427
encoder.encoder.weight_hh_l0: -0.00011607460328377783 0.08916474133729935
encoder.encoder.bias_ih_l0: 0.01752994954586029 0.09114663302898407
encoder.encoder.bias_hh_l0: 0.027527019381523132 0.08899101614952087
encoder.encoder.weight_ih_l0_reverse: 0.0021483316086232662 0.08946598321199417
encoder.encoder.weight_hh_l0_reverse: 0.009194068610668182 0.0881710797548294
encoder.encoder.bias_ih_l0_reverse: 0.03718350827693939 0.08666053414344788
encoder.encoder.bias_hh_l0_reverse: 0.029049111530184746 0.08292471617460251
decider.lstm.weight_ih_l0: 0.002702531171962619 0.14981751143932343
decider.lstm.weight_hh_l0: 0.003654691856354475 0.14928172528743744
decider.lstm.bias_ih_l0: 0.028510794043540955 0.15984180569648743
decider.lstm.bias_hh_l0: 0.009523272514343262 0.14176791906356812
decider.linear1.weight: 0.004438145086169243 0.12236455827951431
decider.linear1.bias: 0.022681696340441704 0.11792897433042526
decider.linear2.weight: 0.006075054407119751 0.05507726967334747
decider.linear2.bias: 0.009889049455523491 0.05712059885263443
decider.linear3.weight: -0.039670705795288086 0.09870398789644241
decider.linear3.bias: -0.009350061416625977 0.044473398476839066

Rewards:
221.7540
221.7540
221.7540
objective = 3.699070930480957
==== episode 8600/10000 ====
action = 1
probs = 0.0610 0.9390 0.0000 0.0000

action = 0
probs = 0.9921 0.0079 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00043356497189961374 0.08706626296043396
encoder.encoder.weight_hh_l0: -0.00011946832819376141 0.08918599039316177
encoder.encoder.bias_ih_l0: 0.01757798157632351 0.09120090305805206
encoder.encoder.bias_hh_l0: 0.027575049549341202 0.08901985734701157
encoder.encoder.weight_ih_l0_reverse: 0.002157979877665639 0.08948682248592377
encoder.encoder.weight_hh_l0_reverse: 0.009193368256092072 0.08818398416042328
encoder.encoder.bias_ih_l0_reverse: 0.03720717504620552 0.08666660636663437
encoder.encoder.bias_hh_l0_reverse: 0.029072780162096024 0.08291427046060562
decider.lstm.weight_ih_l0: 0.002708466025069356 0.14984473586082458
decider.lstm.weight_hh_l0: 0.0036473998334258795 0.14932069182395935
decider.lstm.bias_ih_l0: 0.02847997471690178 0.1598123162984848
decider.lstm.bias_hh_l0: 0.009492453187704086 0.14201204478740692
decider.linear1.weight: 0.004438748583197594 0.12235455960035324
decider.linear1.bias: 0.022662753239274025 0.11796511709690094
decider.linear2.weight: 0.0060652196407318115 0.05509638041257858
decider.linear2.bias: 0.009914688766002655 0.05717695504426956
decider.linear3.weight: -0.03979365527629852 0.09896537661552429
decider.linear3.bias: -0.009402387775480747 0.04408295825123787

Rewards:
221.7540
221.7540
221.7540
objective = 5.242707252502441
==== episode 8700/10000 ====
action = 1
probs = 0.1850 0.8150 0.0000 0.0000

action = 0
probs = 0.9969 0.0031 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0004643341526389122 0.08718523383140564
encoder.encoder.weight_hh_l0: -0.0001654257794143632 0.08932888507843018
encoder.encoder.bias_ih_l0: 0.017967602238059044 0.09139957278966904
encoder.encoder.bias_hh_l0: 0.027964670211076736 0.08916210383176804
encoder.encoder.weight_ih_l0_reverse: 0.002185059478506446 0.08961493521928787
encoder.encoder.weight_hh_l0_reverse: 0.009221796877682209 0.0882476195693016
encoder.encoder.bias_ih_l0_reverse: 0.03748797997832298 0.08674495667219162
encoder.encoder.bias_hh_l0_reverse: 0.029353585094213486 0.08294173330068588
decider.lstm.weight_ih_l0: 0.0027646906673908234 0.14996187388896942
decider.lstm.weight_hh_l0: 0.003691521706059575 0.14943566918373108
decider.lstm.bias_ih_l0: 0.02883794903755188 0.15990570187568665
decider.lstm.bias_hh_l0: 0.00985043402761221 0.1421310305595398
decider.linear1.weight: 0.004436276387423277 0.12236974388360977
decider.linear1.bias: 0.022769562900066376 0.11805553734302521
decider.linear2.weight: 0.006113830488175154 0.05513552948832512
decider.linear2.bias: 0.01004883460700512 0.05731797218322754
decider.linear3.weight: -0.039997704327106476 0.09940238296985626
decider.linear3.bias: -0.009487533010542393 0.043298158794641495

Rewards:
221.7540
221.7540
221.7540
objective = 15.349276542663574
==== episode 8800/10000 ====
action = 1
probs = 0.0663 0.9337 0.0000 0.0000

action = 0
probs = 0.9943 0.0057 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00044067183625884354 0.08706072717905045
encoder.encoder.weight_hh_l0: -0.00012652263103518635 0.08917540311813354
encoder.encoder.bias_ih_l0: 0.01757446490228176 0.09116438031196594
encoder.encoder.bias_hh_l0: 0.027571534737944603 0.08902332931756973
encoder.encoder.weight_ih_l0_reverse: 0.002163029508665204 0.08950009942054749
encoder.encoder.weight_hh_l0_reverse: 0.009195586666464806 0.08819115906953812
encoder.encoder.bias_ih_l0_reverse: 0.03724395111203194 0.08666996657848358
encoder.encoder.bias_hh_l0_reverse: 0.02910955622792244 0.08291809260845184
decider.lstm.weight_ih_l0: 0.0027044080197811127 0.14985015988349915
decider.lstm.weight_hh_l0: 0.0036358193028718233 0.14933183789253235
decider.lstm.bias_ih_l0: 0.02843095362186432 0.159826397895813
decider.lstm.bias_hh_l0: 0.009443437680602074 0.1420702040195465
decider.linear1.weight: 0.004439056850969791 0.12237013876438141
decider.linear1.bias: 0.022709980607032776 0.11798858642578125
decider.linear2.weight: 0.006059464067220688 0.0551547110080719
decider.linear2.bias: 0.009923972189426422 0.05719679594039917
decider.linear3.weight: -0.040234051644802094 0.09995082765817642
decider.linear3.bias: -0.009577712044119835 0.04399034380912781

Rewards:
221.7540
221.7540
221.7540
objective = 5.493379592895508
==== episode 8900/10000 ====
action = 1
probs = 0.0708 0.9292 0.0000 0.0000

action = 0
probs = 0.9956 0.0044 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00045314087765291333 0.08708591759204865
encoder.encoder.weight_hh_l0: -0.00014094820653554052 0.0892050713300705
encoder.encoder.bias_ih_l0: 0.01766977831721306 0.09118165820837021
encoder.encoder.bias_hh_l0: 0.027666844427585602 0.08905930072069168
encoder.encoder.weight_ih_l0_reverse: 0.0021715317852795124 0.08953830599784851
encoder.encoder.weight_hh_l0_reverse: 0.009207742288708687 0.08821150660514832
encoder.encoder.bias_ih_l0_reverse: 0.03734434023499489 0.08669284731149673
encoder.encoder.bias_hh_l0_reverse: 0.02920994535088539 0.08292573690414429
decider.lstm.weight_ih_l0: 0.002709202701225877 0.14986377954483032
decider.lstm.weight_hh_l0: 0.0036395590286701918 0.14934678375720978
decider.lstm.bias_ih_l0: 0.028470497578382492 0.15982727706432343
decider.lstm.bias_hh_l0: 0.009482978843152523 0.1420988291501999
decider.linear1.weight: 0.004437576979398727 0.12238838523626328
decider.linear1.bias: 0.022774750366806984 0.11800386011600494
decider.linear2.weight: 0.006088078022003174 0.05517715960741043
decider.linear2.bias: 0.00995856523513794 0.05720385164022446
decider.linear3.weight: -0.04039459675550461 0.10030806064605713
decider.linear3.bias: -0.009653129614889622 0.043903887271881104

Rewards:
221.7540
221.7540
221.7540
objective = 5.753613471984863
==== episode 9000/10000 ====
action = 1
probs = 0.0299 0.9701 0.0000 0.0000

action = 0
probs = 0.9895 0.0105 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00042814112384803593 0.08698377758264542
encoder.encoder.weight_hh_l0: -0.00010269170888932422 0.0890728235244751
encoder.encoder.bias_ih_l0: 0.017309291288256645 0.09099867939949036
encoder.encoder.bias_hh_l0: 0.027306361123919487 0.08894281089305878
encoder.encoder.weight_ih_l0_reverse: 0.002143068937584758 0.08942539989948273
encoder.encoder.weight_hh_l0_reverse: 0.009183884598314762 0.08815594762563705
encoder.encoder.bias_ih_l0_reverse: 0.03709683194756508 0.08662447333335876
encoder.encoder.bias_hh_l0_reverse: 0.028962435200810432 0.08291705697774887
decider.lstm.weight_ih_l0: 0.0026605301536619663 0.14975973963737488
decider.lstm.weight_hh_l0: 0.0036031012423336506 0.14924576878547668
decider.lstm.bias_ih_l0: 0.02817053720355034 0.15974996984004974
decider.lstm.bias_hh_l0: 0.009183023124933243 0.14196303486824036
decider.linear1.weight: 0.0044427840039134026 0.12237877398729324
decider.linear1.bias: 0.022673189640045166 0.11795027554035187
decider.linear2.weight: 0.006042908877134323 0.05515974760055542
decider.linear2.bias: 0.009874876588582993 0.05710844695568085
decider.linear3.weight: -0.04054645448923111 0.10062486678361893
decider.linear3.bias: -0.009724306873977184 0.04468827694654465

Rewards:
221.7540
221.7540
221.7540
objective = 3.0288360118865967
==== episode 9100/10000 ====
action = 1
probs = 0.0207 0.9793 0.0000 0.0000

action = 0
probs = 0.9882 0.0118 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0004382932966109365 0.08699651807546616
encoder.encoder.weight_hh_l0: -0.00010724999447120354 0.08908341079950333
encoder.encoder.bias_ih_l0: 0.017346464097499847 0.09096941351890564
encoder.encoder.bias_hh_l0: 0.02734353020787239 0.08896220475435257
encoder.encoder.weight_ih_l0_reverse: 0.0021453003864735365 0.08944331109523773
encoder.encoder.weight_hh_l0_reverse: 0.009198934771120548 0.08817040920257568
encoder.encoder.bias_ih_l0_reverse: 0.03716838359832764 0.08663609623908997
encoder.encoder.bias_hh_l0_reverse: 0.029033992439508438 0.08293521404266357
decider.lstm.weight_ih_l0: 0.0026620447169989347 0.14975251257419586
decider.lstm.weight_hh_l0: 0.0036102328449487686 0.14924359321594238
decider.lstm.bias_ih_l0: 0.028214316815137863 0.1597491055727005
decider.lstm.bias_hh_l0: 0.009226806461811066 0.14184553921222687
decider.linear1.weight: 0.004438655450940132 0.1224040538072586
decider.linear1.bias: 0.0227394737303257 0.11793676763772964
decider.linear2.weight: 0.006054767407476902 0.05518334358930588
decider.linear2.bias: 0.009883545339107513 0.05707888305187225
decider.linear3.weight: -0.040643446147441864 0.10088387131690979
decider.linear3.bias: -0.009764952585101128 0.044964730739593506

Rewards:
221.7540
221.7540
221.7540
objective = 2.4217991828918457
==== episode 9200/10000 ====
action = 1
probs = 0.0186 0.9814 0.0000 0.0000

action = 0
probs = 0.9883 0.0117 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00043916856520809233 0.08699724078178406
encoder.encoder.weight_hh_l0: -0.0001084647374227643 0.0890837088227272
encoder.encoder.bias_ih_l0: 0.01735132746398449 0.09095977991819382
encoder.encoder.bias_hh_l0: 0.027348393574357033 0.08896569907665253
encoder.encoder.weight_ih_l0_reverse: 0.0021454107481986284 0.08944674581289291
encoder.encoder.weight_hh_l0_reverse: 0.009199515916407108 0.08817192167043686
encoder.encoder.bias_ih_l0_reverse: 0.03717600554227829 0.086635060608387
encoder.encoder.bias_hh_l0_reverse: 0.02904161438345909 0.08293496817350388
decider.lstm.weight_ih_l0: 0.002656946424394846 0.14973832666873932
decider.lstm.weight_hh_l0: 0.0036075208336114883 0.1492248922586441
decider.lstm.bias_ih_l0: 0.028199555352330208 0.15969082713127136
decider.lstm.bias_hh_l0: 0.009212043136358261 0.14179310202598572
decider.linear1.weight: 0.004437720403075218 0.12241210788488388
decider.linear1.bias: 0.022763505578041077 0.11792770028114319
decider.linear2.weight: 0.00605824263766408 0.055194444954395294
decider.linear2.bias: 0.00988234207034111 0.057062700390815735
decider.linear3.weight: -0.040717899799346924 0.10107310861349106
decider.linear3.bias: -0.009795356541872025 0.04501558840274811

Rewards:
221.7540
221.7540
221.7540
objective = 2.260324001312256
==== episode 9300/10000 ====
action = 1
probs = 0.0174 0.9826 0.0000 0.0000

action = 0
probs = 0.9890 0.0110 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.00044511223677545786 0.08701223880052567
encoder.encoder.weight_hh_l0: -0.00011183771857758984 0.08909977972507477
encoder.encoder.bias_ih_l0: 0.01738825812935829 0.09096672385931015
encoder.encoder.bias_hh_l0: 0.027385324239730835 0.08898816257715225
encoder.encoder.weight_ih_l0_reverse: 0.002149696694687009 0.08946484327316284
encoder.encoder.weight_hh_l0_reverse: 0.009206980466842651 0.08818412572145462
encoder.encoder.bias_ih_l0_reverse: 0.037223104387521744 0.08664759248495102
encoder.encoder.bias_hh_l0_reverse: 0.029088715091347694 0.08294347673654556
decider.lstm.weight_ih_l0: 0.0026638396084308624 0.14975064992904663
decider.lstm.weight_hh_l0: 0.0036145499907433987 0.14923898875713348
decider.lstm.bias_ih_l0: 0.028253555297851562 0.15970245003700256
decider.lstm.bias_hh_l0: 0.009266043081879616 0.14178092777729034
decider.linear1.weight: 0.004435529466718435 0.12242423743009567
decider.linear1.bias: 0.022797033190727234 0.11793135106563568
decider.linear2.weight: 0.0060683744959533215 0.05520707741379738
decider.linear2.bias: 0.009894881397485733 0.05705663561820984
decider.linear3.weight: -0.040804654359817505 0.10129663348197937
decider.linear3.bias: -0.009831426665186882 0.04507514834403992

Rewards:
221.7540
221.7540
221.7540
objective = 2.1190567016601562
==== episode 9400/10000 ====
action = 1
probs = 0.0128 0.9872 0.0000 0.0000

action = 0
probs = 0.9919 0.0081 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0004774903354700655 0.08707702904939651
encoder.encoder.weight_hh_l0: -0.00013877848687116057 0.08917208760976791
encoder.encoder.bias_ih_l0: 0.017618786543607712 0.09098701924085617
encoder.encoder.bias_hh_l0: 0.027615852653980255 0.08907265961170197
encoder.encoder.weight_ih_l0_reverse: 0.002162950113415718 0.08955217152833939
encoder.encoder.weight_hh_l0_reverse: 0.00925438478589058 0.0882422998547554
encoder.encoder.bias_ih_l0_reverse: 0.037487927824258804 0.08670781552791595
encoder.encoder.bias_hh_l0_reverse: 0.029353542253375053 0.08298290520906448
decider.lstm.weight_ih_l0: 0.0026811789721250534 0.1497744470834732
decider.lstm.weight_hh_l0: 0.0036423495039343834 0.14925654232501984
decider.lstm.bias_ih_l0: 0.028456225991249084 0.15975302457809448
decider.lstm.bias_hh_l0: 0.00946870818734169 0.14164215326309204
decider.linear1.weight: 0.004421064164489508 0.1224871277809143
decider.linear1.bias: 0.02297811023890972 0.11794401705265045
decider.linear2.weight: 0.006131112575531006 0.05527156963944435
decider.linear2.bias: 0.009974871762096882 0.05704871937632561
decider.linear3.weight: -0.040873389691114426 0.10154050588607788
decider.linear3.bias: -0.00985964760184288 0.04523554444313049

Rewards:
221.7540
221.7540
221.7540
objective = 1.551990270614624
==== episode 9500/10000 ====
action = 1
probs = 0.0128 0.9872 0.0000 0.0000

action = 0
probs = 0.9945 0.0055 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0004955363692715764 0.08711686730384827
encoder.encoder.weight_hh_l0: -0.00015889528731349856 0.08921943604946136
encoder.encoder.bias_ih_l0: 0.0177728570997715 0.09100944548845291
encoder.encoder.bias_hh_l0: 0.02776992693543434 0.08912081271409988
encoder.encoder.weight_ih_l0_reverse: 0.0021709853317588568 0.08960763365030289
encoder.encoder.weight_hh_l0_reverse: 0.009278906509280205 0.08827719837427139
encoder.encoder.bias_ih_l0_reverse: 0.037645015865564346 0.0867462009191513
encoder.encoder.bias_hh_l0_reverse: 0.029510626569390297 0.08299694210290909
decider.lstm.weight_ih_l0: 0.002687044907361269 0.1497822403907776
decider.lstm.weight_hh_l0: 0.003651901613920927 0.14925113320350647
decider.lstm.bias_ih_l0: 0.028549425303936005 0.15968413650989532
decider.lstm.bias_hh_l0: 0.009561896324157715 0.14158432185649872
decider.linear1.weight: 0.004409851506352425 0.12252235412597656
decider.linear1.bias: 0.023086581379175186 0.11795835942029953
decider.linear2.weight: 0.006176514085382223 0.05531313642859459
decider.linear2.bias: 0.010033102706074715 0.057056717574596405
decider.linear3.weight: -0.04093156009912491 0.10172491520643234
decider.linear3.bias: -0.009883742779493332 0.04517184942960739

Rewards:
221.7540
221.7540
221.7540
objective = 1.3634374141693115
==== episode 9600/10000 ====
action = 1
probs = 0.0094 0.9906 0.0000 0.0000

action = 0
probs = 0.9952 0.0048 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0005157882114872336 0.08715341240167618
encoder.encoder.weight_hh_l0: -0.00017823743110056967 0.08925791829824448
encoder.encoder.bias_ih_l0: 0.017920659855008125 0.0910005271434784
encoder.encoder.bias_hh_l0: 0.02791772596538067 0.08915812522172928
encoder.encoder.weight_ih_l0_reverse: 0.0021714987233281136 0.08965655416250229
encoder.encoder.weight_hh_l0_reverse: 0.009312056936323643 0.08831416815519333
encoder.encoder.bias_ih_l0_reverse: 0.037814535200595856 0.08678339421749115
encoder.encoder.bias_hh_l0_reverse: 0.029680151492357254 0.0830216109752655
decider.lstm.weight_ih_l0: 0.00268514989875257 0.14976339042186737
decider.lstm.weight_hh_l0: 0.0036630090326070786 0.1491985023021698
decider.lstm.bias_ih_l0: 0.02864760346710682 0.15961268544197083
decider.lstm.bias_hh_l0: 0.00966007262468338 0.1413852423429489
decider.linear1.weight: 0.00439293822273612 0.12257058918476105
decider.linear1.bias: 0.023205086588859558 0.11795811355113983
decider.linear2.weight: 0.006219103932380676 0.05536247417330742
decider.linear2.bias: 0.010086292400956154 0.05705223232507706
decider.linear3.weight: -0.040979497134685516 0.10189900547266006
decider.linear3.bias: -0.009903334081172943 0.045353665947914124

Rewards:
221.7540
221.7540
221.7540
objective = 1.0567305088043213
==== episode 9700/10000 ====
action = 1
probs = 0.0215 0.9785 0.0000 0.0000

action = 0
probs = 0.9977 0.0023 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0005254801362752914 0.08720290660858154
encoder.encoder.weight_hh_l0: -0.00019697114476002753 0.08932825922966003
encoder.encoder.bias_ih_l0: 0.01807914301753044 0.0911102145910263
encoder.encoder.bias_hh_l0: 0.028076209127902985 0.08923842012882233
encoder.encoder.weight_ih_l0_reverse: 0.0022075623273849487 0.08973023295402527
encoder.encoder.weight_hh_l0_reverse: 0.0093303257599473 0.08836246281862259
encoder.encoder.bias_ih_l0_reverse: 0.037955645471811295 0.08681311458349228
encoder.encoder.bias_hh_l0_reverse: 0.029821261763572693 0.08302908390760422
decider.lstm.weight_ih_l0: 0.0027343269903212786 0.1498776078224182
decider.lstm.weight_hh_l0: 0.0036902676802128553 0.14933258295059204
decider.lstm.bias_ih_l0: 0.028887450695037842 0.15975524485111237
decider.lstm.bias_hh_l0: 0.009899921715259552 0.14164844155311584
decider.linear1.weight: 0.004387007560580969 0.1225656270980835
decider.linear1.bias: 0.023225486278533936 0.11800382286310196
decider.linear2.weight: 0.006243228912353516 0.05537344142794609
decider.linear2.bias: 0.010131939314305782 0.05710253491997719
decider.linear3.weight: -0.04103120416402817 0.10200993716716766
decider.linear3.bias: -0.00992374587804079 0.044773925095796585

Rewards:
221.7540
221.7540
221.7540
objective = 1.7711198329925537
==== episode 9800/10000 ====
action = 1
probs = 0.0212 0.9788 0.0000 0.0000

action = 0
probs = 0.9980 0.0020 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0005320126656442881 0.08721058070659637
encoder.encoder.weight_hh_l0: -0.0002045341971097514 0.08933746069669724
encoder.encoder.bias_ih_l0: 0.018115123733878136 0.09110929816961288
encoder.encoder.bias_hh_l0: 0.02811218611896038 0.08925215154886246
encoder.encoder.weight_ih_l0_reverse: 0.002211672021076083 0.08974854648113251
encoder.encoder.weight_hh_l0_reverse: 0.009338556788861752 0.0883752778172493
encoder.encoder.bias_ih_l0_reverse: 0.03800469636917114 0.08682488650083542
encoder.encoder.bias_hh_l0_reverse: 0.02987031452357769 0.08303365111351013
decider.lstm.weight_ih_l0: 0.002733348635956645 0.1498810350894928
decider.lstm.weight_hh_l0: 0.0036900993436574936 0.14933562278747559
decider.lstm.bias_ih_l0: 0.028890646994113922 0.15975262224674225
decider.lstm.bias_hh_l0: 0.009903114289045334 0.14166365563869476
decider.linear1.weight: 0.00438435934484005 0.12257692217826843
decider.linear1.bias: 0.02326018176972866 0.11800628155469894
decider.linear2.weight: 0.006256419233977795 0.055391062051057816
decider.linear2.bias: 0.010146507062017918 0.05711062625050545
decider.linear3.weight: -0.0410955548286438 0.10217735171318054
decider.linear3.bias: -0.009950178675353527 0.04473656788468361

Rewards:
221.7540
221.7540
221.7540
objective = 1.727522373199463
==== episode 9900/10000 ====
action = 1
probs = 0.0240 0.9760 0.0000 0.0000

action = 0
probs = 0.9984 0.0016 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0005391177255660295 0.08722732216119766
encoder.encoder.weight_hh_l0: -0.00021400667901616544 0.08935882896184921
encoder.encoder.bias_ih_l0: 0.018173502758145332 0.09112749248743057
encoder.encoder.bias_hh_l0: 0.028170570731163025 0.08927616477012634
encoder.encoder.weight_ih_l0_reverse: 0.0022206827998161316 0.08977644145488739
encoder.encoder.weight_hh_l0_reverse: 0.009348896332085133 0.08839406818151474
encoder.encoder.bias_ih_l0_reverse: 0.0380716472864151 0.08684080094099045
encoder.encoder.bias_hh_l0_reverse: 0.02993726171553135 0.08303964883089066
decider.lstm.weight_ih_l0: 0.002739877672865987 0.1499015986919403
decider.lstm.weight_hh_l0: 0.0036949659697711468 0.14935468137264252
decider.lstm.bias_ih_l0: 0.028934594243764877 0.1597706824541092
decider.lstm.bias_hh_l0: 0.009947062470018864 0.14170493185520172
decider.linear1.weight: 0.004381764214485884 0.12258674949407578
decider.linear1.bias: 0.023290973156690598 0.11801785975694656
decider.linear2.weight: 0.006270122714340687 0.05540711060166359
decider.linear2.bias: 0.010166315361857414 0.057122714817523956
decider.linear3.weight: -0.041157498955726624 0.10233364254236221
decider.linear3.bias: -0.009976129047572613 0.04462602362036705

Rewards:
221.7540
221.7540
221.7540
objective = 1.9081230163574219
==== episode 10000/10000 ====
action = 1
probs = 0.0330 0.9670 0.0000 0.0000

action = 0
probs = 0.9989 0.0011 0.0000 0.0000

action = 0
probs = 1.0000 0.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: 0.0005461617256514728 0.0872507244348526
encoder.encoder.weight_hh_l0: -0.00022425722272600979 0.08939097821712494
encoder.encoder.bias_ih_l0: 0.01824883185327053 0.09117183834314346
encoder.encoder.bias_hh_l0: 0.028245896100997925 0.08931253105401993
encoder.encoder.weight_ih_l0_reverse: 0.0022341199219226837 0.08981015533208847
encoder.encoder.weight_hh_l0_reverse: 0.009355375543236732 0.08841236680746078
encoder.encoder.bias_ih_l0_reverse: 0.03813793882727623 0.08685889840126038
encoder.encoder.bias_hh_l0_reverse: 0.030003558844327927 0.08304496854543686
decider.lstm.weight_ih_l0: 0.0027531650848686695 0.14993524551391602
decider.lstm.weight_hh_l0: 0.003703674301505089 0.14938737452030182
decider.lstm.bias_ih_l0: 0.029011130332946777 0.15980486571788788
decider.lstm.bias_hh_l0: 0.01002359576523304 0.1417691707611084
decider.linear1.weight: 0.004380769096314907 0.12258896231651306
decider.linear1.bias: 0.023305680602788925 0.11803560703992844
decider.linear2.weight: 0.006279066205024719 0.05541778355836868
decider.linear2.bias: 0.01018340140581131 0.057150956243276596
decider.linear3.weight: -0.04123435914516449 0.1025095134973526
decider.linear3.bias: -0.010008554905653 0.044380344450473785

Rewards:
221.7540
221.7540
221.7540
objective = 2.5655319690704346
[INFO] : learning runtime (h:mm:ss): 0:02:28
[INFO] : learning end time: 12/17/2023 06:57:24 PM
