Policy:
Policy(
  (encoder): NetworkEncoder(
    (embedder): Embedding(13, 16)
    (encoder): LSTM(16, 50, batch_first=True, bidirectional=True)
  )
  (decider): Decider2(
    (lstm): LSTM(100, 16)
    (linear1): Linear(in_features=24, out_features=128, bias=True)
    (relu1): ReLU()
    (linear2): Linear(in_features=128, out_features=128, bias=True)
    (relu2): ReLU()
    (linear3): Linear(in_features=128, out_features=4, bias=True)
    (softmax): Softmax(dim=1)
  )
  (softmax): Softmax(dim=1)
)
[INFO] : learning start time: 12/17/2023 12:21:28 PM
==== episode 1/10000 ====
action = 0
probs = 0.2454 0.2673 0.2437 0.2436

action = 0
probs = 0.2437 0.2691 0.2436 0.2436

action = 0
probs = 0.2438 0.2690 0.2436 0.2436

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003006646584253758 0.08382798731327057
encoder.encoder.weight_hh_l0: -0.0004346513596829027 0.08493989706039429
encoder.encoder.bias_ih_l0: 0.006772986613214016 0.0856880322098732
encoder.encoder.bias_hh_l0: 0.016770076006650925 0.08572649210691452
encoder.encoder.weight_ih_l0_reverse: 0.0016379916341975331 0.08582904934883118
encoder.encoder.weight_hh_l0_reverse: 0.002271551638841629 0.08397234976291656
encoder.encoder.bias_ih_l0_reverse: 0.022404536604881287 0.08511289954185486
encoder.encoder.bias_hh_l0_reverse: 0.014269971288740635 0.08350056409835815
decider.lstm.weight_ih_l0: -0.00036898444523103535 0.14689278602600098
decider.lstm.weight_hh_l0: -0.0014363074442371726 0.14599120616912842
decider.lstm.bias_ih_l0: 0.017449505627155304 0.15304474532604218
decider.lstm.bias_hh_l0: -0.001538032665848732 0.14339259266853333
decider.linear1.weight: 0.0018393396167084575 0.12068705260753632
decider.linear1.bias: 0.01328780222684145 0.11647672951221466
decider.linear2.weight: 0.0037795514799654484 0.0551372766494751
decider.linear2.bias: 0.0043180398643016815 0.05695607513189316
decider.linear3.weight: -0.030951354652643204 0.08705335110425949
decider.linear3.bias: -0.01891692541539669 0.05361824482679367

Rewards:
206.9982
206.9982
206.9982
objective = 291.7494812011719
==== episode 100/10000 ====
action = 1
probs = 0.0653 0.9340 0.0006 0.0001

action = 1
probs = 0.0018 0.9982 0.0000 0.0000

action = 1
probs = 0.0014 0.9986 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000303089153021574 0.08385509997606277
encoder.encoder.weight_hh_l0: -0.000444612349383533 0.0849672183394432
encoder.encoder.bias_ih_l0: 0.006804517470300198 0.08574049174785614
encoder.encoder.bias_hh_l0: 0.016801603138446808 0.08576536923646927
encoder.encoder.weight_ih_l0_reverse: 0.0016270196065306664 0.08584417402744293
encoder.encoder.weight_hh_l0_reverse: 0.0022577522322535515 0.08398184180259705
encoder.encoder.bias_ih_l0_reverse: 0.022377613931894302 0.08515576273202896
encoder.encoder.bias_hh_l0_reverse: 0.014243046753108501 0.08357542008161545
decider.lstm.weight_ih_l0: -0.00036977563286200166 0.14691364765167236
decider.lstm.weight_hh_l0: -0.0014322976348921657 0.14600571990013123
decider.lstm.bias_ih_l0: 0.017572278156876564 0.15305761992931366
decider.lstm.bias_hh_l0: -0.001415263395756483 0.1434447467327118
decider.linear1.weight: 0.001819275552406907 0.12068603187799454
decider.linear1.bias: 0.01355693582445383 0.11658180505037308
decider.linear2.weight: 0.003819772507995367 0.05523786321282387
decider.linear2.bias: 0.004304397385567427 0.05714046582579613
decider.linear3.weight: -0.03358718380331993 0.08937466889619827
decider.linear3.bias: -0.023328281939029694 0.05449652671813965

Rewards:
190.8927
190.8927
190.8927
objective = 4.544024467468262
==== episode 200/10000 ====
action = 1
probs = 0.0569 0.9427 0.0004 0.0001

action = 1
probs = 0.0009 0.9991 0.0000 0.0000

action = 1
probs = 0.0007 0.9993 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030648158281110227 0.08387265354394913
encoder.encoder.weight_hh_l0: -0.0004531496961135417 0.08498989045619965
encoder.encoder.bias_ih_l0: 0.006874111946672201 0.08575356751680374
encoder.encoder.bias_hh_l0: 0.016871200874447823 0.08578257262706757
encoder.encoder.weight_ih_l0_reverse: 0.0016152551397681236 0.08585795015096664
encoder.encoder.weight_hh_l0_reverse: 0.0022615157067775726 0.08399798721075058
encoder.encoder.bias_ih_l0_reverse: 0.022370005026459694 0.08517579734325409
encoder.encoder.bias_hh_l0_reverse: 0.014235434122383595 0.08359332382678986
decider.lstm.weight_ih_l0: -0.000360919046215713 0.14692984521389008
decider.lstm.weight_hh_l0: -0.0014384366804733872 0.14601941406726837
decider.lstm.bias_ih_l0: 0.017644913867115974 0.15315119922161102
decider.lstm.bias_hh_l0: -0.0013426202349364758 0.14341138303279877
decider.linear1.weight: 0.001784913009032607 0.12067674845457077
decider.linear1.bias: 0.01391538418829441 0.11647331714630127
decider.linear2.weight: 0.0039041077252477407 0.0553237609565258
decider.linear2.bias: 0.004336642101407051 0.05723150074481964
decider.linear3.weight: -0.03525175899267197 0.09099174290895462
decider.linear3.bias: -0.026279980316758156 0.055494289845228195

Rewards:
190.8927
190.8927
190.8927
objective = 3.8562705516815186
==== episode 300/10000 ====
action = 1
probs = 0.0351 0.9647 0.0002 0.0000

action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0002 0.9998 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031327357282862067 0.0839582309126854
encoder.encoder.weight_hh_l0: -0.00048068937030620873 0.08510660380125046
encoder.encoder.bias_ih_l0: 0.007243001833558083 0.08585429191589355
encoder.encoder.bias_hh_l0: 0.017240092158317566 0.08588197082281113
encoder.encoder.weight_ih_l0_reverse: 0.0016088733682408929 0.08591774106025696
encoder.encoder.weight_hh_l0_reverse: 0.002286771312355995 0.0840461328625679
encoder.encoder.bias_ih_l0_reverse: 0.022520456463098526 0.08526346832513809
encoder.encoder.bias_hh_l0_reverse: 0.014385884627699852 0.08360659331083298
decider.lstm.weight_ih_l0: -0.0003122033376712352 0.14702819287776947
decider.lstm.weight_hh_l0: -0.0014890017919242382 0.14610208570957184
decider.lstm.bias_ih_l0: 0.01820407435297966 0.15337367355823517
decider.lstm.bias_hh_l0: -0.000783462543040514 0.14345921576023102
decider.linear1.weight: 0.0017369812121614814 0.1207064837217331
decider.linear1.bias: 0.014527810737490654 0.1164502203464508
decider.linear2.weight: 0.004075311124324799 0.05548115074634552
decider.linear2.bias: 0.004489053972065449 0.05734330788254738
decider.linear3.weight: -0.03670749068260193 0.09252801537513733
decider.linear3.bias: -0.028952378779649734 0.0571405291557312

Rewards:
190.8927
190.8927
190.8927
objective = 2.309335947036743
==== episode 400/10000 ====
action = 1
probs = 0.0402 0.9597 0.0001 0.0000

action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0002 0.9998 0.0000 0.0000

Learning rate: 1.0000e-04
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000318844395224005 0.08393946290016174
encoder.encoder.weight_hh_l0: -0.0004689822089858353 0.08506373316049576
encoder.encoder.bias_ih_l0: 0.0070435223169624805 0.08584277331829071
encoder.encoder.bias_hh_l0: 0.017040612176060677 0.08586398512125015
encoder.encoder.weight_ih_l0_reverse: 0.0016084518283605576 0.08591020107269287
encoder.encoder.weight_hh_l0_reverse: 0.002273065969347954 0.08404025435447693
encoder.encoder.bias_ih_l0_reverse: 0.022399334236979485 0.08524203300476074
encoder.encoder.bias_hh_l0_reverse: 0.014264763332903385 0.08362472057342529
decider.lstm.weight_ih_l0: -0.00033614312997087836 0.14698778092861176
decider.lstm.weight_hh_l0: -0.0014448349829763174 0.14607301354408264
decider.lstm.bias_ih_l0: 0.017963331192731857 0.1533014476299286
decider.lstm.bias_hh_l0: -0.0010242043063044548 0.14345532655715942
decider.linear1.weight: 0.001728367293253541 0.12069748342037201
decider.linear1.bias: 0.014664946123957634 0.11625628173351288
decider.linear2.weight: 0.0041091046296060085 0.055510979145765305
decider.linear2.bias: 0.004478062503039837 0.05740609019994736
decider.linear3.weight: -0.037958867847919464 0.09369660168886185
decider.linear3.bias: -0.031128570437431335 0.05779010057449341

Rewards:
190.8927
190.8927
190.8927
objective = 2.6421046257019043
==== episode 500/10000 ====
action = 1
probs = 0.0158 0.9842 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031800547731108963 0.08404327929019928
encoder.encoder.weight_hh_l0: -0.0005138994310982525 0.08525130152702332
encoder.encoder.bias_ih_l0: 0.00770210474729538 0.08596225827932358
encoder.encoder.bias_hh_l0: 0.017699196934700012 0.08600562810897827
encoder.encoder.weight_ih_l0_reverse: 0.0015820014523342252 0.08593524247407913
encoder.encoder.weight_hh_l0_reverse: 0.002317539183422923 0.08406395465135574
encoder.encoder.bias_ih_l0_reverse: 0.022699909284710884 0.08536576479673386
encoder.encoder.bias_hh_l0_reverse: 0.014565340243279934 0.08350592851638794
decider.lstm.weight_ih_l0: -0.00024876350653357804 0.14715397357940674
decider.lstm.weight_hh_l0: -0.0015819442924112082 0.1462048441171646
decider.lstm.bias_ih_l0: 0.018896307796239853 0.1536663919687271
decider.lstm.bias_hh_l0: -9.122909978032112e-05 0.14354035258293152
decider.linear1.weight: 0.0016479979967698455 0.12089068442583084
decider.linear1.bias: 0.015565246343612671 0.11614541709423065
decider.linear2.weight: 0.00441186735406518 0.05577273666858673
decider.linear2.bias: 0.00474207429215312 0.05759771913290024
decider.linear3.weight: -0.03863733261823654 0.09439989924430847
decider.linear3.bias: -0.032240889966487885 0.05927492305636406

Rewards:
190.8927
190.8927
190.8927
objective = 1.0166997909545898
==== episode 600/10000 ====
action = 1
probs = 0.0064 0.9936 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000308536778902635 0.08409722149372101
encoder.encoder.weight_hh_l0: -0.0005459839012473822 0.08536859601736069
encoder.encoder.bias_ih_l0: 0.008158202283084393 0.0860089659690857
encoder.encoder.bias_hh_l0: 0.01815529353916645 0.08606579899787903
encoder.encoder.weight_ih_l0_reverse: 0.0015878811245784163 0.08595810830593109
encoder.encoder.weight_hh_l0_reverse: 0.0023741284385323524 0.08409285545349121
encoder.encoder.bias_ih_l0_reverse: 0.023091107606887817 0.08541464060544968
encoder.encoder.bias_hh_l0_reverse: 0.014956539496779442 0.08338817209005356
decider.lstm.weight_ih_l0: -0.00020396924810484052 0.14726018905639648
decider.lstm.weight_hh_l0: -0.0017068522283807397 0.14628060162067413
decider.lstm.bias_ih_l0: 0.019484542310237885 0.15378378331661224
decider.lstm.bias_hh_l0: 0.0004970128647983074 0.14365622401237488
decider.linear1.weight: 0.0015800900291651487 0.12108379602432251
decider.linear1.bias: 0.016170766204595566 0.11618378758430481
decider.linear2.weight: 0.005010751076042652 0.05604729428887367
decider.linear2.bias: 0.005354809574782848 0.058065272867679596
decider.linear3.weight: -0.039082758128643036 0.0947369784116745
decider.linear3.bias: -0.03252442926168442 0.05985301360487938

Rewards:
190.8927
190.8927
190.8927
objective = 0.40956318378448486
==== episode 700/10000 ====
action = 1
probs = 0.0026 0.9974 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003023772733286023 0.08412551134824753
encoder.encoder.weight_hh_l0: -0.0005646196659654379 0.08543862402439117
encoder.encoder.bias_ih_l0: 0.008432216010987759 0.08602814376354218
encoder.encoder.bias_hh_l0: 0.018429305404424667 0.08608714491128922
encoder.encoder.weight_ih_l0_reverse: 0.0015974892303347588 0.08597976714372635
encoder.encoder.weight_hh_l0_reverse: 0.002414967631921172 0.08411908149719238
encoder.encoder.bias_ih_l0_reverse: 0.02337140031158924 0.08544335514307022
encoder.encoder.bias_hh_l0_reverse: 0.015236827544867992 0.08332720398902893
decider.lstm.weight_ih_l0: -0.00018512678798288107 0.1473199725151062
decider.lstm.weight_hh_l0: -0.0017973618814721704 0.14632590115070343
decider.lstm.bias_ih_l0: 0.019829044118523598 0.15381067991256714
decider.lstm.bias_hh_l0: 0.0008414969779551029 0.14375054836273193
decider.linear1.weight: 0.001529328408651054 0.1212170198559761
decider.linear1.bias: 0.016526605933904648 0.11621835082769394
decider.linear2.weight: 0.005597861483693123 0.05632132664322853
decider.linear2.bias: 0.006009893491864204 0.05829556658864021
decider.linear3.weight: -0.03942939639091492 0.09509816765785217
decider.linear3.bias: -0.032605528831481934 0.060092318803071976

Rewards:
190.8927
190.8927
190.8927
objective = 0.16426488757133484
==== episode 800/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002992300142068416 0.08414116501808167
encoder.encoder.weight_hh_l0: -0.0005750374402850866 0.08548130840063095
encoder.encoder.bias_ih_l0: 0.008595466613769531 0.08603773266077042
encoder.encoder.bias_hh_l0: 0.018592555075883865 0.08609572052955627
encoder.encoder.weight_ih_l0_reverse: 0.0016052480787038803 0.0859966054558754
encoder.encoder.weight_hh_l0_reverse: 0.0024426481686532497 0.08413968235254288
encoder.encoder.bias_ih_l0_reverse: 0.023557687178254128 0.08546215295791626
encoder.encoder.bias_hh_l0_reverse: 0.015423117205500603 0.08329235762357712
decider.lstm.weight_ih_l0: -0.0001770473609212786 0.1473546177148819
decider.lstm.weight_hh_l0: -0.0018589342944324017 0.14635491371154785
decider.lstm.bias_ih_l0: 0.020035725086927414 0.1538083404302597
decider.lstm.bias_hh_l0: 0.0010481839999556541 0.14381663501262665
decider.linear1.weight: 0.001492166775278747 0.12130246311426163
decider.linear1.bias: 0.016746103763580322 0.11624237149953842
decider.linear2.weight: 0.005913178902119398 0.05654393509030342
decider.linear2.bias: 0.006343299522995949 0.058508578687906265
decider.linear3.weight: -0.03960590064525604 0.09536506235599518
decider.linear3.bias: -0.03263372182846069 0.06020157411694527

Rewards:
190.8927
190.8927
190.8927
objective = 0.0831105038523674
==== episode 900/10000 ====
action = 1
probs = 0.0008 0.9992 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.9000e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000297490565571934 0.08415163308382034
encoder.encoder.weight_hh_l0: -0.0005819444777444005 0.08551129698753357
encoder.encoder.bias_ih_l0: 0.008707216009497643 0.08604428917169571
encoder.encoder.bias_hh_l0: 0.018704302608966827 0.08610016852617264
encoder.encoder.weight_ih_l0_reverse: 0.0016111084260046482 0.08600950241088867
encoder.encoder.weight_hh_l0_reverse: 0.0024629035033285618 0.08415613323450089
encoder.encoder.bias_ih_l0_reverse: 0.023692382499575615 0.0854746401309967
encoder.encoder.bias_hh_l0_reverse: 0.015557815320789814 0.0832684189081192
decider.lstm.weight_ih_l0: -0.00017303662025369704 0.14737793803215027
decider.lstm.weight_hh_l0: -0.0019042397616431117 0.14637577533721924
decider.lstm.bias_ih_l0: 0.020176663994789124 0.15380226075649261
decider.lstm.bias_hh_l0: 0.0011891154572367668 0.1438625007867813
decider.linear1.weight: 0.0014636184787377715 0.1213630735874176
decider.linear1.bias: 0.016897914931178093 0.11626061052083969
decider.linear2.weight: 0.006115589290857315 0.05671539530158043
decider.linear2.bias: 0.006552271544933319 0.05867378041148186
decider.linear3.weight: -0.0397053137421608 0.09555761516094208
decider.linear3.bias: -0.032647669315338135 0.06026532128453255

Rewards:
190.8927
190.8927
190.8927
objective = 0.049939051270484924
==== episode 1000/10000 ====
action = 1
probs = 0.0005 0.9995 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029648427153006196 0.08415941894054413
encoder.encoder.weight_hh_l0: -0.0005870223976671696 0.08553445339202881
encoder.encoder.bias_ih_l0: 0.0087915463373065 0.08604934066534042
encoder.encoder.bias_hh_l0: 0.01878863200545311 0.08610279113054276
encoder.encoder.weight_ih_l0_reverse: 0.0016157574718818069 0.08601997792720795
encoder.encoder.weight_hh_l0_reverse: 0.002478785114362836 0.08416984230279922
encoder.encoder.bias_ih_l0_reverse: 0.023796983063220978 0.08548387140035629
encoder.encoder.bias_hh_l0_reverse: 0.015662414953112602 0.08325091749429703
decider.lstm.weight_ih_l0: -0.0001708552590571344 0.14739538729190826
decider.lstm.weight_hh_l0: -0.0019401558674871922 0.14639215171337128
decider.lstm.bias_ih_l0: 0.020282672718167305 0.15379565954208374
decider.lstm.bias_hh_l0: 0.0012951241806149483 0.14389704167842865
decider.linear1.weight: 0.0014403490349650383 0.12140976637601852
decider.linear1.bias: 0.01701301336288452 0.11627484858036041
decider.linear2.weight: 0.006262689828872681 0.05685453861951828
decider.linear2.bias: 0.0067013585940003395 0.05880600959062576
decider.linear3.weight: -0.0397714227437973 0.09570708125829697
decider.linear3.bias: -0.03265611082315445 0.06030833348631859

Rewards:
190.8927
190.8927
190.8927
objective = 0.033236488699913025
==== episode 1100/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002959013800136745 0.084165558218956
encoder.encoder.weight_hh_l0: -0.0005909724277444184 0.08555319905281067
encoder.encoder.bias_ih_l0: 0.008858502842485905 0.08605346828699112
encoder.encoder.bias_hh_l0: 0.018855588510632515 0.08610443025827408
encoder.encoder.weight_ih_l0_reverse: 0.0016195609932765365 0.08602870255708694
encoder.encoder.weight_hh_l0_reverse: 0.002491742605343461 0.08418156206607819
encoder.encoder.bias_ih_l0_reverse: 0.023881658911705017 0.08549100160598755
encoder.encoder.bias_hh_l0_reverse: 0.01574709452688694 0.08323730528354645
decider.lstm.weight_ih_l0: -0.00016966676048468798 0.14740915596485138
decider.lstm.weight_hh_l0: -0.001969701610505581 0.14640560746192932
decider.lstm.bias_ih_l0: 0.020366493612527847 0.1537894755601883
decider.lstm.bias_hh_l0: 0.0013789390213787556 0.14392413198947906
decider.linear1.weight: 0.0014208536595106125 0.12144730985164642
decider.linear1.bias: 0.01710437797009945 0.11628641188144684
decider.linear2.weight: 0.006376348435878754 0.05697062984108925
decider.linear2.bias: 0.006814915221184492 0.05891462042927742
decider.linear3.weight: -0.039819277822971344 0.09582793712615967
decider.linear3.bias: -0.032661788165569305 0.060339681804180145

Rewards:
190.8927
190.8927
190.8927
objective = 0.0237201489508152
==== episode 1200/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003050900995731354 0.08408820629119873
encoder.encoder.weight_hh_l0: -0.0005494053475558758 0.08537079393863678
encoder.encoder.bias_ih_l0: 0.008272534236311913 0.08596276491880417
encoder.encoder.bias_hh_l0: 0.018269622698426247 0.08599749207496643
encoder.encoder.weight_ih_l0_reverse: 0.0015982493059709668 0.08595196902751923
encoder.encoder.weight_hh_l0_reverse: 0.002428365871310234 0.08412537723779678
encoder.encoder.bias_ih_l0_reverse: 0.023434828966856003 0.08538835495710373
encoder.encoder.bias_hh_l0_reverse: 0.015300269238650799 0.08316086232662201
decider.lstm.weight_ih_l0: -0.00021710213331971318 0.14728356897830963
decider.lstm.weight_hh_l0: -0.001849411171860993 0.14631104469299316
decider.lstm.bias_ih_l0: 0.019652068614959717 0.15369589626789093
decider.lstm.bias_hh_l0: 0.0006645144894719124 0.1437622308731079
decider.linear1.weight: 0.0014903356786817312 0.12130021303892136
decider.linear1.bias: 0.01650993525981903 0.11625120788812637
decider.linear2.weight: 0.006214102264493704 0.056935761123895645
decider.linear2.bias: 0.00662055891007185 0.058849580585956573
decider.linear3.weight: -0.03985791653394699 0.09581652283668518
decider.linear3.bias: -0.03266612067818642 0.05989067628979683

Rewards:
190.8927
190.8927
190.8927
objective = 0.040105223655700684
==== episode 1300/10000 ====
action = 1
probs = 0.0009 0.9991 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030954330577515066 0.08406618982553482
encoder.encoder.weight_hh_l0: -0.0005328264669515193 0.08530446141958237
encoder.encoder.bias_ih_l0: 0.008036615327000618 0.08593466877937317
encoder.encoder.bias_hh_l0: 0.018033700063824654 0.08596519380807877
encoder.encoder.weight_ih_l0_reverse: 0.0015883001033216715 0.08592808246612549
encoder.encoder.weight_hh_l0_reverse: 0.002400160999968648 0.08410874754190445
encoder.encoder.bias_ih_l0_reverse: 0.023236984387040138 0.08535771816968918
encoder.encoder.bias_hh_l0_reverse: 0.015102426521480083 0.08314083516597748
decider.lstm.weight_ih_l0: -0.0002330889255972579 0.1472415328025818
decider.lstm.weight_hh_l0: -0.001794051961041987 0.14627915620803833
decider.lstm.bias_ih_l0: 0.019381025806069374 0.15366427600383759
decider.lstm.bias_hh_l0: 0.0003934856504201889 0.14370834827423096
decider.linear1.weight: 0.0015244833193719387 0.12123837321996689
decider.linear1.bias: 0.016272295266389847 0.11623542755842209
decider.linear2.weight: 0.006126489490270615 0.056889358907938004
decider.linear2.bias: 0.00652187317609787 0.05879778787493706
decider.linear3.weight: -0.040021635591983795 0.09589759260416031
decider.linear3.bias: -0.032688457518815994 0.05973908305168152

Rewards:
190.8927
190.8927
190.8927
objective = 0.05502166599035263
==== episode 1400/10000 ====
action = 1
probs = 0.0019 0.9981 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.8010e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003088397206738591 0.08396784216165543
encoder.encoder.weight_hh_l0: -0.0004925261600874364 0.08512314409017563
encoder.encoder.bias_ih_l0: 0.007443931419402361 0.0858224481344223
encoder.encoder.bias_hh_l0: 0.01744101196527481 0.08583236485719681
encoder.encoder.weight_ih_l0_reverse: 0.0015696848277002573 0.08584762364625931
encoder.encoder.weight_hh_l0_reverse: 0.00234264531172812 0.08404938131570816
encoder.encoder.bias_ih_l0_reverse: 0.022822588682174683 0.08523707091808319
encoder.encoder.bias_hh_l0_reverse: 0.014688031747937202 0.08309317380189896
decider.lstm.weight_ih_l0: -0.000293406454147771 0.14708442986011505
decider.lstm.weight_hh_l0: -0.0016816242132335901 0.14615367352962494
decider.lstm.bias_ih_l0: 0.018505558371543884 0.1535627543926239
decider.lstm.bias_hh_l0: -0.000481998547911644 0.1434716433286667
decider.linear1.weight: 0.0015778522938489914 0.12106742709875107
decider.linear1.bias: 0.015609391033649445 0.11619756370782852
decider.linear2.weight: 0.005897620227187872 0.05677565559744835
decider.linear2.bias: 0.006217062473297119 0.058654867112636566
decider.linear3.weight: -0.040214862674474716 0.09595011919736862
decider.linear3.bias: -0.03272049129009247 0.059120018035173416

Rewards:
190.8927
190.8927
190.8927
objective = 0.11877667158842087
==== episode 1500/10000 ====
action = 1
probs = 0.0015 0.9985 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031030390528030694 0.08398721367120743
encoder.encoder.weight_hh_l0: -0.0004980344674549997 0.08514980226755142
encoder.encoder.bias_ih_l0: 0.007525297347456217 0.08584146201610565
encoder.encoder.bias_hh_l0: 0.017522376030683517 0.08585751056671143
encoder.encoder.weight_ih_l0_reverse: 0.0015729197766631842 0.08586207777261734
encoder.encoder.weight_hh_l0_reverse: 0.0023518563248217106 0.08406148105859756
encoder.encoder.bias_ih_l0_reverse: 0.02287857048213482 0.08525528758764267
encoder.encoder.bias_hh_l0_reverse: 0.01474401168525219 0.08309829980134964
decider.lstm.weight_ih_l0: -0.0002816500491462648 0.14711636304855347
decider.lstm.weight_hh_l0: -0.0016925801755860448 0.1461779773235321
decider.lstm.bias_ih_l0: 0.018657024949789047 0.15357612073421478
decider.lstm.bias_hh_l0: -0.0003305249847471714 0.14352767169475555
decider.linear1.weight: 0.0015513894613832235 0.12106794863939285
decider.linear1.bias: 0.015945404767990112 0.11625692248344421
decider.linear2.weight: 0.005950231105089188 0.056811001151800156
decider.linear2.bias: 0.0062629589810967445 0.058675751090049744
decider.linear3.weight: -0.04051376134157181 0.09624967724084854
decider.linear3.bias: -0.03278867527842522 0.05926118418574333

Rewards:
190.8927
190.8927
190.8927
objective = 0.09848526120185852
==== episode 1600/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031134849996306 0.08400632441043854
encoder.encoder.weight_hh_l0: -0.0005041172844357789 0.08517785370349884
encoder.encoder.bias_ih_l0: 0.0076133147813379765 0.08585984259843826
encoder.encoder.bias_hh_l0: 0.017610395327210426 0.0858827605843544
encoder.encoder.weight_ih_l0_reverse: 0.001576863694936037 0.08587662130594254
encoder.encoder.weight_hh_l0_reverse: 0.0023615655954927206 0.08407332748174667
encoder.encoder.bias_ih_l0_reverse: 0.022941503673791885 0.08527278155088425
encoder.encoder.bias_hh_l0_reverse: 0.014806944876909256 0.083104707300663
decider.lstm.weight_ih_l0: -0.00027021809364669025 0.14714717864990234
decider.lstm.weight_hh_l0: -0.0017055969219654799 0.1462017446756363
decider.lstm.bias_ih_l0: 0.018808860331773758 0.1535896211862564
decider.lstm.bias_hh_l0: -0.00017868494614958763 0.1435808539390564
decider.linear1.weight: 0.0015302188694477081 0.12110558152198792
decider.linear1.bias: 0.01621578261256218 0.11633484810590744
decider.linear2.weight: 0.00600501149892807 0.056854985654354095
decider.linear2.bias: 0.006310754455626011 0.058697376400232315
decider.linear3.weight: -0.04069206118583679 0.09645520150661469
decider.linear3.bias: -0.03283357620239258 0.05939141660928726

Rewards:
190.8927
190.8927
190.8927
objective = 0.08080916106700897
==== episode 1700/10000 ====
action = 1
probs = 0.0010 0.9990 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000312081043375656 0.08402315527200699
encoder.encoder.weight_hh_l0: -0.000509748759213835 0.08520321547985077
encoder.encoder.bias_ih_l0: 0.0076933857053518295 0.0858754813671112
encoder.encoder.bias_hh_l0: 0.01769046112895012 0.08590525388717651
encoder.encoder.weight_ih_l0_reverse: 0.0015808498719707131 0.08588961511850357
encoder.encoder.weight_hh_l0_reverse: 0.002370458794757724 0.08408386260271072
encoder.encoder.bias_ih_l0_reverse: 0.023000670596957207 0.08528757840394974
encoder.encoder.bias_hh_l0_reverse: 0.014866110868752003 0.08311118930578232
decider.lstm.weight_ih_l0: -0.00026031723245978355 0.14717385172843933
decider.lstm.weight_hh_l0: -0.0017178518464788795 0.14622251689434052
decider.lstm.bias_ih_l0: 0.018942469730973244 0.1536010056734085
decider.lstm.bias_hh_l0: -4.507601261138916e-05 0.14362674951553345
decider.linear1.weight: 0.001511798007413745 0.12115582823753357
decider.linear1.bias: 0.0164431631565094 0.11641868203878403
decider.linear2.weight: 0.00606271019205451 0.05690477043390274
decider.linear2.bias: 0.006354370154440403 0.0587163008749485
decider.linear3.weight: -0.040815211832523346 0.0966087058186531
decider.linear3.bias: -0.03286493569612503 0.05950169637799263

Rewards:
190.8927
190.8927
190.8927
objective = 0.06672194600105286
==== episode 1800/10000 ====
action = 1
probs = 0.0009 0.9991 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003126500523649156 0.08403799682855606
encoder.encoder.weight_hh_l0: -0.0005149213830009103 0.08522621542215347
encoder.encoder.bias_ih_l0: 0.007766013033688068 0.08588892966508865
encoder.encoder.bias_hh_l0: 0.01776309125125408 0.08592544496059418
encoder.encoder.weight_ih_l0_reverse: 0.001584645127877593 0.08590128272771835
encoder.encoder.weight_hh_l0_reverse: 0.002378645120188594 0.08409339189529419
encoder.encoder.bias_ih_l0_reverse: 0.023055538535118103 0.0853007584810257
encoder.encoder.bias_hh_l0_reverse: 0.014920979738235474 0.08311763405799866
decider.lstm.weight_ih_l0: -0.0002516629174351692 0.14719709753990173
decider.lstm.weight_hh_l0: -0.0017293617129325867 0.14624077081680298
decider.lstm.bias_ih_l0: 0.019060930237174034 0.15361081063747406
decider.lstm.bias_hh_l0: 7.338356226682663e-05 0.14366640150547028
decider.linear1.weight: 0.0014951735502108932 0.12121253460645676
decider.linear1.bias: 0.016641156747937202 0.1165049821138382
decider.linear2.weight: 0.006118119694292545 0.0569600984454155
decider.linear2.bias: 0.006394504103809595 0.05873175710439682
decider.linear3.weight: -0.040905196219682693 0.09672744572162628
decider.linear3.bias: -0.03288755938410759 0.05959635227918625

Rewards:
190.8927
190.8927
190.8927
objective = 0.055332936346530914
==== episode 1900/10000 ====
action = 1
probs = 0.0036 0.9963 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.7030e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029691439704038203 0.08382561802864075
encoder.encoder.weight_hh_l0: -0.0004357954894658178 0.08489236235618591
encoder.encoder.bias_ih_l0: 0.006647048983722925 0.08566708117723465
encoder.encoder.bias_hh_l0: 0.016644131392240524 0.08561592549085617
encoder.encoder.weight_ih_l0_reverse: 0.0015265082474797964 0.08574327826499939
encoder.encoder.weight_hh_l0_reverse: 0.0022623122204095125 0.08396506309509277
encoder.encoder.bias_ih_l0_reverse: 0.0222465842962265 0.08512450009584427
encoder.encoder.bias_hh_l0_reverse: 0.014112023636698723 0.08302149176597595
decider.lstm.weight_ih_l0: -0.00038623629370704293 0.14686809480190277
decider.lstm.weight_hh_l0: -0.0015525124035775661 0.14596998691558838
decider.lstm.bias_ih_l0: 0.01724334806203842 0.1533973067998886
decider.lstm.bias_hh_l0: -0.001744195818901062 0.14314858615398407
decider.linear1.weight: 0.001572438864968717 0.1209094300866127
decider.linear1.bias: 0.015334201976656914 0.11644265800714493
decider.linear2.weight: 0.0058179982006549835 0.05676615983247757
decider.linear2.bias: 0.005971717648208141 0.058480408042669296
decider.linear3.weight: -0.04131757467985153 0.09695158153772354
decider.linear3.bias: -0.03300423175096512 0.05818673595786095

Rewards:
190.8927
190.8927
190.8927
objective = 0.23287618160247803
==== episode 2000/10000 ====
action = 1
probs = 0.0021 0.9978 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030221973429434 0.08386732637882233
encoder.encoder.weight_hh_l0: -0.00044482300290837884 0.08493885397911072
encoder.encoder.bias_ih_l0: 0.006786749232560396 0.08571592718362808
encoder.encoder.bias_hh_l0: 0.016783827915787697 0.08566934615373611
encoder.encoder.weight_ih_l0_reverse: 0.0015363144921138883 0.08577527850866318
encoder.encoder.weight_hh_l0_reverse: 0.0022804527543485165 0.08399233967065811
encoder.encoder.bias_ih_l0_reverse: 0.02235131710767746 0.08514667302370071
encoder.encoder.bias_hh_l0_reverse: 0.014216762036085129 0.08303307741880417
decider.lstm.weight_ih_l0: -0.00036008041934110224 0.1469338834285736
decider.lstm.weight_hh_l0: -0.0015618730103597045 0.14602038264274597
decider.lstm.bias_ih_l0: 0.017552301287651062 0.15343336760997772
decider.lstm.bias_hh_l0: -0.0014352458529174328 0.14326211810112
decider.linear1.weight: 0.0015701319789513946 0.12094955891370773
decider.linear1.bias: 0.015526171773672104 0.11645253747701645
decider.linear2.weight: 0.006065879482775927 0.05689903348684311
decider.linear2.bias: 0.006307484582066536 0.058622825890779495
decider.linear3.weight: -0.041841596364974976 0.09760109335184097
decider.linear3.bias: -0.033162012696266174 0.05850311368703842

Rewards:
190.8927
190.8927
190.8927
objective = 0.13709047436714172
==== episode 2100/10000 ====
action = 1
probs = 0.0014 0.9986 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030496646650135517 0.08389505743980408
encoder.encoder.weight_hh_l0: -0.0004514947650022805 0.08497142046689987
encoder.encoder.bias_ih_l0: 0.0068878307938575745 0.08574520796537399
encoder.encoder.bias_hh_l0: 0.016884909942746162 0.08570437878370285
encoder.encoder.weight_ih_l0_reverse: 0.0015427678590640426 0.08579651266336441
encoder.encoder.weight_hh_l0_reverse: 0.0022928270045667887 0.08401016891002655
encoder.encoder.bias_ih_l0_reverse: 0.022426046431064606 0.08516309410333633
encoder.encoder.bias_hh_l0_reverse: 0.014291484840214252 0.08304154127836227
decider.lstm.weight_ih_l0: -0.0003430618380662054 0.14697657525539398
decider.lstm.weight_hh_l0: -0.001570529886521399 0.1460537314414978
decider.lstm.bias_ih_l0: 0.01775655895471573 0.15345579385757446
decider.lstm.bias_hh_l0: -0.0012309807352721691 0.1433357149362564
decider.linear1.weight: 0.001566971419379115 0.12097933143377304
decider.linear1.bias: 0.01567697525024414 0.11646167933940887
decider.linear2.weight: 0.006214556284248829 0.057038985192775726
decider.linear2.bias: 0.006509232334792614 0.05878446251153946
decider.linear3.weight: -0.0421084426343441 0.09801670163869858
decider.linear3.bias: -0.03324444591999054 0.05869710072875023

Rewards:
190.8927
190.8927
190.8927
objective = 0.08846922963857651
==== episode 2200/10000 ====
action = 1
probs = 0.0010 0.9990 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030657334718853235 0.08391517400741577
encoder.encoder.weight_hh_l0: -0.0004566579300444573 0.08499590307474136
encoder.encoder.bias_ih_l0: 0.006965107750147581 0.08576496690511703
encoder.encoder.bias_hh_l0: 0.016962187364697456 0.08572962135076523
encoder.encoder.weight_ih_l0_reverse: 0.0015474557876586914 0.08581207692623138
encoder.encoder.weight_hh_l0_reverse: 0.002302006585523486 0.08402302116155624
encoder.encoder.bias_ih_l0_reverse: 0.02248314395546913 0.0851757600903511
encoder.encoder.bias_hh_l0_reverse: 0.014348587952554226 0.08304798603057861
decider.lstm.weight_ih_l0: -0.0003308971063233912 0.14700715243816376
decider.lstm.weight_hh_l0: -0.0015779314562678337 0.14607790112495422
decider.lstm.bias_ih_l0: 0.01790444552898407 0.15347091853618622
decider.lstm.bias_hh_l0: -0.0010830950923264027 0.14338861405849457
decider.linear1.weight: 0.001563671394251287 0.12100265175104141
decider.linear1.bias: 0.015798985958099365 0.11646965891122818
decider.linear2.weight: 0.006320839747786522 0.05716514214873314
decider.linear2.bias: 0.006652172189205885 0.05893101543188095
decider.linear3.weight: -0.04227812960743904 0.09831791371107101
decider.linear3.bias: -0.0332958921790123 0.058830320835113525

Rewards:
190.8927
190.8927
190.8927
objective = 0.06155487895011902
==== episode 2300/10000 ====
action = 1
probs = 0.0019 0.9981 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00029841915238648653 0.08379530161619186
encoder.encoder.weight_hh_l0: -0.00041626577149145305 0.08482896536588669
encoder.encoder.bias_ih_l0: 0.006386186927556992 0.08564118295907974
encoder.encoder.bias_hh_l0: 0.01638326793909073 0.08556457608938217
encoder.encoder.weight_ih_l0_reverse: 0.001517611090093851 0.08572135865688324
encoder.encoder.weight_hh_l0_reverse: 0.0022415420971810818 0.08395140618085861
encoder.encoder.bias_ih_l0_reverse: 0.02208409458398819 0.08508975803852081
encoder.encoder.bias_hh_l0_reverse: 0.013949538581073284 0.0830039381980896
decider.lstm.weight_ih_l0: -0.0004094016330782324 0.14683033525943756
decider.lstm.weight_hh_l0: -0.0015055201947689056 0.14593088626861572
decider.lstm.bias_ih_l0: 0.01693723350763321 0.15335635840892792
decider.lstm.bias_hh_l0: -0.0020503075793385506 0.14309343695640564
decider.linear1.weight: 0.00160515820607543 0.12083813548088074
decider.linear1.bias: 0.014965180307626724 0.11640413850545883
decider.linear2.weight: 0.006197554059326649 0.05713150277733803
decider.linear2.bias: 0.006466396152973175 0.058868732303380966
decider.linear3.weight: -0.04243304207921028 0.09845275431871414
decider.linear3.bias: -0.033343441784381866 0.05808328464627266

Rewards:
190.8927
190.8927
190.8927
objective = 0.1194644421339035
==== episode 2400/10000 ====
action = 1
probs = 0.0017 0.9983 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.6060e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003010966465808451 0.08381988853216171
encoder.encoder.weight_hh_l0: -0.00042095311800949275 0.08485298603773117
encoder.encoder.bias_ih_l0: 0.006458125077188015 0.08566915988922119
encoder.encoder.bias_hh_l0: 0.01645520329475403 0.08559326827526093
encoder.encoder.weight_ih_l0_reverse: 0.0015253862366080284 0.08574258536100388
encoder.encoder.weight_hh_l0_reverse: 0.002253101672977209 0.08396871387958527
encoder.encoder.bias_ih_l0_reverse: 0.022145504131913185 0.08509887754917145
encoder.encoder.bias_hh_l0_reverse: 0.01401094626635313 0.0830070972442627
decider.lstm.weight_ih_l0: -0.0003941054455935955 0.14686837792396545
decider.lstm.weight_hh_l0: -0.0015067355707287788 0.14595909416675568
decider.lstm.bias_ih_l0: 0.01710600033402443 0.1533709168434143
decider.lstm.bias_hh_l0: -0.00188154517672956 0.14316287636756897
decider.linear1.weight: 0.0016053927829489112 0.12085888534784317
decider.linear1.bias: 0.015076548792421818 0.11641068011522293
decider.linear2.weight: 0.006213784217834473 0.057143375277519226
decider.linear2.bias: 0.0064936005510389805 0.058889277279376984
decider.linear3.weight: -0.04276236146688461 0.09889329224824905
decider.linear3.bias: -0.033465947955846786 0.05826788768172264

Rewards:
190.8927
190.8927
190.8927
objective = 0.10728716850280762
==== episode 2500/10000 ====
action = 1
probs = 0.0015 0.9985 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000303790409816429 0.08384795486927032
encoder.encoder.weight_hh_l0: -0.00042757095070555806 0.08488389849662781
encoder.encoder.bias_ih_l0: 0.006556794047355652 0.0856994092464447
encoder.encoder.bias_hh_l0: 0.01655387133359909 0.08562752604484558
encoder.encoder.weight_ih_l0_reverse: 0.001533651608042419 0.08576589822769165
encoder.encoder.weight_hh_l0_reverse: 0.0022663527633994818 0.08398738503456116
encoder.encoder.bias_ih_l0_reverse: 0.022221848368644714 0.08511248230934143
encoder.encoder.bias_hh_l0_reverse: 0.014087295159697533 0.08301316201686859
decider.lstm.weight_ih_l0: -0.0003766031004488468 0.14691030979156494
decider.lstm.weight_hh_l0: -0.0015130701940506697 0.14599160850048065
decider.lstm.bias_ih_l0: 0.01730639487504959 0.15339049696922302
decider.lstm.bias_hh_l0: -0.0016811499372124672 0.14323756098747253
decider.linear1.weight: 0.0016027301317080855 0.12088726460933685
decider.linear1.bias: 0.015225501731038094 0.11642055958509445
decider.linear2.weight: 0.006239101756364107 0.057160452008247375
decider.linear2.bias: 0.006533442996442318 0.058915819972753525
decider.linear3.weight: -0.04298607259988785 0.09922449290752411
decider.linear3.bias: -0.033555082976818085 0.05846508592367172

Rewards:
190.8927
190.8927
190.8927
objective = 0.09252938628196716
==== episode 2600/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003060372546315193 0.08387292921543121
encoder.encoder.weight_hh_l0: -0.00043377565452829003 0.08491237461566925
encoder.encoder.bias_ih_l0: 0.0066483817063272 0.08572538942098618
encoder.encoder.bias_hh_l0: 0.016645459458231926 0.08565818518400192
encoder.encoder.weight_ih_l0_reverse: 0.001540723373182118 0.08578642457723618
encoder.encoder.weight_hh_l0_reverse: 0.0022778937127441168 0.0840037539601326
encoder.encoder.bias_ih_l0_reverse: 0.02229035273194313 0.08512579649686813
encoder.encoder.bias_hh_l0_reverse: 0.014155806973576546 0.08301975578069687
decider.lstm.weight_ih_l0: -0.0003613398876041174 0.14694653451442719
decider.lstm.weight_hh_l0: -0.0015202034264802933 0.14602024853229523
decider.lstm.bias_ih_l0: 0.01748359575867653 0.1534084975719452
decider.lstm.bias_hh_l0: -0.0015039453282952309 0.14330123364925385
decider.linear1.weight: 0.001599499024450779 0.12091382592916489
decider.linear1.bias: 0.015362833626568317 0.11643005907535553
decider.linear2.weight: 0.006263528484851122 0.057176679372787476
decider.linear2.bias: 0.006571355741471052 0.05894022807478905
decider.linear3.weight: -0.0431489571928978 0.09947898983955383
decider.linear3.bias: -0.03362112119793892 0.058635711669921875

Rewards:
190.8927
190.8927
190.8927
objective = 0.08067625761032104
==== episode 2700/10000 ====
action = 1
probs = 0.0026 0.9974 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0002958851691801101 0.08376245945692062
encoder.encoder.weight_hh_l0: -0.0003960621834266931 0.08476337045431137
encoder.encoder.bias_ih_l0: 0.006115070544183254 0.0856052115559578
encoder.encoder.bias_hh_l0: 0.01611214689910412 0.08550804853439331
encoder.encoder.weight_ih_l0_reverse: 0.0015099700540304184 0.0857020914554596
encoder.encoder.weight_hh_l0_reverse: 0.0022218753583729267 0.08393757790327072
encoder.encoder.bias_ih_l0_reverse: 0.02193872444331646 0.08504605293273926
encoder.encoder.bias_hh_l0_reverse: 0.013804182410240173 0.08298271149396896
decider.lstm.weight_ih_l0: -0.00043505243957042694 0.14679254591464996
decider.lstm.weight_hh_l0: -0.001455209800042212 0.1458897590637207
decider.lstm.bias_ih_l0: 0.016600385308265686 0.15329618752002716
decider.lstm.bias_hh_l0: -0.0023871595039963722 0.14304596185684204
decider.linear1.weight: 0.001633746549487114 0.12076597660779953
decider.linear1.bias: 0.014617092907428741 0.11638089269399643
decider.linear2.weight: 0.006109918002039194 0.057089321315288544
decider.linear2.bias: 0.00634223036468029 0.058822810649871826
decider.linear3.weight: -0.043434370309114456 0.0998179242014885
decider.linear3.bias: -0.03375072032213211 0.057937875390052795

Rewards:
190.8927
190.8927
190.8927
objective = 0.16793063282966614
==== episode 2800/10000 ====
action = 1
probs = 0.0021 0.9979 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030062749283388257 0.0838046595454216
encoder.encoder.weight_hh_l0: -0.00040533731225878 0.08480727672576904
encoder.encoder.bias_ih_l0: 0.00625251978635788 0.08565588295459747
encoder.encoder.bias_hh_l0: 0.01624959707260132 0.0855596736073494
encoder.encoder.weight_ih_l0_reverse: 0.0015245487447828054 0.08573882281780243
encoder.encoder.weight_hh_l0_reverse: 0.002242386108264327 0.08396704494953156
encoder.encoder.bias_ih_l0_reverse: 0.02205064333975315 0.08506566286087036
encoder.encoder.bias_hh_l0_reverse: 0.013916101306676865 0.08299047499895096
decider.lstm.weight_ih_l0: -0.0004095799522474408 0.14685149490833282
decider.lstm.weight_hh_l0: -0.0014603298623114824 0.14593474566936493
decider.lstm.bias_ih_l0: 0.016887269914150238 0.15332821011543274
decider.lstm.bias_hh_l0: -0.002100270241498947 0.1431528478860855
decider.linear1.weight: 0.0016318948473781347 0.12080447375774384
decider.linear1.bias: 0.014817393384873867 0.11639440804719925
decider.linear2.weight: 0.006142839789390564 0.057110078632831573
decider.linear2.bias: 0.006395641248673201 0.05885492265224457
decider.linear3.weight: -0.043739914894104004 0.10032457113265991
decider.linear3.bias: -0.033901866525411606 0.05825510621070862

Rewards:
190.8927
190.8927
190.8927
objective = 0.13691182434558868
==== episode 2900/10000 ====
action = 1
probs = 0.0018 0.9982 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.5099e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000304290879284963 0.08384060114622116
encoder.encoder.weight_hh_l0: -0.00041394680738449097 0.08484639972448349
encoder.encoder.bias_ih_l0: 0.0063778734765946865 0.08569635450839996
encoder.encoder.bias_hh_l0: 0.016374947503209114 0.085603728890419
encoder.encoder.weight_ih_l0_reverse: 0.00153649493586272 0.08576955646276474
encoder.encoder.weight_hh_l0_reverse: 0.002259443048387766 0.08399146050214767
encoder.encoder.bias_ih_l0_reverse: 0.022147759795188904 0.08508344739675522
encoder.encoder.bias_hh_l0_reverse: 0.014013214968144894 0.08299931138753891
decider.lstm.weight_ih_l0: -0.0003880826698150486 0.14689959585666656
decider.lstm.weight_hh_l0: -0.0014682506443932652 0.14597278833389282
decider.lstm.bias_ih_l0: 0.017129534855484962 0.15335682034492493
decider.lstm.bias_hh_l0: -0.0018580062314867973 0.1432373821735382
decider.linear1.weight: 0.0016286562895402312 0.1208396852016449
decider.linear1.bias: 0.014996368438005447 0.11640699952840805
decider.linear2.weight: 0.006174623034894466 0.05712972208857536
decider.linear2.bias: 0.006446273997426033 0.05888413265347481
decider.linear3.weight: -0.04394099861383438 0.10067465156316757
decider.linear3.bias: -0.034002941101789474 0.05851393938064575

Rewards:
190.8927
190.8927
190.8927
objective = 0.11401572078466415
==== episode 3000/10000 ====
action = 1
probs = 0.0015 0.9985 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030720618087798357 0.08387168496847153
encoder.encoder.weight_hh_l0: -0.0004219927650410682 0.0848817229270935
encoder.encoder.bias_ih_l0: 0.006492950953543186 0.08572953939437866
encoder.encoder.bias_hh_l0: 0.0164900254458189 0.08564214408397675
encoder.encoder.weight_ih_l0_reverse: 0.0015465110773220658 0.08579577505588531
encoder.encoder.weight_hh_l0_reverse: 0.0022740208078175783 0.08401218801736832
encoder.encoder.bias_ih_l0_reverse: 0.022233741357922554 0.08509980142116547
encoder.encoder.bias_hh_l0_reverse: 0.01409919373691082 0.08300855755805969
decider.lstm.weight_ih_l0: -0.0003695207124110311 0.14694015681743622
decider.lstm.weight_hh_l0: -0.0014777466421946883 0.14600566029548645
decider.lstm.bias_ih_l0: 0.017339864745736122 0.15338227152824402
decider.lstm.bias_hh_l0: -0.001647681463509798 0.14330671727657318
decider.linear1.weight: 0.0016244337894022465 0.12087219953536987
decider.linear1.bias: 0.015158555470407009 0.11641903966665268
decider.linear2.weight: 0.006205207668244839 0.057148344814777374
decider.linear2.bias: 0.006494208704680204 0.05891101062297821
decider.linear3.weight: -0.044085584580898285 0.10093597322702408
decider.linear3.bias: -0.03407540172338486 0.058733392506837845

Rewards:
190.8927
190.8927
190.8927
objective = 0.0965404361486435
==== episode 3100/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030955843976698816 0.08389874547719955
encoder.encoder.weight_hh_l0: -0.00042950711213052273 0.08491374552249908
encoder.encoder.bias_ih_l0: 0.006598551291972399 0.08575715124607086
encoder.encoder.bias_hh_l0: 0.0165956262499094 0.08567600697278976
encoder.encoder.weight_ih_l0_reverse: 0.0015550428070127964 0.0858183354139328
encoder.encoder.weight_hh_l0_reverse: 0.002286651637405157 0.08402998000383377
encoder.encoder.bias_ih_l0_reverse: 0.022310635074973106 0.08511479943990707
encoder.encoder.bias_hh_l0_reverse: 0.014176089316606522 0.08301789313554764
decider.lstm.weight_ih_l0: -0.00035334296990185976 0.14697490632534027
decider.lstm.weight_hh_l0: -0.0014881001552566886 0.1460343301296234
decider.lstm.bias_ih_l0: 0.017524736002087593 0.15340499579906464
decider.lstm.bias_hh_l0: -0.0014628113713115454 0.1433645635843277
decider.linear1.weight: 0.0016195254866033792 0.12090222537517548
decider.linear1.bias: 0.015305881388485432 0.11643045395612717
decider.linear2.weight: 0.0062344009056687355 0.05716591700911522
decider.linear2.bias: 0.006539283785969019 0.05893578752875328
decider.linear3.weight: -0.044194139540195465 0.10113850235939026
decider.linear3.bias: -0.03412934020161629 0.058922722935676575

Rewards:
190.8927
190.8927
190.8927
objective = 0.08292442560195923
==== episode 3200/10000 ====
action = 1
probs = 0.0011 0.9989 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003115099389106035 0.08392287790775299
encoder.encoder.weight_hh_l0: -0.00043665364501066506 0.08494339138269424
encoder.encoder.bias_ih_l0: 0.006697251461446285 0.08578083664178848
encoder.encoder.bias_hh_l0: 0.016694325953722 0.08570662885904312
encoder.encoder.weight_ih_l0_reverse: 0.0015625428641214967 0.08583823591470718
encoder.encoder.weight_hh_l0_reverse: 0.0022979185450822115 0.08404569327831268
encoder.encoder.bias_ih_l0_reverse: 0.022381220012903214 0.0851287916302681
encoder.encoder.bias_hh_l0_reverse: 0.014246674254536629 0.08302725106477737
decider.lstm.weight_ih_l0: -0.0003388814511708915 0.1470055729150772
decider.lstm.weight_hh_l0: -0.0014990740455687046 0.14605998992919922
decider.lstm.bias_ih_l0: 0.01769171841442585 0.15342572331428528
decider.lstm.bias_hh_l0: -0.0012958291918039322 0.14341433346271515
decider.linear1.weight: 0.0016140512889251113 0.1209305003285408
decider.linear1.bias: 0.015442422591149807 0.11644142866134644
decider.linear2.weight: 0.006262617185711861 0.05718274787068367
decider.linear2.bias: 0.006582248490303755 0.05895905941724777
decider.linear3.weight: -0.0442795604467392 0.10130244493484497
decider.linear3.bias: -0.03417132794857025 0.05909101665019989

Rewards:
190.8927
190.8927
190.8927
objective = 0.0719577744603157
==== episode 3300/10000 ====
action = 1
probs = 0.0010 0.9990 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031314700026996434 0.08394463360309601
encoder.encoder.weight_hh_l0: -0.00044349164818413556 0.08497107028961182
encoder.encoder.bias_ih_l0: 0.006790100131183863 0.08580146729946136
encoder.encoder.bias_hh_l0: 0.016787175089120865 0.08573463559150696
encoder.encoder.weight_ih_l0_reverse: 0.001569245127029717 0.08585600554943085
encoder.encoder.weight_hh_l0_reverse: 0.0023081155959516764 0.08405975252389908
encoder.encoder.bias_ih_l0_reverse: 0.02244679629802704 0.08514190465211868
encoder.encoder.bias_hh_l0_reverse: 0.01431224774569273 0.08303657174110413
decider.lstm.weight_ih_l0: -0.0003258074866607785 0.14703305065631866
decider.lstm.weight_hh_l0: -0.001510472735390067 0.14608322083950043
decider.lstm.bias_ih_l0: 0.017844446003437042 0.1534447968006134
decider.lstm.bias_hh_l0: -0.0011431029997766018 0.14345777034759521
decider.linear1.weight: 0.0016081234207376838 0.12095727771520615
decider.linear1.bias: 0.015569918788969517 0.11645197123289108
decider.linear2.weight: 0.006289941258728504 0.05719891935586929
decider.linear2.bias: 0.006623319815844297 0.05898106470704079
decider.linear3.weight: -0.04434850439429283 0.10143832117319107
decider.linear3.bias: -0.03420482203364372 0.05924273282289505

Rewards:
190.8927
190.8927
190.8927
objective = 0.06296713650226593
==== episode 3400/10000 ====
action = 1
probs = 0.0009 0.9991 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.4148e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003145311784464866 0.08396440744400024
encoder.encoder.weight_hh_l0: -0.0004500672221183777 0.08499710261821747
encoder.encoder.bias_ih_l0: 0.006877927575260401 0.08581966161727905
encoder.encoder.bias_hh_l0: 0.016875000670552254 0.08576050400733948
encoder.encoder.weight_ih_l0_reverse: 0.0015753201441839337 0.08587203174829483
encoder.encoder.weight_hh_l0_reverse: 0.002317457227036357 0.08407247066497803
encoder.encoder.bias_ih_l0_reverse: 0.022508325055241585 0.08515425026416779
encoder.encoder.bias_hh_l0_reverse: 0.014373776502907276 0.08304581046104431
decider.lstm.weight_ih_l0: -0.00031387447961606085 0.14705796539783478
decider.lstm.weight_hh_l0: -0.001522168517112732 0.14610446989536285
decider.lstm.bias_ih_l0: 0.01798553764820099 0.1534624844789505
decider.lstm.bias_hh_l0: -0.0010020120535045862 0.14349614083766937
decider.linear1.weight: 0.0016018215101212263 0.12098278105258942
decider.linear1.bias: 0.015689700841903687 0.11646214127540588
decider.linear2.weight: 0.006316452752798796 0.057214513421058655
decider.linear2.bias: 0.006662685424089432 0.05900198593735695
decider.linear3.weight: -0.044405266642570496 0.1015530377626419
decider.linear3.bias: -0.03423207253217697 0.05938103049993515

Rewards:
190.8927
190.8927
190.8927
objective = 0.05549237132072449
==== episode 3500/10000 ====
action = 1
probs = 0.0008 0.9992 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003157082246616483 0.08398251980543137
encoder.encoder.weight_hh_l0: -0.0004564192204270512 0.08502174913883209
encoder.encoder.bias_ih_l0: 0.006961401551961899 0.08583588153123856
encoder.encoder.bias_hh_l0: 0.01695847697556019 0.08578459173440933
encoder.encoder.weight_ih_l0_reverse: 0.0015808966709300876 0.08588659763336182
encoder.encoder.weight_hh_l0_reverse: 0.0023261038586497307 0.08408407866954803
encoder.encoder.bias_ih_l0_reverse: 0.022566523402929306 0.08516590297222137
encoder.encoder.bias_hh_l0_reverse: 0.014431978575885296 0.08305494487285614
decider.lstm.weight_ih_l0: -0.00030289843562059104 0.14708076417446136
decider.lstm.weight_hh_l0: -0.0015340889804065228 0.14612405002117157
decider.lstm.bias_ih_l0: 0.01811695657670498 0.15347900986671448
decider.lstm.bias_hh_l0: -0.0008705917280167341 0.14353036880493164
decider.linear1.weight: 0.0015952069079503417 0.12100717425346375
decider.linear1.bias: 0.015802830457687378 0.11647196114063263
decider.linear2.weight: 0.006342224311083555 0.05722959339618683
decider.linear2.bias: 0.006700512021780014 0.0590219609439373
decider.linear3.weight: -0.0444527342915535 0.10165137052536011
decider.linear3.bias: -0.03425460308790207 0.059508226811885834

Rewards:
190.8927
190.8927
190.8927
objective = 0.04919510707259178
==== episode 3600/10000 ====
action = 1
probs = 0.0007 0.9993 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003166708047501743 0.0839991569519043
encoder.encoder.weight_hh_l0: -0.00046253998880274594 0.08504512161016464
encoder.encoder.bias_ih_l0: 0.007040256168693304 0.08585093170404434
encoder.encoder.bias_hh_l0: 0.01703733205795288 0.08580683171749115
encoder.encoder.weight_ih_l0_reverse: 0.0015863534063100815 0.08590001612901688
encoder.encoder.weight_hh_l0_reverse: 0.002334152814000845 0.08409479260444641
encoder.encoder.bias_ih_l0_reverse: 0.022622331976890564 0.08517632633447647
encoder.encoder.bias_hh_l0_reverse: 0.01448778621852398 0.08306386321783066
decider.lstm.weight_ih_l0: -0.0002928318572230637 0.14710170030593872
decider.lstm.weight_hh_l0: -0.001546097337268293 0.14614206552505493
decider.lstm.bias_ih_l0: 0.01823931187391281 0.15349392592906952
decider.lstm.bias_hh_l0: -0.0007482287473976612 0.14356113970279694
decider.linear1.weight: 0.0015883517917245626 0.12103034555912018
decider.linear1.bias: 0.015910182148218155 0.11648175865411758
decider.linear2.weight: 0.006370076909661293 0.057245269417762756
decider.linear2.bias: 0.006736584939062595 0.05904092267155647
decider.linear3.weight: -0.04449257254600525 0.10173589736223221
decider.linear3.bias: -0.03427330031991005 0.05962495505809784

Rewards:
190.8927
190.8927
190.8927
objective = 0.0438738577067852
==== episode 3700/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003174694429617375 0.0840146467089653
encoder.encoder.weight_hh_l0: -0.0004685161111410707 0.08506756275892258
encoder.encoder.bias_ih_l0: 0.007115846034139395 0.08586493879556656
encoder.encoder.bias_hh_l0: 0.01711292378604412 0.08582775294780731
encoder.encoder.weight_ih_l0_reverse: 0.0015916788252070546 0.0859125405550003
encoder.encoder.weight_hh_l0_reverse: 0.0023417766205966473 0.08410479128360748
encoder.encoder.bias_ih_l0_reverse: 0.022676415741443634 0.08518591523170471
encoder.encoder.bias_hh_l0_reverse: 0.014541861601173878 0.08307264000177383
decider.lstm.weight_ih_l0: -0.00028343949816189706 0.14712122082710266
decider.lstm.weight_hh_l0: -0.0015582735650241375 0.14615891873836517
decider.lstm.bias_ih_l0: 0.018355004489421844 0.15350773930549622
decider.lstm.bias_hh_l0: -0.0006325412541627884 0.14358921349048615
decider.linear1.weight: 0.0015812355559319258 0.12105266749858856
decider.linear1.bias: 0.016013117507100105 0.11649147421121597
decider.linear2.weight: 0.006396865472197533 0.057262323796749115
decider.linear2.bias: 0.006771412678062916 0.05905916169285774
decider.linear3.weight: -0.04452671483159065 0.10181010514497757
decider.linear3.bias: -0.034289147704839706 0.059733856469392776

Rewards:
190.8927
190.8927
190.8927
objective = 0.039289288222789764
==== episode 3800/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031813813257031143 0.08402909338474274
encoder.encoder.weight_hh_l0: -0.0004743604513350874 0.08508910983800888
encoder.encoder.bias_ih_l0: 0.007188578601926565 0.08587782084941864
encoder.encoder.bias_hh_l0: 0.017185654491186142 0.08584751188755035
encoder.encoder.weight_ih_l0_reverse: 0.0015967664076015353 0.0859241932630539
encoder.encoder.weight_hh_l0_reverse: 0.0023490218445658684 0.08411411941051483
encoder.encoder.bias_ih_l0_reverse: 0.02272871881723404 0.0851949155330658
encoder.encoder.bias_hh_l0_reverse: 0.014594168402254581 0.0830812081694603
decider.lstm.weight_ih_l0: -0.00027463398873806 0.1471395045518875
decider.lstm.weight_hh_l0: -0.001570577616803348 0.14617475867271423
decider.lstm.bias_ih_l0: 0.018464744091033936 0.15352077782154083
decider.lstm.bias_hh_l0: -0.0005228002555668354 0.14361485838890076
decider.linear1.weight: 0.001573897316120565 0.12107422947883606
decider.linear1.bias: 0.01611180044710636 0.11650101840496063
decider.linear2.weight: 0.006422742269933224 0.057279519736766815
decider.linear2.bias: 0.006805354729294777 0.05907697230577469
decider.linear3.weight: -0.044556234031915665 0.10187583416700363
decider.linear3.bias: -0.03430270403623581 0.05983598157763481

Rewards:
190.8927
190.8927
190.8927
objective = 0.03532738983631134
==== episode 3900/10000 ====
action = 1
probs = 0.0005 0.9995 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.3207e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003186455578543246 0.08404255658388138
encoder.encoder.weight_hh_l0: -0.00048010615864768624 0.08510986715555191
encoder.encoder.bias_ih_l0: 0.007259226869791746 0.0858892872929573
encoder.encoder.bias_hh_l0: 0.017256300896406174 0.08586622029542923
encoder.encoder.weight_ih_l0_reverse: 0.0016014828579500318 0.08593502640724182
encoder.encoder.weight_hh_l0_reverse: 0.0023559248074889183 0.08412270247936249
encoder.encoder.bias_ih_l0_reverse: 0.022779293358325958 0.08520349860191345
encoder.encoder.bias_hh_l0_reverse: 0.014644735492765903 0.08308927714824677
decider.lstm.weight_ih_l0: -0.0002663250488694757 0.14715677499771118
decider.lstm.weight_hh_l0: -0.0015829717740416527 0.14618980884552002
decider.lstm.bias_ih_l0: 0.018569117411971092 0.1535329669713974
decider.lstm.bias_hh_l0: -0.0004184325225651264 0.14363868534564972
decider.linear1.weight: 0.0015662926016375422 0.12109515070915222
decider.linear1.bias: 0.01620742306113243 0.11651118099689484
decider.linear2.weight: 0.006449755281209946 0.05729634314775467
decider.linear2.bias: 0.006840821355581284 0.05909484997391701
decider.linear3.weight: -0.04458194971084595 0.10193447023630142
decider.linear3.bias: -0.034314386546611786 0.05993221327662468

Rewards:
190.8927
190.8927
190.8927
objective = 0.03190457075834274
==== episode 4000/10000 ====
action = 1
probs = 0.0005 0.9995 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003190445131622255 0.08405525237321854
encoder.encoder.weight_hh_l0: -0.0004857591411564499 0.0851299837231636
encoder.encoder.bias_ih_l0: 0.00732765905559063 0.0858999639749527
encoder.encoder.bias_hh_l0: 0.017324738204479218 0.08588404208421707
encoder.encoder.weight_ih_l0_reverse: 0.0016060849884524941 0.085945263504982
encoder.encoder.weight_hh_l0_reverse: 0.0023625807370990515 0.08413084596395493
encoder.encoder.bias_ih_l0_reverse: 0.022828705608844757 0.08521164953708649
encoder.encoder.bias_hh_l0_reverse: 0.014694152399897575 0.08309726417064667
decider.lstm.weight_ih_l0: -0.00025847082724794745 0.14717313647270203
decider.lstm.weight_hh_l0: -0.0015954619739204645 0.14620409905910492
decider.lstm.bias_ih_l0: 0.018669020384550095 0.15354451537132263
decider.lstm.bias_hh_l0: -0.0003185286186635494 0.1436607390642166
decider.linear1.weight: 0.0015584856737405062 0.1211155354976654
decider.linear1.bias: 0.01629980467259884 0.11652132123708725
decider.linear2.weight: 0.006476313807070255 0.0573129840195179
decider.linear2.bias: 0.006875541992485523 0.05911209061741829
decider.linear3.weight: -0.04460448399186134 0.10198713093996048
decider.linear3.bias: -0.0343245230615139 0.06002329662442207

Rewards:
190.8927
190.8927
190.8927
objective = 0.028895525261759758
==== episode 4100/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003193510347045958 0.08406712114810944
encoder.encoder.weight_hh_l0: -0.0004912695731036365 0.08514931797981262
encoder.encoder.bias_ih_l0: 0.0073934271931648254 0.08590984344482422
encoder.encoder.bias_hh_l0: 0.017390506342053413 0.0859009250998497
encoder.encoder.weight_ih_l0_reverse: 0.001610569073818624 0.08595487475395203
encoder.encoder.weight_hh_l0_reverse: 0.002368965419009328 0.08413849771022797
encoder.encoder.bias_ih_l0_reverse: 0.022876758128404617 0.08521918207406998
encoder.encoder.bias_hh_l0_reverse: 0.01474220585078001 0.08310499787330627
decider.lstm.weight_ih_l0: -0.0002510997874196619 0.14718851447105408
decider.lstm.weight_hh_l0: -0.0016079168999567628 0.14621758460998535
decider.lstm.bias_ih_l0: 0.018763937056064606 0.15355534851551056
decider.lstm.bias_hh_l0: -0.00022361497394740582 0.14368101954460144
decider.linear1.weight: 0.0015506426570937037 0.1211351603269577
decider.linear1.bias: 0.01638762652873993 0.11653083562850952
decider.linear2.weight: 0.006503306329250336 0.05732810124754906
decider.linear2.bias: 0.006908929906785488 0.059128668159246445
decider.linear3.weight: -0.04462415724992752 0.10203424096107483
decider.linear3.bias: -0.034333281219005585 0.0601089708507061

Rewards:
190.8927
190.8927
190.8927
objective = 0.026262253522872925
==== episode 4200/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003195837198290974 0.0840783640742302
encoder.encoder.weight_hh_l0: -0.0004967065760865808 0.08516814559698105
encoder.encoder.bias_ih_l0: 0.007457407657057047 0.08591911941766739
encoder.encoder.bias_hh_l0: 0.0174544844776392 0.08591712266206741
encoder.encoder.weight_ih_l0_reverse: 0.0016149868024513125 0.08596402406692505
encoder.encoder.weight_hh_l0_reverse: 0.0023751850239932537 0.08414577692747116
encoder.encoder.bias_ih_l0_reverse: 0.022924073040485382 0.08522624522447586
encoder.encoder.bias_hh_l0_reverse: 0.014789517037570477 0.08311256766319275
decider.lstm.weight_ih_l0: -0.000244084294536151 0.14720319211483002
decider.lstm.weight_hh_l0: -0.0016204495914280415 0.14623045921325684
decider.lstm.bias_ih_l0: 0.018855314701795578 0.15356570482254028
decider.lstm.bias_hh_l0: -0.0001322233583778143 0.14369988441467285
decider.linear1.weight: 0.0015426881145685911 0.1211543008685112
decider.linear1.bias: 0.01647222973406315 0.11653993278741837
decider.linear2.weight: 0.006531297229230404 0.05734331160783768
decider.linear2.bias: 0.006941418629139662 0.05914479121565819
decider.linear3.weight: -0.04464161396026611 0.10207711905241013
decider.linear3.bias: -0.03434097021818161 0.06019063666462898

Rewards:
190.8927
190.8927
190.8927
objective = 0.023921236395835876
==== episode 4300/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031976442551240325 0.08408903330564499
encoder.encoder.weight_hh_l0: -0.000502071634400636 0.08518647402524948
encoder.encoder.bias_ih_l0: 0.007519576232880354 0.08592792600393295
encoder.encoder.bias_hh_l0: 0.01751665584743023 0.08593272417783737
encoder.encoder.weight_ih_l0_reverse: 0.0016192463226616383 0.08597268909215927
encoder.encoder.weight_hh_l0_reverse: 0.0023812418803572655 0.08415278047323227
encoder.encoder.bias_ih_l0_reverse: 0.02297031320631504 0.0852331817150116
encoder.encoder.bias_hh_l0_reverse: 0.014835759066045284 0.083120197057724
decider.lstm.weight_ih_l0: -0.00023737677838653326 0.14721724390983582
decider.lstm.weight_hh_l0: -0.0016330775106325746 0.14624282717704773
decider.lstm.bias_ih_l0: 0.018943671137094498 0.1535758674144745
decider.lstm.bias_hh_l0: -4.387320950627327e-05 0.14371734857559204
decider.linear1.weight: 0.0015345009742304683 0.12117308378219604
decider.linear1.bias: 0.016555102542042732 0.11654936522245407
decider.linear2.weight: 0.006558569148182869 0.05736038088798523
decider.linear2.bias: 0.006973068229854107 0.0591605007648468
decider.linear3.weight: -0.04465716704726219 0.10211628675460815
decider.linear3.bias: -0.0343477725982666 0.060268696397542953

Rewards:
190.8927
190.8927
190.8927
objective = 0.02183450385928154
==== episode 4400/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.2274e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003198946942575276 0.084099180996418
encoder.encoder.weight_hh_l0: -0.0005073741776868701 0.08520437031984329
encoder.encoder.bias_ih_l0: 0.007580115459859371 0.08593631535768509
encoder.encoder.bias_hh_l0: 0.017577189952135086 0.08594775944948196
encoder.encoder.weight_ih_l0_reverse: 0.0016233796486631036 0.08598092943429947
encoder.encoder.weight_hh_l0_reverse: 0.0023871641606092453 0.08415952324867249
encoder.encoder.bias_ih_l0_reverse: 0.02301565557718277 0.0852399617433548
encoder.encoder.bias_hh_l0_reverse: 0.014881109818816185 0.08312782645225525
decider.lstm.weight_ih_l0: -0.00023095353390090168 0.14723071455955505
decider.lstm.weight_hh_l0: -0.001645804033614695 0.1462547332048416
decider.lstm.bias_ih_l0: 0.019029228016734123 0.1535857617855072
decider.lstm.bias_hh_l0: 4.168180748820305e-05 0.14373353123664856
decider.linear1.weight: 0.0015260959044098854 0.12119154632091522
decider.linear1.bias: 0.01663626730442047 0.11655905097723007
decider.linear2.weight: 0.00658502196893096 0.05737851560115814
decider.linear2.bias: 0.007003930397331715 0.05917583405971527
decider.linear3.weight: -0.04467107355594635 0.1021522507071495
decider.linear3.bias: -0.03435377776622772 0.06034344807267189

Rewards:
190.8927
190.8927
190.8927
objective = 0.019960299134254456
==== episode 4500/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031288861646316946 0.08394785970449448
encoder.encoder.weight_hh_l0: -0.0004147134313825518 0.0849083736538887
encoder.encoder.bias_ih_l0: 0.006487399339675903 0.085789754986763
encoder.encoder.bias_hh_l0: 0.016484469175338745 0.08569595217704773
encoder.encoder.weight_ih_l0_reverse: 0.0015541085740551353 0.08585736900568008
encoder.encoder.weight_hh_l0_reverse: 0.002285407157614827 0.0840691402554512
encoder.encoder.bias_ih_l0_reverse: 0.02224869281053543 0.08514419943094254
encoder.encoder.bias_hh_l0_reverse: 0.014114146120846272 0.08304981142282486
decider.lstm.weight_ih_l0: -0.00033433179487474263 0.1470019668340683
decider.lstm.weight_hh_l0: -0.0014362969668582082 0.14605671167373657
decider.lstm.bias_ih_l0: 0.01755143143236637 0.15334409475326538
decider.lstm.bias_hh_l0: -0.0014361273497343063 0.14345601201057434
decider.linear1.weight: 0.001651067635975778 0.1208847314119339
decider.linear1.bias: 0.015280721709132195 0.11641789972782135
decider.linear2.weight: 0.006145533174276352 0.05718478560447693
decider.linear2.bias: 0.006408140994608402 0.058897458016872406
decider.linear3.weight: -0.04476337134838104 0.10213398933410645
decider.linear3.bias: -0.03440000116825104 0.05895432084798813

Rewards:
190.8927
190.8927
190.8927
objective = 0.08584488928318024
==== episode 4600/10000 ====
action = 1
probs = 0.0011 0.9989 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031559274066239595 0.08397994190454483
encoder.encoder.weight_hh_l0: -0.0004228394536767155 0.08494414389133453
encoder.encoder.bias_ih_l0: 0.00660342862829566 0.08582410216331482
encoder.encoder.bias_hh_l0: 0.01660050079226494 0.08573279529809952
encoder.encoder.weight_ih_l0_reverse: 0.0015632326249033213 0.08588525652885437
encoder.encoder.weight_hh_l0_reverse: 0.002300301333889365 0.08409389108419418
encoder.encoder.bias_ih_l0_reverse: 0.022327637299895287 0.08516141027212143
encoder.encoder.bias_hh_l0_reverse: 0.014193085953593254 0.08305943757295609
decider.lstm.weight_ih_l0: -0.0003156063030473888 0.14704178273677826
decider.lstm.weight_hh_l0: -0.0014456752687692642 0.14608998596668243
decider.lstm.bias_ih_l0: 0.017753666266798973 0.15337708592414856
decider.lstm.bias_hh_l0: -0.0012338906526565552 0.14352020621299744
decider.linear1.weight: 0.0016475804150104523 0.12091639637947083
decider.linear1.bias: 0.015431275591254234 0.11642894893884659
decider.linear2.weight: 0.006178635638207197 0.05720258876681328
decider.linear2.bias: 0.006459677591919899 0.05892523005604744
decider.linear3.weight: -0.04490211606025696 0.10240981727838516
decider.linear3.bias: -0.034470684826374054 0.05918765068054199

Rewards:
190.8927
190.8927
190.8927
objective = 0.07291462272405624
==== episode 4700/10000 ====
action = 1
probs = 0.0010 0.9990 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031781187863089144 0.08400796353816986
encoder.encoder.weight_hh_l0: -0.0004304260073695332 0.08497674018144608
encoder.encoder.bias_ih_l0: 0.006710618734359741 0.08585269004106522
encoder.encoder.bias_hh_l0: 0.01670769229531288 0.08576567471027374
encoder.encoder.weight_ih_l0_reverse: 0.0015708219725638628 0.08590950816869736
encoder.encoder.weight_hh_l0_reverse: 0.0023132828064262867 0.08411513268947601
encoder.encoder.bias_ih_l0_reverse: 0.02239866741001606 0.08517728000879288
encoder.encoder.bias_hh_l0_reverse: 0.014264119789004326 0.08306869119405746
decider.lstm.weight_ih_l0: -0.0002991884248331189 0.1470760703086853
decider.lstm.weight_hh_l0: -0.0014555362286046147 0.1461191028356552
decider.lstm.bias_ih_l0: 0.01793266087770462 0.15340667963027954
decider.lstm.bias_hh_l0: -0.0010549011640250683 0.14357437193393707
decider.linear1.weight: 0.0016435146098956466 0.12094604223966599
decider.linear1.bias: 0.015570642426609993 0.11644004285335541
decider.linear2.weight: 0.006212306208908558 0.057219497859478
decider.linear2.bias: 0.006511280313134193 0.05895141139626503
decider.linear3.weight: -0.045007191598415375 0.10262452065944672
decider.linear3.bias: -0.03452376276254654 0.059392087161540985

Rewards:
190.8927
190.8927
190.8927
objective = 0.06272417306900024
==== episode 4800/10000 ====
action = 1
probs = 0.0024 0.9975 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030799576779827476 0.0838785469532013
encoder.encoder.weight_hh_l0: -0.00037870529922656715 0.08478864282369614
encoder.encoder.bias_ih_l0: 0.005999686662107706 0.08572383970022202
encoder.encoder.bias_hh_l0: 0.01599675975739956 0.08559231460094452
encoder.encoder.weight_ih_l0_reverse: 0.0015321458922699094 0.0858050212264061
encoder.encoder.weight_hh_l0_reverse: 0.002245700918138027 0.08403149992227554
encoder.encoder.bias_ih_l0_reverse: 0.02197166718542576 0.0850929394364357
encoder.encoder.bias_hh_l0_reverse: 0.013837117701768875 0.08301939070224762
decider.lstm.weight_ih_l0: -0.00038869655691087246 0.1469099074602127
decider.lstm.weight_hh_l0: -0.0013564068358391523 0.1459730714559555
decider.lstm.bias_ih_l0: 0.016893723979592323 0.15323035418987274
decider.lstm.bias_hh_l0: -0.0020938373636454344 0.14332830905914307
decider.linear1.weight: 0.0016941081266850233 0.12075653672218323
decider.linear1.bias: 0.01468895748257637 0.11637288331985474
decider.linear2.weight: 0.005959558300673962 0.05711062625050545
decider.linear2.bias: 0.006141426041722298 0.05879182741045952
decider.linear3.weight: -0.045321375131607056 0.10310407727956772
decider.linear3.bias: -0.03470538184046745 0.05843542143702507

Rewards:
190.8927
190.8927
190.8927
objective = 0.15610527992248535
==== episode 4900/10000 ====
action = 1
probs = 0.0019 0.9981 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.1352e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031203782418742776 0.08392800390720367
encoder.encoder.weight_hh_l0: -0.0003896584967151284 0.08483996242284775
encoder.encoder.bias_ih_l0: 0.006164900958538055 0.08578047156333923
encoder.encoder.bias_hh_l0: 0.016161974519491196 0.08564378321170807
encoder.encoder.weight_ih_l0_reverse: 0.0015466497279703617 0.08584816008806229
encoder.encoder.weight_hh_l0_reverse: 0.002268295967951417 0.08406738191843033
encoder.encoder.bias_ih_l0_reverse: 0.022081855684518814 0.08512203395366669
encoder.encoder.bias_hh_l0_reverse: 0.013947305269539356 0.08302952349185944
decider.lstm.weight_ih_l0: -0.0003592637076508254 0.1469726413488388
decider.lstm.weight_hh_l0: -0.001365013886243105 0.14602349698543549
decider.lstm.bias_ih_l0: 0.017203902825713158 0.15327993035316467
decider.lstm.bias_hh_l0: -0.0017836629413068295 0.14343443512916565
decider.linear1.weight: 0.0016914966981858015 0.12079969793558121
decider.linear1.bias: 0.014900920912623405 0.11638476699590683
decider.linear2.weight: 0.006003694608807564 0.05713186413049698
decider.linear2.bias: 0.006212197709828615 0.05882759764790535
decider.linear3.weight: -0.04561077430844307 0.10369019210338593
decider.linear3.bias: -0.03488143905997276 0.05883679911494255

Rewards:
190.8927
190.8927
190.8927
objective = 0.12412698566913605
==== episode 5000/10000 ====
action = 1
probs = 0.0019 0.9981 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031165318796411157 0.08392170071601868
encoder.encoder.weight_hh_l0: -0.0003853755770251155 0.08482640236616135
encoder.encoder.bias_ih_l0: 0.006109841167926788 0.08577419072389603
encoder.encoder.bias_hh_l0: 0.01610691100358963 0.08563420921564102
encoder.encoder.weight_ih_l0_reverse: 0.0015456342371180654 0.08584345132112503
encoder.encoder.weight_hh_l0_reverse: 0.0022644379641860723 0.08406472206115723
encoder.encoder.bias_ih_l0_reverse: 0.022054284811019897 0.08511383831501007
encoder.encoder.bias_hh_l0_reverse: 0.013919733464717865 0.08302484452724457
decider.lstm.weight_ih_l0: -0.0003645145916379988 0.14696520566940308
decider.lstm.weight_hh_l0: -0.001354425447061658 0.14601613581180573
decider.lstm.bias_ih_l0: 0.0171365849673748 0.15326754748821259
decider.lstm.bias_hh_l0: -0.001850977074354887 0.14342595636844635
decider.linear1.weight: 0.0016972038429230452 0.1207851991057396
decider.linear1.bias: 0.014836063608527184 0.11638089269399643
decider.linear2.weight: 0.00598167534917593 0.05712307617068291
decider.linear2.bias: 0.006180792115628719 0.058815304189920425
decider.linear3.weight: -0.04579663276672363 0.1040460541844368
decider.linear3.bias: -0.034994568675756454 0.05882420763373375

Rewards:
190.8927
190.8927
190.8927
objective = 0.12256136536598206
==== episode 5100/10000 ====
action = 1
probs = 0.0031 0.9969 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030729733407497406 0.08386854082345963
encoder.encoder.weight_hh_l0: -0.00036064573214389384 0.08474382758140564
encoder.encoder.bias_ih_l0: 0.005770696327090263 0.08572424203157425
encoder.encoder.bias_hh_l0: 0.015767766162753105 0.08556137979030609
encoder.encoder.weight_ih_l0_reverse: 0.0015305139822885394 0.08580180257558823
encoder.encoder.weight_hh_l0_reverse: 0.002234106883406639 0.08403468132019043
encoder.encoder.bias_ih_l0_reverse: 0.02186453342437744 0.08508048951625824
encoder.encoder.bias_hh_l0_reverse: 0.013729982078075409 0.08300692588090897
decider.lstm.weight_ih_l0: -0.00040664555854164064 0.14689867198467255
decider.lstm.weight_hh_l0: -0.001304966863244772 0.14595508575439453
decider.lstm.bias_ih_l0: 0.016668211668729782 0.15318770706653595
decider.lstm.bias_hh_l0: -0.0023193536326289177 0.14332857728004456
decider.linear1.weight: 0.001721309032291174 0.12069796025753021
decider.linear1.bias: 0.014417191036045551 0.11635158210992813
decider.linear2.weight: 0.005858321208506823 0.05707374960184097
decider.linear2.bias: 0.005999104119837284 0.058745309710502625
decider.linear3.weight: -0.0462459959089756 0.10488469153642654
decider.linear3.bias: -0.0353110209107399 0.05851291865110397

Rewards:
190.8927
190.8927
190.8927
objective = 0.1994173377752304
==== episode 5200/10000 ====
action = 1
probs = 0.0024 0.9976 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031135822064243257 0.08392277359962463
encoder.encoder.weight_hh_l0: -0.0003727229777723551 0.08480106294155121
encoder.encoder.bias_ih_l0: 0.005956784822046757 0.08578547090291977
encoder.encoder.bias_hh_l0: 0.015953855589032173 0.08561566472053528
encoder.encoder.weight_ih_l0_reverse: 0.0015449809143319726 0.08584962785243988
encoder.encoder.weight_hh_l0_reverse: 0.00225898833014071 0.08407177776098251
encoder.encoder.bias_ih_l0_reverse: 0.02198307402431965 0.08511846512556076
encoder.encoder.bias_hh_l0_reverse: 0.013848521746695042 0.0830182358622551
decider.lstm.weight_ih_l0: -0.00037390313809737563 0.1469653695821762
decider.lstm.weight_hh_l0: -0.0013142724055796862 0.14600922167301178
decider.lstm.bias_ih_l0: 0.017010509967803955 0.15324363112449646
decider.lstm.bias_hh_l0: -0.0019770492799580097 0.1434427797794342
decider.linear1.weight: 0.0017185405595228076 0.12074622511863708
decider.linear1.bias: 0.014656230807304382 0.11636294424533844
decider.linear2.weight: 0.005911053158342838 0.05709758773446083
decider.linear2.bias: 0.006084618158638477 0.05878550186753273
decider.linear3.weight: -0.04654078185558319 0.105506032705307
decider.linear3.bias: -0.035526979714632034 0.05898602306842804

Rewards:
190.8927
190.8927
190.8927
objective = 0.1543411761522293
==== episode 5300/10000 ====
action = 1
probs = 0.0019 0.9981 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031440198654308915 0.08396601676940918
encoder.encoder.weight_hh_l0: -0.00038341665640473366 0.08484926074743271
encoder.encoder.bias_ih_l0: 0.006119029596447945 0.08583080768585205
encoder.encoder.bias_hh_l0: 0.016116099432110786 0.0856606587767601
encoder.encoder.weight_ih_l0_reverse: 0.0015558659797534347 0.08588723093271255
encoder.encoder.weight_hh_l0_reverse: 0.0022787086199969053 0.08410032093524933
encoder.encoder.bias_ih_l0_reverse: 0.022081753239035606 0.0851479321718216
encoder.encoder.bias_hh_l0_reverse: 0.013947195373475552 0.08302859961986542
decider.lstm.weight_ih_l0: -0.00034724510624073446 0.14701665937900543
decider.lstm.weight_hh_l0: -0.0013259213883429766 0.14605215191841125
decider.lstm.bias_ih_l0: 0.017286881804466248 0.15328983962535858
decider.lstm.bias_hh_l0: -0.0017006807029247284 0.14352773129940033
decider.linear1.weight: 0.001714119454845786 0.12078908085823059
decider.linear1.bias: 0.014864247292280197 0.11637471616268158
decider.linear2.weight: 0.00596109963953495 0.057120081037282944
decider.linear2.bias: 0.006163797341287136 0.05882102996110916
decider.linear3.weight: -0.04672319442033768 0.10590185225009918
decider.linear3.bias: -0.035659387707710266 0.05934933200478554

Rewards:
190.8927
190.8927
190.8927
objective = 0.12380018085241318
==== episode 5400/10000 ====
action = 1
probs = 0.0016 0.9984 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 9.0438e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031678436789661646 0.08400172740221024
encoder.encoder.weight_hh_l0: -0.0003931288083549589 0.08489109575748444
encoder.encoder.bias_ih_l0: 0.00626327283680439 0.08586620539426804
encoder.encoder.bias_hh_l0: 0.016260342672467232 0.08569937944412231
encoder.encoder.weight_ih_l0_reverse: 0.0015644587110728025 0.0859178826212883
encoder.encoder.weight_hh_l0_reverse: 0.0022950354032218456 0.08412336558103561
encoder.encoder.bias_ih_l0_reverse: 0.02216709963977337 0.08517193049192429
encoder.encoder.bias_hh_l0_reverse: 0.014032547362148762 0.08303827047348022
decider.lstm.weight_ih_l0: -0.0003248759894631803 0.14705818891525269
decider.lstm.weight_hh_l0: -0.0013386995997279882 0.14608760178089142
decider.lstm.bias_ih_l0: 0.017520001158118248 0.1533292829990387
decider.lstm.bias_hh_l0: -0.0014675636775791645 0.14359445869922638
decider.linear1.weight: 0.0017085892613977194 0.12082786113023758
decider.linear1.bias: 0.015049138106405735 0.11638641357421875
decider.linear2.weight: 0.006008412688970566 0.05714128911495209
decider.linear2.bias: 0.006237057503312826 0.058853164315223694
decider.linear3.weight: -0.04684758931398392 0.10617920011281967
decider.linear3.bias: -0.03574817627668381 0.05964486300945282

Rewards:
190.8927
190.8927
190.8927
objective = 0.101835697889328
==== episode 5500/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031869657686911523 0.08403198421001434
encoder.encoder.weight_hh_l0: -0.00040210236329585314 0.0849282294511795
encoder.encoder.bias_ih_l0: 0.006393526680767536 0.0858948826789856
encoder.encoder.bias_hh_l0: 0.016390597447752953 0.08573353290557861
encoder.encoder.weight_ih_l0_reverse: 0.0015714990440756083 0.08594352006912231
encoder.encoder.weight_hh_l0_reverse: 0.002308973576873541 0.08414256572723389
encoder.encoder.bias_ih_l0_reverse: 0.022242913022637367 0.08519219607114792
encoder.encoder.bias_hh_l0_reverse: 0.014108359813690186 0.08304739743471146
decider.lstm.weight_ih_l0: -0.00030566647183150053 0.1470930427312851
decider.lstm.weight_hh_l0: -0.0013520680367946625 0.14611776173114777
decider.lstm.bias_ih_l0: 0.017722565680742264 0.15336377918720245
decider.lstm.bias_hh_l0: -0.0012649991549551487 0.14364883303642273
decider.linear1.weight: 0.0017022726824507117 0.12086344510316849
decider.linear1.bias: 0.015216093510389328 0.11639785021543503
decider.linear2.weight: 0.006053204648196697 0.057161349803209305
decider.linear2.bias: 0.006305096670985222 0.058882683515548706
decider.linear3.weight: -0.04693762958049774 0.10638526827096939
decider.linear3.bias: -0.03581126034259796 0.05989423394203186

Rewards:
190.8927
190.8927
190.8927
objective = 0.08536255359649658
==== episode 5600/10000 ====
action = 1
probs = 0.0011 0.9989 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032024038955569267 0.08405785262584686
encoder.encoder.weight_hh_l0: -0.00041041983058676124 0.0849614292383194
encoder.encoder.bias_ih_l0: 0.006511503364890814 0.08591851592063904
encoder.encoder.bias_hh_l0: 0.016508573666214943 0.08576392382383347
encoder.encoder.weight_ih_l0_reverse: 0.0015773891936987638 0.08596518635749817
encoder.encoder.weight_hh_l0_reverse: 0.0023210332728922367 0.08415879309177399
encoder.encoder.bias_ih_l0_reverse: 0.022310931235551834 0.08520954847335815
encoder.encoder.bias_hh_l0_reverse: 0.01417637336999178 0.0830560028553009
decider.lstm.weight_ih_l0: -0.0002890284522436559 0.14712278544902802
decider.lstm.weight_hh_l0: -0.00136562529951334 0.14614379405975342
decider.lstm.bias_ih_l0: 0.017900709062814713 0.15339423716068268
decider.lstm.bias_hh_l0: -0.0010868576355278492 0.1436939239501953
decider.linear1.weight: 0.0016954445745795965 0.12089613825082779
decider.linear1.bias: 0.015367258340120316 0.11640884727239609
decider.linear2.weight: 0.006095333490520716 0.057180218398571014
decider.linear2.bias: 0.006367992609739304 0.05890984088182449
decider.linear3.weight: -0.04700493812561035 0.10654336959123611
decider.linear3.bias: -0.03585759177803993 0.06010816991329193

Rewards:
190.8927
190.8927
190.8927
objective = 0.07272477447986603
==== episode 5700/10000 ====
action = 1
probs = 0.0010 0.9990 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032151310006156564 0.08408059179782867
encoder.encoder.weight_hh_l0: -0.00041828627581708133 0.08499182760715485
encoder.encoder.bias_ih_l0: 0.006620620843023062 0.08593864738941193
encoder.encoder.bias_hh_l0: 0.016617685556411743 0.08579164743423462
encoder.encoder.weight_ih_l0_reverse: 0.0015824990114197135 0.085984006524086
encoder.encoder.weight_hh_l0_reverse: 0.002331769559532404 0.08417292684316635
encoder.encoder.bias_ih_l0_reverse: 0.022373542189598083 0.08522488921880722
encoder.encoder.bias_hh_l0_reverse: 0.014238984324038029 0.0830642431974411
decider.lstm.weight_ih_l0: -0.0002742501092143357 0.1471489518880844
decider.lstm.weight_hh_l0: -0.0013793734833598137 0.1461668461561203
decider.lstm.bias_ih_l0: 0.018061665818095207 0.15342184901237488
decider.lstm.bias_hh_l0: -0.0009259006474167109 0.1437324732542038
decider.linear1.weight: 0.0016881730407476425 0.12092678993940353
decider.linear1.bias: 0.015506958588957787 0.11641949415206909
decider.linear2.weight: 0.006135519593954086 0.05719822272658348
decider.linear2.bias: 0.006427048705518246 0.05893530696630478
decider.linear3.weight: -0.04705740883946419 0.10666987299919128
decider.linear3.bias: -0.03589311242103577 0.06029728427529335

Rewards:
190.8927
190.8927
190.8927
objective = 0.06267102062702179
==== episode 5800/10000 ====
action = 1
probs = 0.0051 0.9949 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00030596950091421604 0.08382637798786163
encoder.encoder.weight_hh_l0: -0.0003240641672164202 0.0846463218331337
encoder.encoder.bias_ih_l0: 0.005299776792526245 0.08568075299263
encoder.encoder.bias_hh_l0: 0.015296842902898788 0.08547765016555786
encoder.encoder.weight_ih_l0_reverse: 0.0015155385481193662 0.0857747420668602
encoder.encoder.weight_hh_l0_reverse: 0.0021957186982035637 0.08401958644390106
encoder.encoder.bias_ih_l0_reverse: 0.021614372730255127 0.08504506945610046
encoder.encoder.bias_hh_l0_reverse: 0.01347981858998537 0.08298618346452713
decider.lstm.weight_ih_l0: -0.0004579434753395617 0.14683446288108826
decider.lstm.weight_hh_l0: -0.001209223410114646 0.14589659869670868
decider.lstm.bias_ih_l0: 0.016063664108514786 0.153082937002182
decider.lstm.bias_hh_l0: -0.002923914697021246 0.14324818551540375
decider.linear1.weight: 0.001776157645508647 0.12058285623788834
decider.linear1.bias: 0.013877788558602333 0.11632265150547028
decider.linear2.weight: 0.0056738536804914474 0.05700813606381416
decider.linear2.bias: 0.005745994858443737 0.058654531836509705
decider.linear3.weight: -0.04729927331209183 0.10696715116500854
decider.linear3.bias: -0.036084115505218506 0.05835554748773575

Rewards:
190.8927
190.8927
190.8927
objective = 0.32661426067352295
==== episode 5900/10000 ====
action = 1
probs = 0.0038 0.9962 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.9534e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003106893855147064 0.0838983803987503
encoder.encoder.weight_hh_l0: -0.00033665046794340014 0.08471663296222687
encoder.encoder.bias_ih_l0: 0.005516085308045149 0.08576636761426926
encoder.encoder.bias_hh_l0: 0.015513149090111256 0.08554234355688095
encoder.encoder.weight_ih_l0_reverse: 0.0015335700009018183 0.08583968132734299
encoder.encoder.weight_hh_l0_reverse: 0.0022280721459537745 0.08406925946474075
encoder.encoder.bias_ih_l0_reverse: 0.021758541464805603 0.08510607481002808
encoder.encoder.bias_hh_l0_reverse: 0.013623989187180996 0.08299911022186279
decider.lstm.weight_ih_l0: -0.0004173204069957137 0.14692217111587524
decider.lstm.weight_hh_l0: -0.0012113642878830433 0.1459653079509735
decider.lstm.bias_ih_l0: 0.016499435529112816 0.1531539410352707
decider.lstm.bias_hh_l0: -0.002488145139068365 0.14340609312057495
decider.linear1.weight: 0.0017769144615158439 0.12063589692115784
decider.linear1.bias: 0.014147299341857433 0.11632738262414932
decider.linear2.weight: 0.005734390579164028 0.057040728628635406
decider.linear2.bias: 0.005838578101247549 0.058702800422906876
decider.linear3.weight: -0.04785626381635666 0.10815560817718506
decider.linear3.bias: -0.036590203642845154 0.05910665541887283

Rewards:
190.8927
190.8927
190.8927
objective = 0.2431396096944809
==== episode 6000/10000 ====
action = 1
probs = 0.0029 0.9971 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031425035558640957 0.083957739174366
encoder.encoder.weight_hh_l0: -0.0003494751872494817 0.08477946370840073
encoder.encoder.bias_ih_l0: 0.0057254815474152565 0.08582989126443863
encoder.encoder.bias_hh_l0: 0.015722541138529778 0.08559945970773697
encoder.encoder.weight_ih_l0_reverse: 0.0015473427483811975 0.08589214831590652
encoder.encoder.weight_hh_l0_reverse: 0.0022552921436727047 0.08410719782114029
encoder.encoder.bias_ih_l0_reverse: 0.02188444323837757 0.08515197038650513
encoder.encoder.bias_hh_l0_reverse: 0.013749890960752964 0.08301080018281937
decider.lstm.weight_ih_l0: -0.0003812805807683617 0.14699053764343262
decider.lstm.weight_hh_l0: -0.0012224412057548761 0.14602167904376984
decider.lstm.bias_ih_l0: 0.01686740666627884 0.15321607887744904
decider.lstm.bias_hh_l0: -0.0021201632916927338 0.14352281391620636
decider.linear1.weight: 0.0017734616994857788 0.12068851292133331
decider.linear1.bias: 0.014408566057682037 0.11633754521608353
decider.linear2.weight: 0.005796939134597778 0.057067520916461945
decider.linear2.bias: 0.00593991857022047 0.05874783545732498
decider.linear3.weight: -0.04814206063747406 0.1087818592786789
decider.linear3.bias: -0.036852799355983734 0.0596507266163826

Rewards:
190.8927
190.8927
190.8927
objective = 0.18427681922912598
==== episode 6100/10000 ====
action = 1
probs = 0.0023 0.9977 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031685063731856644 0.08400356769561768
encoder.encoder.weight_hh_l0: -0.0003609617124311626 0.08483105897903442
encoder.encoder.bias_ih_l0: 0.005904078483581543 0.08587565273046494
encoder.encoder.bias_hh_l0: 0.01590113528072834 0.08564619719982147
encoder.encoder.weight_ih_l0_reverse: 0.0015573216369375587 0.08593205362558365
encoder.encoder.weight_hh_l0_reverse: 0.0022766422480344772 0.08413529396057129
encoder.encoder.bias_ih_l0_reverse: 0.021986598148941994 0.08518562465906143
encoder.encoder.bias_hh_l0_reverse: 0.013852044939994812 0.0830211192369461
decider.lstm.weight_ih_l0: -0.00035247913911007345 0.1470419019460678
decider.lstm.weight_hh_l0: -0.001236234325915575 0.14606519043445587
decider.lstm.bias_ih_l0: 0.017159298062324524 0.15326598286628723
decider.lstm.bias_hh_l0: -0.0018282674718648195 0.14360696077346802
decider.linear1.weight: 0.001767980633303523 0.12073457986116409
decider.linear1.bias: 0.014632678590714931 0.11634881049394608
decider.linear2.weight: 0.0058549540117383 0.05709230527281761
decider.linear2.bias: 0.0060311974957585335 0.058786436915397644
decider.linear3.weight: -0.0483124703168869 0.10916543006896973
decider.linear3.bias: -0.03700624778866768 0.06005195528268814

Rewards:
190.8927
190.8927
190.8927
objective = 0.1458825021982193
==== episode 6200/10000 ====
action = 1
probs = 0.0019 0.9981 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00031886249780654907 0.0840408056974411
encoder.encoder.weight_hh_l0: -0.0003715760540217161 0.08487540483474731
encoder.encoder.bias_ih_l0: 0.006061586085706949 0.08591095358133316
encoder.encoder.bias_hh_l0: 0.01605864427983761 0.08568630367517471
encoder.encoder.weight_ih_l0_reverse: 0.0015650519635528326 0.08596405386924744
encoder.encoder.weight_hh_l0_reverse: 0.0022943327203392982 0.08415752649307251
encoder.encoder.bias_ih_l0_reverse: 0.022074222564697266 0.08521213382482529
encoder.encoder.bias_hh_l0_reverse: 0.01393966842442751 0.08303069323301315
decider.lstm.weight_ih_l0: -0.0003284644626546651 0.14708322286605835
decider.lstm.weight_hh_l0: -0.0012513725087046623 0.14610075950622559
decider.lstm.bias_ih_l0: 0.017404738813638687 0.15330815315246582
decider.lstm.bias_hh_l0: -0.0015828297473490238 0.1436721235513687
decider.linear1.weight: 0.0017611393705010414 0.12077616155147552
decider.linear1.bias: 0.014831304550170898 0.1163603886961937
decider.linear2.weight: 0.005909208208322525 0.05711551010608673
decider.linear2.bias: 0.006114439573138952 0.0588209331035614
decider.linear3.weight: -0.048426106572151184 0.10942823439836502
decider.linear3.bias: -0.037106242030858994 0.06037196144461632

Rewards:
190.8927
190.8927
190.8927
objective = 0.11877667158842087
==== episode 6300/10000 ====
action = 1
probs = 0.0015 0.9984 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032046122942119837 0.08407191187143326
encoder.encoder.weight_hh_l0: -0.0003815260133706033 0.08491446077823639
encoder.encoder.bias_ih_l0: 0.006202902644872665 0.08593922108411789
encoder.encoder.bias_hh_l0: 0.01619996316730976 0.08572158962488174
encoder.encoder.weight_ih_l0_reverse: 0.0015713026514276862 0.08599042147397995
encoder.encoder.weight_hh_l0_reverse: 0.002309437608346343 0.08417575806379318
encoder.encoder.bias_ih_l0_reverse: 0.022151652723550797 0.0852338969707489
encoder.encoder.bias_hh_l0_reverse: 0.01401710044592619 0.0830397829413414
decider.lstm.weight_ih_l0: -0.00030796407372690737 0.1471177637577057
decider.lstm.weight_hh_l0: -0.0012672217562794685 0.14613077044487
decider.lstm.bias_ih_l0: 0.017617622390389442 0.1533447653055191
decider.lstm.bias_hh_l0: -0.00136994244530797 0.14372462034225464
decider.linear1.weight: 0.0017533416394144297 0.1208142563700676
decider.linear1.bias: 0.015010176226496696 0.11637189239263535
decider.linear2.weight: 0.005960102658718824 0.05713731795549393
decider.linear2.bias: 0.00619080476462841 0.05885233357548714
decider.linear3.weight: -0.04850666970014572 0.10961981862783432
decider.linear3.bias: -0.037175558507442474 0.06063804402947426

Rewards:
190.8927
190.8927
190.8927
objective = 0.09872838109731674
==== episode 6400/10000 ====
action = 1
probs = 0.0013 0.9987 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.8638e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032175309024751186 0.08409847319126129
encoder.encoder.weight_hh_l0: -0.0003909579536411911 0.08494950085878372
encoder.encoder.bias_ih_l0: 0.006331430748105049 0.08596248924732208
encoder.encoder.bias_hh_l0: 0.016328491270542145 0.08575322479009628
encoder.encoder.weight_ih_l0_reverse: 0.0015765383141115308 0.08601262420415878
encoder.encoder.weight_hh_l0_reverse: 0.002322623273357749 0.08419108390808105
encoder.encoder.bias_ih_l0_reverse: 0.02222156524658203 0.0852523073554039
encoder.encoder.bias_hh_l0_reverse: 0.014087009243667126 0.083048515021801
decider.lstm.weight_ih_l0: -0.00029014283791184425 0.14714738726615906
decider.lstm.weight_hh_l0: -0.0012834749650210142 0.14615674316883087
decider.lstm.bias_ih_l0: 0.01780642196536064 0.1533772051334381
decider.lstm.bias_hh_l0: -0.0011811424046754837 0.14376811683177948
decider.linear1.weight: 0.0017448391299694777 0.12084952741861343
decider.linear1.bias: 0.015173270367085934 0.1163831427693367
decider.linear2.weight: 0.006008060649037361 0.05715791881084442
decider.linear2.bias: 0.0062613352201879025 0.05888129398226738
decider.linear3.weight: -0.0485662966966629 0.10976577550172806
decider.linear3.bias: -0.03722579777240753 0.06086580827832222

Rewards:
190.8927
190.8927
190.8927
objective = 0.08339153975248337
==== episode 6500/10000 ====
action = 1
probs = 0.0011 0.9989 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032281281892210245 0.08412151038646698
encoder.encoder.weight_hh_l0: -0.0003999815380666405 0.08498138934373856
encoder.encoder.bias_ih_l0: 0.006449620705097914 0.08598203957080841
encoder.encoder.bias_hh_l0: 0.016446683555841446 0.0857819989323616
encoder.encoder.weight_ih_l0_reverse: 0.0015810590703040361 0.08603159338235855
encoder.encoder.weight_hh_l0_reverse: 0.002334334421902895 0.08420424908399582
encoder.encoder.bias_ih_l0_reverse: 0.02228572964668274 0.08526825159788132
encoder.encoder.bias_hh_l0_reverse: 0.014151177369058132 0.0830569639801979
decider.lstm.weight_ih_l0: -0.00027443142607808113 0.14717334508895874
decider.lstm.weight_hh_l0: -0.0012999726459383965 0.14617960155010223
decider.lstm.bias_ih_l0: 0.01797669194638729 0.15340647101402283
decider.lstm.bias_hh_l0: -0.0010108754504472017 0.14380495250225067
decider.linear1.weight: 0.0017357990145683289 0.12088251113891602
decider.linear1.bias: 0.01532346848398447 0.11639408022165298
decider.linear2.weight: 0.00605346355587244 0.057177476584911346
decider.linear2.bias: 0.006326896138489246 0.05890825390815735
decider.linear3.weight: -0.04861185699701309 0.10988074541091919
decider.linear3.bias: -0.03726344555616379 0.06106498837471008

Rewards:
190.8927
190.8927
190.8927
objective = 0.07133886218070984
==== episode 6600/10000 ====
action = 1
probs = 0.0010 0.9990 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003236837510485202 0.08414158225059509
encoder.encoder.weight_hh_l0: -0.00040859842556528747 0.08501046150922775
encoder.encoder.bias_ih_l0: 0.006558256223797798 0.08599858731031418
encoder.encoder.bias_hh_l0: 0.016555320471525192 0.08580821752548218
encoder.encoder.weight_ih_l0_reverse: 0.0015850290656089783 0.08604790270328522
encoder.encoder.weight_hh_l0_reverse: 0.0023447819985449314 0.08421559631824493
encoder.encoder.bias_ih_l0_reverse: 0.02234482206404209 0.08528218418359756
encoder.encoder.bias_hh_l0_reverse: 0.01421026885509491 0.08306511491537094
decider.lstm.weight_ih_l0: -0.0002605566114652902 0.14719624817371368
decider.lstm.weight_hh_l0: -0.0013164696283638477 0.14619985222816467
decider.lstm.bias_ih_l0: 0.018130799755454063 0.1534329503774643
decider.lstm.bias_hh_l0: -0.0008567629847675562 0.1438363492488861
decider.linear1.weight: 0.0017264302587136626 0.12091327458620071
decider.linear1.bias: 0.015461592003703117 0.11640457063913345
decider.linear2.weight: 0.006096219643950462 0.05719594657421112
decider.linear2.bias: 0.006387605797499418 0.05893330276012421
decider.linear3.weight: -0.04864722490310669 0.10997287184000015
decider.linear3.bias: -0.03729214891791344 0.06124037504196167

Rewards:
190.8927
190.8927
190.8927
objective = 0.06175228953361511
==== episode 6700/10000 ====
action = 1
probs = 0.0008 0.9992 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003244154795538634 0.08415946364402771
encoder.encoder.weight_hh_l0: -0.00041696958942338824 0.08503751456737518
encoder.encoder.bias_ih_l0: 0.006659954786300659 0.08601290732622147
encoder.encoder.bias_hh_l0: 0.016657015308737755 0.08583259582519531
encoder.encoder.weight_ih_l0_reverse: 0.0015886357286944985 0.08606220781803131
encoder.encoder.weight_hh_l0_reverse: 0.002354311989620328 0.08422563225030899
encoder.encoder.bias_ih_l0_reverse: 0.02240040712058544 0.08529464900493622
encoder.encoder.bias_hh_l0_reverse: 0.01426585204899311 0.08307306468486786
decider.lstm.weight_ih_l0: -0.0002480640832800418 0.14721696078777313
decider.lstm.weight_hh_l0: -0.0013330872170627117 0.1462182104587555
decider.lstm.bias_ih_l0: 0.018273260444402695 0.1534574180841446
decider.lstm.bias_hh_l0: -0.0007142992690205574 0.1438637524843216
decider.linear1.weight: 0.001716717379167676 0.12094246596097946
decider.linear1.bias: 0.015590847469866276 0.11641473323106766
decider.linear2.weight: 0.0061370739713311195 0.05721363425254822
decider.linear2.bias: 0.006444719620049 0.05895695835351944
decider.linear3.weight: -0.04867555946111679 0.11004917323589325
decider.linear3.bias: -0.0373147577047348 0.061398524791002274

Rewards:
190.8927
190.8927
190.8927
objective = 0.053894273936748505
==== episode 6800/10000 ====
action = 1
probs = 0.0007 0.9993 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003250390291213989 0.08417553454637527
encoder.encoder.weight_hh_l0: -0.00042514837696217 0.08506287634372711
encoder.encoder.bias_ih_l0: 0.006755761802196503 0.0860254317522049
encoder.encoder.bias_hh_l0: 0.016752824187278748 0.08585541695356369
encoder.encoder.weight_ih_l0_reverse: 0.001591977197676897 0.08607486635446548
encoder.encoder.weight_hh_l0_reverse: 0.0023630887735635042 0.0842345654964447
encoder.encoder.bias_ih_l0_reverse: 0.02245314046740532 0.08530595153570175
encoder.encoder.bias_hh_l0_reverse: 0.014318586327135563 0.08308087289333344
decider.lstm.weight_ih_l0: -0.00023674072872381657 0.14723588526248932
decider.lstm.weight_hh_l0: -0.0013498044572770596 0.14623501896858215
decider.lstm.bias_ih_l0: 0.018406063318252563 0.15348026156425476
decider.lstm.bias_hh_l0: -0.0005814940668642521 0.1438879370689392
decider.linear1.weight: 0.0017067184671759605 0.12097028642892838
decider.linear1.bias: 0.01571248285472393 0.1164245679974556
decider.linear2.weight: 0.006176247261464596 0.057230643928050995
decider.linear2.bias: 0.006498692091554403 0.05897941440343857
decider.linear3.weight: -0.04869861900806427 0.1101134791970253
decider.linear3.bias: -0.03733287751674652 0.06154259294271469

Rewards:
190.8927
190.8927
190.8927
objective = 0.047377027571201324
==== episode 6900/10000 ====
action = 1
probs = 0.0007 0.9993 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.7752e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032557526719756424 0.08419009298086166
encoder.encoder.weight_hh_l0: -0.0004331817617639899 0.08508681505918503
encoder.encoder.bias_ih_l0: 0.006846521981060505 0.08603647351264954
encoder.encoder.bias_hh_l0: 0.016843585297465324 0.08587691932916641
encoder.encoder.weight_ih_l0_reverse: 0.001595127279870212 0.08608616888523102
encoder.encoder.weight_hh_l0_reverse: 0.002371239708736539 0.08424260467290878
encoder.encoder.bias_ih_l0_reverse: 0.022503534331917763 0.08531627804040909
encoder.encoder.bias_hh_l0_reverse: 0.014368978329002857 0.08308853209018707
decider.lstm.weight_ih_l0: -0.00022642371186520904 0.1472533494234085
decider.lstm.weight_hh_l0: -0.0013666111044585705 0.14625053107738495
decider.lstm.bias_ih_l0: 0.01853073388338089 0.1535017192363739
decider.lstm.bias_hh_l0: -0.00045682559721171856 0.14390946924686432
decider.linear1.weight: 0.001696474151685834 0.12099692970514297
decider.linear1.bias: 0.015827493742108345 0.11643409729003906
decider.linear2.weight: 0.00621392484754324 0.057247038930654526
decider.linear2.bias: 0.00654989667236805 0.05900082364678383
decider.linear3.weight: -0.04871764034032822 0.11016850918531418
decider.linear3.bias: -0.03734758496284485 0.06167495995759964

Rewards:
190.8927
190.8927
190.8927
objective = 0.041896529495716095
==== episode 7000/10000 ====
action = 1
probs = 0.0006 0.9994 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032591744093224406 0.0842035636305809
encoder.encoder.weight_hh_l0: -0.0004412043490447104 0.08510999381542206
encoder.encoder.bias_ih_l0: 0.006932567339390516 0.08604761213064194
encoder.encoder.bias_hh_l0: 0.0169296283274889 0.08589621633291245
encoder.encoder.weight_ih_l0_reverse: 0.0015988796949386597 0.08609689772129059
encoder.encoder.weight_hh_l0_reverse: 0.002379161072894931 0.08425053209066391
encoder.encoder.bias_ih_l0_reverse: 0.02255450189113617 0.08532574772834778
encoder.encoder.bias_hh_l0_reverse: 0.014419949613511562 0.08309682458639145
decider.lstm.weight_ih_l0: -0.0002169550716644153 0.14726975560188293
decider.lstm.weight_hh_l0: -0.0013835947029292583 0.14626489579677582
decider.lstm.bias_ih_l0: 0.018649088218808174 0.15352100133895874
decider.lstm.bias_hh_l0: -0.0003384763840585947 0.14392931759357452
decider.linear1.weight: 0.0016859136521816254 0.12102242559194565
decider.linear1.bias: 0.015939727425575256 0.1164444088935852
decider.linear2.weight: 0.006250297650694847 0.05726289376616478
decider.linear2.bias: 0.006598630920052528 0.05902129411697388
decider.linear3.weight: -0.048733487725257874 0.1102161705493927
decider.linear3.bias: -0.03735967352986336 0.061797402799129486

Rewards:
190.8927
190.8927
190.8927
objective = 0.037209637463092804
==== episode 7100/10000 ====
action = 1
probs = 0.0005 0.9995 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032618484692648053 0.08421584963798523
encoder.encoder.weight_hh_l0: -0.00044910929864272475 0.08513198047876358
encoder.encoder.bias_ih_l0: 0.007013953290879726 0.08605773746967316
encoder.encoder.bias_hh_l0: 0.017011014744639397 0.08591409772634506
encoder.encoder.weight_ih_l0_reverse: 0.0016026741359382868 0.08610663563013077
encoder.encoder.weight_hh_l0_reverse: 0.002386646345257759 0.0842578262090683
encoder.encoder.bias_ih_l0_reverse: 0.022603964433073997 0.08533435314893723
encoder.encoder.bias_hh_l0_reverse: 0.014469415880739689 0.08310501277446747
decider.lstm.weight_ih_l0: -0.0002083171420963481 0.14728499948978424
decider.lstm.weight_hh_l0: -0.001400517881847918 0.14627820253372192
decider.lstm.bias_ih_l0: 0.018760399892926216 0.15353888273239136
decider.lstm.bias_hh_l0: -0.00022716261446475983 0.14394721388816833
decider.linear1.weight: 0.0016752472147345543 0.12104674428701401
decider.linear1.bias: 0.01604633592069149 0.1164545789361
decider.linear2.weight: 0.006285238079726696 0.057278092950582504
decider.linear2.bias: 0.006644676439464092 0.05904074013233185
decider.linear3.weight: -0.048746682703495026 0.11025748401880264
decider.linear3.bias: -0.03736959770321846 0.061910178512334824

Rewards:
190.8927
190.8927
190.8927
objective = 0.03322889655828476
==== episode 7200/10000 ====
action = 1
probs = 0.0005 0.9995 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003264294355176389 0.08422717452049255
encoder.encoder.weight_hh_l0: -0.00045698502799496055 0.08515305072069168
encoder.encoder.bias_ih_l0: 0.007092131767421961 0.08606675267219543
encoder.encoder.bias_hh_l0: 0.01708919182419777 0.08593114465475082
encoder.encoder.weight_ih_l0_reverse: 0.0016063754446804523 0.08611547946929932
encoder.encoder.weight_hh_l0_reverse: 0.002393764443695545 0.08426450192928314
encoder.encoder.bias_ih_l0_reverse: 0.02265203185379505 0.08534233272075653
encoder.encoder.bias_hh_l0_reverse: 0.014517487026751041 0.08311300724744797
decider.lstm.weight_ih_l0: -0.0002003439440159127 0.14729942381381989
decider.lstm.weight_hh_l0: -0.0014175237156450748 0.14629073441028595
decider.lstm.bias_ih_l0: 0.018866509199142456 0.1535559445619583
decider.lstm.bias_hh_l0: -0.00012105284258723259 0.14396345615386963
decider.linear1.weight: 0.0016644143033772707 0.12107027322053909
decider.linear1.bias: 0.01614820957183838 0.11646442115306854
decider.linear2.weight: 0.006319230422377586 0.05729286000132561
decider.linear2.bias: 0.0066887685097754 0.059059444814920425
decider.linear3.weight: -0.048757877200841904 0.11029405891895294
decider.linear3.bias: -0.03737790882587433 0.06201572343707085

Rewards:
190.8927
190.8927
190.8927
objective = 0.029794808477163315
==== episode 7300/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003266583080403507 0.08423767238855362
encoder.encoder.weight_hh_l0: -0.0004648567992262542 0.08517330139875412
encoder.encoder.bias_ih_l0: 0.007167472038418055 0.08607478439807892
encoder.encoder.bias_hh_l0: 0.01716453582048416 0.0859474167227745
encoder.encoder.weight_ih_l0_reverse: 0.0016100156353786588 0.08612355589866638
encoder.encoder.weight_hh_l0_reverse: 0.002400572644546628 0.08427064120769501
encoder.encoder.bias_ih_l0_reverse: 0.02269895002245903 0.08534977585077286
encoder.encoder.bias_hh_l0_reverse: 0.01456440333276987 0.08312081545591354
decider.lstm.weight_ih_l0: -0.0001929775025928393 0.14731308817863464
decider.lstm.weight_hh_l0: -0.0014346191892400384 0.14630261063575745
decider.lstm.bias_ih_l0: 0.01896803081035614 0.15357232093811035
decider.lstm.bias_hh_l0: -1.952843740582466e-05 0.14397823810577393
decider.linear1.weight: 0.0016534270253032446 0.12109310179948807
decider.linear1.bias: 0.01624583825469017 0.1164739727973938
decider.linear2.weight: 0.006352359429001808 0.05730724334716797
decider.linear2.bias: 0.006731096655130386 0.059077490121126175
decider.linear3.weight: -0.04876744747161865 0.11032672226428986
decider.linear3.bias: -0.03738493472337723 0.06211494654417038

Rewards:
190.8927
190.8927
190.8927
objective = 0.026812423020601273
==== episode 7400/10000 ====
action = 1
probs = 0.0004 0.9996 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6875e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032687775092199445 0.08424744755029678
encoder.encoder.weight_hh_l0: -0.0004727488267235458 0.08519285917282104
encoder.encoder.bias_ih_l0: 0.007240304723381996 0.08608193695545197
encoder.encoder.bias_hh_l0: 0.017237363383173943 0.08596296608448029
encoder.encoder.weight_ih_l0_reverse: 0.001613619620911777 0.08613096177577972
encoder.encoder.weight_hh_l0_reverse: 0.0024071200750768185 0.08427632600069046
encoder.encoder.bias_ih_l0_reverse: 0.02274492383003235 0.08535671979188919
encoder.encoder.bias_hh_l0_reverse: 0.014610378071665764 0.08312845975160599
decider.lstm.weight_ih_l0: -0.00018617020396050066 0.14732614159584045
decider.lstm.weight_hh_l0: -0.0014518111711367965 0.1463138908147812
decider.lstm.bias_ih_l0: 0.0190654918551445 0.15358808636665344
decider.lstm.bias_hh_l0: 7.793447002768517e-05 0.14399173855781555
decider.linear1.weight: 0.001642297487705946 0.1211152970790863
decider.linear1.bias: 0.01633964478969574 0.11648324877023697
decider.linear2.weight: 0.0063846963457763195 0.05732126906514168
decider.linear2.bias: 0.006771819666028023 0.05909493565559387
decider.linear3.weight: -0.04877568408846855 0.1103561520576477
decider.linear3.bias: -0.03739089518785477 0.062208592891693115

Rewards:
190.8927
190.8927
190.8927
objective = 0.024202002212405205
==== episode 7500/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003270948363933712 0.08425658196210861
encoder.encoder.weight_hh_l0: -0.0004806849465239793 0.08521179109811783
encoder.encoder.bias_ih_l0: 0.007310896180570126 0.08608828485012054
encoder.encoder.bias_hh_l0: 0.017307957634329796 0.08597782254219055
encoder.encoder.weight_ih_l0_reverse: 0.0016172061441466212 0.08613777160644531
encoder.encoder.weight_hh_l0_reverse: 0.0024134486448019743 0.08428162336349487
encoder.encoder.bias_ih_l0_reverse: 0.022790130227804184 0.0853632390499115
encoder.encoder.bias_hh_l0_reverse: 0.01465558260679245 0.0831359252333641
decider.lstm.weight_ih_l0: -0.00017988569743465632 0.1473386138677597
decider.lstm.weight_hh_l0: -0.0014690982643514872 0.14632464945316315
decider.lstm.bias_ih_l0: 0.019159330055117607 0.15360334515571594
decider.lstm.bias_hh_l0: 0.000171770341694355 0.14400415122509003
decider.linear1.weight: 0.0016310319770127535 0.12113691866397858
decider.linear1.bias: 0.01642998494207859 0.11649226397275925
decider.linear2.weight: 0.006416305899620056 0.05733497813344002
decider.linear2.bias: 0.006811076775193214 0.05911184102296829
decider.linear3.weight: -0.04878281056880951 0.11038282513618469
decider.linear3.bias: -0.03739600256085396 0.06229729577898979

Rewards:
190.8927
190.8927
190.8927
objective = 0.021902795881032944
==== episode 7600/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032731107785366476 0.0842650905251503
encoder.encoder.weight_hh_l0: -0.0004886075621470809 0.0852300226688385
encoder.encoder.bias_ih_l0: 0.007378832437098026 0.08609383553266525
encoder.encoder.bias_hh_l0: 0.017375895753502846 0.08599187433719635
encoder.encoder.weight_ih_l0_reverse: 0.0016207584412768483 0.08614401519298553
encoder.encoder.weight_hh_l0_reverse: 0.002419535769149661 0.08428652584552765
encoder.encoder.bias_ih_l0_reverse: 0.022834286093711853 0.08536931872367859
encoder.encoder.bias_hh_l0_reverse: 0.014699740335345268 0.08314315974712372
decider.lstm.weight_ih_l0: -0.00017414642206858844 0.14735053479671478
decider.lstm.weight_hh_l0: -0.0014863185351714492 0.14633487164974213
decider.lstm.bias_ih_l0: 0.019249029457569122 0.1536179780960083
decider.lstm.bias_hh_l0: 0.0002614744007587433 0.14401541650295258
decider.linear1.weight: 0.0016197500517591834 0.12115781009197235
decider.linear1.bias: 0.016516320407390594 0.11650097370147705
decider.linear2.weight: 0.0064469436183571815 0.05734826251864433
decider.linear2.bias: 0.006848623044788837 0.05912809073925018
decider.linear3.weight: -0.048788949847221375 0.11040696501731873
decider.linear3.bias: -0.03740035369992256 0.06238074600696564

Rewards:
190.8927
190.8927
190.8927
objective = 0.019892007112503052
==== episode 7700/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032753325649537146 0.08427310734987259
encoder.encoder.weight_hh_l0: -0.0004966180422343314 0.08524779230356216
encoder.encoder.bias_ih_l0: 0.007445062045007944 0.08609869331121445
encoder.encoder.bias_hh_l0: 0.0174421276897192 0.08600528538227081
encoder.encoder.weight_ih_l0_reverse: 0.0016243256395682693 0.08614982664585114
encoder.encoder.weight_hh_l0_reverse: 0.0024254785384982824 0.08429115265607834
encoder.encoder.bias_ih_l0_reverse: 0.022877978160977364 0.08537504076957703
encoder.encoder.bias_hh_l0_reverse: 0.014743437059223652 0.08315026015043259
decider.lstm.weight_ih_l0: -0.0001688593765720725 0.14736202359199524
decider.lstm.weight_hh_l0: -0.001503652660176158 0.14634469151496887
decider.lstm.bias_ih_l0: 0.019335893914103508 0.15363220870494843
decider.lstm.bias_hh_l0: 0.0003483286127448082 0.14402583241462708
decider.linear1.weight: 0.0016083416994661093 0.12117825448513031
decider.linear1.bias: 0.016599850729107857 0.11650945991277695
decider.linear2.weight: 0.00647698575630784 0.05736130103468895
decider.linear2.bias: 0.006884973030537367 0.05914388969540596
decider.linear3.weight: -0.04879432171583176 0.11042916029691696
decider.linear3.bias: -0.0374041311442852 0.06246032938361168

Rewards:
190.8927
190.8927
190.8927
objective = 0.01810511387884617
==== episode 7800/10000 ====
action = 1
probs = 0.0003 0.9997 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032776399166323245 0.08428070694208145
encoder.encoder.weight_hh_l0: -0.0005047367885708809 0.08526516705751419
encoder.encoder.bias_ih_l0: 0.007509766612201929 0.08610288798809052
encoder.encoder.bias_hh_l0: 0.017506832256913185 0.08601803332567215
encoder.encoder.weight_ih_l0_reverse: 0.0016279190313071012 0.0861552432179451
encoder.encoder.weight_hh_l0_reverse: 0.0024313037283718586 0.08429552614688873
encoder.encoder.bias_ih_l0_reverse: 0.022921327501535416 0.08538045734167099
encoder.encoder.bias_hh_l0_reverse: 0.01478678546845913 0.08315720409154892
decider.lstm.weight_ih_l0: -0.00016400677850469947 0.14737318456172943
decider.lstm.weight_hh_l0: -0.001521107624284923 0.14635415375232697
decider.lstm.bias_ih_l0: 0.019420146942138672 0.1536460965871811
decider.lstm.bias_hh_l0: 0.00043259328231215477 0.1440354585647583
decider.linear1.weight: 0.0015968106454238296 0.12119825929403305
decider.linear1.bias: 0.016680803149938583 0.11651775240898132
decider.linear2.weight: 0.006506450939923525 0.05737410485744476
decider.linear2.bias: 0.006920190993696451 0.05915931984782219
decider.linear3.weight: -0.04879903420805931 0.11044970154762268
decider.linear3.bias: -0.03740740939974785 0.06253639608621597

Rewards:
190.8927
190.8927
190.8927
objective = 0.01651174947619438
==== episode 7900/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.6006e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032800555345602334 0.08428792655467987
encoder.encoder.weight_hh_l0: -0.0005129813216626644 0.08528219908475876
encoder.encoder.bias_ih_l0: 0.00757312448695302 0.08610643446445465
encoder.encoder.bias_hh_l0: 0.017570191994309425 0.08603013306856155
encoder.encoder.weight_ih_l0_reverse: 0.0016315472312271595 0.0861603319644928
encoder.encoder.weight_hh_l0_reverse: 0.002437037182971835 0.08429969847202301
encoder.encoder.bias_ih_l0_reverse: 0.02296442538499832 0.08538558334112167
encoder.encoder.bias_hh_l0_reverse: 0.014829878695309162 0.08316399902105331
decider.lstm.weight_ih_l0: -0.00015957214054651558 0.14738404750823975
decider.lstm.weight_hh_l0: -0.0015386820305138826 0.1463632881641388
decider.lstm.bias_ih_l0: 0.019502054899930954 0.1536596715450287
decider.lstm.bias_hh_l0: 0.0005144858732819557 0.14404433965682983
decider.linear1.weight: 0.0015851602656766772 0.12121789902448654
decider.linear1.bias: 0.016759363934397697 0.11652586609125137
decider.linear2.weight: 0.006535332649946213 0.05738672986626625
decider.linear2.bias: 0.0069543058052659035 0.05917448550462723
decider.linear3.weight: -0.04880319535732269 0.1104687750339508
decider.linear3.bias: -0.037410274147987366 0.0626092329621315

Rewards:
190.8927
190.8927
190.8927
objective = 0.015085341408848763
==== episode 8000/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032826061942614615 0.08429481834173203
encoder.encoder.weight_hh_l0: -0.0005213735275901854 0.08529891818761826
encoder.encoder.bias_ih_l0: 0.007635296322405338 0.08610931783914566
encoder.encoder.bias_hh_l0: 0.017632368952035904 0.08604151755571365
encoder.encoder.weight_ih_l0_reverse: 0.001635223743505776 0.08616511523723602
encoder.encoder.weight_hh_l0_reverse: 0.002442703116685152 0.08430366963148117
encoder.encoder.bias_ih_l0_reverse: 0.023007353767752647 0.08539041876792908
encoder.encoder.bias_hh_l0_reverse: 0.014872810803353786 0.08317065238952637
decider.lstm.weight_ih_l0: -0.00015554310812149197 0.14739464223384857
decider.lstm.weight_hh_l0: -0.00155638309661299 0.14637215435504913
decider.lstm.bias_ih_l0: 0.019581764936447144 0.15367291867733002
decider.lstm.bias_hh_l0: 0.0005942080169916153 0.14405256509780884
decider.linear1.weight: 0.0015733921900391579 0.12123717367649078
decider.linear1.bias: 0.016835717484354973 0.1165338084101677
decider.linear2.weight: 0.006563754286617041 0.05739915743470192
decider.linear2.bias: 0.006987488828599453 0.059189293533563614
decider.linear3.weight: -0.04880686104297638 0.11048656702041626
decider.linear3.bias: -0.037412770092487335 0.06267911195755005

Rewards:
190.8927
190.8927
190.8927
objective = 0.013803118839859962
==== episode 8100/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032851091236807406 0.08430137485265732
encoder.encoder.weight_hh_l0: -0.0005298659671097994 0.0853152647614479
encoder.encoder.bias_ih_l0: 0.007696084678173065 0.08611137419939041
encoder.encoder.bias_hh_l0: 0.017693160101771355 0.0860520601272583
encoder.encoder.weight_ih_l0_reverse: 0.0016389619559049606 0.08616964519023895
encoder.encoder.weight_hh_l0_reverse: 0.002448278246447444 0.08430743217468262
encoder.encoder.bias_ih_l0_reverse: 0.023049911484122276 0.0853949636220932
encoder.encoder.bias_hh_l0_reverse: 0.014915362000465393 0.08317704498767853
decider.lstm.weight_ih_l0: -0.00015194440493360162 0.14740495383739471
decider.lstm.weight_hh_l0: -0.0015740386443212628 0.14638066291809082
decider.lstm.bias_ih_l0: 0.01965869404375553 0.15368564426898956
decider.lstm.bias_hh_l0: 0.0006711466703563929 0.14406026899814606
decider.linear1.weight: 0.0015615744050592184 0.12125594168901443
decider.linear1.bias: 0.016909627243876457 0.11654169112443924
decider.linear2.weight: 0.006591891869902611 0.05741129070520401
decider.linear2.bias: 0.007019960321485996 0.059203654527664185
decider.linear3.weight: -0.04881008714437485 0.11050307750701904
decider.linear3.bias: -0.037414923310279846 0.06274563074111938

Rewards:
190.8927
190.8927
190.8927
objective = 0.012657485902309418
==== episode 8200/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032880090293474495 0.08430778980255127
encoder.encoder.weight_hh_l0: -0.0005385892582125962 0.08533148467540741
encoder.encoder.bias_ih_l0: 0.007756502833217382 0.0861126258969307
encoder.encoder.bias_hh_l0: 0.01775357872247696 0.0860617458820343
encoder.encoder.weight_ih_l0_reverse: 0.0016430544201284647 0.08617425709962845
encoder.encoder.weight_hh_l0_reverse: 0.0024539190344512463 0.08431126177310944
encoder.encoder.bias_ih_l0_reverse: 0.02309294231235981 0.0853990763425827
encoder.encoder.bias_hh_l0_reverse: 0.014958392828702927 0.08318324387073517
decider.lstm.weight_ih_l0: -0.00014871571329422295 0.14741510152816772
decider.lstm.weight_hh_l0: -0.0015918915160000324 0.1463889479637146
decider.lstm.bias_ih_l0: 0.019734079018235207 0.15369802713394165
decider.lstm.bias_hh_l0: 0.0007465416565537453 0.1440674215555191
decider.linear1.weight: 0.0015494584804400802 0.12127476930618286
decider.linear1.bias: 0.01698298379778862 0.11655037105083466
decider.linear2.weight: 0.00661992933601141 0.05742323026061058
decider.linear2.bias: 0.007051950320601463 0.059218134731054306
decider.linear3.weight: -0.04881296306848526 0.11051864922046661
decider.linear3.bias: -0.037416838109493256 0.06280975043773651

Rewards:
190.8927
190.8927
190.8927
objective = 0.011625676415860653
==== episode 8300/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032911403104662895 0.08431403338909149
encoder.encoder.weight_hh_l0: -0.0005475583020597696 0.08534757792949677
encoder.encoder.bias_ih_l0: 0.007816435769200325 0.0861130878329277
encoder.encoder.bias_hh_l0: 0.017813507467508316 0.08607051521539688
encoder.encoder.weight_ih_l0_reverse: 0.0016473151044920087 0.08617877960205078
encoder.encoder.weight_hh_l0_reverse: 0.0024595847353339195 0.08431503176689148
encoder.encoder.bias_ih_l0_reverse: 0.023136219009757042 0.08540289103984833
encoder.encoder.bias_hh_l0_reverse: 0.015001663938164711 0.08318930864334106
decider.lstm.weight_ih_l0: -0.0001458787446608767 0.14742511510849
decider.lstm.weight_hh_l0: -0.0016099141212180257 0.14639703929424286
decider.lstm.bias_ih_l0: 0.01980789564549923 0.15371014177799225
decider.lstm.bias_hh_l0: 0.0008203429169952869 0.14407403767108917
decider.linear1.weight: 0.0015371395274996758 0.12129347026348114
decider.linear1.bias: 0.01705513894557953 0.11655927449464798
decider.linear2.weight: 0.006647732574492693 0.05743500590324402
decider.linear2.bias: 0.007083314936608076 0.05923248827457428
decider.linear3.weight: -0.0488155223429203 0.11053334176540375
decider.linear3.bias: -0.03741854429244995 0.06287163496017456

Rewards:
190.8927
190.8927
190.8927
objective = 0.010696303099393845
==== episode 8400/10000 ====
action = 1
probs = 0.0002 0.9998 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.5146e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00032943725818768144 0.08432009816169739
encoder.encoder.weight_hh_l0: -0.0005567781045101583 0.08536351472139359
encoder.encoder.bias_ih_l0: 0.007875789888203144 0.08611273765563965
encoder.encoder.bias_hh_l0: 0.01787285879254341 0.08607830852270126
encoder.encoder.weight_ih_l0_reverse: 0.0016516119940206409 0.0861831083893776
encoder.encoder.weight_hh_l0_reverse: 0.0024652464780956507 0.08431867510080338
encoder.encoder.bias_ih_l0_reverse: 0.023179642856121063 0.08540650457143784
encoder.encoder.bias_hh_l0_reverse: 0.015045086853206158 0.08319520205259323
decider.lstm.weight_ih_l0: -0.00014343680231831968 0.1474350243806839
decider.lstm.weight_hh_l0: -0.0016281051794067025 0.1464049220085144
decider.lstm.bias_ih_l0: 0.019880227744579315 0.1537221223115921
decider.lstm.bias_hh_l0: 0.0008926657028496265 0.1440802365541458
decider.linear1.weight: 0.0015246893744915724 0.12131195515394211
decider.linear1.bias: 0.01712583191692829 0.11656767129898071
decider.linear2.weight: 0.0066754259169101715 0.05744663253426552
decider.linear2.bias: 0.007113935425877571 0.05924653634428978
decider.linear3.weight: -0.048817817121744156 0.11054727435112
decider.linear3.bias: -0.03742004185914993 0.06293143332004547

Rewards:
190.8927
190.8927
190.8927
objective = 0.009846600703895092
==== episode 8500/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003297715447843075 0.08432585000991821
encoder.encoder.weight_hh_l0: -0.0005661495961248875 0.08537887036800385
encoder.encoder.bias_ih_l0: 0.007934329099953175 0.08611112087965012
encoder.encoder.bias_hh_l0: 0.01793139986693859 0.08608528226613998
encoder.encoder.weight_ih_l0_reverse: 0.001655450090765953 0.08618668466806412
encoder.encoder.weight_hh_l0_reverse: 0.002470673294737935 0.08432120829820633
encoder.encoder.bias_ih_l0_reverse: 0.023223664611577988 0.08541026711463928
encoder.encoder.bias_hh_l0_reverse: 0.015089111402630806 0.08320029824972153
decider.lstm.weight_ih_l0: -0.0001413358113495633 0.14744488894939423
decider.lstm.weight_hh_l0: -0.0016466182423755527 0.14641273021697998
decider.lstm.bias_ih_l0: 0.01995181478559971 0.1537342369556427
decider.lstm.bias_hh_l0: 0.0009642345830798149 0.14408645033836365
decider.linear1.weight: 0.0015115623828023672 0.12133146822452545
decider.linear1.bias: 0.01720130629837513 0.11656779050827026
decider.linear2.weight: 0.006705868057906628 0.057459570467472076
decider.linear2.bias: 0.007143906783312559 0.05926038697361946
decider.linear3.weight: -0.04881983995437622 0.11056046932935715
decider.linear3.bias: -0.03742135688662529 0.0629892349243164

Rewards:
190.8927
190.8927
190.8927
objective = 0.009053809568285942
==== episode 8600/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033010568586178124 0.08433136343955994
encoder.encoder.weight_hh_l0: -0.0005756401806138456 0.08539382368326187
encoder.encoder.bias_ih_l0: 0.007991514168679714 0.08610885590314865
encoder.encoder.bias_hh_l0: 0.017988581210374832 0.08609122037887573
encoder.encoder.weight_ih_l0_reverse: 0.0016590091399848461 0.08618984371423721
encoder.encoder.weight_hh_l0_reverse: 0.0024759573861956596 0.08432340621948242
encoder.encoder.bias_ih_l0_reverse: 0.02326708659529686 0.08541397005319595
encoder.encoder.bias_hh_l0_reverse: 0.015132535248994827 0.08320480585098267
decider.lstm.weight_ih_l0: -0.00013965136895421892 0.14745455980300903
decider.lstm.weight_hh_l0: -0.0016651242040097713 0.14642034471035004
decider.lstm.bias_ih_l0: 0.0200213436037302 0.15374644100666046
decider.lstm.bias_hh_l0: 0.0010337531566619873 0.14409233629703522
decider.linear1.weight: 0.0014982661232352257 0.12135080993175507
decider.linear1.bias: 0.01727590709924698 0.11656563729047775
decider.linear2.weight: 0.006735015660524368 0.057473570108413696
decider.linear2.bias: 0.007172870449721813 0.059273816645145416
decider.linear3.weight: -0.048821642994880676 0.1105729192495346
decider.linear3.bias: -0.03742256015539169 0.06304458528757095

Rewards:
190.8927
190.8927
190.8927
objective = 0.00833689235150814
==== episode 8700/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003305494610685855 0.08433681726455688
encoder.encoder.weight_hh_l0: -0.0005853397306054831 0.08540864288806915
encoder.encoder.bias_ih_l0: 0.008047457784414291 0.08610616624355316
encoder.encoder.bias_hh_l0: 0.018044540658593178 0.08609610050916672
encoder.encoder.weight_ih_l0_reverse: 0.0016626300057396293 0.08619306981563568
encoder.encoder.weight_hh_l0_reverse: 0.0024812589399516582 0.08432584255933762
encoder.encoder.bias_ih_l0_reverse: 0.023309916257858276 0.08541762083768845
encoder.encoder.bias_hh_l0_reverse: 0.015175365842878819 0.08320911228656769
decider.lstm.weight_ih_l0: -0.00013837053847964853 0.14746415615081787
decider.lstm.weight_hh_l0: -0.0016838592709973454 0.14642773568630219
decider.lstm.bias_ih_l0: 0.020089881494641304 0.1537587195634842
decider.lstm.bias_hh_l0: 0.0011023213155567646 0.1440977305173874
decider.linear1.weight: 0.0014842653181403875 0.12137050181627274
decider.linear1.bias: 0.017353104427456856 0.11656185239553452
decider.linear2.weight: 0.006766628008335829 0.057495422661304474
decider.linear2.bias: 0.007201171014457941 0.059286925941705704
decider.linear3.weight: -0.04882325977087021 0.1105847880244255
decider.linear3.bias: -0.037423525005578995 0.06309802085161209

Rewards:
190.8927
190.8927
190.8927
objective = 0.0076730865985155106
==== episode 8800/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003310771135147661 0.08434238284826279
encoder.encoder.weight_hh_l0: -0.0005953714135102928 0.08542358875274658
encoder.encoder.bias_ih_l0: 0.008103427477180958 0.08610261976718903
encoder.encoder.bias_hh_l0: 0.018100501969456673 0.08609947562217712
encoder.encoder.weight_ih_l0_reverse: 0.001666707918047905 0.08619678020477295
encoder.encoder.weight_hh_l0_reverse: 0.002486712299287319 0.08432869613170624
encoder.encoder.bias_ih_l0_reverse: 0.023352932184934616 0.0854208841919899
encoder.encoder.bias_hh_l0_reverse: 0.015218378975987434 0.08321332931518555
decider.lstm.weight_ih_l0: -0.0001374982384731993 0.1474737823009491
decider.lstm.weight_hh_l0: -0.0017028669826686382 0.14643502235412598
decider.lstm.bias_ih_l0: 0.020157571882009506 0.15377075970172882
decider.lstm.bias_hh_l0: 0.0011699842289090157 0.14410293102264404
decider.linear1.weight: 0.0014694867422804236 0.12139058113098145
decider.linear1.bias: 0.017432402819395065 0.11655775457620621
decider.linear2.weight: 0.006798245012760162 0.05751775950193405
decider.linear2.bias: 0.007229161448776722 0.059299368411302567
decider.linear3.weight: -0.04882470518350601 0.11059611290693283
decider.linear3.bias: -0.037424422800540924 0.06314975768327713

Rewards:
190.8927
190.8927
190.8927
objective = 0.007066184654831886
==== episode 8900/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.4294e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003315924550406635 0.0843479111790657
encoder.encoder.weight_hh_l0: -0.0006057349964976311 0.08543851226568222
encoder.encoder.bias_ih_l0: 0.008159225806593895 0.08609803020954132
encoder.encoder.bias_hh_l0: 0.018156304955482483 0.08610131591558456
encoder.encoder.weight_ih_l0_reverse: 0.0016708049224689603 0.08620037883520126
encoder.encoder.weight_hh_l0_reverse: 0.002492198720574379 0.08433154970407486
encoder.encoder.bias_ih_l0_reverse: 0.023396024480462074 0.08542408794164658
encoder.encoder.bias_hh_l0_reverse: 0.015261467546224594 0.08321738988161087
decider.lstm.weight_ih_l0: -0.00013706633762922138 0.14748337864875793
decider.lstm.weight_hh_l0: -0.0017220508307218552 0.14644214510917664
decider.lstm.bias_ih_l0: 0.02022402361035347 0.15378275513648987
decider.lstm.bias_hh_l0: 0.0012364299036562443 0.14410778880119324
decider.linear1.weight: 0.0014545228332281113 0.12141059339046478
decider.linear1.bias: 0.01751047559082508 0.11655323952436447
decider.linear2.weight: 0.006829589139670134 0.05753957852721214
decider.linear2.bias: 0.0072564478032290936 0.05931156501173973
decider.linear3.weight: -0.048825979232788086 0.11060690879821777
decider.linear3.bias: -0.03742526099085808 0.06319986283779144

Rewards:
190.8927
190.8927
190.8927
objective = 0.006508599501103163
==== episode 9000/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033208532840944827 0.08435345441102982
encoder.encoder.weight_hh_l0: -0.0006164626101963222 0.08545345813035965
encoder.encoder.bias_ih_l0: 0.008215055800974369 0.08609223365783691
encoder.encoder.bias_hh_l0: 0.01821213774383068 0.08610143512487411
encoder.encoder.weight_ih_l0_reverse: 0.001674945349805057 0.08620390295982361
encoder.encoder.weight_hh_l0_reverse: 0.0024977352004498243 0.08433441817760468
encoder.encoder.bias_ih_l0_reverse: 0.023439224809408188 0.08542721718549728
encoder.encoder.bias_hh_l0_reverse: 0.015304669737815857 0.08322127908468246
decider.lstm.weight_ih_l0: -0.00013708042388316244 0.14749297499656677
decider.lstm.weight_hh_l0: -0.0017413990572094917 0.14644911885261536
decider.lstm.bias_ih_l0: 0.020289286971092224 0.15379470586776733
decider.lstm.bias_hh_l0: 0.0013017002493143082 0.1441122442483902
decider.linear1.weight: 0.001439366489648819 0.12143054604530334
decider.linear1.bias: 0.017587414011359215 0.11654842644929886
decider.linear2.weight: 0.006860952824354172 0.057561103254556656
decider.linear2.bias: 0.007283072918653488 0.0593235045671463
decider.linear3.weight: -0.04882711172103882 0.11061722785234451
decider.linear3.bias: -0.03742600604891777 0.06324835866689682

Rewards:
190.8927
190.8927
190.8927
objective = 0.006000327877700329
==== episode 9100/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.000332538562361151 0.08435899019241333
encoder.encoder.weight_hh_l0: -0.0006274731131270528 0.08546830713748932
encoder.encoder.bias_ih_l0: 0.00827048160135746 0.08608522266149521
encoder.encoder.bias_hh_l0: 0.018267564475536346 0.08609966933727264
encoder.encoder.weight_ih_l0_reverse: 0.0016790721565485 0.0862073302268982
encoder.encoder.weight_hh_l0_reverse: 0.002503263996914029 0.08433728665113449
encoder.encoder.bias_ih_l0_reverse: 0.023482048884034157 0.08543024957180023
encoder.encoder.bias_hh_l0_reverse: 0.015347491949796677 0.08322494477033615
decider.lstm.weight_ih_l0: -0.0001375458377879113 0.14750251173973083
decider.lstm.weight_hh_l0: -0.0017607250483706594 0.14645588397979736
decider.lstm.bias_ih_l0: 0.020352810621261597 0.15380653738975525
decider.lstm.bias_hh_l0: 0.0013652066700160503 0.1441163420677185
decider.linear1.weight: 0.0014241491444408894 0.12145029008388519
decider.linear1.bias: 0.017662692815065384 0.11654355376958847
decider.linear2.weight: 0.006892136298120022 0.057582225650548935
decider.linear2.bias: 0.007308790925890207 0.059335071593523026
decider.linear3.weight: -0.0488281175494194 0.11062701791524887
decider.linear3.bias: -0.03742657229304314 0.06329475343227386

Rewards:
190.8927
190.8927
190.8927
objective = 0.00552999135106802
==== episode 9200/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003329422324895859 0.08436454832553864
encoder.encoder.weight_hh_l0: -0.0006388810579665005 0.08548322319984436
encoder.encoder.bias_ih_l0: 0.008325943723320961 0.08607697486877441
encoder.encoder.bias_hh_l0: 0.018323028460144997 0.08609592914581299
encoder.encoder.weight_ih_l0_reverse: 0.0016831529792398214 0.08621060848236084
encoder.encoder.weight_hh_l0_reverse: 0.0025087841786444187 0.0843401625752449
encoder.encoder.bias_ih_l0_reverse: 0.023524465039372444 0.08543326705694199
encoder.encoder.bias_hh_l0_reverse: 0.015389899723231792 0.08322852849960327
decider.lstm.weight_ih_l0: -0.0001384727074764669 0.14751209318637848
decider.lstm.weight_hh_l0: -0.0017802545335143805 0.14646252989768982
decider.lstm.bias_ih_l0: 0.02041536010801792 0.15381856262683868
decider.lstm.bias_hh_l0: 0.0014277496375143528 0.1441200226545334
decider.linear1.weight: 0.0014085217844694853 0.1214701309800148
decider.linear1.bias: 0.017738735303282738 0.1165395975112915
decider.linear2.weight: 0.006923379842191935 0.05760327726602554
decider.linear2.bias: 0.0073337131179869175 0.05934623256325722
decider.linear3.weight: -0.04882900416851044 0.110636405646801
decider.linear3.bias: -0.03742707520723343 0.0633397325873375

Rewards:
190.8927
190.8927
190.8927
objective = 0.005097587592899799
==== episode 9300/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003332804189994931 0.08437023311853409
encoder.encoder.weight_hh_l0: -0.0006507484358735383 0.08549830317497253
encoder.encoder.bias_ih_l0: 0.008381980471313 0.08606711775064468
encoder.encoder.bias_hh_l0: 0.01837906427681446 0.08608981221914291
encoder.encoder.weight_ih_l0_reverse: 0.0016872783889994025 0.0862138643860817
encoder.encoder.weight_hh_l0_reverse: 0.002514367690309882 0.0843430757522583
encoder.encoder.bias_ih_l0_reverse: 0.02356697991490364 0.08543621003627777
encoder.encoder.bias_hh_l0_reverse: 0.01543241273611784 0.08323192596435547
decider.lstm.weight_ih_l0: -0.00013987366401124746 0.1475217193365097
decider.lstm.weight_hh_l0: -0.0017999329138547182 0.14646905660629272
decider.lstm.bias_ih_l0: 0.020476873964071274 0.15383057296276093
decider.lstm.bias_hh_l0: 0.0014892448671162128 0.144123375415802
decider.linear1.weight: 0.0013927229447290301 0.12148997187614441
decider.linear1.bias: 0.017813632264733315 0.11653541773557663
decider.linear2.weight: 0.006954830605536699 0.057624317705631256
decider.linear2.bias: 0.007357886992394924 0.05935695022344589
decider.linear3.weight: -0.048829782754182816 0.11064539849758148
decider.linear3.bias: -0.03742753714323044 0.0633833259344101

Rewards:
190.8927
190.8927
190.8927
objective = 0.004699323792010546
==== episode 9400/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.3451e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033353481558151543 0.08437608927488327
encoder.encoder.weight_hh_l0: -0.0006631192518398166 0.085513636469841
encoder.encoder.bias_ih_l0: 0.008438795804977417 0.08605547994375229
encoder.encoder.bias_hh_l0: 0.018435882404446602 0.08608103543519974
encoder.encoder.weight_ih_l0_reverse: 0.0016914441948756576 0.08621709793806076
encoder.encoder.weight_hh_l0_reverse: 0.0025200163945555687 0.08434604108333588
encoder.encoder.bias_ih_l0_reverse: 0.02360956184566021 0.085439033806324
encoder.encoder.bias_hh_l0_reverse: 0.01547499280422926 0.08323511481285095
decider.lstm.weight_ih_l0: -0.0001417726743966341 0.1475314348936081
decider.lstm.weight_hh_l0: -0.001819763914681971 0.1464754343032837
decider.lstm.bias_ih_l0: 0.020537300035357475 0.1538424789905548
decider.lstm.bias_hh_l0: 0.00154969934374094 0.1441265344619751
decider.linear1.weight: 0.0013767591444775462 0.12150982022285461
decider.linear1.bias: 0.017887400463223457 0.11653103679418564
decider.linear2.weight: 0.006986646447330713 0.05764535441994667
decider.linear2.bias: 0.007381448522210121 0.05936741456389427
decider.linear3.weight: -0.04883047938346863 0.1106540635228157
decider.linear3.bias: -0.03742801025509834 0.06342558562755585

Rewards:
190.8927
190.8927
190.8927
objective = 0.004331406205892563
==== episode 9500/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033367937430739403 0.08438215404748917
encoder.encoder.weight_hh_l0: -0.0006760440883226693 0.08552930504083633
encoder.encoder.bias_ih_l0: 0.008496641181409359 0.0860418751835823
encoder.encoder.bias_hh_l0: 0.01849372312426567 0.0860692486166954
encoder.encoder.weight_ih_l0_reverse: 0.001695644692517817 0.08622031658887863
encoder.encoder.weight_hh_l0_reverse: 0.0025257293600589037 0.08434905111789703
encoder.encoder.bias_ih_l0_reverse: 0.023652171716094017 0.08544176816940308
encoder.encoder.bias_hh_l0_reverse: 0.01551759708672762 0.08323809504508972
decider.lstm.weight_ih_l0: -0.00014418899081647396 0.14754125475883484
decider.lstm.weight_hh_l0: -0.0018397296080365777 0.1464817225933075
decider.lstm.bias_ih_l0: 0.020596692338585854 0.15385441482067108
decider.lstm.bias_hh_l0: 0.0016090767458081245 0.14412930607795715
decider.linear1.weight: 0.0013606345746666193 0.12152967602014542
decider.linear1.bias: 0.017960071563720703 0.11652646213769913
decider.linear2.weight: 0.007018833886831999 0.057666439563035965
decider.linear2.bias: 0.007404418662190437 0.05937764048576355
decider.linear3.weight: -0.04883112013339996 0.11066244542598724
decider.linear3.bias: -0.03742840141057968 0.06346651166677475

Rewards:
190.8927
190.8927
190.8927
objective = 0.003990041092038155
==== episode 9600/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003336820809636265 0.08438843488693237
encoder.encoder.weight_hh_l0: -0.0006894344696775079 0.08554524928331375
encoder.encoder.bias_ih_l0: 0.008555197156965733 0.0860261544585228
encoder.encoder.bias_hh_l0: 0.018552273511886597 0.0860542580485344
encoder.encoder.weight_ih_l0_reverse: 0.0016998297069221735 0.08622348308563232
encoder.encoder.weight_hh_l0_reverse: 0.002531445352360606 0.0843520388007164
encoder.encoder.bias_ih_l0_reverse: 0.023694386705756187 0.08544443547725677
encoder.encoder.bias_hh_l0_reverse: 0.015559813939034939 0.08324086666107178
decider.lstm.weight_ih_l0: -0.0001471211144234985 0.14755111932754517
decider.lstm.weight_hh_l0: -0.001859649084508419 0.14648781716823578
decider.lstm.bias_ih_l0: 0.020654547959566116 0.15386618673801422
decider.lstm.bias_hh_l0: 0.001666918396949768 0.1441318243741989
decider.linear1.weight: 0.0013444226933643222 0.12154944986104965
decider.linear1.bias: 0.018031679093837738 0.11652277410030365
decider.linear2.weight: 0.007051457650959492 0.05768806114792824
decider.linear2.bias: 0.007426541298627853 0.059387464076280594
decider.linear3.weight: -0.04883168637752533 0.11067043244838715
decider.linear3.bias: -0.03742877393960953 0.06350576877593994

Rewards:
190.8927
190.8927
190.8927
objective = 0.0036790212616324425
==== episode 9700/10000 ====
action = 1
probs = 0.0001 0.9999 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033349700970575213 0.08439496159553528
encoder.encoder.weight_hh_l0: -0.0007034264272078872 0.08556162565946579
encoder.encoder.bias_ih_l0: 0.008615158498287201 0.08600781857967377
encoder.encoder.bias_hh_l0: 0.01861223205924034 0.08603572845458984
encoder.encoder.weight_ih_l0_reverse: 0.0017039756057783961 0.08622650057077408
encoder.encoder.weight_hh_l0_reverse: 0.002537194872274995 0.08435490727424622
encoder.encoder.bias_ih_l0_reverse: 0.02373671531677246 0.08544734120368958
encoder.encoder.bias_hh_l0_reverse: 0.01560213789343834 0.08324363827705383
decider.lstm.weight_ih_l0: -0.0001506212865933776 0.1475611925125122
decider.lstm.weight_hh_l0: -0.001879816292785108 0.1464938223361969
decider.lstm.bias_ih_l0: 0.0207117460668087 0.15387815237045288
decider.lstm.bias_hh_l0: 0.0017241276800632477 0.14413410425186157
decider.linear1.weight: 0.0013276461977511644 0.12156955897808075
decider.linear1.bias: 0.01810537464916706 0.11652334779500961
decider.linear2.weight: 0.007087020203471184 0.05771315470337868
decider.linear2.bias: 0.007448080461472273 0.059396956115961075
decider.linear3.weight: -0.04883217811584473 0.11067812889814377
decider.linear3.bias: -0.03742915764451027 0.06354380398988724

Rewards:
190.8927
190.8927
190.8927
objective = 0.0033831745386123657
==== episode 9800/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.0003330995386932045 0.08440189063549042
encoder.encoder.weight_hh_l0: -0.0007181477849371731 0.0855787992477417
encoder.encoder.bias_ih_l0: 0.008677035570144653 0.0859869047999382
encoder.encoder.bias_hh_l0: 0.018674103543162346 0.08601311594247818
encoder.encoder.weight_ih_l0_reverse: 0.0017081302357837558 0.08622951060533524
encoder.encoder.weight_hh_l0_reverse: 0.0025429956149309874 0.08435782045125961
encoder.encoder.bias_ih_l0_reverse: 0.02377890981733799 0.0854501873254776
encoder.encoder.bias_hh_l0_reverse: 0.015644337981939316 0.08324617892503738
decider.lstm.weight_ih_l0: -0.00015473482199013233 0.14757142961025238
decider.lstm.weight_hh_l0: -0.001900104689411819 0.14649969339370728
decider.lstm.bias_ih_l0: 0.02076798863708973 0.15389011800289154
decider.lstm.bias_hh_l0: 0.0017803609371185303 0.1441362053155899
decider.linear1.weight: 0.001310652820393443 0.12158982455730438
decider.linear1.bias: 0.018178442493081093 0.11652444303035736
decider.linear2.weight: 0.007122368551790714 0.05773871764540672
decider.linear2.bias: 0.007469031028449535 0.05940619111061096
decider.linear3.weight: -0.04883260279893875 0.11068551987409592
decider.linear3.bias: -0.037429504096508026 0.06358055025339127

Rewards:
190.8927
190.8927
190.8927
objective = 0.0031138795893639326
==== episode 9900/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.2617e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033244548831135035 0.08440929651260376
encoder.encoder.weight_hh_l0: -0.0007336934795603156 0.08559708297252655
encoder.encoder.bias_ih_l0: 0.008741241879761219 0.08596323430538177
encoder.encoder.bias_hh_l0: 0.018738318234682083 0.08598604798316956
encoder.encoder.weight_ih_l0_reverse: 0.0017122788121923804 0.0862325131893158
encoder.encoder.weight_hh_l0_reverse: 0.0025488329119980335 0.0843607485294342
encoder.encoder.bias_ih_l0_reverse: 0.023820871487259865 0.08545297384262085
encoder.encoder.bias_hh_l0_reverse: 0.015686295926570892 0.08324848115444183
decider.lstm.weight_ih_l0: -0.0001595024368725717 0.14758192002773285
decider.lstm.weight_hh_l0: -0.0019204993732273579 0.1465054750442505
decider.lstm.bias_ih_l0: 0.020823176950216293 0.15390203893184662
decider.lstm.bias_hh_l0: 0.0018355846405029297 0.14413802325725555
decider.linear1.weight: 0.001293429173529148 0.12161028385162354
decider.linear1.bias: 0.01825089566409588 0.11652594804763794
decider.linear2.weight: 0.007157995365560055 0.05776460841298103
decider.linear2.bias: 0.007489435374736786 0.059415191411972046
decider.linear3.weight: -0.048832967877388 0.11069262772798538
decider.linear3.bias: -0.037429630756378174 0.06361591070890427

Rewards:
190.8927
190.8927
190.8927
objective = 0.002859757049009204
==== episode 10000/10000 ====
action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

action = 1
probs = 0.0000 1.0000 0.0000 0.0000

Learning rate: 8.1791e-05
Weights:
encoder.embedder.weight: -0.00207973038777709 0.9450823068618774
encoder.encoder.weight_ih_l0: -0.00033147490466944873 0.08441729843616486
encoder.encoder.weight_hh_l0: -0.0007501651416532695 0.08561684936285019
encoder.encoder.bias_ih_l0: 0.00880820769816637 0.08593671023845673
encoder.encoder.bias_hh_l0: 0.018805285915732384 0.08595413714647293
encoder.encoder.weight_ih_l0_reverse: 0.0017164228484034538 0.08623551577329636
encoder.encoder.weight_hh_l0_reverse: 0.002554703736677766 0.08436372131109238
encoder.encoder.bias_ih_l0_reverse: 0.023862505331635475 0.08545563369989395
encoder.encoder.bias_hh_l0_reverse: 0.015727931633591652 0.08325053751468658
decider.lstm.weight_ih_l0: -0.00016497750766575336 0.1475926637649536
decider.lstm.weight_hh_l0: -0.0019409683300182223 0.14651113748550415
decider.lstm.bias_ih_l0: 0.020877324044704437 0.1539139598608017
decider.lstm.bias_hh_l0: 0.0018897377885878086 0.1441396176815033
decider.linear1.weight: 0.0012760590761899948 0.12163084745407104
decider.linear1.bias: 0.018322354182600975 0.1165277287364006
decider.linear2.weight: 0.007193908095359802 0.05779082328081131
decider.linear2.bias: 0.007509232498705387 0.059423934668302536
decider.linear3.weight: -0.04883328825235367 0.11069948971271515
decider.linear3.bias: -0.037429723888635635 0.06365003436803818

Rewards:
190.8927
190.8927
190.8927
objective = 0.002624599728733301
[INFO] : learning runtime (h:mm:ss): 0:02:29
[INFO] : learning end time: 12/17/2023 12:23:56 PM
